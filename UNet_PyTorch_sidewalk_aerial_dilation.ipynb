{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic segmentation of aerial images with deep networks\n",
    "\n",
    "This notebook presents a straightforward PyTorch implementation of a Fully Convolutional Network for semantic segmentation of aerial images. More specifically, we aim to automatically perform scene interpretation of images taken from a plane or a satellite by classifying every pixel into several land cover classes.\n",
    "\n",
    "As a demonstration, we are going to use the [SegNet architecture](http://mi.eng.cam.ac.uk/projects/segnet/) to segment aerial images over the cities of Vaihingen and Potsdam. The images are from the [ISPRS 2D Semantic Labeling dataset](http://www2.isprs.org/commissions/comm3/wg4/results.html). We will train a network to segment roads, buildings, vegetation and cars.\n",
    "\n",
    "This work is a PyTorch implementation of the baseline presented in [\"Beyond RGB: Very High Resolution Urban Remote Sensing With Multimodal Deep Networks \"](https://hal.archives-ouvertes.fr/hal-01636145), *Nicolas Audebert*, *Bertrand Le Saux* and *Sébastien Lefèvre*, ISPRS Journal, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "This notebook requires a few useful libraries, e.g. `torch`, `scikit-image`, `numpy` and `matplotlib`. You can install everything using `pip install -r requirements.txt`.\n",
    "\n",
    "This is expected to run on GPU, and therefore you should use `torch` in combination with CUDA/cuDNN. This can probably be made to run on CPU but be warned that:\n",
    "  * you have to remove all calls to `torch.Tensor.cuda()` throughout this notebook,\n",
    "  * this will be very slow.\n",
    "  \n",
    "A \"small\" GPU should be enough, e.g. this runs fine on a 4.7GB Tesla K20m. It uses quite a lot of RAM as the dataset is stored in-memory (about 5GB for Vaihingen). You can spare some memory by disabling the caching below. 4GB should be more than enough without caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ! \n",
      "Memory usage: 56.3\n"
     ]
    }
   ],
   "source": [
    "# imports and stuff\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler\n",
    "import torch.nn.init\n",
    "from torch.autograd import Variable\n",
    "import psutil\n",
    "import timeit\n",
    "\n",
    "print('Start ! ')\n",
    "print (\"Memory usage: \" + str(psutil.virtual_memory().percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "There are several parameters than can be tuned to use this notebook with different datasets. The default parameters are suitable for the ISPRS dataset, but you can change them to work with your data.\n",
    "\n",
    "### Examples\n",
    "\n",
    "  * Binary classification: `N_CLASSES = 2`\n",
    "  * Multi-spectral data (e.g. IRRGB): `IN_CHANNELS = 4`\n",
    "  * New folder naming convention : `DATA_FOLDER = MAIN_FOLDER + 'sentinel2/sentinel2_img_{}.tif'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Background', 'Sidewalk']\n",
      "WEIGHTS\n",
      "tensor([1., 5.])\n",
      "N_CLASSES\n",
      "2\n",
      "patch_number_image\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "patch_width = 256\n",
    "tile_width = 5000\n",
    "\n",
    "#Memory_tiles = 80  # how many tiles can be stored in CPU memeory\n",
    "#number_tiles_in_memory = 0 # \n",
    "#Intervals = [] # If total tiles = 142, Memory_tiles = 40, the Intervals = [40, 80, 120, 142]\n",
    "#number_tiles = 0 # number of total tiles\n",
    "#start_tile_id = 1\n",
    "#end_tile_id = number_tiles_in_memory\n",
    "\n",
    "Memory_usage = 90\n",
    "\n",
    "#data_extension = '.TIF'\n",
    "#label_extension = '.tif'\n",
    "\n",
    "WINDOW_SIZE = (patch_width, patch_width) # Patch size\n",
    "\n",
    "patch_number_image = (int(tile_width / patch_width) + 1) ** 2  \n",
    "number_sample = 0 # will = patch_number_image * len(all_ids), number of samples of each epoch\n",
    "\n",
    "STRIDE = 32 # Stride for testing\n",
    "IN_CHANNELS = 4 # Number of input channels (e.g. RGB)\n",
    "FOLDER = r\"D:\\Dataset\\ISPRS\" # Replace with your \"/path/to/the/ISPRS/dataset/folder/\"\n",
    "BATCH_SIZE = 1 # Number of samples in a mini-batch\n",
    "TEST_BATCH_SIZE = 30\n",
    "\n",
    "#LABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"] # Label names\n",
    "#LABELS = [\"0000\", \"0601\", \"0610\", \"0521\", \"0750\", \"0311\", \"0411\", \"0511\", \"1001\", \"0250\", \"0340\", \"0360\", \"0710\", \"0422\", \"0890\", \"0830\", \"0312\", \"0110\", \"0313\", \"0120\", \"0550\", \"0321\", \"0424\", \"0211\", \"0291\", \"0721\", \"0810\", \"0540\", \"0330\", \"0522\", \"0212\", \"0770\", \"0790\", \"1012\", \"0760\", \"0530\", \"0230\", \"0370\", \"0920\", \"0220\", \"0822\", \"0821\", \"0950\", \"0293\", \"0930\"]\n",
    "#LABELS = [\"00\", \"06\", \"05\", \"07\", \"03\", \"04\", \"10\", \"02\", \"99\", \"01\", \"08\", \"09\"]\n",
    "LABELS = [\"00\", \"Road\", \"Housing area\", \"Structure\", \"Forest\", \"Grass\", \"Water\", \"Orchard\", \"Ignored\", \"Cropland\", \"Excavated\", \"Bareland\"]\n",
    "LABELS = ['Background', 'Sidewalk']\n",
    "print(LABELS)\n",
    "\n",
    "#Labels for confusion matrix \"8\" is the ignored changed area\n",
    "Label_values = [0, 1]\n",
    "\n",
    "\n",
    "N_CLASSES = len(LABELS) # Number of classes\n",
    "#WEIGHTS = torch.ones(N_CLASSES) # Weights for class balancing\n",
    "# huan\n",
    "#WEIGHTS = torch.FloatTensor([0, 0.044289626, 0.01262308, 0.092527621, 0.001295222, 0.010091334, 0.011178817, 0.023869527, 0.036896865, 0.001978375, 1])\n",
    "WEIGHTS = torch.FloatTensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1])\n",
    "WEIGHTS = torch.FloatTensor([1, 5])\n",
    "\n",
    "#WEIGHTS = WEIGHTS * 100\n",
    "\n",
    "print('WEIGHTS')\n",
    "print(WEIGHTS)\n",
    "CACHE = True # Store the dataset in-memory\n",
    "#CACHE = False\n",
    "print('N_CLASSES')\n",
    "print(N_CLASSES)\n",
    "\n",
    "print('patch_number_image')\n",
    "print(patch_number_image)\n",
    "\n",
    "image_cache = []\n",
    "label_cache = []\n",
    "\n",
    "DATASET = 'Potsdam'\n",
    "\n",
    "if DATASET == 'Potsdam':\n",
    "    MAIN_FOLDER = FOLDER + 'Potsdam/'\n",
    "    DATA_FOLDER = MAIN_FOLDER + 'Y_Ortho_IRRG/top_potsdam_{}_IRRG.tif'\n",
    "    LABEL_FOLDER = MAIN_FOLDER + '5_Labels_for_participants/top_potsdam_{}_label.tif'\n",
    "    ERODED_FOLDER = MAIN_FOLDER + '5_Labels_for_participants_no_Boundary/top_potsdam_{}_label_noBoundary.tif'    \n",
    "elif DATASET == 'Vaihingen':\n",
    "    MAIN_FOLDER = FOLDER + 'Vaihingen/'\n",
    "    DATA_FOLDER = MAIN_FOLDER + 'top/top_mosaic_09cm_area{}.tif'\n",
    "    LABEL_FOLDER = MAIN_FOLDER + 'gts_for_participants/top_mosaic_09cm_area{}.tif'\n",
    "    ERODED_FOLDER = MAIN_FOLDER + 'gts_eroded_for_participants/top_mosaic_09cm_area{}_noBoundary.tif'\n",
    "    \n",
    "#FOLDER = r\"D:\\Dataset\"\n",
    "#MAIN_FOLDER = os.path.join(FOLDER, 'DX')\n",
    "DATA_FOLDER = r'I:\\NewYorkCity_sidewalks\\Images\\{}.TIF'\n",
    "LABEL_FOLDER = r'I:\\NewYorkCity_sidewalks\\sidewalks\\{}.tif'\n",
    "#ERODED_FOLDER = MAIN_FOLDER + '\\RemovedTag5\\C1\\{}.tif'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the dataset\n",
    "\n",
    "First, let's check that we are able to access the dataset and see what's going on. We use ```scikit-image``` for image manipulation.\n",
    "\n",
    "As the ISPRS dataset is stored with a ground truth in the RGB format, we need to define the color palette that can map the label id to its RGB color. We define two helper functions to convert from numeric to colors and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invert_palette:\n",
      "{(255, 255, 255): 12, (165, 165, 165): 1, (255, 0, 0): 2, (171, 93, 160): 3, (84, 130, 53): 4, (226, 240, 217): 5, (91, 155, 213): 6, (169, 209, 142): 7, (255, 230, 153): 9, (158, 72, 14): 10, (99, 99, 99): 11}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth in numerical format has shape (5000,5000e) : \n",
      " [[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "# ISPRS color palette\n",
    "# Let's define the standard ISPRS color palette\n",
    "palette = { # Impervious surfaces (white)\n",
    "           0 : (255,255,255),\n",
    "           1 : (165,165,165),     # Road\n",
    "           2 : (255,0,0),   #  Building\n",
    "           3 : (171,93,160),     # Structure\n",
    "           4 : (84,130,53),   #  Forest\n",
    "           5 : (226,240,217),     # Grass\n",
    "           6 : (91,155,213),   # Water\n",
    "           7 : (169,209,142),  # Garden\n",
    "           8 : (255, 255, 255),  # Ignore\n",
    "           9 : (255,230,153),    # Farmland\n",
    "           10 : (158,72,14),      # Excavated\n",
    "           11 : (99,99,99),        # Bared\n",
    "           12 : (255, 255, 255)\n",
    "          }       \n",
    "#\n",
    " \n",
    "\n",
    "invert_palette = {v: k for k, v in palette.items()}\n",
    "\n",
    "print('invert_palette:')\n",
    "print(invert_palette)\n",
    "\n",
    "def convert_to_color(arr_2d, palette=palette):\n",
    "    \"\"\" Numeric labels to RGB-color encoding \"\"\"\n",
    "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for c, i in palette.items():\n",
    "        m = arr_2d == c\n",
    "        arr_3d[m] = i\n",
    "\n",
    "    return arr_3d\n",
    "\n",
    "def convert_from_color(arr_3d, palette=invert_palette):\n",
    "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
    "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    for c, i in palette.items():\n",
    "        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
    "        arr_2d[m] = i\n",
    "\n",
    "    return arr_2d\n",
    "\n",
    "# We load one tile from the dataset and we display it\n",
    "img = io.imread(r'I:\\NewYorkCity_sidewalks\\Images\\0.TIF')\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(121)\n",
    "plt.imshow(img)\n",
    "\n",
    "# We load the ground truth\n",
    "gt = io.imread(r'I:\\NewYorkCity_sidewalks\\sidewalks\\0.tif')\n",
    "gt_c = convert_to_color(gt)\n",
    "fig.add_subplot(122)\n",
    "plt.imshow(gt_c)\n",
    "plt.show()\n",
    "\n",
    "# We also check that we can convert the ground truth into an array format\n",
    "# huan array_gt = convert_from_color(gt)\n",
    "array_gt = gt\n",
    "print(\"Ground truth in numerical format has shape ({},{}e) : \\n\".format(*array_gt.shape[:2]), array_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define a bunch of utils functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "def get_random_pos(img, window_shape):\n",
    "    w, h = window_shape\n",
    "    W, H = img.shape[-2:]\n",
    "    x1 = random.randint(0, W - w - 1)\n",
    "    x2 = x1 + w\n",
    "    y1 = random.randint(0, H - h - 1)\n",
    "    y2 = y1 + h\n",
    "    return x1, x2, y1, y2\n",
    "\n",
    "def CrossEntropy2d(input, target, weight=None, size_average=True):\n",
    "    # huan\n",
    "    #print('input: ')\n",
    "    #print(input)\n",
    "    \n",
    "    #print('target: ')\n",
    "    #print(target)\n",
    "    \n",
    "    \n",
    "    \"\"\" 2D version of the cross entropy loss \"\"\"\n",
    "    dim = input.dim()\n",
    "    if dim == 2:\n",
    "        return F.cross_entropy(input, target, weight, size_average)\n",
    "        #print('dim: ')\n",
    "        #print(dim)\n",
    "    elif dim == 4:\n",
    "        output = input.view(input.size(0),input.size(1), -1)\n",
    "        output = torch.transpose(output,1,2).contiguous()\n",
    "        output = output.view(-1,output.size(2))\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        #print('input.size: {}, {}'.format(input.size(0), input.size(1)))\n",
    "        \n",
    "        #print('target: ')\n",
    "        #print(target)\n",
    "        \n",
    "        \n",
    "        #print('output: ')\n",
    "        #print(output)\n",
    "        \n",
    "        \n",
    "        return F.cross_entropy(output, target,weight, size_average)\n",
    "    else:\n",
    "        raise ValueError('Expected 2 or 4 dimensions (got {})'.format(dim))\n",
    "\n",
    "def accuracy(input, target):\n",
    "    return 100 * float(np.count_nonzero(input == target)) / target.size\n",
    "\n",
    "def sliding_window(top, step=10, window_size=(20,20)):\n",
    "    \"\"\" Slide a window_shape window across the image with a stride of step \"\"\"\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            yield x, y, window_size[0], window_size[1]\n",
    "            \n",
    "def count_sliding_window(top, step=10, window_size=(20,20)):\n",
    "    \"\"\" Count the number of windows in an image \"\"\"\n",
    "    c = 0\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def grouper(n, iterable):\n",
    "    \"\"\" Browse an iterator by chunk of n elements \"\"\"\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, n))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk\n",
    "\n",
    "def metrics(predictions, gts, label_values, report_path):\n",
    "    print('range(len(gts))')\n",
    "    print(range(len(gts)))\n",
    "    \n",
    "    print('range(len(predictions))')\n",
    "    print(range(len(predictions)))\n",
    "    \n",
    "    print('range(len(label_values))')\n",
    "    print(range(len(label_values)))\n",
    "    \n",
    "    #report = open(MAIN_FOLDER + 'Test_all_report_100tiles_QS.txt', 'w')\n",
    "    report = open(report_path, 'w')\n",
    "    report.writelines('Train ids: ' + str(\"Confusion matrix :\\n\"))\n",
    "    \n",
    "    cm = confusion_matrix(gts, predictions, label_values)\n",
    "    \n",
    "    f1 = f1_score(gts, predictions, average='micro')\n",
    "    print(\"F1_score:  micro\")\n",
    "    print(f1)\n",
    "    \n",
    "    f1 = f1_score(gts, predictions, average='macro')\n",
    "    print(\"F1_score:  macro\")\n",
    "    print(f1)\n",
    "    \n",
    "    f1 = f1_score(gts, predictions, average=None)\n",
    "    print(\"F1_score: None\")\n",
    "    print(f1)\n",
    "    \n",
    "#     accur = accuracy_score(gts, predictions)\n",
    "#     print(\"accuracy_score:  \")\n",
    "#     print(accur)\n",
    "        \n",
    "#     rpt = classification_report(gts, predictions, LABELS)\n",
    "#     print(\"classification_report:  \")\n",
    "#     print(accur)    \n",
    "    \n",
    "    \n",
    "    print(\"Confusion matrix :\")\n",
    "    report.writelines(str(\"Confusion matrix : \\n\"))\n",
    "    print(cm)\n",
    "    report.writelines(str(cm) +'\\n')\n",
    "    report.writelines('----------- \\n ')\n",
    "    \n",
    "    print(\"---\")\n",
    "    \n",
    "    # Compute global accuracy\n",
    "    total = sum(sum(cm))\n",
    "    accuracy = sum([cm[x][x] for x in range(len(cm))])\n",
    "    accuracy *= 100 / float(total)\n",
    "    print(\"{} pixels processed\".format(total))\n",
    "    print(\"Total accuracy : {}%\".format(accuracy))\n",
    "    \n",
    "    print(\"---\")\n",
    "    \n",
    "    report.writelines(\"{} pixels processed \\n\".format(total))\n",
    "    report.writelines(\"Total accuracy : {}% \\n\".format(accuracy))\n",
    "    report.writelines(\"---\\n\")\n",
    "    \n",
    "    # Compute F1 score\n",
    "    F1Score = np.zeros(len(label_values))\n",
    "    class_accuracy = np.zeros(len(label_values))\n",
    "    class_recall = np.zeros(len(label_values))\n",
    "    for i in range(len(label_values)):\n",
    "        try:\n",
    "            F1Score[i] = 2. * cm[i,i] / (np.sum(cm[i,:]) + np.sum(cm[:,i]))\n",
    "            class_accuracy[i] =  cm[i,i] / np.sum(cm[:,i])\n",
    "            class_recall[i] = cm[i,i] / np.sum(cm[i,:])\n",
    "        except:\n",
    "            # Ignore exception if there is no element in class i for test set\n",
    "            pass\n",
    "        \n",
    "    report.writelines(\"F1Score : \\n\")    \n",
    "    print(\"F1Score :\")\n",
    "    \n",
    "    \n",
    "    for l_id, score in enumerate(F1Score):\n",
    "        print(\"{}: {}\".format(LABELS[label_values[l_id]], score))\n",
    "        report.writelines(\"{}: {} \\n\".format(LABELS[label_values[l_id]], score))\n",
    "    print(\"---\")\n",
    "    \n",
    "    print(\"class_accuracy :\") \n",
    "    report.writelines(\"\\n class_accuracy : \\n\")  \n",
    "    for l_id, score in enumerate(class_accuracy):\n",
    "        print(\"{}: {}\".format(LABELS[label_values[l_id]], score))\n",
    "        report.writelines(\"{}: {} \\n\".format(LABELS[label_values[l_id]], score))\n",
    "    print(\"---\")\n",
    "\n",
    "    print(\"class_recall :\") \n",
    "    report.writelines(\"\\n class_recall : \\n\")  \n",
    "    for l_id, score in enumerate(class_recall):\n",
    "        print(\"{}: {}\".format(LABELS[label_values[l_id]], score))\n",
    "        report.writelines(\"{}: {} \\n\".format(LABELS[label_values[l_id]], score))\n",
    "    print(\"---\")\n",
    "\n",
    "    print(\"\\nClass summary :\") \n",
    "    report.writelines(\"\\nClass summary :\\n\")\n",
    "    for i in range(len(label_values)):\n",
    "        print('Correct, Ground truth, Predict: ', LABELS[label_values[i]], cm[i,i], np.sum(cm[i,:]),np.sum(cm[:,i]))\n",
    "        report.writelines('Correct, Ground truth, Predict: {}: {}, {}, {}\\n'.format(LABELS[label_values[i]], cm[i,i], np.sum(cm[i,:]), np.sum(cm[:,i])))\n",
    "        \n",
    "    \n",
    "    report.writelines(\"---\\n\")\n",
    "    \n",
    "        \n",
    "    # Compute kappa coefficient\n",
    "    total = np.sum(cm)\n",
    "    pa = np.trace(cm) / float(total)\n",
    "    pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / float(total*total)\n",
    "    kappa = (pa - pe) / (1 - pe);\n",
    "    print(\"Kappa: \" + str(kappa))\n",
    "    \n",
    "    report.writelines(\"Kappa: \" + str(kappa) +'\\n')\n",
    "    \n",
    "    report.close()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "We define a PyTorch dataset (```torch.utils.data.Dataset```) that loads all the tiles in memory and performs random sampling. Tiles are stored in memory on the fly.\n",
    "\n",
    "The dataset also performs random data augmentation (horizontal and vertical flips) and normalizes the data in [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "\n",
    "class RS_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_cache, label_cache, augmentation=True):\n",
    "        super(RS_dataset, self).__init__()\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "         \n",
    "        \n",
    "        # List of files\n",
    "        #self.data_files = [DATA_FOLDER.format(id) for id in ids]\n",
    "        #self.label_files = [LABEL_FOLDER.format(id) for id in ids]\n",
    "\n",
    "        # Sanity check : raise an error if some files do not exist\n",
    "#         for f in self.data_files + self.label_files:\n",
    "#             if not os.path.isfile(f):\n",
    "#                 raise KeyError('{} is not a file !'.format(f))\n",
    "        \n",
    "#         # Initialize cache dicts\n",
    "#         #if self.cache:\n",
    "#         self.image_dic = []\n",
    "#         self.label_dic = []\n",
    "#             \n",
    "    \n",
    "    def __len__(self):\n",
    "        # Default epoch size is 10 000 samples\n",
    "        return number_sample  \n",
    "    \n",
    "    @classmethod\n",
    "    def data_augmentation(cls, *arrays, flip=True, mirror=True):\n",
    "        will_flip, will_mirror = False, False\n",
    "        if flip and random.random() < 0.5:\n",
    "            will_flip = True\n",
    "        if mirror and random.random() < 0.5:\n",
    "            will_mirror = True\n",
    "        \n",
    "        results = []\n",
    "        for array in arrays:\n",
    "            if will_flip:\n",
    "                if len(array.shape) == 2:\n",
    "                    array = array[::-1, :]\n",
    "                else:\n",
    "                    array = array[:, ::-1, :]\n",
    "            if will_mirror:\n",
    "                if len(array.shape) == 2:\n",
    "                    array = array[:, ::-1]\n",
    "                else:\n",
    "                    array = array[:, :, ::-1]\n",
    "            results.append(np.copy(array))\n",
    "            \n",
    "        return tuple(results)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # Pick a random image\n",
    "        random_idx = random.randint(0, len(image_cache) - 1)\n",
    "        \n",
    "        # If the tile hasn't been loaded yet, put in cache\n",
    "#         if random_idx in self.data_cache_.keys():\n",
    "#             data = self.data_cache_[random_idx]\n",
    "#         else:\n",
    "            # Data is normalized in [0, 1]\n",
    "        data = image_cache[random_idx]\n",
    "#             if self.cache:\n",
    "#                 self.data_cache_[random_idx] = data\n",
    "            \n",
    "#         if random_idx in self.label_cache_.keys():\n",
    "        label = label_cache[random_idx]\n",
    "#         else: \n",
    "#             # Labels are converted from RGB to their numeric values\n",
    "#             # huan label = np.asarray(convert_from_color(io.imread(self.label_files[random_idx])), dtype='int64')\n",
    "#             label = np.asarray(io.imread(self.label_files[random_idx]), dtype='int64')\n",
    "#             #huan\n",
    "#             #print(label)\n",
    "#             if self.cache:\n",
    "#                 self.label_cache_[random_idx] = label\n",
    "\n",
    "        # Get a random patch\n",
    "        x1, x2, y1, y2 = get_random_pos(data, WINDOW_SIZE)\n",
    "        data_p = data[:, x1:x2,y1:y2]\n",
    "        label_p = label[x1:x2,y1:y2]\n",
    "        \n",
    "        # Data augmentation\n",
    "        data_p, label_p = self.data_augmentation(data_p, label_p)\n",
    "\n",
    "        # Return the torch.Tensor values\n",
    "        return (torch.from_numpy(data_p),\n",
    "                torch.from_numpy(label_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network definition\n",
    "\n",
    "We can now define the Fully Convolutional network based on the SegNet architecture. We could use any other network as drop-in replacement, provided that the output has dimensions `(N_CLASSES, W, H)` where `W` and `H` are the sliding window dimensions (i.e. the network should preserve the spatial dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegNet(nn.Module):\n",
    "    # SegNet network\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.kaiming_normal(m.weight.data)\n",
    "    \n",
    "    def __init__(self, in_channels=IN_CHANNELS, out_channels=N_CLASSES):\n",
    "        super(SegNet, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, return_indices=True)\n",
    "        self.unpool = nn.MaxUnpool2d(2)\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
    "        self.conv1_1_bn = nn.BatchNorm2d(64)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv1_2_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv2_1_bn = nn.BatchNorm2d(128)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv2_2_bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv3_1_bn = nn.BatchNorm2d(256)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv3_2_bn = nn.BatchNorm2d(256)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv3_3_bn = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv4_1_bn = nn.BatchNorm2d(512)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv4_2_bn = nn.BatchNorm2d(512)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv4_3_bn = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_1_bn = nn.BatchNorm2d(512)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_2_bn = nn.BatchNorm2d(512)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_3_bn = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5_3_D = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_3_D_bn = nn.BatchNorm2d(512)\n",
    "        self.conv5_2_D = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_2_D_bn = nn.BatchNorm2d(512)\n",
    "        self.conv5_1_D = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_1_D_bn = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv4_3_D = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv4_3_D_bn = nn.BatchNorm2d(512)\n",
    "        self.conv4_2_D = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv4_2_D_bn = nn.BatchNorm2d(512)\n",
    "        self.conv4_1_D = nn.Conv2d(512, 256, 3, padding=1)\n",
    "        self.conv4_1_D_bn = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv3_3_D = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv3_3_D_bn = nn.BatchNorm2d(256)\n",
    "        self.conv3_2_D = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv3_2_D_bn = nn.BatchNorm2d(256)\n",
    "        self.conv3_1_D = nn.Conv2d(256, 128, 3, padding=1)\n",
    "        self.conv3_1_D_bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv2_2_D = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv2_2_D_bn = nn.BatchNorm2d(128)\n",
    "        self.conv2_1_D = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.conv2_1_D_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv1_2_D = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv1_2_D_bn = nn.BatchNorm2d(64)\n",
    "        self.conv1_1_D = nn.Conv2d(64, out_channels, 3, padding=1)\n",
    "        \n",
    "        self.apply(self.weight_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder block 1\n",
    "        x = self.conv1_1_bn(F.relu(self.conv1_1(x)))\n",
    "        x = self.conv1_2_bn(F.relu(self.conv1_2(x)))\n",
    "        x, mask1 = self.pool(x)\n",
    "        \n",
    "        # Encoder block 2\n",
    "        x = self.conv2_1_bn(F.relu(self.conv2_1(x)))\n",
    "        x = self.conv2_2_bn(F.relu(self.conv2_2(x)))\n",
    "        x, mask2 = self.pool(x)\n",
    "        \n",
    "        # Encoder block 3\n",
    "        x = self.conv3_1_bn(F.relu(self.conv3_1(x)))\n",
    "        x = self.conv3_2_bn(F.relu(self.conv3_2(x)))\n",
    "        x = self.conv3_3_bn(F.relu(self.conv3_3(x)))\n",
    "        x, mask3 = self.pool(x)\n",
    "        \n",
    "        # Encoder block 4\n",
    "        x = self.conv4_1_bn(F.relu(self.conv4_1(x)))\n",
    "        x = self.conv4_2_bn(F.relu(self.conv4_2(x)))\n",
    "        x = self.conv4_3_bn(F.relu(self.conv4_3(x)))\n",
    "        x, mask4 = self.pool(x)\n",
    "        \n",
    "        # Encoder block 5\n",
    "        x = self.conv5_1_bn(F.relu(self.conv5_1(x)))\n",
    "        x = self.conv5_2_bn(F.relu(self.conv5_2(x)))\n",
    "        x = self.conv5_3_bn(F.relu(self.conv5_3(x)))\n",
    "        x, mask5 = self.pool(x)\n",
    "        \n",
    "        # Decoder block 5\n",
    "        x = self.unpool(x, mask5)\n",
    "        x = self.conv5_3_D_bn(F.relu(self.conv5_3_D(x)))\n",
    "        x = self.conv5_2_D_bn(F.relu(self.conv5_2_D(x)))\n",
    "        x = self.conv5_1_D_bn(F.relu(self.conv5_1_D(x)))\n",
    "        \n",
    "        # Decoder block 4\n",
    "        x = self.unpool(x, mask4)\n",
    "        x = self.conv4_3_D_bn(F.relu(self.conv4_3_D(x)))\n",
    "        x = self.conv4_2_D_bn(F.relu(self.conv4_2_D(x)))\n",
    "        x = self.conv4_1_D_bn(F.relu(self.conv4_1_D(x)))\n",
    "        \n",
    "        # Decoder block 3\n",
    "        x = self.unpool(x, mask3)\n",
    "        x = self.conv3_3_D_bn(F.relu(self.conv3_3_D(x)))\n",
    "        x = self.conv3_2_D_bn(F.relu(self.conv3_2_D(x)))\n",
    "        x = self.conv3_1_D_bn(F.relu(self.conv3_1_D(x)))\n",
    "        \n",
    "        # Decoder block 2\n",
    "        x = self.unpool(x, mask2)\n",
    "        x = self.conv2_2_D_bn(F.relu(self.conv2_2_D(x)))\n",
    "        x = self.conv2_1_D_bn(F.relu(self.conv2_1_D(x)))\n",
    "        \n",
    "        # Decoder block 1\n",
    "        x = self.unpool(x, mask1)\n",
    "        x = self.conv1_2_D_bn(F.relu(self.conv1_2_D(x)))\n",
    "        x = F.log_softmax(self.conv1_1_D(x))\n",
    "        return x\n",
    "    \n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet5layer(nn.Module):\n",
    "\n",
    "    #def __init__(self, n_class):\n",
    "    def __init__(self, in_channels=IN_CHANNELS, n_class=N_CLASSES):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(in_channels, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)\n",
    "        self.dconv_down5 = double_conv(512, 512)   # Huan  \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        #self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "             \n",
    "        self.dconv_up4 = double_conv(512 + 512, 512) # HUAN\n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        conv4 = self.dconv_down4(x)\n",
    "        x = self.maxpool(conv4)   \n",
    "        \n",
    "        x = self.dconv_down5(x)\n",
    "        \n",
    "        #x = self.dconv_down5(x)        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv4], dim=1)\n",
    "        \n",
    "        x = self.dconv_up4(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)               \n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return out   \n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=IN_CHANNELS, n_class=N_CLASSES):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(in_channels, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now instantiate the network using the specified parameters. By default, the weights will be initialized using the [He policy](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Network Parameters: {} 7783554\n"
     ]
    }
   ],
   "source": [
    "# instantiate the network\n",
    "\n",
    "#net1 = SegNet()\n",
    "net1 = UNet()\n",
    "#net = torch.nn.DataParallel(net1)\n",
    "net = net1\n",
    "\n",
    "cnt = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('Number of Network Parameters: {}', cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download and load the pre-trained weights from VGG-16 on ImageNet. This step is optional but it makes the network converge faster. We skip the weights from VGG-16 that have no counterpart in SegNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping features.0.weight to dconv_down1.0.weight\n",
      "Mapping features.0.bias to dconv_down1.0.bias\n",
      "Mapping features.1.weight to dconv_down1.2.weight\n",
      "Mapping features.1.bias to dconv_down1.2.bias\n",
      "Mapping features.1.running_mean to dconv_down2.0.weight\n",
      "Mapping features.1.running_var to dconv_down2.0.bias\n",
      "Mapping features.3.weight to dconv_down2.2.weight\n",
      "Mapping features.3.bias to dconv_down2.2.bias\n",
      "Mapping features.4.weight to dconv_down3.0.weight\n",
      "Mapping features.4.bias to dconv_down3.0.bias\n",
      "Mapping features.4.running_mean to dconv_down3.2.weight\n",
      "Mapping features.4.running_var to dconv_down3.2.bias\n",
      "Mapping features.7.weight to dconv_down4.0.weight\n",
      "Mapping features.7.bias to dconv_down4.0.bias\n",
      "Mapping features.8.weight to dconv_down4.2.weight\n",
      "Mapping features.8.bias to dconv_down4.2.bias\n",
      "Mapping features.8.running_mean to dconv_up3.0.weight\n",
      "Mapping features.8.running_var to dconv_up3.0.bias\n",
      "Mapping features.10.weight to dconv_up3.2.weight\n",
      "Mapping features.10.bias to dconv_up3.2.bias\n",
      "Mapping features.11.weight to dconv_up2.0.weight\n",
      "Mapping features.11.bias to dconv_up2.0.bias\n",
      "Mapping features.11.running_mean to dconv_up2.2.weight\n",
      "Mapping features.11.running_var to dconv_up2.2.bias\n",
      "Mapping features.14.weight to dconv_up1.0.weight\n",
      "Mapping features.14.bias to dconv_up1.0.bias\n",
      "Mapping features.15.weight to dconv_up1.2.weight\n",
      "Mapping features.15.bias to dconv_up1.2.bias\n",
      "Mapping features.15.running_mean to conv_last.weight\n",
      "Mapping features.15.running_var to conv_last.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "# Download VGG-16 weights from PyTorch\n",
    "vgg_url = 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth'\n",
    "# if not os.path.isfile('vgg16_bn-6c64b313.pth'):\n",
    "#     #weights = urllib.URLopener()\n",
    "#     weights = urllib.URLopener()\n",
    "#     weights.retrieve(vgg_url, 'vgg16_bn-6c64b313.pth')\n",
    "\n",
    "vgg16_weights = torch.load(r'I:\\NewYorkCity_sidewalks\\vgg16_bn-6c64b313.pth')\n",
    "mapped_weights = {}\n",
    "for k_vgg, k_segnet in zip(vgg16_weights.keys(), net.state_dict().keys()):\n",
    "    if \"features\" in k_vgg:\n",
    "        mapped_weights[k_segnet] = vgg16_weights[k_vgg]\n",
    "        print(\"Mapping {} to {}\".format(k_vgg, k_segnet))\n",
    "        \n",
    "try:\n",
    "    net.load_state_dict(mapped_weights)\n",
    "    print(\"Loaded VGG-16 weights in SegNet !\")\n",
    "except:\n",
    "    # Ignore missing keys\n",
    "    pass\n",
    "\n",
    "\n",
    "net.load_state_dict(torch.load(r'unet256_5layer_epoch5_40tiles.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load the network on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (dconv_down1): Sequential(\n",
       "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_down4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (dconv_up3): Sequential(\n",
       "    (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_up2): Sequential(\n",
       "    (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (dconv_up1): Sequential(\n",
       "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "We now create a train/test split. If you want to use another dataset, you have to adjust the method to collect all filenames. In our case, we specify a fixed train/test split for the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "LABEL_FOLDER\n",
      "I:\\NewYorkCity_sidewalks\\sidewalks\\{}.tif\n",
      "all_files\n",
      "replace\n",
      "I:\\NewYorkCity_sidewalks\\sidewalks\\*.tif\n",
      "len(all_ids)\n",
      "433\n",
      "Number of train tiles: 320  Tiles for training :  ['1', '5', '6', '7', '8', '9', '10', '11', '12', '18', '19', '20', '21', '22', '23', '24', '25', '29', '32', '34', '35', '36', '37', '38', '39', '42', '43', '45', '46', '48', '50', '51', '52', '57', '58', '59', '61', '62', '63', '66', '67', '68', '69', '70', '71', '75', '76', '77', '78', '79', '81', '82', '83', '84', '86', '87', '89', '90', '91', '92', '93', '94', '95', '100', '101', '103', '104', '105', '106', '107', '108', '109', '112', '113', '114', '115', '116', '117', '118', '119', '124', '127', '128', '129', '130', '131', '132', '134', '135', '136', '138', '139', '140', '141', '142', '143', '149', '150', '154', '156', '157', '158', '159', '160', '161', '162', '163', '164', '166', '168', '169', '170', '171', '172', '173', '174', '175', '177', '178', '179', '180', '181', '182', '183', '184', '185', '187', '190', '191', '192', '193', '194', '195', '196', '197', '199', '200', '201', '202', '203', '204', '205', '206', '210', '212', '213', '214', '215', '216', '217', '218', '219', '220', '222', '223', '224', '225', '226', '227', '228', '229', '230', '232', '233', '234', '235', '236', '237', '238', '239', '240', '242', '243', '244', '245', '246', '247', '248', '249', '250', '252', '253', '254', '255', '256', '257', '258', '259', '261', '263', '264', '265', '266', '267', '268', '269', '270', '271', '273', '274', '275', '276', '277', '278', '279', '280', '281', '283', '284', '285', '286', '287', '288', '289', '290', '291', '293', '294', '295', '296', '298', '299', '300', '301', '302', '304', '305', '306', '307', '308', '309', '310', '311', '312', '316', '317', '318', '319', '320', '321', '322', '323', '326', '328', '329', '330', '332', '334', '335', '336', '337', '338', '340', '344', '345', '346', '347', '348', '350', '351', '352', '354', '355', '356', '357', '361', '362', '363', '364', '365', '367', '368', '369', '372', '373', '374', '375', '376', '377', '379', '381', '382', '383', '384', '385', '386', '387', '388', '391', '392', '393', '394', '395', '396', '397', '398', '399', '402', '403', '404', '405', '406', '407', '408', '410', '411', '413', '414', '415', '416', '419', '420', '421', '422', '425', '427', '429', '430', '431', '0']\n",
      "Number of test tiles: 35  Tiles for testing :  ['17', '30', '44', '60', '72', '85', '96', '111', '126', '137', '155', '165', '176', '186', '198', '211', '221', '231', '241', '251', '262', '272', '282', '292', '303', '313', '327', '339', '353', '366', '378', '390', '401', '412', '426']\n",
      "number_sample\n",
      "128000\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "print(\"Loading data\")\n",
    "if DATASET == 'Potsdam':\n",
    "    all_files = sorted(glob(LABEL_FOLDER.replace('{}', '*')))\n",
    "    all_ids = [\"_\".join(f.split('_')[3:5]) for f in all_files]\n",
    "    print('LABEL_FOLDER') # Huan\n",
    "    print(LABEL_FOLDER)  # Huan\n",
    "    print('all_files')  # huan\n",
    "    #print(all_files)  # huan\n",
    "    \n",
    "    print('replace') # Huan\n",
    "    print(LABEL_FOLDER.replace('{}', '*'))  # Huan\n",
    "elif DATASET == 'Vaihingen':\n",
    "    #all_ids = \n",
    "    all_files = sorted(glob(LABEL_FOLDER.replace('{}', '*')))\n",
    "    print('LABEL_FOLDER') # Huan\n",
    "    print(glob(LABEL_FOLDER.replace('{}', '*')))  # Huan\n",
    "    print('all_files')  # huan\n",
    "    print(all_files)  # huan\n",
    "    print('replace') # Huan\n",
    "    print(LABEL_FOLDER.replace('{}', '*'))  # Huan\n",
    "    all_ids = [f.split('area')[-1].split('.')[0] for f in all_files]\n",
    "\n",
    "all_files = sorted(glob(LABEL_FOLDER.replace('{}', '*')))\n",
    "# print('LABEL_FOLDER') # Huan\n",
    "# print(glob(LABEL_FOLDER.replace('{}', '*')))  # Huan\n",
    "# print('all_files')  # huan\n",
    "# print(all_files[0])  # huan\n",
    "#print('replace') # Huan\n",
    "#print(LABEL_FOLDER.replace('{}', '*'))  # Huan\n",
    "all_ids = [f.split('/')[-1].split('.')[0] for f in all_files]\n",
    "\n",
    "# huan\n",
    "#print('all_ids')\n",
    "#print(all_ids)\n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "    \n",
    "# Random tile numbers for train/test split\n",
    "#print(all_ids) #Huan\n",
    "print('len(all_ids)')  # Huan\n",
    "print(len(all_ids)) \n",
    "number_tiles = len(all_ids) \n",
    "\n",
    "# train_ids = random.sample(all_ids, 2 * len(all_ids) // 3 + 1)\n",
    "# test_ids = list(set(all_ids) - set(train_ids))\n",
    "\n",
    "# # Exemple of a train/test split on Vaihingen :\n",
    "# train_ids = ['1', '2','3', '23', '26', '7', '11', '13', '28', '17', '32', '34', '37']\n",
    "# test_ids = ['5', '21', '15', '30'] \n",
    "\n",
    "# # Exemple of a train/test split on Potsdam :\n",
    "# train_ids = ['2_10', '2_11', '2_12', '3_10', '3_11', '3_12', '4_10', '4_11', '4_12', '5_10', '5_11', '5_12', '6_7', '6_8','6_9', '6_10', '6_11', '6_12', '7_7', '7_8', '7_9', '7_10', '7_11', '7_12']\n",
    "# test_ids = ['4_12', '7_7', '3_10', '5_10'] \n",
    "# test_ids = ['5_10'] \n",
    "\n",
    "\n",
    "# train_ids = ['65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '141', '142', '143', '144', '145', '146']\n",
    "# test_ids = ['20', '60', '100', '140'] \n",
    "\n",
    "\n",
    "#train_ids = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52','53','54','55','56','57','58','59','61','62','63','64','65','66','67','68','69','70','71','72','73','74','75','76','77','78','79','80','81','82','83','84','85','86','87','88','89','90','91','92','93','94','95','96','97','98','99','101','102','103','104','105','106','107','108','109','110','111','112','113','114','115','116','117','118','119','120','121','122','123','124','125','126','127','128','129','130','131','132','133','134','135','136','137','138','139','141','142','143','144','145','146']\n",
    "#train_ids = ['40','41','42','43','44','45','46','47','48','49','50','51','52','53','54','55','56','57','58','59','61','62','63','64','65','66','67','68','69','70','71','72','73','74','75','76','77','78','79']\n",
    "#test_ids = ['80','81']\n",
    "\n",
    "#train_ids = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39']\n",
    "\n",
    "#train_ids = ['80','81','82','83','84','85','86','87','88','89','90','91','92','93','94','95','96','97','98','99','101','102','103','104','105','106','107','108','109','110','111','112','113','114','115','116','117','118','119','120','121','122','123','124','125','126','127','128','129','130','131','132','133','134','135','136','137','138','139','141','142','143','144','145','146']\n",
    "\n",
    "train_ids = ['0','7','14','21','28','35','42','49','56','63','70','77','84','91','98','105','112','119','126','140']\n",
    "# test_ids = ['20'] \n",
    "train_ids = ['0']\n",
    "train_ids = ['0','7','14','21','28','35','42','49','56','63','70','77','84','91','98','105','112','119','126','140','1','8','15','22','29','36','43','50','57','64','71','78','85','92','99','106','113','120','127','134','141','2','9','16','23','30','37','44','51','58','65','72','79','86','93','100','107','121','128','135','142','3','10','17','24','31','38','45','52','59','66','73','80','87','94','101','108','115','122','129','136','143','4','11','18','25','32','39','46','53','60','67','74','81','88','102','109','116','130','137','144','5','12','19','26','33','40','47','54','61','68','75','82','89','96','110','117','124','131','138','145','6','13','20','27','34','41','48','55','62','69','76','83','90','97','104','111','118','125','132','139','146']\n",
    "#test_ids = ['80']\n",
    "#test_ids = ['0'] \n",
    "\n",
    "# without the first 20 tiles, 122 tiles\n",
    "train_ids = ['1','8','15','22','29','36','43','50','57','64','71','78','85','92','99','106','113','120','127','134','141','2','9','16','23','30','37','44','51','58','65','72','79','86','93','100','107','121','128','135','142','3','10','17','24','31','38','45','52','59','66','73','80','87','94','101','108','115','122','129','136','143','4','11','18','25','32','39','46','53','60','67','74','81','88','102','109','116','130','137','144','5','12','19','26','33','40','47','54','61','68','75','82','89','96','110','117','124','131','138','145','6','13','20','27','34','41','48','55','62','69','76','83','90','97','104','111','118','125','132','139','146']\n",
    "\n",
    "# without the last 20 tiles, 120 tiles\n",
    "train_ids = ['0','7','14','21','28','35','42','49','56','63','70','77','84','91','98','105','112','119','126','140','1','8','15','22','29','36','43','50','57','64','71','78','85','92','99','106','113','120','127','134','141','2','9','16','23','30','37','44','51','58','65','72','79','86','93','100','107','121','128','135','142','3','10','17','24','31','38','45','52','59','66','73','80','87','94','101','108','115','122','129','136','143','4','11','18','25','32','39','46','53','60','67','74','81','88','102','109','116','130','137','144','5','12','19','26','33','40','47','54','61','68','75','82','89','96','110','117','124','131','138','145']\n",
    " \n",
    "# without the last 40 tiles, 100 tiles\n",
    "train_ids = ['0','7','14','21','28','35','42','49','56','63','70','77','84','91','98','105','112','119','126','140','1','8','15','22','29','36','43','50','57','64','71','78','85','92','99','106','113','120','127','134','141','2','9','16','23','30','37','44','51','58','65','72','79','86','93','100','107','121','128','135','142','3','10','17','24','31','38','45','52','59','66','73','80','87','94','101','108','115','122','129','136','143','4','11','18','25','32','39','46','53','60','67','74','81','88','102','109','116','130','137','144']\n",
    " \n",
    "# without the last 60 tiles, 80 tiles\n",
    "train_ids = ['0','7','14','21','28','35','42','49','56','63','70','77','84','91','98','105','112','119','126','140','1','8','15','22','29','36','43','50','57','64','71','78','85','92','99','106','113','120','127','134','141','2','9','16','23','30','37','44','51','58','65','72','79','86','93','100','107','121','128','135','142','3','10','17','24','31','38','45','52','59','66','73','80','87','94','101','108','115','122','129','136','143']\n",
    "\n",
    "# without the last 80 tiles, 60 tiles\n",
    "train_ids = ['0','7','14','21','28','35','42','49','56','63','70','77','84','91','98','105','112','119','126','140','1','8','15','22','29','36','43','50','57','64','71','78','85','92','99','106','113','120','127','134','141','2','9','16','23','30','37','44','51','58','65','72','79','86','93','100','107','121','128','135','142']\n",
    "\n",
    "# without the last 100 tiles, 40 tiles\n",
    "train_ids = ['0','7','14','21','28','35','42','49','56','63','70','77','84','91','98','105','112','119','126','140','1','8','15','22','29','36','43','50','57','64','71','78','85','92','99','106','113','120','127','134','141','2','9','16','23','30','37','44','51','58','65','72','79','86','93','100','107','121','128','135','142']\n",
    "\n",
    "# without the last 120 tiles, 20 tiles\n",
    "train_ids = ['0','7','14','21','28','35','42','49','56','63','70','77','84','91','98','105','112','119','126','140']\n",
    "train_ids = ['1', '5', '6', '7', '8', '9', '10', '11', '12', '18', '19', '20', '21', '22', '23', '24', '25', '29', '32', '34', '35', '36', '37', '38', '39', '42', '43', '45', '46', '48', '50', '51', '52', '57', '58', '59', '61', '62', '63', '66', '67', '68', '69', '70', '71', '75', '76', '77', '78', '79', '81', '82', '83', '84', '86', '87', '89', '90', '91', '92', '93', '94', '95', '100', '101', '103', '104', '105', '106', '107', '108', '109', '112', '113', '114', '115', '116', '117', '118', '119', '124', '127', '128', '129', '130', '131', '132', '134', '135', '136', '138', '139', '140', '141', '142', '143', '149', '150', '154', '156', '157', '158', '159', '160', '161', '162', '163', '164', '166', '168', '169', '170', '171', '172', '173', '174', '175', '177', '178', '179', '180', '181', '182', '183', '184', '185', '187', '190', '191', '192', '193', '194', '195', '196', '197', '199', '200', '201', '202', '203', '204', '205', '206', '210', '212', '213', '214', '215', '216', '217', '218', '219', '220', '222', '223', '224', '225', '226', '227', '228', '229', '230', '232', '233', '234', '235', '236', '237', '238', '239', '240', '242', '243', '244', '245', '246', '247', '248', '249', '250', '252', '253', '254', '255', '256', '257', '258', '259', '261', '263', '264', '265', '266', '267', '268', '269', '270', '271', '273', '274', '275', '276', '277', '278', '279', '280', '281', '283', '284', '285', '286', '287', '288', '289', '290', '291', '293', '294', '295', '296', '298', '299', '300', '301', '302', '304', '305', '306', '307', '308', '309', '310', '311', '312', '316', '317', '318', '319', '320', '321', '322', '323', '326', '328', '329', '330', '332', '334', '335', '336', '337', '338', '340', '344', '345', '346', '347', '348', '350', '351', '352', '354', '355', '356', '357', '361', '362', '363', '364', '365', '367', '368', '369', '372', '373', '374', '375', '376', '377', '379', '381', '382', '383', '384', '385', '386', '387', '388', '391', '392', '393', '394', '395', '396', '397', '398', '399', '402', '403', '404', '405', '406', '407', '408', '410', '411', '413', '414', '415', '416', '419', '420', '421', '422', '425', '427', '429', '430', '431', '0']\n",
    "\n",
    "#test_ids = ['t']\n",
    "test_ids = ['small'] \n",
    "test_ids = ['4','5','6','11','12','13','18','19','20','25','26','27','32','33','34','39','40','41','46','47','48','53','54','55','60','61','62','67','68','69','74','75','76','81','82','83','88','89','90','96','97','102','104','109','110','111','116','117','118','124','125','130','131','132','137','138','139','144','145','146']\n",
    "\n",
    "test_ids = all_ids\n",
    "test_ids = ['Q_T35']\n",
    "test_ids = ['6','13','20','27','34','41','48','55','62','69','76','83','90','97','104','111','118','125','132','139','146','t']\n",
    "test_ids = ['17', '30', '44', '60', '72', '85', '96', '111', '126', '137', '155', '165', '176', '186', '198', '211', '221', '231', '241', '251', '262', '272', '282', '292', '303', '313', '327', '339', '353', '366', '378', '390', '401', '412', '426']\n",
    "#train_ids = random.sample(all_ids, 2 * len(all_ids) // 3 + 1)\n",
    "#test_ids = list(set(all_ids) - set(train_ids))\n",
    "\n",
    "#number_sample = len(all_ids) * number_smaple\n",
    "\n",
    "print(\"Number of train tiles:\", len(train_ids), \" Tiles for training : \", train_ids)\n",
    "print(\"Number of test tiles:\", len(test_ids), \" Tiles for testing : \", test_ids)\n",
    "\n",
    "number_sample =   patch_number_image * len(train_ids)\n",
    "print('number_sample')\n",
    "print(number_sample)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the optimizer\n",
    "\n",
    "#e use the standard Stochastic Gradient Descent algorithm to optimize the network's weights.\n",
    "\n",
    "The encoder is trained at half the learning rate of the decoder, as we rely on the pre-trained VGG-16 weights. We use the ``torch.optim.lr_scheduler`` to reduce the learning rate by 10 after 25, 35 and 45 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = 0.0001\n",
    "params_dict = dict(net.named_parameters())\n",
    "params = []\n",
    "for key, value in params_dict.items():\n",
    "    if '_D' in key:\n",
    "        # Decoder weights are trained at the nominal learning rate\n",
    "        params += [{'params':[value],'lr': base_lr}]\n",
    "    else:\n",
    "        # Encoder weights are trained at lr / 2 (we have VGG-16 weights as initialization)\n",
    "        params += [{'params':[value],'lr': base_lr / 2}]\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=base_lr, momentum=0.9, weight_decay=0.0005)\n",
    "# We define the scheduler\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [25, 35, 45,55,65,80,90,100], gamma=0.1)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [5, 10, 35,45,55,65,80,90,100], gamma=0.1)\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.3, patience=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_ids, all=False, stride=WINDOW_SIZE[0], batch_size=TEST_BATCH_SIZE, window_size=WINDOW_SIZE, prefix=None, saved_path=None):\n",
    "    # Use the network on the test set\n",
    "    cnt = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    print('Number of Network Parameters: {}', cnt)\n",
    "    test_images = (1 / 255 * np.asarray(io.imread(DATA_FOLDER.format(id)), dtype='float32') for id in test_ids)\n",
    "    test_labels = (np.asarray(io.imread(LABEL_FOLDER.format(id)), dtype='uint8') for id in test_ids)\n",
    "    # huan \n",
    "    # eroded_labels = (convert_from_color(io.imread(ERODED_FOLDER.format(id))) for id in test_ids)\n",
    "    #eroded_labels = ((io.imread(ERODED_FOLDER.format(id))) for id in test_ids)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_gts = []\n",
    "    \n",
    "    # Switch the network to inference mode\n",
    "    #net = torch.nn.DataParallel(net)\n",
    "    net.eval()\n",
    "    \n",
    "    id_index = 0\n",
    "    \n",
    "    # huan tqdm is a progress bar for notebook.  zipped:      zipped((1,2),(3,4)) = ((1,3), (2,4))\n",
    "    for img, gt, in tqdm(zip(test_images, test_labels), total=len(test_ids), leave=False):\n",
    "        pred = np.zeros(img.shape[:2] + (N_CLASSES,))\n",
    "        \n",
    "        print('Processing image: {}'.format(test_ids[id_index]))\n",
    "\n",
    "        total = count_sliding_window(img, step=stride, window_size=window_size) // batch_size\n",
    "        for i, coords in enumerate(tqdm(grouper(batch_size, sliding_window(img, step=stride, window_size=window_size)), total=total, leave=False)):\n",
    "            # Display in progress results\n",
    "#             if i > 0 and total > 10 and i % int(10 * total / 100) == 0:\n",
    "#                     _pred = np.argmax(pred, axis=-1)\n",
    "#                     fig = plt.figure(figsize=(256, 256))\n",
    "#                     fig.add_subplot(1,3,1)\n",
    "#                     plt.imshow(np.asarray(255 * img, dtype='uint8'))\n",
    "#                     fig.add_subplot(1,3,2)\n",
    "#                     plt.imshow(convert_to_color(_pred))\n",
    "#                     fig.add_subplot(1,3,3)\n",
    "#                     plt.imshow(gt)\n",
    "#                     clear_output()\n",
    "#                     plt.show()\n",
    "                     \n",
    "\n",
    "            # Build the tensor\n",
    "            torch.no_grad()\n",
    "            image_patches = [np.copy(img[x:x+w, y:y+h]).transpose((2,0,1)) for x,y,w,h in coords]\n",
    "            image_patches = np.asarray(image_patches)\n",
    "            #image_patches = Variable(torch.from_numpy(image_patches).cuda(), volatile=torch.no_grad())\n",
    "            image_patches = Variable(torch.from_numpy(image_patches).cuda())\n",
    "            \n",
    "            # Do the inference\n",
    "            outs = net(image_patches)\n",
    "            outs = outs.data.cpu().numpy()\n",
    "            \n",
    "            # Fill in the results array\n",
    "            for out, (x, y, w, h) in zip(outs, coords):\n",
    "                out = out.transpose((1,2,0))\n",
    "                pred[x:x+w, y:y+h] += out\n",
    "            del(outs)\n",
    "\n",
    "        pred = np.argmax(pred, axis=-1)\n",
    "\n",
    "        # Display the result\n",
    "        clear_output()\n",
    "        fig = plt.figure(figsize=(256, 256))\n",
    "        fig.add_subplot(1,3,1)\n",
    "        plt.imshow(np.asarray(255 * img, dtype='uint8'))\n",
    "        fig.add_subplot(1,3,2)\n",
    "        plt.imshow(convert_to_color(pred))\n",
    "        fig.add_subplot(1,3,3)\n",
    "        plt.imshow(convert_to_color(gt))\n",
    "        plt.show()\n",
    "\n",
    "        all_preds.append(pred)\n",
    "        all_gts.append(gt)\n",
    "\n",
    "        #clear_output()\n",
    "        accuracy = 0\n",
    "        # Compute some metrics\n",
    "        #metrics(pred.ravel(), gt_e.ravel(), Label_values)\n",
    "        report_path = os.path.join(saved_path, prefix + '_test_report_{}.txt'.format(test_ids[id_index]))\n",
    "        #accuracy = metrics(np.concatenate([p.ravel() for p in all_preds]), np.concatenate([p.ravel() for p in all_gts]).ravel(), Label_values, report_path)\n",
    "        \n",
    "        #accuracy =  metrics(pred.ravel(), gt.ravel(), Label_values, report_path)\n",
    "        \n",
    "        #metrics(np.concatenate([p.ravel() for p in all_preds]), np.concatenate([p.ravel() for p in all_gts]).ravel(), Label_values)\n",
    "        #img = convert_to_color(pred)\n",
    "        #plt.imshow(img) and plt.show()\n",
    "        #io.imsave('./{}_100tiles.png'.format(test_ids[id_index]), img)\n",
    "        io.imsave(os.path.join(saved_path, '{}_{}.png'.format(prefix,test_ids[id_index])), pred)\n",
    "        #print('Result was saved: {}'.format(test_ids[id_index]))\n",
    "        \n",
    "        io.imsave(os.path.join(saved_path, '{}_{}_color.png'.format(prefix,test_ids[id_index])), convert_to_color(pred))\n",
    "        print('Result was saved: {}'.format(test_ids[id_index]))\n",
    "        \n",
    "        id_index = id_index + 1\n",
    "        \n",
    "    report_path = os.path.join(saved_path, prefix + '_test_report_all.txt')    \n",
    "    accuracy = metrics(np.concatenate([p.ravel() for p in all_preds]), np.concatenate([p.ravel() for p in all_gts]).ravel(), Label_values, report_path)\n",
    "            \n",
    "    if all:\n",
    "        return accuracy, all_preds, all_gts\n",
    "    else:\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def train(net, optimizer, epochs, scheduler=None, weights=WEIGHTS, save_epoch = 1):\n",
    "    losses = np.zeros(1000000)\n",
    "    mean_losses = np.zeros(100000000)\n",
    "    weights = weights.cuda()\n",
    "\n",
    "    #criterion = nn.NLLLoss2d(weight=weights)\n",
    "    criterion = nn.NLLLoss(weight=weights)\n",
    "    iter_ = 0\n",
    "    \n",
    "    for e in range(1, epochs + 1):\n",
    "        random.shuffle(train_ids)\n",
    "#         print('e')\n",
    "        print('e:',e)\n",
    "        ee = e\n",
    "        current_train_idx = 0\n",
    "        global image_cache\n",
    "        global label_cache \n",
    "        #print(len(train_ids))\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        while current_train_idx < len(train_ids): \n",
    "            i = 0\n",
    "            while psutil.virtual_memory().percent < Memory_usage and current_train_idx < len(train_ids):\n",
    "                #start_pos = current_train_idx - 1\n",
    "                #print('current_train_idx: ', current_train_idx)\n",
    "                #print(io.imread( DATA_FOLDER.replace('{}',str(train_ids[current_train_idx]))))\n",
    "                image_cache.append(1/255 * np.asarray(io.imread( DATA_FOLDER.replace('{}',str(train_ids[current_train_idx]))).transpose((2,0,1)), dtype='float32'))\n",
    "                label_cache.append(np.asarray(io.imread(LABEL_FOLDER.replace('{}',str(train_ids[current_train_idx]))), dtype='int64'))\n",
    "                i += 1\n",
    "                current_train_idx +=1\n",
    "            global number_sample\n",
    "            print('Current percentage of epoch: {:.2f}'.format(current_train_idx / len(train_ids)))\n",
    "            number_sample = patch_number_image * (i)\n",
    "            print('Images in memory: ', i)\n",
    "            print('number_sample: ', number_sample)\n",
    "                \n",
    "            print('len label_cache:', len(label_cache))\n",
    "            \n",
    "            train_set = RS_dataset(image_cache, label_cache)\n",
    "            #train_loader = torch.utils.data.DataLoader(train_set,batch_size=BATCH_SIZE, num_workers=12) \n",
    "            train_loader = torch.utils.data.DataLoader(train_set,batch_size=BATCH_SIZE) \n",
    "            \n",
    "            print(\"len of train_set: \", len(train_set))\n",
    "            print('len of train_loader: ', len(train_loader))\n",
    "                                    #huan\n",
    "                \n",
    "\n",
    "                #loss = CrossEntropy2d(output, target, weight=weights)\n",
    "                    #print(\"Learning rate before and after: \")\n",
    "\n",
    "                    #val_loss = loss.data[0]d\n",
    "                    #scheduler.step(val_loss)\n",
    "\n",
    "            net.train()\n",
    "            \n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "                #\n",
    "                try:                     \n",
    "                    #print('batch_idx: ', batch_idx)\n",
    "                    data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "                    #print('target: ', target)\n",
    "                    optimizer.zero_grad()\n",
    "                    output = net(data)\n",
    "                    print('shape of output:', output.shape, type(output))\n",
    "                    print('output:', output[:, :, :4, :5])\n",
    "                    pred = np.argmax(output[:, :, :4, :5].data.cpu().numpy()[0], axis=0)\n",
    "                    print('pred:', pred)\n",
    "                    \n",
    "                    loss = CrossEntropy2d(output, target, weight=weights)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #print('loss.data[0]: ', loss.data[0])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue\n",
    "\n",
    "                #losses[iter_] = loss.data[0]\n",
    "                losses[iter_] = loss.item()\n",
    "                mean_losses[iter_] = np.mean(losses[max(0,iter_-100):iter_])\n",
    "\n",
    "                if iter_ % 1500 == 0:\n",
    "                    clear_output()\n",
    "                    rgb = np.asarray(255 * np.transpose(data.data.cpu().numpy()[0],(1,2,0)), dtype='uint8')\n",
    "                    pred = np.argmax(output.data.cpu().numpy()[0], axis=0)\n",
    "                    gt = target.data.cpu().numpy()[0]\n",
    "                    print('e:',ee)\n",
    "                    print('Train (epoch {}/{}) [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}'.format(\n",
    "                        ee, epochs, batch_idx, len(train_loader),\n",
    "                        #100. * batch_idx / len(train_loader), loss.data[0], accuracy(pred, gt)))\n",
    "                        100. * batch_idx / len(train_loader), loss.item(), accuracy(pred, gt)))\n",
    "                    plt.plot(mean_losses[:iter_]) and plt.show()\n",
    "                    fig = plt.figure(figsize=(256, 256))\n",
    "                    fig.add_subplot(131)\n",
    "                    plt.imshow(rgb)\n",
    "                    plt.title('RGB')\n",
    "                    fig.add_subplot(132)\n",
    "                    plt.imshow(convert_to_color(gt))\n",
    "                    plt.title('Ground truth')\n",
    "                    fig.add_subplot(133)\n",
    "                    plt.title('Prediction')\n",
    "                    plt.imshow(convert_to_color(pred))\n",
    "                    plt.show()\n",
    "\n",
    "                    print('Current percentage of epoch: {:.2f}'.format(current_train_idx / len(train_ids)))\n",
    "                    print('Train (epoch {}/{}) [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}'.format(\n",
    "                        ee, epochs, batch_idx, len(train_loader),\n",
    "                        #100. * batch_idx / len(train_loader), loss.data[0], accuracy(pred, gt)))\n",
    "                        100. * batch_idx / len(train_loader), loss.item(), accuracy(pred, gt)))\n",
    "\n",
    "                    print(\"learning rate {}\".format(optimizer.param_groups[0]['lr']))\n",
    "                    \n",
    "                iter_ += 1\n",
    "\n",
    "\n",
    "                #huan\n",
    "                #if scheduler is not None:\n",
    "                #loss = CrossEntropy2d(output, target, weight=weights)\n",
    "                    #print(\"Learning rate before and after: \")\n",
    "\n",
    "                    #val_loss = loss.data[0]\n",
    "                    #scheduler.step(val_loss)\n",
    "                    #scheduler.step()\n",
    "                    #print(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "                del(data, target, loss)\n",
    "\n",
    "            if ee % save_epoch == 0:\n",
    "    #             We validate with the largest possible stride for faster computing\n",
    "    #             acc = test(net, test_ids, all=False, stride=min(WINDOW_SIZE))\n",
    "    #            print(acc)\n",
    "    #             torch.save(net.state_dict(), './segnet256_epoch{}_ee{}'.format(e, acc))\n",
    "                torch.save(net.state_dict(), 'unet256_5layer_epoch{}_40tiles.pth'.format(e))\n",
    "                \n",
    "            image_cache = []\n",
    "            label_cache = []\n",
    "       \n",
    "    print(\"Training finished!\")\n",
    "    \n",
    "\n",
    "    torch.save(net.state_dict(), 'unet__5layer_final_20tiles_201904.pth')\n",
    "    \n",
    "    f = open('losses_unet__5layer_final_20tiles_201904.txt','w')\n",
    "    i = 0\n",
    "    for i in range(len(losses[:iter_])):\n",
    "        f.writelines(\"{} {} {} {}\".format(i, losses[i], mean_losses[i], '\\n'))\n",
    "    f.close()\n",
    "    \n",
    "    return losses, mean_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network\n",
    "\n",
    "Let's train the network for 50 epochs. The `matplotlib` graph is periodically udpated with the loss plot and a sample inference. Depending on your GPU, this might take from a few hours (Titan Pascal) to a full day (old K20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 1\n",
      "Train (epoch 1/15) [0/800 (0%)]\tLoss: 0.344465\tAccuracy: 94.65179443359375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAN/UAABCYCAYAAABaVG2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdeZCl11kf4N97e5vRjKSRNNpGq+UFYygsGbEYHEOApHDAgaScBESZbEAlJCQpQhmomMIhGFcJqJCQhIKwmE0QB8JaBkwWY2QbjGRkg40DipGsfV9merZeTv6Ya2ippJFG7525rdHzVE1V9+37nvt+2/nOOd+5Z2qMEQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB4KpN5JwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9jWZdwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbF+TeScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPY1mXcCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGxfk3knAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2NZl3AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsX5N5JwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnm6q6raq+5BR/5luq6mdO5WcCAAAAAAAAAAAAAAAAAAAAAAAA8PSq6sqqGlW1OP39N6rq7z+Hci6vqgNVtTD7LAEAAAAAAAAAnp3JvBMAAAAAAAAAADhVquq2qjo0XfDh3qp6e1Xt3vL3a6vq16vqkap6tKo+WlVvrapzpn//B1W1MY0/UFUfr6p/Or8tAgAAAAAAAAAAAAAAAAAAAAAAAHjhqqqvqqrfr6rVqrp/+vM3VlXNO7dnMl0P77ubZXxhVd05q5wAAAAAAAAAAAAAAAAAAAAAAAAAXsiq6raqOlRVB6rqvqr6iaraPevPGWO8bozxk88yny/ZEveJMcbuMcbGrHMCAAAAAAAAAHi2JvNOAAAAAAAAAADgFHv9GGN3kquTXJPk25Okqj4vybuTvDfJy8cYe5J8aZL1JK/cEv/+6YIRu5O8Icn1VXXNKcwfAAAAAAAAAAAAAAAAAAAAAAAA4AWvqv51kv+Q5HuTXJTkwiT/JMnnJ1l+mpiFU5ZgU1UtzjsHAAAAAAAAAAAAAAAAAAAAAAAAgBeg148xdid5VZLPSvLmrX+sYyZzyQwAAAAAAAAAYBswcQIAAAAAAAAAeEEaY9yb5LeSXD196fokPzHGeNsY477pez4xxvjOMca7n6aMDyb5kySfegpSBgAAAAAAAAAAAAAAAAAAAAAAACBJVZ2d5LuSfOMY4xfGGPvHMX84xviaMcaR6fveXlU/VFXvrKrVJH+1qs6uqp+qqgeq6vaqenNVTabvf0tV/cyWz7myqkZVLU5/f3dV/buqem9V7a+qd1XV3i3vf+O0zIeq6t8cJ/9vSPI1Sd5UVQeq6temr99WVd9aVR9OslpVi9PPf8mW2LdX1XdX1a4kv5Fk37SMA1W1b/q25ek27q+qj1TVtTPZ8QAAAAAAAAAAAAAAAAAAAAAAAAAvEGOMu3JszbdPn65F99aqem+Sg0mumq5t92NVdU9V3TVdJ24hSapqoaq+r6oerKqPJ/myrWVPy/u6Lb9/fVX9yXQNuY9W1auq6qeTXJ7k16brzb3pKdbI21dVv1pVD1fVrVX19VvKfEtVvcPadAAAAAAAAADArE3mnQAAAAAAAAAAwDxU1aVJXpfk1qraleTVSX7xBMv4rCQvS3LT7DMEAAAAAAAAAAAAAAAAAAAAAAAA4Gm8OslKkl95Fu+9Lslbk5yZ5MYkP5jk7CRXJfmCJF+b5B+ewGdfN33/BUmWk3xLklTVK5L8UJI3JtmX5Lwklz5VAWOMH0nys0muH2PsHmO8fsufvzrJlyXZM8ZYf7okxhirObam3t3TMnaPMe6e/vlvJvn5JHuS/GqS/3QC2wcAAAAAAAAAAAAAAAAAAAAAAADwgldVlyX5G0n+cPrSG5N8Q46tbXd7kp9Msp7kJUmuSfLXk3zd9L1fn+TLp69fm+QNx/mcv5PkLTm2Nt5ZObae3ENjjDcm+USS10/Xm7v+KcJ/LsmdObYG3huSfE9VffGWv1ubDgAAAAAAAACYucm8EwAAAAAAAAAAOMV+uar2J7kjyf1JvjPJOTk2j+LeT76pqq6vqkerarWq3rwl/nOnrx9I8oEkP53kz05d+gAAAAAAAAAAAAAAAAAAAAAAAAAveHuTPDjGWP/kC1X1vulacYeq6rVb3vsrY4z3jjE2k6wl+XtJvn2MsX+McVuS70/yxhP47J8YY/zpGONQknckuXr6+huS/PoY4z1jjCNJviPJ5nPYtv84xrhjWv5zdeMY451jjI0cWzPvlY2yAAAAAAAAAAAAAAAAAAAAAAAAAF5IfrmqHk1yY5LfSfI909ffPsb4yHQdvHOTvC7JvxpjrI4x7k/y75N81fS9fzfJD0zXlns4yduO83lfl+T6McYfjGNuHWPc/kxJVtVlSV6T5FvHGIfHGLck+dE8cX09a9MBAAAAAAAAADM3mXcCAAAAAAAAAACn2FeOMc5M8oVJXp5kb5JHkmwmufiTbxpjvGmMsSfJLyVZ3BL/e2OMPWOM3UkuSvJp+csFLQAAAAAAAAAAAAAAAAAAAAAAAAA4+R5Ksreq/mKtuDHG503XkHsoT/x/+u7Y8vPeJMtJbt/y2u1JLjmBz753y88Hk+ye/rxv62eNMVanuZyoO575Lc/oyTnu2LqvAAAAAAAAAAAAAAAAAAAAAAAAAHhaXznG2DPGuGKM8Y1jjEPT17euFXdFkqUk91TVo1X1aJIfTnLB9O/7nvT+rWvgPdllSf7fc8hzX5KHxxj7n/Q5W9fXszYdAAAAAAAAADBzk2d+CwAAAAAAAADA6WeM8TtJ3p7k+8YYq0l+P8nfPsEy7kvyi0leP/MEAQAAAAAAAAAAAAAAAAAAAAAAAHg6709yJMlXPIv3ji0/P5hkLckVW167PMld059Xk5yx5W8XnUBO9yS57JO/VNUZSc57lnkd7/WDx8np6coAAAAAAAAAAAAAAAAAAAAAAAAAYLa2rv92R46tibd3jLFn+u+sMcanTf/+hPXpcmzdu6dzR5IXP4vPfLK7k5xbVWc+6XPuepr3AwAAAAAAAADMxGTeCQAAAAAAAAAAzNEPJPlrVXV1kjcl+UdV9W1VdUGSVNWlSV70dMFVdV6Sv5XkI6ciWQAAAAAAAAAAAAAAAAAAAAAAAACSMcajSf5tkv9SVW+oqt1VNZmuLbfrOHEbSd6R5K1VdWZVXZHkm5P8zPQttyR5bVVdXlVnJ/n2E0jrF5J8eVW9pqqWk3xXjv//Bd6X5KpnUe4tSa6rqoWq+tIkX/CkMs6b5goAAAAAAAAAAAAAAAAAAAAAAADAKTDGuCfJu5J8f1WdNV0P78VV9cn14t6R5F9U1aVVdU6SbztOcT+a5Fuq6jPrmJdM18pLjrNu3RjjjiTvS/K2qtpRVZ+R5B8n+dkZbCIAAAAAAAAAwNM63n/SBwAAAAAAAABwWhtjPJDkp5J8xxjjxiRflOS1Sf60qh5N8ptJ3p3kB7eEvbqqDlTVgSR/kuSBJN90ShMHAAAAAAAAAAAAAAAAAAAAAAAAeIEbY1yf5JuTvCnJ/UnuS/LDSb41yfuOE/pNSVaTfDzJjUluSPLj0zJ/O8l/S/LhJDcn+fUTyOcjSf7ZtLx7kjyS5M7jhPxYkldU1aNV9cvHed+/TPL6JI8m+Zokf/HeMcbHkvxcko9Py9n3bPMFAAAAAAAAAAAAAAAAAAAAAAAAoOVrkywn+WiOrT/3C0kunv7tvyb5rSQfSvLBJP/j6QoZY/z3JG/NsbXs9ufYmnPnTv/8tiRvnq439y1PEf7VSa5McneSX0ryndN19QAAAAAAAAAATpoaY8w7BwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2qcm8EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABg+5rMOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtq/JvBMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYPuazDsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALavxXknkCR79uwZF+27+DnHj83NGWRRMyija7Sit8MWbIckNkdvPy4uLLRzWJhMWvFr6xut+KrePkiS5m5MbYeToXlNzUI1d0P3OBzLoZdEN37MYCPGmEU937O42LtlzmIb5n1VLSz06rZkBudTO4P529jo1fGzMJn073Vds6gblprX5XqzDXnw0HorPkl27dzRip9JHdttSzev61lcE5uba634Mfo1bPdQLC726tjNGfSJNpplrKystHPo3mtmcz71DubCYq+Onc39vltKP4tK95zs7ceFGfTr9u/f34pfWekPuSwu9a6r0Tyfk2RSveuy2w6eTfuve07PIotu/dQ8n2ZRubR3wwzawdWsY5v7YXV1tVdAkpXl3nW9Ofpt0JUdZ7TiV/c/3s6hJvMdq5hUv45e3+i1Qc84Y1c7h4Vm3+7x1d6xnDSvyaRfPXXHgpN+3TCLKnbe42+z6Ft27xNjBvfb7n6cQQLz/fzMpv037/04i3OhW8L2eL7Rz2GhOXaW5vm0vNS/33bHCQ6sHmzn0L5PNOMnM7gm2/fLGdwnNpt9w+5YcJLsaLaD19ePtnPoWlvr9QdmMYY4k3ZDxza4385Ce/RuBvthcWmpFb92tDkuP4vxlu6chhmcTu2t2BYPP7dFEs973XN6Fm3Q9vyUGfQnuvuhOx49m9vEfMetkmTSnZuxDcYJFibN9t9y7zl6kqSWW+GHDvbHQbuX1a4zevth9eCRXgJJlpZ65+Pycq8dniRHjvT6dt129EJzPDvpzzubRQXX7Q9058TOZBs2etuw0ZyXOxOnQZdm3t3C7aLd9ppFEu1xefhL835WtbKysxWfpH1hHm7OQUyS3UszaMfOWXc8eXX1QDuHbpdoaQbtt0mz7bOx2fw+UCv6k2XMv3/bnZPaH/+bxbnQS2JzBvOTawZPP/vm23IYYxbfY+mdj7P4/sWB1UOt+F27evfLI2v9Z12Thd69bjKLOrp5KNpzlWbyPeaeGezG9nhw9zlTkhw8eLgVv7TSOx9n8t2uZj2/sDSD71U158yvrXfnpM5iPLlXz2+H78jN5l7Z2w833/yhB8cY588gEQAAgOe1vXv3jiuvvHLeaQBwmnr44YfnnQLASXHuuefOOwUAAAAAAAAAAAAAAAAATrHbbrstDz744GnwPygAAAD0WccOOBmsXcZ2Yq2pY06H69KxBAAAAAAAAIAnMh8A4OQ4HerX04X7BAAAAADbzfHWsVs81ck8lYv2XZwf/6mffM7xhw8daudQk0m7jLax0Qpf6C5VWKNZQDJp7sfN9HM4una0FX/unjPbOezZfUYr/p77V1vxk4XePkiSsdk7FpPqVy/VPB82N3vX1GTSX/9zoVnGxnpvG5JkZWWlFT+ZLLTiNzb623D4cK+e755LSbL3/HNa8etrh9s5LCz06tgam634s8/e3YpPksXmzWqz+tdlt4ju2fTYY482S0hGswm3c+eudg7V3JFHmvfrJLlo7wWt+McOHmzF33TLA634JPncqz+1Fb92dK2dw+HDvfpp0ryuH3t8fys+SQ4cuKsVv7m+o53DevN+d955vTbo/ub5nCSP7e8di5e+7MXtHM46q3eveezRx9s5HDp8pBV/zjlnt+K77cckqeq1/8ZYauewOOmdk5WzWvG7d/fik+Q97/nfrfirXry3ncP5e69qxa8d6bX/kmRlebkVv77eu1dtNsdKkiTVO6fHDHLY3OzVTwuTXn+kZlC3bI5uH71/z19Y7F3bk4XeNXHzBz/Qik+SF1/6klb840cfbOfw0pe9qhX//vf8djuH5TN6dcviYm+sYvfiea34JHlg9e5W/Kuu+Zx2Dnt29uqGd/1B71juWtjTik+SSXNM+uh6v2/ZHG7J0gzGKpaXe/eqo81+3dG1ft+y+3hhozlulSQLS726ZTQP5WRhBo/cNnv7Ye3IDK6JpWbbqXlNbMyg7bW+0TshFxf6faJJepXLaMYnyZ5zeve7jaO9Y3HFhf0+0e7dvXHM9910UzuHxcXe+bSjeTqtNO8RSXKkOYa4ubHezqH7nOeii3pjwUny8pdd3Yp/6OFPtOI3m3V8ktx3b68/cGC1/6xqfb13PnSfLWQbzOtob0OSheZ2LCz0+kRJctFFF7Xi776r1ydaa55LSZLmWEX3OXiSbHbbsc1tmMX/aLq52byuZ3BdtuvI5nXZnR+T9Mcxl2ZwXXfrlrWjvecjSf9YLq/0+nXLizOYq9Sc77S01L8mdu/qPS9bbz6Ln0X778xdvedE+/a9vJ1DdlzeCv/wLf+zncLB5rTWz/rM3n74wM1/2ksgycWX9PplV17eG49Okj//s17f7u57HmnF797dr1v27u31kReX+jmsrvauy927e3MaFmfQZjiwvzev9pGH+s+qqtkCq4V+u6Oag7EbzYHQjc1+K3Q028GzsNBsQ3b7hqP64wTdY9F9/nusjF78mMHc3vaE0GYOszibF6rXH2h265IkO1Z695pDa73+xMte2hu7S/rzIj525P52Dp934ae04rvDDDWDobMDzb7hBz7we+0cztnZu7IuOqM/rr5jV2/+3erBXrtjcQb3icXqzsvot0H37++NSW9s9PZD93s0SbJjpXdNHF3rHYckqeqNO9UsKofm2Fc1n32urfW+o5ckS4u9PtHKGf3v0rz3po+04j/nsz+tFf/nd/bm2yfJrnNf2opf2dG/Jnbt6d3zV5rtx0MHD7Tik7Tnhuxozp1Lko3m/JJzL7y4ncPNH/poK/7SK3rXxGOP9caMkmSM3v3yrAv6PYoL9/S+u3Dv/fe24hdm8J303Tt73+fZtav/ffCM5nVVM+iYVe9+V3Xe7f0kAAAAnv+uvPLK3DSD7xEAwFO54YYb5p0CwElx3XXXzTsFAAAAAAAAAAAAAAAAAE6xa6+9dt4pAAAAbBvWsQNOBmuXsZ1Ya+qY0+G6dCwBAAAAAAAA4InMBwA4OU6H+vV04T4BAAAAwHZzvHXsJqcwDwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACeZybzTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7Wsy7wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2L4mJ6vgqvrSqvq/VXVrVX3byfocAAAAAAAAAAAAAAAAAAAAAAAAAJ7/rGEHAAAAAAAAAAAAAAAAAAAAAAAAwImwjh0AAAAAAAAAAAAAAAAAAADAqTU5GYVW1UKS/5zkdUlekeSrq+oVJ+OzAAAAAAAAAAAAAAAAAAAAAAAAAHh+s4YdAAAAAAAAAAAAAAAAAAAAAAAAACfCOnYAAAAAAAAAAAAAAAAAAAAAp97kJJX72UluHWN8fIxxNMnPJ/mKk/RZAAAAAAAAAAAAAAAAAAAAAAAAADy/WcMOAAAAAAAAAAAAAAAAAAAAAAAAgBNhHTsAAAAAAAAAAAAAAAAAAACAU2xyksq9JMkdW36/c/oaAAAAAAAAAAAAAAAAAAAAAAAAADyZNewAAAAAAAAAAAAAAAAAAAAAAAAAOBHWsQMAAAAAAAAAAAAAAAAAAAA4xSYnqdx6itfGE95Q9Q1VdVNV3fToI4+epDQAAAAAAAAAAAAAAAAAAAAAAAAAeB54xjXskieuY/fAAw+cgrQAAAAAAAAAAAAAAAAAAAAAAAAA2KasYwcAAAAAAAAAAAAAAAAAAABwik1OUrl3Jrlsy++XJrl76xvGGD8yxrh2jHHtnnP2nKQ0AAAAAAAAAAAAAAAAAAAAAAAAAHgeeMY17JInrmN3/vnnn7LkAAAAAAAAAAAAAAAAAAAAAAAAANh2rGMHAAAAAAAAAAAAAAAAAAAAcIpNTlK5f5DkpVX1oqpaTvJVSX71JH0WAAAAAAAAAAAAAAAAAAAAAAAAAM9v1rADAAAAAAAAAAAAAAAAAAAAAAAA4ERYxw4AAAAAAAAAAAAAAAAAAADgFFs8GYWOMdar6p8n+a0kC0l+fIzxkZPxWQAAAAAAAAAAAAAAAAAAAAAAAAA8v1nDDgAAAAAAAAAAAAAAAAAAAAAAAIATYR07AAAAAAAAAAAAAAAAAAAAgFNv8WQVPMZ4Z5J3nqzyAQAAAAAAAAAAAAAAAAAAAAAAADh9WMMOAAAAAAAAAAAAAAAAAAAAAAAAgBNhHTsAAAAAAAAAAAAAAAAAAACAU2sy7wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2L4m804AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgO1rcd4JJMnYHDl65Mhzjl+YVD+JGRTRtTE2W/ELSwut+PWNjVZ8kmw0y6jJpJ3D8vJKK37HzjPbOTz00OOt+MqhVvzGRv/SXllebsUfPnSwncPSYnc7Rit6cdK7ppJkcbFXxvLiUjuHjN5+GKN3Xe/f/1grPklWVnrn43LzfE6StaOHW/GThd5xSJLdu89oxS8u9OrYnTv6+3E073WHjx5t53D46HNvcyTJaF5TO3b2jmOSrK/34o8cbRaQZOfOHa34i/fta+dwz129+uW2u3r36y/+/Gtb8Uly/333t+IX2/fKZHGpV8a9993Xij+y/kgrPkkWq3ddbW726vgkOevM3a34Q4fXWvGP7z/Qik+SK668shW/c+eudg4P3P9gK/6hhx5q53Duuee24teb96rlM3a24pPk4KFe/XZgdbWdwyUXvqQVP9nstaMPH+xvw1957Wta8e9/3++3czg6bm/F7zv/inYOY61XR9botUEX0m+DbjbboBsb+9s5LCyc3Yqv6g1cjc1++y/p3asWFvb0U9jstcU3mm35a65+VSs+SW75ow+34q+69Kp2Dh/60Ptb8a99zRe1c/jdG/9XK35xqTf+98DGba34JLnssstb8Xt2ntPO4Xduencrftek14YdC736NUk2m9f15lqvbkqSpWafaLM5dpYka5vNMpr128IMxuW7zwbWN/rn02SpOQ7aTGFtsz9utbzUGw/uPidKkmqfDt0Hbv3zMdV9VjWDh4bN4eCz917STuGx+3t95Je/6OJW/NEj/Wvi3gO9Z01jqTcWnCRjs3c+HD7cOx+PHOqPW600205HD/ePZTWv7Uv2XdrOYTSfv+7c2RuzOWNnv0906FDvWNSk/9zx8OHeOXlkBnXD6WBzs9fw6MYnyZ49vXPyjk/c0YrvjnUkyUZzP6zN4LnjpNlu6LbFu+Nex3S3od8G3Wz2iUazP9F/kt9vxW7OYPxu0jwWO3b22gxJstk8FosLvT76ytIM+hObvfvl5nq/DXqk2f4686zesbzk0n5/JAvN9tvoPYNOkvf9n19pxW9U//nErp296/K9N97cin/tF312Kz5JfvNdN7biL730ynYOL3rpq1vxY+F3W/F339Wf03Dhxb36aceOWdxve3XDI4/09sPOlVnMg+zdLycL/f145HCvnl+cwWT1peXm/a49pN3fhnZ3oDkmvh2M5nP0pH8kZvHViUk1x+VnkEV3PudonpCz6N92t2EGj3my3pxX++kveVEr/v0f++NWfJK8+pXXtOI/ZVzQzuH+x3v3ywvO6j1Dvu3x3hhokjx+55+34s8/d287h7vu6s2X2mzOJ02Sc5vNhh3NMaPJDOZLTdLbiEMzeD5Rk+Z3QBab84RmMN5y8PHm99P602rbbafNGbSdumOxGxu9m1VVfz7okaO9caellf759OJLenXkH/3Rx1rx1zTvlUnyx7ff2oq/+povbufwe7fc1Ir//M98eSv+6AyeLYzmGOL6Rv987H7f8dFH7m3n8Bmf3huH/OCHe+2Wiy6+qBWf9Mfl77i1Pw56zit734XedVZvfvOh1f4c67Xml+T27+/nsGO59x25pebzjSTJZv/5AgAAAABwfDfccMO8UwA4Ka677rp5pwAAAAAAAAAAAAAAAAAAAAAAAKcVa5dxOpnF+dxd78o1NRvbYT9a+wwAAAAAAACAWdkOz8G3g+5+8CwfYPtSRwMAAADwQjOZdwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbF+TeScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPY1mXcCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGxfk3knAAAAAAAAAAAAAAAAAAAAAOYwVt4AACAASURBVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2NZl3AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsX5N5JwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9jWZdwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbF+TeScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPY1mXcCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGxfk3knAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2NZl3AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsX5N5JwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9jWZdwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbF+TeScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPY1mXcCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/2fvzp7tKu/0AP/22tMZNCEZIcACWchgjBjcTLbTcduZKjdJpVK50h+ovyDpSsdNV0y3bWxsZsu2zGgDEgKN50jn7DkXNEnfdFeFd3WvXdTz3L9bv73Wt771TfsIAAAAAAAAAAAAANZX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvQdcFfG5VvdXyy6eD7Bf6gybL9/NL2VtmNSxWiyh//J67o3xV1WRvGuU//exqXMOhI9tZDVeuxDWMwvYwGIyi/GKRPxPL+Tz8gLyG+XwW5bc2NqL8YNiP8lVVtcriWa/wuX5/GOWvXf8syvd64UWoqo2NcZQ/dOhQXMNymfVvk8l+XMNimV3Lre3sOlbTy/JVNZ9kz/W8jf5tlX2P0SjrW4bD7JmsqhqNs+8wm2btuarq6OFjUf6P716Ka7h2J8s/duZ0lL96NR+3bIyz9rSobPxXVXXlw0+i/HL+aZQfD7eifFXVZD/rW6rJ37iT8Lm6dWs3yg9Ged+yvz+J8rd3P45r2Ll1K8ovluEYtqr29/ei/MGDB6L83n7eR/d6WXu4/95TcQ3LeTZuaZrsXrYxZpjvZn3sc9/7XlzDr3/1y+wDlr+Pazh5z6NRfjEJ78Uqn08sVjejfK85GNeQzu56q+yZWKWT06rqVfiuWebjlqr02Q6vwyofMzz7/HNR/uVfhv1CVT14/IEo/8rvXolr+NHzP4zyf/PST6L84WP3RPmqqm+efirK/+QXL8Y1LMPnctnP5pZNuE5RVdWEz+VomK/Lp8sd/V7eNwzC77EK12J7ixb66PBCbo2yNfGqqsksnBv2wsaQ5qtqGd7LYQtzw3RpfzbP2tMi3Zuoqia8F7NwPlNVtXnwSJS/cfmjuIaHH3wwyi9n2b1sY63i4nvZnObo0ew+VFXt38kWIQfhHH3Zxvw2fK4GLaxpLxZZDa+99kZcw7GjR6P8Q2dORfnpLFv3qspfNdMW9gYW6bgh/A6rFsagq3CtoWlhv6zCMeRkkq3lVlX9/vd/iPJpe9rcyvcG0nWjZQvtqZc26lALS2fxhyxaWPPphR1cC9OyWNq3xB1kC9qYT+zvZfOyyTTbo5kv8rnlvSeyezkcHI5rOHY0uxej8YmsgP7xLF9Vq723o/xfvfBqXMP2gaw9PPpYfpbya3c/EuX/8LvXovzLL+fj6D979vEo/9cv/DSu4T/++/8a5U+ffj7KX7/2v6N8VdXOzvUof9dd2Ry/qqppsr5lNs36+F4vP4s53sj24kejnbiGSx9nY5+9/fwMYTXZGcB02NI03c/LWhkHd6yN0V86jm5DPq1qoT11XUELDbLz71BVy3Bt/4MPL0f5v3j2TJSvqvrZi9n+62NPPBPXcON6dgbw9Qu/jfJnTtwX5auqtsbZOHpvLzzYW1VHwnP//X52Lreqahaug26Ms8WKZfg7mqqqefjbh+Uq+11WVdVwlLWHdNkp+Z3iF5qj4b3Iljqqqmq6CH8XFd6HqqrFMmsPvSarod/P33bpzz5v3Mzb0+nT2XmlK7ey5/q1ixeifFXVo/efjPJ//Vd/Gdfwn/7Lf4vyL7zwP6L8d7//nShfVbV7O2tP8xZ+n7YMx7H9Fn7xOAu3u/qV7b/Opl/LCqiqfj97WT106lRcw//6u99E+f/8o+xM6zjfWqib18Jz3vHZ4qpV2KaHB/ILMQ33SAAAAADgq+78+fNdlwDwz+LcuXNdlwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAP+D/mwQAAACA/z9N1wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL6argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH01XRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqui4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXVdF0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOur6boAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvpusCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhfTdcFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+mq4LAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6arouAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWV9N1AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr0HXBfxfq1WQXcb//HKRfkZeQzNoonz6FT65/Gn2AVX1w+//2yj/0WcfxjW8/fY7Ub7fzx+LwSD7jPHGKMpP9veifFXVcpk1qOEwv47bW1tRfrGYZwUE3dIXJvv7WQlx31TV72V9y2DQj/K3925H+aqqyWQS5Xd378Q1DAbZvZjPe3ENe3tZewq7puxd/ff2w++warL2WFXV64ef0cvyy2X2TFZVHTlyKMo3LYxb3rjwXpQ/dOCeuIZvPnBXlN/d2Yny441xlK+q6oV99NsXLuQ1NNMof/Dg4Si/mOfviQPbm1F+b7KIa7hx42aU397ajvKTWXYfq6qufno1yg9Hw7iGo0ePRfnFchbX0O9n7+zVKsuPN7L2XFU1bMLPmHe/VDBbZnOa1SofM9Qqa9OzSTbuqao6+8SjUf7VV96Ia5hPLkb5M6ez73A7fF9XVY1Gd0f5+SLvW2oVzk97Wb7XyhJg9lytKn/f9uJxbDgWb6FvWexl3+HpJ5+Oa/j1Ky9H+QfvOxXX8Pp7b0X55579XpT/4MOsb6uq+uT6u1G+hSXtGoZriL2wiF64flhVtVxmfcNqnvct03nWz4/6+Tx/Ga5jTqfZfCBeK6mqJlxDnM7zOU2vye9F12azdMzQRhXZdUz7tzbWxEejbM1meCBb66iqunUna9OPnzoV1zBIn4mwPb397vvZB1TV9oFsTXrn+q24hkG4f7tzJ9ufGI+z931V/lxtbG7ENUyn2b2cz/O+4dq1bP1u48OPovx8ke11VVVdv5a16cUif1Gk79u0glULG7ir8GXVxrpTL7wQ4/BdV1U1nWTvquEw65/icU9VrZZZe+ilN6Klz8i08EyEn5GeLamq6jfZdey6b6qqWobtcT7Pn4l5OEduYUm7luGZgke+fTLKHzp0JMpXVQ0HXw8/IV/Trsr2DdN53UcXXwr//arfvZedQ3zu+cfiGo7efV+Un1W+VlF1MEpvbGT38omHvhPlq6ou/CE7k3D4SL73+dpbfxPlnzr7b6L808/8qyhfVbW7+36UT8+jVlUNB9neZ3oO8s6d/EXT64XrBDv52OnEiWzd6E8f5XPD+TzrG+Kjcy0MntKPWHY9DK+qXvotWjiLuQqfiaaNOVGYX7RwTjv+GmENLdzKvE238Ez0R1nnsDfNzgBe/G12HrWq6kc/eDzKv/hifsbm5EOno/zD954IK8gb5M3dbB21jT3kVbh3+sjD345r+PnP/y7KP/yNo1G+l54zqqrFLHuuR+P89xe9cA+5+uF5gEH+TDR3sk52Oco76aafjaXni3Sdoao/yObIq2V4vjgc91RVpUc7tjbydYIrl7LzKc9+51SU/9mrv4/yVVWXbmbv/O9+65G4hp/8+H9G+T//wb+L8hdaWDt7+NvZudrda9mZ/6qqWbiPXeHvYKqqZpPsfffk2Wzs9dKvLkf5qqoHTmXryddvXItr+NdPPRnl//aN30T5Z57I1vWrqsab2Tt/NmthvSXcQ77dwu+5N0bd/4YDAAAAAP4p58+f77oEgLV07ty5rksAAAAAAAAAAAAAAAAAAAAAAICvFH/7DL560r/ZpV9oh7+dBgAAAAAAAAAAAAAAAAD8c2m6LgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9dV0XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66vpugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1lfTdQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK+m6wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF9N1wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL6argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH01XRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqui4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXVdF0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOur6boAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvpusCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhfTdcFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+mq4LAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6GnRdQFVVr6p6vdWXzvcH/biG1WoefsAsrqFW2feYTfaj/GIZxauq6ldv/jLKP/P4c3ENH/3pT1G+t8wvxHiY3cvFLGtPs2nYnqtqc2Mc5QfDjbiG1XIa5hdRfr748v3SF5K+raqqP2jiGnZu7ET54Thrz5vDYZSvqrqzezPK95v8Xvb7R6L84cNZe66q2s+6+frgg+w6Hr1rKyugqra3RlF+scrv5TJ8307DPvbgoc0oX1V1cz/rG9588524hsfPfCvKr1p4385n2XO1uZXdiz/+8cMoX1W1s3slym+Os2eqqmqx7EX5jY2sn296B6N8VdXO7UmUn06zfFXV5mY29kmv43CYjxl279yO8qsWxk4HDmbvmtGohWdinvVPmxsHovywlXF0lp8t8vntaBDOT+dZW2jyZYJq+tmFvH7jalzDcJy1h+8/9edxDS+98bMoP9q8EOXvO/FolK+qmu5n93LYz/vYxSJ7364qa9R5D11VvbBzaaOIXnYdmuw21KqydYaqqlqE7Skcu1VVPfnkU1H+jVdfjWs4c+axKH/xgw+i/Nmzz0f5qqr3P7gY5Zt+C2va8Ts7ezAX83zMkPew+dyyCYtYrPK+oZeOpXvpe6aF9ZYW5vmx8Gssw3WnNvaqeuH7dm+Sz2+3t7ajfLrxON7O1mGrqmbh2Gt/mj/XTz5wf5QfpAOXyt8177ybvW8PHcyfiVs72btmFa4FV1XNZll76A/CpyLs46uqNjazddC9dHOiqlZhH5v20X9fRBT/6FK2ljvZ34vyVfl13NjI93n6YZNswsFXv4U5+jLcQ25jgruYZ3tNgxb2X8fj7DzALJwPTKf53mnanlp43cb7XWl7bGUcHl+H/JnIu/nwOrTwvp3Nsud6ld+IGvezccdomB8j/M7Tp8NPyPLtTE3TsU8+p6nK+tg3f/5ClL+8k+0ZVlWdOXMiyl+9kY29qqomy+w9ce892ZmIqqo7e+9F+Q8/3o3yJ08dj/JVVbPpW1H+8Sfytdif/e1Po/yVe38b5Y8fy/eqxhvZvdifZGe+qqo2wn3HAweyffA2+ujJNOsfxxv5eYJ03HDkyOG4hFu72RrgMhy/pecRPtfCYLxj8VpHS3UkWhgGx5/RW7VQxDKdUITPRPivt6G3Bs9U+juU27v5GPTjj7NzOt9++MG4hiu3su9x19FjUf7CW29G+aqq7z+c7W+88+mluIZaZWP5q1fzM1tnzjwc5S++k92L43flY/m7D2brb22caZiHe27pmlHTxk8mwxpWs3xNu3rZulPTtPB7x/jMVffv23l4NrhJ9/yqajDILuQyXNT+4X/4iyhfVfXjv/xJlP/aoXzt7NiRbH77xusvR/lDh++O8lVVt8P1t+3tfM9vZ5atgy5bOC9VvayPXIR7LKe/kf+O5dKVG1H+3nu/Ftdw8+a1KP+NY/dG+fc//CzKV1WdvC97rlaT/H07vZOtxc7CZ6qqanj4UPwZAAAAAPCPOX/+fNclAKytc+fOdV0CAAAAAAAAAAAAAAAAAAAAAAAA8E9o42+GfRX+NqO/nQYAAAAAAAAAAPxLcGYLAAAAAPgymq4LAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6arouAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWV9N1AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr6brAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYX03XBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvpquCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgfTVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mq6LgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9dV0XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66vpugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1lfTdQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK+m6wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF+DrguoqlrVqubL+ZfOD/v51+g3Wb7preIaprNplD+wtRnlhxtZvqrq5q2dKP+LV34a1zAKb+ZisYhrWM6z9rBYZPk2noleL7uOq+UyrmGyfzvKN9XPCuhl8aqq4SC7F/t7k7iGXtg/9ZZZvh/ehqqqjdFGlF8uwk6+qra3suvw2Wdf/j33hX4/65/uuWc7yo+Ged+ynGXXYbnK++jFMmsPB44cjvL90TDKV1X9+uevR/nvPvO9uIZPr3wa5Q8dOhjXMJlmY6e333s3yp88mX+HgwfvjvLj0Siu4ZPLl6L8Yj6L8nem+btufz9rC/0WXlajYfZsr5ZZ/7ZaZvehqurAOGtPx+8/EdewuTWO8stFPoDb3M6e7V6F445l3h4Xi72shFWWr6qazbNxx7CX3cvFKusXqqr2Jnei/GiQt8etQXYdb/duxTU89dSTUf6tN34T5Rf1fpSvqvr6Paej/DJ8z1RVxVPkJp3T5OtWvV72JeL+sar6vWxOsqrsfdurfK1jFd6KNt51o3HWtzz25DNxDa+++nKUf+ShR6L8Sy+/GOWrqg4fPhLlh8P8nT8P15ObcB01zVdV1Sp7rhbzfL2labLnahmu5VZVfB0qHDu1YZm/7FqpI5H20W3ch0E4t9wL+4Wqqus3r0f5rXG4ltvP5oVVVRtHjkf5w4sW1nLD9jCf5fP8jy9fjvKL3m6UX83z9eSN0YGshuV+XMNkmt2LQbhPNG2hLfTS/qmF/m0WXsc2Nu2aJht/pXufW9vZOPzzIrJ4f5CPQWdhm5xNsnfVqIU18V7YntJ8VdU8fNcsw/XkqqpVuAecamMEu0ivQxtD+fBD0r4lH4fnc6I2buYqHIyn+fQSVFWNwj3gzc38PbG1mV2Hh791Mq6hVtle0WqRtemmfyPKfy4dt2Rn56qqXvjxL6L8IlzHfP6Zp6J8VdW1m59F+VMPPhTXcPlKtg/+8ZVX4hruOZ6tYzaDi3ENqe3tQ1H+wPhoXMOjjz4Q5a9/lvWP7/7hv0f5qqo/ezp7rsbjrbiGdAw5maRnO7qfW7ZxxmZvP9tLP3AwW+uoqrq1m9WQroOuWriX6VpFvNZRVemEIJ5Sdb+s30oJ6VnzZQv7r/nkrtv5yOe6fyb66W8PwvMELSxb1aWPszHoI9/M9n+rqoY3snX1t9/I9tGf+9b9Ub6qaq+Xras/dCI7Y11VNetlv2u6tJPPy9Lz6g88+FiU39l5L8pXVa1G+Rnn1GKZ3YtmlXUO8e+JKh/7tHC0t5rwfEm/n+99LsN3fi88+xa+Zqqqaj7PPmTjQD6W3zyY7aXvz7O+95az4AAAIABJREFUaXErXzt74uyZKP/6a7+Nazh7NutjP/ksGzO04bWXL0T5H/zgbFzDVjg/3b+dnbGuqlqEE6vd29m45f6vH4vyVVV/+uiPUX46zfvoVXjuLJ1O7Hya/x5o9+7sOozDcxlVVatws2g0yNeddu9kv6UGAAAA4Kvt/PnzXZcAsJbOnTvXdQkAAAAAAAAAAAAAAAAAAAAAAMA/4G+nwVeTZ7sd/n4aAAAAAAAAAPw/beyjO9MAwD/GeS0AAAAA+JfXdF0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOur6boAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvpusCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhfTdcFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+mq4LAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6arouAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11XRdAAAAAAAAAAAAAAAAwP9h58565LrP/AC/59TSC5vNVSS1kKb2XRYl2hMh28CDuQkmX4CfK7cD5IrfIEHiIEEQO7bHpiVrl6xtrM2iKIlNNsmuru3kYuYiyEUQ6Hc8VQ6e5/5X/dZZ/ns1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurXXUBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvdtUFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+2lUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6alddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq111AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr3bVBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvoarLqCqqmmaGo3a750ftF0PNXz/v19VdXDvIK5h9/jxKD+dzlaar6oajkZRvm2bvIbhIMp3i3lcw7KyZ3JreyvKTybTKF9V1XXZZ8ym+TsxaI9E+Yfuz67jrf38OzRt1syOBtnzXFU1D9/txXKR5RfLKF9Vdezk0Si/ezJrX6uq9veztuFI9jhXVdVovBnlt49sZwV0+b2cLbPnsZuF36Gqdk9m79X1b+9F+b0P96J8VdVLL7yc1fDdzbiGU6dPRfk/fnU9rmG0mbVPzz93PsrP5lnbVFV1c/Zllt+/E9dw8vSZKH/rVvY8jcLxY1XVZmVj+dF4I66hbbMa7t3L2pbjx05E+aqqnZ2dKN8MsmtQVbWYZf3t0aN5n7+YZ3OSxTydl02ifFXVcJi9V4PKxhxVFb6VVdWG85FJPpbfGIft08Z9cQ1dl7UNTT58q66yD3n2+Vei/Hvv/ibKV1VtDj6I8g+ceSKu4SCcp7dNts4wXxxG+aqqprL+smnyNZ+uS9dswjXEcP2wFz282MsuG0cPe+jzn3v++Sj/zrvvRflnHsvf699/9GGUf+yJi3ENX37+WZSfz7Jxy3CQv9fTedY+jUf5FsfBQTZu2N7K1yrm8+zdnkyzfiZd16+qGgyzexFegqqqWqZbReEjvexhbyHtqu7c/C4uYXMze6bvLrM5zQOnz0X5qqrFXnYdTp/P1oyqqg4OsrF8H+/EndtfR/mtzaxtuHuQz2/n4f5EOp+pqhqEY582HAfP5tk1qKqazLLnsR3k/cTWZrbWcNDD8zQYhHt2G9mc6CBc/6uqGoVjn8NJPjds4zFg2NnlR0N6+JA+2pbsOrZtvod8797dKD8O34lhD/vgyy67l12Yr6pKlzuacG9hGI7Dq/Jxy2CYrxO04fcYhWvifax1LJdZ27Bc5H1+ddl12L+Z91VHT2TndJr4kT6WfkB9/oe3ovxrr2frVlVVp+87GeWffCZb+9rbz88TPPzwj6L8519l96Gq6s7drK97+vGn4xpu3v44yj/62MNhBfkZwq+vfxvl79z6aVzDxjDbA755M1tHHY3zNvr69RtR/vxD+VpFOg4ejbP5xN7efpSvysdOTQ/nk9Mzzvmcqmo0zjrMe+G+5SAce1VVhVuf1cOtrOqyD4nnEz3MR9J1p66fSXaoh+sQPhDLRVZDH/vg6XdIfwdTVTWZZOtvm+H5u66H3wO1G9l1+PDvP49rePyR3Sh/9r6sz4+PVFRVE76Xkx42OE7cn51Pfu3ta3ENjz7zUpRPf3/RdNmzVFV1cJjVEA69qqqqacLfdoWPUxeej6nK1yAXPfz+oklPY+YLLvFZo66yBmoerr1VVR05kZ2R3j2Rv5eLcH9hGZ7zmYRrJVVVp05n59XPnsvPu3/0yUdR/snHn4ryb7+fr//95b/+myj/n3/6H+Ia/u3f/GWU75bZeYSqqsntbK1gazv7od7X1/N10Esvno3yv/xV9jxXVT3y6ONRfnKYrRM8/oN0DbPqf/zPv4vyf/WTv4hrGOxm/e28h98utE0Pe0UAAAAArKWrV6+uugSAP4krV66sugQAAAAAAAAAAAAAAAAAAAAAAOD/4P+fAfxp+P9rAAAAAAAAAAAA/+/SM1fOxAIAAADAn5921QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL7aVRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqV10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurXXUBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvdtUFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+2lUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6alddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq111AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr3bVBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvtpVFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mpXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66tddQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK921QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL7aVRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqV10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurXXUBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvpuu6VddQTz39RPe3//7ffe/8YjqPaxiNN6L8pUuX4ho2xyei/GSyF+V/+8YbUb6qatE2UX5Y+fO4NWij/HyxjGuYLxZRfjQcR/m2HUb5qqrJQfY83Xd6N67h2M4oyo+aQZRfhPmqqtv7d6P89DB7lqqqBoOsfeuWWQ1ND/1MM8rey3nl93JrM8tvbmzFNaStU9rn99G2LBdZDeNR1i5UVb378fUof/bEuSx/NstXVR3cO4jyG5tZu1BV9fHffxLlT53ejmuY3JtF+Rtffxfln3z28ShfVXVrP6vh5rc34xp2d45G+Z0j2b2cHGR9ZVXV5PAwyo838neimmwcvH97P8ofOZrdx6qqja2sr2p76POPHtnJamjzfmKxyO7lcpm1TcvFNMpXVW2Ms7F4t8jmI1VVyybrq9L8uM3HXs0iG/ssK1+rqCZrn5ZNNj+uqlp22TsxGE3Cv5+PQX//7ntR/uhuPp+4eOGpKH94kF7HLF9VNRofzz4gfJaqqmqZfY+uy96Jps2fhdSyh/62a7LP6GM1eTjO3u07d+9E+XfefDvKV1Vd+uGLUf71N38b1/DE4xei/I0b2frf/v7tKF9VNRyF72W8WpKv5bY9tA3tIBvHzufZdeijiV6E7dOyh7XYLhz7bG1k96Ht8vHfnVvZezke5uO/b29nY/HjZx+I8gc3sza+quqVl38c5WeTfOzUhuuYH3yQ79kNw2d6EK4Hz6bZ/LiqajrL1nx6aFqqC9e0u7CNXs7zfaK2wv3bcQ/rBOn+xCCfGy6WaQ3Z32/bvI2eTrP2qQnnAlVVW5vZ8zA9zNqG0Sh/HhfztM/OB0/pnehh+FbDYdZPNOHZkMkka+Or8rZl2EPb0oV3cxnuxXddPicaDrIGbhyOOaqqNsK+ZjbN1tUPw32mqqrRMHueNnvYq9q/nc3TT53M92+ffuFfhJ+Q3cu/+/kvw79fNZ1n7dup09n5v6qq46ey/bIH7s/2sfen2R52VdVymd3LX/wsXzs7f/5MlH/uqcfiGqbLrI19//0Po/zX17+N8lVVFy88EuX39vIzDffu3Ijyp04fi/KDcA2zqurUyfui/MkTp+Ia0inJ5G62bnUwydcJlmEbfet29h2qqo4cyfah797L150Wy+w63Pj2VpQfhuebq6qa8IxN/lbmZykrXGfoY46ezg3D21BVVYNwbjjvYe8znRum+XR/5B/0MdPPpPtdi3AdtBnk12AQfsaozddix202t3vgTDZumd3L+7pBOL+dhc9CVdWgCfuasK+sqnrn82y/6uFHsr38U6ey+UxV1bVrv4jyL5wPzwlV1cEs23escC131EP72oS/T2t72L+dzrL2adbDXtNoHLaxG9l12O7hjPQw3N9I95mq8v2udF616OFI63yerfmceeDBuIaf/desfbvvxOkoP97I11E//SL7TdO//Kt/E9fw81f/e5R/uYff0hze+ibKp2e+hqN8n6gNz6uPxnk/8c572frbufvvj/KLLu9nTp/K1s5e+/1v4hpeeSk7a7R/kD3PVVWj8Czk7vYjv+267nJcCAAAwJ+5y5cvd9euXVt1GcCauXr16qpLAFhLV65cWXUJAAAAAAAAAAAAAAAAAMCKXL58ua5du7b6f5IOAACwBvwfO9aJ/50G8Kfj/68BAAAAAAAAAAAAAAAAAGT+b//Hrv2nLgYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAPx/tqgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH21qy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXVrroAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZXu+oCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhf7aoLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9tasuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11a66AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWV7vqAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYX+2qCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgfbWrLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9dWuugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1le76gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF/tqgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH21qy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPU1XHUBVVXLZVN3D75/KWcfOBXX8MMnXo4/Y9U2N49H+R//6C/iGn7x619F+fmgjWuYLpZRfjQcxDWMRtln3LlzJ8oPhvl1PHnyWJQ/cXw3rmG5mET5pm2i/KCyfFXV7pEjUf7rg2/jGobDUZSfLw6j/GiUX8fZbCvK7+SPY7Xha9WFbVNV/kzHj/Q8v5eb21lfde3t9+Mann/kmSjfLbN7eS9s46uqdnazNvqNt96Ia3j6mYej/Gh4Oq5hb3Ajyt/c24/y+7e/ivJVVadPPhLlTx0/F9fw+u9ejfLnH7o/yo/Hm1G+qqodjaP8sotLqPE4q2G8kV2H+XwR5auqNsPruLW1HdewCL/Hssv7qqpsLD8Mx+Lp89yHeTgOr6pqKnuxBt1GlO+6fF7XNfMs38N8osLrWJW3DW2b1dA22bhlb+8PUb6q6sLFC1H+i8++iGv47Iv3ovz5B7Mx7PQwXwJslveifNccjWuYh2Pxpgnbpia/jl3Xw8AjFLdOXT6/bcOP2NnM1luee+7ZrICq+sOnWft06YUfxTW8++G7Uf7y5Ww+8t67n0f5qqobX1+P8hvjvM8fDLK1s9k8fyfC5eQahtdh0MMYNL0Oiy4ft+zfvRvlmy57Fib3snWGqqrTJ7L9rnHawFbVzon7ovxnX2Zr2v/shZeifFXVZJLNaY7t5uOWV3/36yh/9Ej+Xt49yNb2p12Wz+czVRvjbPw1maTfIR87deHYabTRw3b+MlxvWUzjEmbzbI6drtf0YWsrXMfsoa+bHWbP9JGdbBzdh3Tfslumz1LVbJZ9xmCQP49Nk7UuTZvXsFiEz+Qy/A5NfqZhNk3b+byGdD14FL4Tbbp/XFWjUVZDH33+bBY+j+HzlO7RVFXtbGdtbB97yCeOZ23D0y/8q7iG6rL5wH/6j7+M8mfvPx/lq6q6SXYvLjx8Mq7h1d99EuU/+jTbx77v3JkoX1U1HGbt00/++idxDde/yNadfvGrN+MaRsPsvNPubnbgaTzK1ypqkPW3L7+Un0l9//3/FuW3trN9xzt3Z1G+qurGN9n5lmPhs1BVtQwPRow3s+f5cJavW6W2w/66Kh9BTg/zOc0gHEP2sYudSmto0sOcVdWke3bhl+h6WCfoehiLp5ZpDT08kE2+ghel2x6+xDJ8HvvYg16E/URaQ7fs4b0O10umeRNdk/DM1fhWth586li+v3Fr71aUP5Kuo1ZVNdm9bHr4TdKLD2Xzorc+y84T9NFfP/fsi1H+rTev5TWEZ80nt7+O8ofTfCw/CPuJYQ9t9LwL92kG+RM13MzOBx89np0hXIZnvqqqpuGZhnROVVXVhHtuw0HWT6S/g6mqGoXnSyZ38rWKf/5K9hvgn/7051H+0qUfRvmqqnPnsjXEn//sv8Q1XLj4eJTfv5ed0amqOn3iRJQ/OMjeqdnsIMpXVXXhOe3t7Xz89uAD4ZmtsG1YpnuOVXXzZra3cOG+x+Ia3vn8wyj/7EMX4xpuhWMfAAAAgP9fXb16ddUlAKylK1eurLoEAAAAAAAAAAAAAAAAAAAAAAAAgH8S/v8aAAAAAAAAAAAAAAAAAMB6a1ddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq111AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr3bVBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvtpVFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mpXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66tddQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK921QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL7aVRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqV10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurXXUBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvdtUFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+2lUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6alddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq111AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr3bVBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvtpVFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+hquuoCqqs2NYT3x8Onvnb/4gxfiGhZh/q1334prOHPuXJS//8T3v4ZVVaNmM8pXVT39+FNR/u2PP4xrmEwnUb5bpk9DVbNcRvlHHnkoyo83BlG+qmo6OYzys1mWr6o6spU9k/PD8FnouihfVbW9uR3ltzbGcQ17t25G+fkie553jh6J8lVVx45l+cFgI64hfR76aFvatllpvmny5/FXr74f5V+59FJcw3SatU/Lpo3yw9EoyldV/frV30T5F198Ma5hucyep/n8VlzDYnEnyl+4eCbKH93O8lVV82nWNgyGeZ//7LPPRfl333knyj/4wNkoX1W1tZP1NZP5PK6h2uxeNG3Wtuxu5f3tKGzflvN87DQLb8Ug7OuqqobhvaxwzLAM5xJVVcvKLuSyZnENgy7r7wbNVpTPn8aqRZPNJ5rKx05N+EW6Ln8nmib7jOnhN1F+d+d4lK+qGoyye3Hh4YtxDV98+nmU/+bml1H+zMnHo3xV1eLw6yh/cPhpXEMzOp/lm3CtInwfqvK5ZfpO/mMRWQ09NLLzw6yvacNxy7Fw/FhV9cHdbE7z1vtvxjU8+Wi2Fvvqax9H+R9ffjbKV1W98042J7r13V5cw/b2TpSfHObziUUXjt+WYQ3LfG55995BlO/CMWxV1a29bNzxybdZ/tFHLkb5qqqPdSMiAAAgAElEQVRpuE5w6eX8vfzNq+9F+Z2NbE38g48/ivJVVUd3svnEJ5/kbXSTvpfhnKqqahAOG2aL7HkcDrP+uqrqIGxb2nSOX1Vbm+HcLhx73bm7n/39qtpI95rypYoaDrIahm1+rGF6OM3yB9nzuJE+S1W1He6d9jCbqNk0u47LcNwxaPP9tnG4T9PDFnIt12BuOJtn87LZLLsXy2V+ITc2sj3gRQ/7t6Nh9m6n93IR9tdVVYfh2ZDBIO/z0+sQvxPhOkNV1cG9bN/ymSd/ENewfeKxKP/tZ6/HNbz+1mdR/tixbM1mJ5uOVFXVzb3sXr773ldxDdtHsjnNibPZ/uu8h1HD9a+y6/DlH67HNZw6dirKz3s4+5YOxZ984lKYv5AVUFVV2Rh0WfnZkCefTM8KZe3862++Fv79qqbJJlYf93Cu9sGHHozyg0E2lp/PexjLD7Px33yQr0He3rsd5UfDfM1nGo7FU00Pu/GL8EzqPJzP9CHd8xuG71RVH2dk+jhZsQbCy9CG/UTXw3XsuuydWIb5f/iQLB5fhR7OtyzCtYbBIG+j5+E5xBs3s35mvJF/h/FWtnc6nWXrh1VVzSJbi60ezt/V7okofvF0dh3DrrKqqg4Osvntw088H9fwx2/+GOXPHM/mx72Mmrp0HbSHcfBm9m4fPZY9j1VV6bGIadjOp+PHqrzPbns5s5XFD8K9qp2d3ayAytdiJ+F3qKoabGZj6R9fzn478eob2W8nqqp++GL2W+jvbn4X13Dr5rdR/suv7sU1nL38aPYB4b7hvIc9ls1w/HVrLz/79uBD2Xrwa7/NzsicezA7w1hVdXBwN8qPN/PfxS++y+aGd8/kaxXHdsMf0AIAAACsqatXr666BIC1dOXKlVWXAAAAAAAAAAAAAAAAAAAAAAAA/G/87zQAAAAAAAAAAAAAAAAAAAD4ftpVFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8L3buo0uO6zwD8NfVPQkzRCKEQGQmkQANEQKDgmV7IR9roaVX+IHYemUd2paPaIo+tClRFsVMEAATSCQiAzPT08EL7rzwQm/ZVUd6nv3b83V31a17v3t7oL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL+argsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoL9GXRdQVbW4uFLHjp76419gPolrGA6yj2JzcxzXsH1xJcpvhX9/IcxXVe3dvT/Kv3f+o7iG1eWlKH///u24hsf274nys9k8yu/ZfTzKf1vD3Sj/1ZefxTVsbWX3djPM7utJ+PerqtY3N6P8zt274hru3L8X5VdXt0X5HTsfifJVVdNJNsKNFgZxDZvjWfYCzTCu4ZGltSh/91Y2vl26fjXKV1X91UsvR/n79x/ENQxHTZRff/Awyn/+RT4+vvzSC1F+c3MjrmEWzr/u3LoR17Br14EoP59ns59JOCxUVW3Ns+fE1mY2Z6iqWlvNxpZ9+7Lv4fJXl6N8VdUzzz0b5ZfCOUNV1Sx8Vm1bXIzyw6aF95BeTvP8eTscZM/LwSCvYTYPb+40X/l9XZU960aDbE1VVTVssmu6abLvcrz1TZSvqhoNs7n4bJB/l5Np2GsYZNdCVdWwsvuyCWsYVH5fpwPc4kLeMTl45GiU//rLL6P80kLeb9m+lj3zl0b74hq2ttJ5bNZ7m8/Xw79fNY+fl/l9XfPsnmjlvgyfd+FbqPX1vJd74uRzUX4yncY1fHj+4yh/+MChKP/GG29F+aqqH7x8Jsq//+47cQ33HmS9huFCPndaDNckg9FylF/fyMe3Bw/vRPlbt27FNWyOs57NE8eyvvrOHdm+QFXV8YNZL3Z5Ma/h3s1sb+AvTn0/yt9qoWd05PjeKL9zLeu9VVW99ea/RPnNjftxDenzdmGUjU3jcbpzWbVtJRvfapY38B6EPemVlWwOurAQfgZVNQ0nT7NZPm8ZhXsk0xbW2IsrWa9iM5wzDIb5XL5Jv4sWzlVMJtncZ2kx64nXPN93bJps7jNtYW9gocl6DfN0UVQVtyEXw572rIUxejLJrunxVr42TFfIC2HfadBCPznuVDQtjG/pc2KaXQvptVRVNZ5lr/GH9y/GNcwmF6L89l3ZPLqqanl/Nnf54emfRvlX/vkfo3xV1XJ4Rubg0SNxDZOwD/r1F59H+YUmn4Me2ftYlP/o4w/jGnaczOZOJ0/+LK6ha1vT/IzNxsbX4Svk/eTV1WwOeOVKdl5qfaOFPehpePZtewv7t6Psebu+nvXeFpay+WNV1baVbIz+9NKncQ2zSTb/Wt62GteQ3ldNmJ9O8j5BOjS0cDSk5mER6fmUQXgm4tvXCOfi8fmWqnkrZ1wy+d5l9jm08QkMw++yaeGmmKTr9DTfQv8vraGFlk98XzbhGcCrN25G+aqqxw9nc/n1cX4+eRyu09MziFVVW+HvLx7Zls1bPvniUpSvqjp07Kko38zzZ/7mLOt9bZtm49vGUj4+pj3EpTbGt/Qs5SS/J5bD/a4797I96DbOBqdrohZmwTUM94q2b98R5Tda+O3raji+tfH7262N7DV27diZ5Xdlv72oqrpwMRvnjx/Le5CfX8p6iE+deDGu4Re/fD3K//zvTmcFNNm1UFV193bWd1pZzM8n376enS8+/UJ2DvLXvz4f5auqnv7uE1H+Xvicqao6uDfbI3mthbOUP//rH8evAQAAAPA/nTt3rusSAHrp7NmzXZcAAAAAAAAAAAAAAAAAAAAAAAAA8GfD/4ADAAAAAAAAAAAAAAAAAPjT1nRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD91XRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD9Neq6gG/Nq2rrj0/PFvIKhln+xee/H9fwzc1vovzvPnovyv/k+y9F+aqqbx7ej/Kj2TyuoalZlN++thLXsLa2FOWvXMuuhQuXrkb5qqpmvhnln336SFzDoBlE+WbYRPlhZX+/qqppshoerj+Ma9izd0/2AuHHMJ1NsheoquFCNs5PpnkNNczu67Wd2+MS3v/gYpTft/tQlD9z4ukoX1V14/q1KL9tbTWu4eJnn0b5Rx7JroVTJ09G+aqq8dY4ym9uPIhrmM2zwWHnrsfiGgaVjbGDyuYdG+P8c1wfZ+P82lJ+T0zH2Rh59MjxKD/eyp91H374cZQ/eDift+xcW4vyC+H1WE2+tJtM07l4dk9WVQ3DuVMb5vGSJHuB2XyaFlCjwWKn+aqqyTR8Vo3vRPmFYT73GsyyZ91gmK1Nq6oms+xzbJqw2VFVC4Pwvkzv6/B7qKqaTrJn3Twdo6tqZTkbp3fv3RHlL1++GeWrqjb3fh7ld+54Nq5h2GTzr42Nr6P8ysreKF9VNRiE11P+oKp4od/CPdEMsvFpMMjuqUk4LlRVDcP512gpf94++cQTUf7ShUtR/rkTeU/8N2/+V5Q/czpfY3/w0fkof/PO7biGZhSub0dZT3tjI+sFV1VNJ9m8ZWuyHtewc2f2vHxwN+vLP/541nurqtr36Pei/IV3fxfXsGM168UOw77+gQN5z+iTjz6N8i+cydcTz504HeX/0MJ3md5XG+vZ2HDw0LEoX1V1+1Y2xrYxvh16LLsmR+H+xuUrV6J8Vb5fNpnm69t5uDbcDHviVVWjUTZ/W9mWPW9ns/xzrMrm0bO4/1c1m9yL8hvTbB68uroR5auqap7dl9MWrsf5KOsBzlo4V1GDcC8+vK+nLezfhm+hlhaX4xpS00l2LaRzr6qq4TAbW+YtXI+T8EzBbJ6NsQuj/NzZoMn2kB88yOct39l7IMpf/vqzuIZdOx6N8q/86pUov+dIvi4bj7P78t13P4xrOH4o27vc+53DUf7yFxeifFXVxUvXo/xSfnyvrn+c9cUnj74R13Ao3Ie+dSvbL/vgo6z/V1W1vJKtkc+8cCKu4caNr6L8g/D83dJS/qybh/Pgu3fycxWfXvo0yj/7TLrPk+9bnv8oG2M31vP1xEJ4hjA83lxVVZub2bwhPZeR9jqqqiaz7Hk7baFXka4nKtxHH7RwPibt+bSxtkzXA4MWzmkPwu8ivZqaNvZv0/PyLawN51t//G95qqrytlMb++DZazTxwFA1GmZj5Hgr6+unZ2Krqq5evxHl9+/O91hubmbz4PFW3ndaXMhGh4cPsz7qqe9mZwGqqn77+w+i/DOnTsU1PHUsex+/evM/ovzfnjkW5auqbtzLfiPXygQwHJ82J/n4tnE3+xyWlrN59HSan6udTbLvIp17VVWNhtnacJA+q1rYq7p5IztXsbgQrqmq6v7dbA/5dnhO+8wPz0T5qqpXf/nvUf7enexZWVW1f+/+KH/h7dfjGn7+s7+P8v/5xj9F+Zd/+HyUr6ra2sz2DWfj/LxUeu5s427Wy/3Bi/lvcc5fzHq5q2vb4hru38/mb3956sW4hl+8kc19AAAAgD9N586d67oEgF46e/Zs1yUAAAAAAAAAAAAAAAAAAAAAAAA94/+3Afzf8T/gAAAAAAAAAAAAAAAAAAD43zRdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAfzVdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAf426LuBbg0pKmbdQwXSW5ReavIavN+5H+aVD+6P82+ffjfJVVZcvfhbljx7eF9cwmG1F+fXNLF9VNd6aRvnDhx6L8u+8czHKV1Xt2bs9yg9H+U0xHA6j/HhrEuUns3x02Xj4IMrP53kNSwsLUX42zwbI+XwQ5auqRouPRPlmuBzXsG20EeV//9b5uIbnT52O8hvr61H+q6tfRfmqqt07d0f59957L67hiSezZ832HYej/NbsbpSvqrp9J3uNjY38Wbdv38EoP51lY3xVVQ3GUfz23WtRfnlpR5Svqtq5diDKD5pwEltV42n2OW6tZ5/jscNPR/mqqgPT7Jp+7+MP4hpWjh+J8gvbFqP83bt3onxV1cJCVkMzyJeXo1FWQ7Uwd7p9+2aUX1vL5tHLy6tRvqpqHs5jJ7NsHl1VtTW9HeWHTTjGDrM5cFXVeJ7N/ypbFlZVVTPI3se25aW4hslW9pyYTLZF+dHwYZT/VrY+bZp8fJuFj+zVbWtRfr5vMyugqq5fzfpW88rn8ru2PxHlV1az9chsmq9vq9L5Wz5GDwZtvI/MfJ4Oklm+GeafQTPMxoZJOA+vqloN55DLK1n+7Xd+H+Wrqp5+MlsPvH/+UlzD8Scfj/KTTz6Oa7hzN5u/jZqs57O1mY3x39aQvYf9u/K9gZvhXP6ZHz0f5Y/uPxnlq6reeuuXUX78MJ//vfSDH0X5d955J8oPRtn8sapqKZwHv/pv/xrX8Dd/9bMof/r0i3ENr73+apRfXs6+i/t3rkf5qqqmsmd20+R7VVeuXYnyazuyPsE83KOpqpqHU8hRk/dyJ+OwiBZ6PrNJ+Brh5dTG9Zi+xuZG2OuofN9vaSmbR8/TL6IqHFmqBk2+nphMsntiOMrvy8E8+yyn0/C+HrRxT4TPiRbWx014pmE+C9e3LYzRFY4tW+m1UFXztHkWnhzbvWtn+Perrl//Jsrnn0HVtWuXo/zJE8/GNRzYn513evW116L87H7+rDv62KEof72Fg4yff56dL1lazO7rA4/tifJVVdcuZ3vIR/dkPfGqqpt3s+thfSPfG/jtb96O8oOwj7m42MJ+2Wa2T/PB+x/GNTx34kSUf7j+aZQ/fPjRKF9VNQ3nf7dv3opruH03q+HLK59H+YP7s/G1qurwkew12jjTMNkMz1LGFeTnamdhFeNxvr+RrmlaWJZVheuB9LtsY/43TftGLayJBunaroWeT9fa2XoNX6SNc9rh2JK+h3ncsenH5TQL98GH4R50C+2WerCRjfN31/PzyY/szNbpN29ka/SqqiY8ezYOz2nfupO/h+8+ne2/Xvjkk7iGo8ezvfif/vgnUf7Xb/4qyldVvfBU9ruBe7O8VzEL+29t/HB0FM7f8jE6H+DSMXrb8kpcQ7o2HG9lY8tCC32Ce/fuRfk2fiO3c1e2/3ovPHN/9YsvonxV1Ytnnovyr7/+u7iGl76X1fBgX37O5xev/EOUf+nMD6P8x+e/jPJVVU8/lfVSr11t4cz+JBvfFqfZGL/cwpn92Wb2u4O1fd+Ja/jmZnbu7PqNG3ENPzrxQvwaAAAAQL+cO3eu6xIAeuns2bNdlwAAAAAAAAAAAAAAAAAAAAAAAAD8GfC/zwAAAAAAAAAAAAAAAAAA4P9H03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPRX03UBAAAAAAAAAAAAAAAAAAAAAAAA/83OnXXLWabnAX7qq2lLe9IsQAjU0EhCYsZAj3ay7F+hH6jDHHolzvKy03SUtmncCDODhBgazfOeas5Bx86hs7hrrSo713V+l5791ffObwkAAAAAAAAAAKk2N6cAACAASURBVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dVZdAH/atL60dHZHP752TT8gCav4cQTx6L8pf/5v6L8k2ubUb6q6uBaL8o300lcw/ff/zHKHzi0Edews7sX5Tc2D0f56WwQ5auqTp16Mco3NYxraDrdKD+a7ET5rcePo3xVVaebtYnOj+8a/1Wrsg/ptLPvIX0GVVXVbkfxRzvbcQl//PpOlH/15dfjGkbDrF2Nx6Mof2jzYJSvqnr/4w+i/NtvnItrWJmtRvndYfYu3Lx3N8pXVR0+kI0TB9bz73I6zcaa2XQc13B/K2vbq2sHonwzm8MEcJSNVaN2PnfanexG+f3NepRvxvlsfqW/EuVPnnw2ruHat99E+Z+cOhHl2938fez1s+XhHKby1WplH3L//r24hrW1/VF+pb8vyk/G+QRwWlkfPZ1l65mqqnbnUJYPF9nTOcyjx+Gapl35PLjfyfq30SDd7KjqtLMaWt3sfZpMsrVAVdVslq6J8u2znd2HUX7WyuZOhw89FeWrqh4Pr0b5ve1+XMN250aUP7D5RJTfG+XzlnY4ZM9m+YDbamXtajaHjdB0zJ/NsjbRamV7HVVVs3Cwac1hV/vRg2zus29fNlY92tqK8lVVH33+cZQ/dzrbw6yqunH7QZQ/e/61uIYvPvswyj+4n435w91sz6iqahouCPZ2s/VxVdVrb52N8i+f+FWU/+Lr96J8VdXte1nfcPhgPt5+8umXUf6NV38R5T/4+O+jfFXVrVvZHPTo4Xyf4N3f/jbK//rXv45r+Pkv/jzKf/B+9k7vbmdz4KqqXn8tyk8n+ZpoNMv6yL1R9j62O/maKDmHr6ra3sn3CbrhWVE3PDOsytd2k0k21k0n+fxvEI6X/ZV8nBgMsr9jMsnPBlLpMr/V5BtPk3HWP3Va87jqk/0d41HWJtqd/G+Yhc1qNIdN7X3dsH8K36dWaw4bofE6fx41ZJom+xu2Hufr2/R97PfncK8i/C5u38zWx1VVD+9n546nTj4f5b/5JtvDrKr68otHUX6ln++dHdzMzqq6vex9ev6nb0X5P31G1sc+3rkS17B3I9s7u33rflxDu7L51154n2Ae9zJ6vWysu3cvf4574dzp5MlTUf7e3dtRvqrq8OEjUf5QeE+oqurO/eyMZTfcQ7xy9VqUr6p67tTJKL9vf3aWX1U1brJBfx776sNRdo6drtHncWm/E86j03uUVVWzcC7dhHOvWfzDharJNPuMdpPvO6Vr5FlrDvfvQukd67nUED6H+awNM93wIHwOW2c1CxdmeavMa6gl+C6rnY0Tt+5la6qqqpMnjkf5A4fy30XtPs7Wt02TPcfxON+3WlnL7nw9cyzfqxiNszXJvbvZnf2zz78c5auqvrp7Lco/cyy7Y11VNQj3Mcej/D5AO+znd3ayNtXv5+cb3U7YLufxHMN9zN2dbJ+gCX+XVVW1sZG907NwDluVL0lW17O/4ebNW2EFVU04F3/zzfNxDZfey37b9Zev5TXceZydFV27Fu4Ht/JJ6IOHWd9w7Hj+2677d7P51zj87cLj+/n+30uvZ3e+fvN3/xjX8OJLb0T57e38t6sP7+fnNAAAAMD/dfHixUWXALC0Lly4sOgSAAAAAAAAAAAAAAAAAAAAAAAAAP5N/u80AAAAAAAAAAAAAAAAAAD496FZdAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK9m0QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLyaRRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPJqFl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMurWXQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyvZtEFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC8mkUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDyahZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq1l0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr2bRBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvJpFFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8moWXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tZdAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK9m0QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLyaRRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPJqFl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMurs+gCqqpms1kNZuMfne938j+jHeYvffaHuIbJo0GUP9Jpony3ux3lq6pm3WmUv33nh7iG48cPR/m7D+7HNexbW43yw+EoyrdbeZv4+utvovzZM8/FNWzv7Eb5h4+2onyrlbWpqqrWLMvPplmbqqpqtbP3ob+Svc+dMF9V9dGHH0f5zfUn4hpee/W1KL+7uxPX0G5no9VgOIzyN299G+Wrqn75TvYc93ZacQ2PJ3ej/M1bN6L80aP5+9jvr2QfkHZOVTXYzfrovb0sX1V1YON49gGt7DmOR/nfsBd+xniQjxNra+vZB8zC8bKbj7f3H96L8vt63biGw4ezOeinn30Z5d95+8+ifFXVcDcbJ9qdvI8eDbJ58MFD2fdQVVVhFzmZTqL8ePzj18b/Iv0u+r18/latXhSfTrP3cTjIxvuqql7vSJRv5U2iapb18/OoYZY2isqKaNp5Hz2dZO3q7t3rcQ1rq2tRvruyP8rf3rkZ5auqTh55JsrfuZe3y0cPsr2zVvtBlF9fPRDlq6qm43DuM5vHdm7WrmezfB5c4Z7LrMLn2Mrn0aNpts7f2c32raqqVlazMXt3mM1bjh49GuWrqm5ez/qnyTj7G6qq1jrZc/zi08/jGl588cUo/4f334/y/U4+3g7Cra/Tr56Ma3jzzF9F+SvXL0f5G989jPJVVaee/UmUH42zeXRV1Z27t6L81R8+i/IvvfKXUb6q6qOP/0eUv3HjWlzD8WPZ3Ond3/xNXMPP38naxAunT0X5K199H+WrqiaTrJ9fXc0XRXvD7DMme9leRys+xa6aTLK5z3p47llVNR5l67LRKO/fJuGeyyxco3d62V5JVVW7n60HWuF9gqqqtZVsfTuPva/ULNzqGI+zdl2Vn/lNw3ZdVZUeQzdN/j6lWk3WR7fn0MeOwnc6f475mV8rPDdstfN3YVrZCzkLN0J3R3m7boV31/bCsbKqqtfrR/lH24/iGlrh2rDbydrlZJZ/l/tX9kX5nTmcg48n2XPYe5B9l72vsn2GqqozPz0f5bvdQ3ENzz33VJjPx9utaXaO/dGlbI09mkObSCdPJ0/mez69sI/d3cvuxR46lL+PrXSsGuzFNWxuZmccrVa2p331anbfqqpqfS37G1bXNuIaJv2sb7h193ZcQzvcz52G69t5zEHTteF8zuLT87LwLH8Oa6omPS+bg3Rtma5HqvL1QGzR/3796bc4+YcsOj+Hd2Eatut5vI+z7H1I9zrmId2XT/dhq6pu387m0U8dPxbXMN2XvQ+jQXiOPYcu/uGDbJG+PoffgHz5efYbkOfOZmvLfjc/B+80m1F+mF11qqqqprI9n1HYP1ZVbW1l+x3rG9ld9WH4O5iqqtXV7P7dznb+m8v0ndzZydr10Tn0j910rJrD+5j+1C+dPz7dPZEVUFWDveydnsPPHevEU9m9r4++uhbX8PLZc1H+Hz7P7mw9d+KFKF9V9Q+/+yDK/+xXb8Y1rKxme9oP72b3nfavZONUVdV4O/s995//57fjGi5/cDXKHz4S/r6tqsZzuAsJAAAA/5FcvHhx0SUALKULFy4sugQAAAAAAAAAAAAAAAAAAAAAAIC583/QAQAAAAAAAAAAAAAAAAAAwL9fzaILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB5NYsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDl1Sy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWV7PoAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXs2iCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgeTWLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dUsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAllez6AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF7NogsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHk1iy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOXVLLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJZXs+gCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhezaILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB5NYsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDl1Sy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWV2fRBVRVtVqt6ncWW8p/vfQ3Uf4nR07GNdwZ/XOUP/PTo1H+959ej/JVVTv3R1F+Y30jruHBg7tRvmm6cQ23bt+P8u12WMMsi1dV3b27E+W/++6HvIhWE8WbVtavrKz0o3xV1Wi4F+W7nV5cw+rKapTfyZp1/f6DrG+rqnrztT+L8qPBIK7h0cMHUb6/shLX8NWVr6L8sScPR/nzL70S5auqhrtZ3zIeP4xr2Anfh6NHjkf5fjtv1+PxNMpPKm8T7c6+KL+xnr2PVVWz6STKN03WwbU7+YA7bdpRfr3J+viqqmaUjZfTXvYcvr+TzxlmYZt4YjWbR1dVrT35ZJS/fj2bi3/y8edRvqrq3JkXovzW1nZcQ6+fzb9arVZcwyh8n5pWlu/2sn7h/1SRxad5DcNpNubvjLJ13Xr/WJSvqmpPs+c4C9+FqqoKX+m8ReQmk2ycaDXh+1xVk+k4ym9u7o9raIXfxg+3s3HiiYPZOFVVNQjn0ceO5/O/K19fifL9rWxdNhzke2eHD56I8uNR9j5XVbWarF3OZtlex59qyL6L2SwbqybTcLOjqrZ3s7lPq533bw+3trIPCNcjD+7fy/79quo02XpkK30GVbWxke1JP33smbiGjy9/HOXPvXgmyr/7m0tRvqrqxNPZ/Ovts38V1/Df/z475zkU7lW89PL5KF9VdfmTcC+1l5+1Hdg4GOU//+qbKJ/2r1VVL537WZT/rP4xruHWrT9G+YOHsj3Iqqr33ns3yv/8V1m73DiQz0E/eP+fovxo+Diuocbp3Ckb89u9/NwyXZ02c1hc9sO/o9POixiPsv3k4STL9zv539CqcB5c+XpisBeeL4Tb6q1036vyNXq/n5/5DYbDKD+ezGHfKfwumvY89jEz7bCG2Sw/5xmPw3YV72nP4XLINKuh083noK1wfdp0svxolO8TTMJzy3YvP0MeTrO+odfL78hMJ1mbGITfxb7V7Ay7qmoafpcr++ZQQ9jPd3tZu/7mm2w9U1W1uZGNl08cy9fYo9HNKD+b7sY1rPVPRfnT57K92Os/3IryVVVbW9mZ340b+X2AfWvZ+7R/JWuXO9tZv1BVNZlk/dsonXNUVTfcN1rZl40T58+/HOWrqq5+9W2Uf+JYfjfk0YPsbvDuXt63rK6Gc/FZegg9jzV6tibqdfO5Uzp/q3A9ka9uq5p21q5ns3xtOZ2Ge2dxBfmHpK/0PO4qzedBhNLnmPYtc1ijp2bh+1xVNY37huw5pnslVVWtsG/pzeF3Ybt72dzp1p3szn9V1ZPHs/Oye4PsLL0bnqNX5fPYrUf5c3z+VHaWfuWLT6L86XP5bx9OHnsiyv/uow/jGl4683SU//KjL+MaTp9+Nsrv7mZnC7057EGOBtm6qj2Hdrm7k60HDh7I+qZmDncx00nDPEqYhOPtJNxHnc5hHp3+DqY3h/3k8+ey3w387tLluIa7t7Ox5syx7K7Ste8/ivJVVWfPvhXl3//Dp3ENP38n23NZP5jdnRvs5Pd8BqOsXXUGeZs4spblmzncaRiGdxoAAABgmVy8eHHRJQAsrQsXLiy6BAAAAAAAAAAAAAAAAAAAAAAAAIB/k/87DQAAAAAAAAAAAAAAAAAA+H/VLLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJZXs+gCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhezaILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB5NYsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDl1Sy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWV7PoAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXs2iCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgeTWLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dUsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAllez6AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF7NogsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHk1iy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOXVLLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJZXs+gCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhezaILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB5NYsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDl1Vl0AVVV27tb9d6Hv/3R+fsPH8U1HOhvRPljrd/HNZz55XPhJ7Sz9Cdfhf9+1eZG9hyHo1Zcw3iavdbt7iyuYTTO3smt7ZUoP5iMonxV1SsvPhvlJ8PduIZON/suZ5W9T8PhIMpXVbWbbpTv7luPa/j25r0ov/04ew5vv/FOlK+q2tndjvLD4TCuYW0t+y4+/PCDuIa33nohys9mm1F+e2snyldVbW9n/WO3n7WpqqoD69lY1Wplfctslo8z4+H9KN/rHYtrqFYT5qdxCZ1mHOWHg2ysardXo3xVVa/J2uW08jF/3OxF+ckw+y4Prh2I8lVV1cra1aydz0EfPHgQ5Z9/9idR/osr+Vz+syvXovwLL6Trmaq97WzMb2dLoqqqmlX2Pk2mWb7VhP1rVU1nWbuchPPoqqq9QTYH3b9yNMoPwr6pqqrXy+aQrVn+HJvwMybTSVxDtbLPmLWy8XI6eRzlq6o6TdYuO/19cQ0/PLoe5Z888FSU7/V6Ub6qajTcivLbO/k+wakTz0T5W7fvRPnOsB/lq6oeP/4+yq+vZfs1VVWDwc3sA1rZvlVV1WgUtstOln/08GGUr8rXp8NhPpcf7GVj1d072dpyPMjH2/0r2fs0msP+3dZWtlcx6uV9w9nTr0f5y//8uyh/5uz5KF9V9fTJU1H+r//bf4lreOLJ56P87k42Tnz+Rbaeqap6++1sL/Xa11/HNTzYzuZfR48ej/L37mRriaqqj8b/FOVffeXXcQ1rV9+P8le//i6u4cjRk1H+0m//Osq/+cZ/ivJVVXt72Zg92Mv3Yjc316L8cJTtYc7DNFwbzuNPaIX7LSv9fE0zHmfzr3i/ZZTP/9qd8HrHNN+raId3ErrdbB49meRz0PQzxuO8UUzDGiaTfM+n086+i3SvYXeQnU1UVQ13s8/Yv7o/rqETNqtmDvvBqXi0zLuW6oR9wzQ8f03vllRVdTpZ/ziawzjRNFkN4znUMJtmfeRslvVv7Sa/CjmdZO/TNDzDrqr47LPby/qW/kq+J375crY+PfQXR+Iaer3D4Sdke+J/ku1dHTqU3e1I81VV3377bZS/+vW1uIbbt+5G+RfPno7y21v5ns/2bnrnKl/ftrvZ/C0d6/av5PcgNzaz+yV/vH4jrmEyyvblV/bnd41G4XqiHd59m8cctmmHY3b4N1Tlf0d6B3Aedwgnk3DeMYfn2GrmsCAIpU8yzbfm8F3Gn5CXEH9Geq82vR9Tla8Nm7n0LeH94vCLSPeCq6pm4T7oPF7HXjfrox8+zs+a9vay57Cxnq2xr9/Mf/uw0sveh94c7kvt7GTnjs8/m92RuXXzdpSvqjp+7FCUf/1MfhZ/5fvPovy5c6/FNXz3w5Uov7mZrQd6czgn2t3L2uX+lbyGfeFvLtNzovRsoqqq083WhrM5nG+MwsPLYbgP2gv3s6uqNsJ3YXsnP2PZ2sr2W37xs+yuU1XV3/5tdt/p9dfPRfmjk+yuelXVp5++F+VfeeWXcQ0fXr4W5V86n91PbsI9p6qqx+neWSvfyz3x0+x+8rt/dymu4bkX3og/AwAAAP7FxYsXF10CwFK6cOHCoksAAAAAAAAAAAAAAAAAAAAAAAD4D8n/gwcAAAAAAAAAAAAAAAAAAAD//2oWXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tZdAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK9m0QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLyaRRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPJqFl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMurWXQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyvZtEFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8b3bubVmO8kwT8JdZdJJWngAAIABJREFUtWrt0Q4kgQAjgQUYg8EYbJq2e2Ycno6OuQNdoO6hO+zppu0ezIANgmZPm40RkkBaQtKSVu1rDhRzNNEnvBlTZcfznBJv6qvMP/9d/gsAAFZXu+wCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhd7bILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1tcsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1S67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWV7vsAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXe2yCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgdbXLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA1dUuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVld/2QVUVa2tD+rkYw9953z//T/HNTz1g5tRfrB5JK6h5t9m+XY9iu+sz7N/v6pufHs7yt8ZjuIaNrez33H00Mm4hlocjeJ3RsMo39/YiPJVVf21tSjfm+fPcjBoo/xkNovyvd4gyldV7d/KnuW7H30Q1/C9hx6L8mfOHI7yw4M7Ub4L09k0vsafPvswyv/0pefjGqajRZSfT7I+ejjMn+XO7m6UX1QvrqEW4fSnnUTxeeX9Y9sei/K99B5U1ayyPna6GMc1DIdZH7u9cSjKN002TlVVzWfZfRjNs3vQxTU2eptRvj/P5hxVVfNe1h6v37qR1zDMnuWJw9l7/bOfvRTlq6p+/8c/RvlPv8jXZSePZeuqb2/sxTUcPXJvlJ9Ns/F6UVm+qqoJh8t5k/fROzvffY1fVbWYZONtu5730eNZ1jf0K+/f2grXJE0+5i/C8W48vhLlB73tKF9VdTDJ5rEH01txDSe3H4jy03E21g2n+Rx0PMvey3H4G6qqNrey9cQDJ05E+T9fzMe6wSTbM7q696e4ht3drD0u5vk70fay/una9W+ifK+f94+TcfZOjEb5eDsNx8vxQZY/eiibw96V7eV2se/UNNn8axDuo1ZVDYcHUb5ts/3gTz/P+7fPv7gU5Q8fvT+u4ds7Wd8w3M/awulH8u9ETbiPeebBh+MaboTzho+//CLK33fkeJSvqrp+M5vLf/DR7+Mazp7+YZQfjfNx4tKlz6P8cz/K9rRfe/V/RvmqqvE062N/9Q//I67h9dd+HeXHd7J58MZGPm9ZW8uusdbP9+Un02zecTDKxsqqqrX17Hc0bbZGbzvYT97eyPZi5+G+VVX+HbtmYQ35T6hFfI0mrmFtLWtPi8rHiX7YNywW2Vx+MMi/xTdt9l7N5vkZmfk8a1DTcL+lF66vq6r64Ro57eOr8t8xj59l3kf3+1mbHh108F4Psvs46+BZtm3WR/b72fyv38E7MZyE50vCfYaqqmqza0zCMb9d5GPd7k72LC+89W5cwwsv/jy7wDzbj66qWrTZGnseTn5u3czOxFZVHT9+X5T/9ka+n3z9WrbO39vLzuXu7ubfqnqjbD2ytZWtBaqqprOsj7x+PXsOw4187nX5ytdRvu2gj27bdG2Zr7GbcC5eTdbPdzDSVa8X3sd8qKomrSH896fT/EzrbJ7tO6Xt+e41srl0F+2pg4V+9s+vwEUW4dq0qqoNX6z0nejgta5wOdLBBfIzpel7vejgfUgv0cU7MZtnz6LXy/+WZjrL5rE3bmb7BLv3dHHuLLsPTQftqd8Lz52F+9G9DvY6Julxp3n+feORU09kJYzyc7WH7s3+pujGXnYfBv28Pe5uZX83sAjPt1RVTadZg5qH43Wvg29+Tfh9Y7rIzxCuhed01gZZfj7L28J4nK0Hmk6+VWX34fLly3ENTz95OspfeCfbQ3zp5Z9F+aqq4UHWHt568/W4hgcfys4KffHl1Sh/773ZmdiqqmaQ/V38wSQfbzeH2bmzn//XcD+6ql5/Nd8XBwAA4K/D+fPnl10CwEo6d+7csksAAAAAAAAAAAAAAAAAAAAAAAAA+Ivh/+EGAAAAAAAAAAAAAAAAAAD8/9IuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVle77AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF3tsgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHW1yy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNXVLrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFZXu+wCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhd7bILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1tcsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1S67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWV7vsAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXe2yCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgdbXLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA1dUuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVle77AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF3tsgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHX1l11AVdVkOK6v3vv8O+dPHZ3ENQw2j4dXuB7XUO3t8AJrUfrs40fCf7/qd/86i/Kbm3EJtXPoVJS/uT+Ka2jbrE1OZtl97PWztlBV1e/1ovykmriG4TC7D+s7u1H+0y8uRfmqqlu3plH+b178eVzDq398Pcrf2r8W5X/8oxejfFXVe++9E+XXtwZxDU899WSUn4yGcQ2jYdaeFvNFlN/ZPhTlq6qqbaP4fJH9hrs1ZNcYjbLnMFjfivJVVc161kfPFvncaTIeR/nxOB9v19dPRvnZPLsPvV5+H0fTG1F+scin84Mmm4A14ZJiFs6bqqpGw6w9bvU24hoGh3ei/DTt30b7Wb6qnnrie1H+wptvxzUc2t6O8k2T9Y9VVaNxNmb317K5+HhyEOWrqnprYZue5/dx3oTzlsrWArPJXpSvqmqbw1F+bZDfx6bJ7kNN8/G2qWz+1utnew39QT6PvnwnGyceOpLvl4yGd6J808uew3QatqWqmk6yazywmc+DR/3svToYZX3siRP3R/mqqi8vXony2xv5fby1/0mUP3YsWx9XVV366oMoP5tlc9Br1/K93EG4Ljty9Ghcw26b3Ye9r7P1SNU8zFf1+1n/ttbP5/KLeda/NZXvVbz54XtR/lcv/22Uf+V3r0T5qqrRJJv/9Tfy9e2hJtu7OryTzTtOHM/Hidk0a0/t2npcQz/8UDOri1H+YDv/DYv97D5evZq156qq2zdfi/LPPfdyXMP992d7Z7f3b0b5YdgvVFW1/ayPfuuN38Q19Hv3RPmNjXRdls/l5/NszJ7O829+6dZX28G3z0UTzjvWsxpm4fffqqrTj56O8tNpvhf7yX98FuX3b2frsl4vnzOshft3B8N8/65psvdqs4ODFbNwr2AefndcG+Tfb6vN7mPbwXfHcfi9rA3PZSwW+bpsvsjaQtvm+6AVvhNN2MfPpvm85eB2tv/XX8v7t+wuVPwcqqra8L3sp/t/HfTRvXAvNmyOd6X9U/ooO2gL6Rx01MG85Z2334jyTz/zUlxDU9l64M5BOHfq589yGp6rOHEiPZdb9fXX2Xe/ixe/ivLfP3smyldVVZP185tb2TnIqqpFZe3pq6+ytvDppx9H+aqq9UG+Nly2cBpdVfncpwnP76V76lVV81k4jw3nHHeFDyPe7Ohg7hWekUnXplVVi/A+Lro4D9rFNZJ/voPz8nFz7OBbVTqJTO9C20F7TCfjXbTHRbrGDv/9eQf3Mf/22cV+cjZOdPJGpOcQw2cxmuR7PmvhubMu3svRMPsbuX747XNnJzvXW1X10UcfRvmnf/h0XEP6Xr7/eX5G5gfffzjKX/v2P6L8MPyOXlXVH2Zr9I1B/k6sheci0n39aQf7oL1wPTHrYD0xCPdS0+6t18Ge+Djc+xp2sA+atqd+B/tOO5vZ3w2cPHlvlL9wIftbxaqqx8+ejfLjO1n/WFU1DPcQv7l6K8pvbObn93Z3snOx/XBfv6pqusja9GCS/r8Bqs483MHfbQIAALASzp8/v+wSAFbSuXPnll0CAAAAAAAAAAAAAAAAAAAAAAAAwF8E//82AAAAAAAAAAAAAAAAAADgL0m77AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF3tsgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHW1yy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNXVLrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFZXu+wCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhd7bILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1tcsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1S67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWV7vsAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXe2yCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgdbXLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA1dUuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVle77AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF3tsgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHW1yy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNXVLrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFZXf9kFVFU1Nav1uvWd80cOH4lrmAyHUb5d78U1zJvdrIa6GuUPH9uJ8lVVW+tfRPl570Rcw81bV6L8ZByXUIcPH4vy/baN8otpE+Wrqi5fyu7jmYfyZzkazaL8Hy58EuWfeuLZKF9V9cH1f4/yf7jwv+Ma+oOsfzpx36ko/2+v/kuUr6o6+/jZKL+5kfdvwzsHUb7XzuMa2jZ7t9fWt6L8bNrBb5iH/VMH93G+mEb5jfg+Zn18VdWiP4nyN29fj2tY721G+e3Nw3ENvf7tKD+bZe3x1n7271dVbWxuR/lmvhbX0Ftk15iE79Rokd/HzY3svezN8mXRvLL+abLI3uvpnSxfVbW7fU+U/+lPXoxrePW1N6P8s88+FdcwHIZ9y0HWFra2s36hqqptsrFmNu1gfdtma+z54k6U7zVZe75bRDZOzGb5e3nr4EaU7+VLw9oYZHsVB9O9KP/ltZtRvqrq8ZPfi/KTaTbWVVVV+FpN5tl6pN/BFuDh9Wz+d9DmfUszzjZtJqOsb+pvD6J8VdXpMw9G+c8+/1Ncw24v27e6tvdpXMP3Hnkyyr//XjZnmM/zteWVy1n/thPOvaqqtray97JtsoGi18FAsz7I3qter4M19iJrD5cufxnX8KuXfxnl33nvjSifvxFVj3z/0Sh/z/ZGXMOdW9ncabF+PMr/4eP3o3xV1dmHsvtY+RS0Nmo9yv/y2eei/K9ffz3KV1Wdejib/3375Z/jGmbzrI9+5ZV/jGv48Y9+GuX7a9ncq+3n87/dQ9mez40b2Ty6qqrX34/y03Bt2YTjdVVVLRZZDfMsX1U1T2tY5GP+eJKt7dbWsjY9Go2ifFXVlWvfRPmd7eydqqp6+JGHovzHH2frifE4+35cVTWZZANmv5+vDStck8wm+X1I10Wz9L3u5eNEOpHNe7eqWbieWO9l7Wkc7pVUVTVNdie6WGPP4z46m8M2HexbrfWz723zWQd7kOF7mZ5VqqpqwjMN6YvZ62AOmmorv4/xbUynkB1MQSudv4V9U1XV5cuXo/xg7dW4hu8/ma1P+4Osf8tbY9Xe1WtRvql87nTs6NEof30v28u9upedy62qOnkiO383HH7389X/1xdfZGeFbnyb7b1tb+XfwdO5TzxO3b1IFJ/N87l8P5xL98L8ZJb/hnSsmXewVxGPd+maqIM9n144j110sSpKLxHexy4u0cX227Ktwk9owplH28H8L+3mZx30b+k1mvD7a3pmrKpqET7LRQfvdbyf3MFb0TRhHxs+i/Ek329pell73O3gHGM/7GTTc9pdnPl6+ES2Hnn37bfjGn74zDNR/uzpM3ENv3373Sj/ixeeiPIX3vhDlK+qOnz64Sifni2pqhoNw29FYd8S7xlV1dWr2Rr7SLjGr6pqw3lwU1n/2Pbys5izWdaeuhjzNzbT7xP5t8/ZLLvG2ceyvbffvPJalK+q+uZKtgd56mR2Vqmq6uPPsr/nfvQHP47yn3yUjRFVVT985vHsAh18Gtg/CA9dzfK/0zt2KjvbCwAAwF17e3t1/vz5ZZcBsHLOnTu37BIAAAAAAAAAAAAAAAAAAAAAAAAA/mL4f7gBAAAAAAAAAAAAAAAAAAB/jc6fP/+ds3t7e//pf2u/81UBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+KvXLrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFZXu+wCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhd7bILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1tcsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1S67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWV7vsAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXe2yCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgdbXLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA1dUuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVle77AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF3tsgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHW1yy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNXVLrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFZXu+wCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhd/WUXUFU1WOvXg6fu/c7528NRXMO02ii/uDOPazh8dCuroQ5nBUyvZ/mq+m+/PBPlf/3Kl3ENbXMsyu/sDOIamhpG+bNPZPfx2tfTKF9VdWnv6yh/78PrcQ1vvftelP/VL/4+yv/uX/4pyldV/fiF56P8W2++Hdfwdy//XZT/7W//Oco//9PsHlRVjQ4mUX42yceJ+SLLL2a9vIbKxprZYhblF5Xlq6rmFfax4XOoqmqatSg/D+/jvBlH+aqq8UHWz2/274lr6PXDaWTbxDVMplnfMJ1lz2Jr+1CUr6pazLN3Yl4d9G+1H+Vnsyy/3j8e5auqer2sj5032dytqmp//2aUH43vRPljR+6P8lVV02n2Xje9/J34yfPPRfn33v/3uIZTDz8Q5UejrG+5fSdvj8fvzZ5lr7KxsqpqPMr6p83NbH3cNNka/65s4jGb52N+M8tq2No9Edcwne9lNaxla8P1Q/lvuHTncpS/dzuvYT7K2uRabzvKN4t8Ip1eYj7L5m53LxLOg7eyeUfb3IryVVXjYfYbzjxyNq7ho4/eifKHd/N5x8WLH0f5M2eejPK/f/U3Ub6q6uTxcP/uar4X+9n+51H+0G62Nmw7WNc1TXaNyTTfB93fvxLlX375v8c1/PGd/xXlDx89FeW3jx+N8lVVn138Ksqf3szm4VVVk0XWHnYW2Vj1i6cej/JVVf/01ofZBWb5e/nCc89G+QuXLkX5zSPht66q+uZSOP+7L6/h1jffhjWcjmu4fP2LKP/ooy9G+Rdf2onyVVVv/9ubUX6xkc+DJ9NsP3itF34vC8fKqqrFIrvGeJyvb9fXs33QtoP70Myza9y+dRDl1wb50Ywrl7Lvt5Oj+Zh/EJ7NmM3CcxV5U6j5Iqsh/+JX1VsL9646WOenr9X21mZ2gQ7WE8Owf8pP+VQNBtle6nSWzWG7WJf1e1l7nHVxJ8M2PZtmbWE6yb+D98K2sLaWjxOzcI286OBjfNoiF+G3+LaL/jG8xmKRf7+tJnuv1sN9+aaDI6Xpnk3b7+As5k72Xl69lq1vq6oOXc7WRSdPnozy+3fyPe2Nzew+zkb5e/ngg/dF+dvDbJy4+GU2D6+qms+y9cTXX+frstk0exZtE/aP8/w7UROeXQs/M1VVVdvL+siN9fxc7WLexUz2u5vP87nTNBwnNsJ9hqqKzyGm8570+8jda4QXCPeMqrqZQy5deCM72KqoRTgH7aI9pc8yPVfbyW9I3+sOHmYvXGPP0/bYxY9IL9HBMBWf++pgbTgPx9t0H3R3OzsnVFU1HWfr09Ekn4OmJ/jafrYb28UoNQr3IB84ma1nqqouX74Y5Q8dzr8N/O0zP4ry73+Yne195LH82+nHn3wa5R97JD/T0LTpXDrtZPNztU24NhwNs/VxVVUT/k3SeJSd027a/EvRNFxX9cP+sapqEK6rmi7OjYXf7K58ne3Z/PK//E2Ur6p65bdvRPnnn3kqruF4eMblg/eycxk/eeHnUb6q6tPPLkT5Z57Oz2zt38zOcw7Cffm7uvj7BwAAAAD+Wp07d27ZJQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/6NddgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABbtzgRAAAgAElEQVQAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK522QXwf9i5sy7LyvIO4M95z1BVXT1DM6UBRQFFcWIwKqwVNTErF/kC/QH7K+QirhgHFi4wiCgzgtAgyGB3dVfXqaoz7FxkeZWVm/5vs0+yfr/7/6nn7P3ud9rvKQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDNNRm6gL/oRutbzq67af7319mlWByt4hqW8+MoP9m6EFaQf4cbe1l+a7od17BuWXto41lcw/bsbJTf359H+es3s7ZUVTXusuvwp7f/HNfw9BNPR/lnnvlxlP/W3z4e5auqXnn5rSj/jW88Edfw43//lyj/0MNfifKLo1vv3/9iFXZP41Hev41qHOVX6yxfVTUKxsqqqvU6y3e1jPJVVa3CPjquoGoUzhsW66yPPl7fjPJVVVvTU1F+tNqJaxiHN2M1ytvTqJ2I8tNRll8vuyhfVdVaeB1aXsOqG0X52fjuKD/u8id7FQ4U82X+XHajrJ8/d/be7O+vs/tYVTVu4b1Yh4uBqtqenozyD38pm7dUVX306QdR/v6L90X5d995N8pXVe3fuBblz57Kxpmqqt2drI/twvF63S2ifFXVMvyM2Tjfqzh78o4of7i4GtewDPcKZuEae3cn3yeYHGX59/c+imu4cDrbs2mLdD2Rr8uqy+YtLRwrq6q6dKyq61F63cO6rgvnLTfTzbeqevihb0T5V17+bVzDvRc/F+Vv3vwkyv/gh/8U5auqfvqTn0b5u+++GNdwOhyzj48Oo3xr+Rx0ucr6lhvzT+MaHn/8R1H+ud88E9dwPmwPO9vZPPrKJ9keZlXV5FQ2Zl+b78c1nN7ZivJtmr0n2ptne0ZVVU8/+qUo//yLr8Q1vPLm61F+Msvuw+5uvm91eCL7jD9/diOu4Ytf/HyUX9zM987euZKtB86eeS/KXziTrY+rqh58LHuuXnkpfya2t7I+dn2cvbNb9fD+Nl0NzKY9vItfhVX0sIe4XmY1TFo2TrTwPVNV1eE86xs+/GM2j66qmoTj5fFxtt/Sxj28b0v31Uf5vvxkkn2PLi+hRpV9SDqXn/ZwLqMLL0SL9xmqunVWw852No9eLfN90ONwrBpVH+8nsmdiHY4z4x7Wt134Ln616uGdX/hcTib5McIu7FvS69h66CDH4Wcc9XCGsEtPRhxlm+LLw3xNtA7H290z+Zi/NQ3P+Szye/nyb38X5W87k/39kycezT6gqpbdx1G+nejh3Fhlbfr06fAs50E+j/7gSnYmYTrN507hIxHPH9fhOFVVNQr76B6m8jUN1yTzg4O4hq1Z1h66cO6TzsOrqo4X2Rx0ayvfqxiN0jlglu+jPVb8HfIi0vVA18N6Iv4e6WXo4Suk7TFvz5VvNoTxdQ9nGtL22MdlHI36OOV86/roo1vaHntYY6f66Fu6sKNO17eLcKysyve+lum+flXNwrnT1k7+3jC1OM7WhotFeHCtqq5ez36bdedd98Q1LA6z73FyK1uXtZ18TXTutuz83vEi34sdT8O9hniwysepdJw4nOdronQ/98Z+tkbfPbEb5auqzp3LnolFuK/fx2f0Me9YhO8Nt7eyvuHGfn5W6WtffTDKP//rF+Ma/vGf/yHK7/3suSj/yUdvRPmqqvl+1j++8KvfxDU89q1HonzrYS2wCvf2AQAAANhcly5dGroEAAAAAAAAAAAAAAAAAAAAAAAAgP8z/A83AAAAAAAAAAAAAAAAAACA/+7y5ctDl/A/akMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmmgxdQFVV13V1fLi45fz2zk5cw2Jx63+/qqpN8kv53vvzKH/x4jLK71+fRvmqqk8/zmo4fea2uIbj1SzK7x+s4homs6yG07tZ/tMPj6J8VdU3H/1qlL929Vpcw8t/eD37gJY9l9euZs9kVdWdd94d5V978z/iGr7z7e9H+Rv7f4zyR0f5MzWbZG16tczHiWqjKD6dZv1jVT5WLVdZDTvbF6J8VVWr61H+8Gg7rmEyyZ7tNgrbQtuN8lVVo7B/q1E+Tly/eSPKn9zt4bmsrSg9aieifNf2o3xV1f7ND6P8bJq3p/E4uw7VsvjRMm+Px/NPovzOzh1xDcuui/KjyuZ/W1v5OHM4/zT7gFG+nmjrrEFtz/K+5eT26Sj/6qtvRPkHH/xilK+qOtjP+ujxNL+XqW6dtenV6jiuYTTK5rHrUdaWqqoODrPncjIJO+mqOjHLxppRZf3jepWvy+bjcZS/72y2rquqWq+z69BN1uHfz8eJ9Spbj4zSSUPl13E6zebR84PDKF9VNR5nfWwfY93BfrYue/jhL8Q1PP9ctt/x9a89FuX3rl2N8lVV3/vet6P8L555Lq7h4t/cG+Unk6w9rsJ9iqqq1c5BlP/uk38f1/Ds6z+P8ucv5OPE2a3zUf6jo4+i/NV5vr49ef72KL8cZX18VdVhy8bL4+ObUX7WelgT7Wfz2C8//EBcw2tvvBPlt3ay/buj63tRvqrq9nuy5/LqJ5/FNbzz9gdR/sx9J+MaHrjv81H+tVeydzTvn3wvyldVPfH4U1F+/rl8PfHWm69F+RM72b0crfL+Me1il8v8PU9qfpjNGaryuc+osncDq/AdTVVV+HqiZrN8rFqts/bQddl4fWIn3xPfv5mN+eFWcFVVrbvwueqhhvQj1uEzcXicvxtIv8Mofah6qGK1DPuGHtrCLN4P7uE6ht8j61mq1n1cyHTrq4fOZRKeXevjkVjHZxKy92V9XMfFzWzesT3N9qOrqiocq1Z7WX7dwvtQVafOh/uYB/n87+oyuw73XrgnruHUvdm7ounOo2EF+ZpoMsr2rT5evRvXMJtnz9Vyme1jrhbpSJPPgxc9zJ22ZgOPE32MdeE7v2V4H6qqFsdZe0q/Q1XV9na2/zYKNwrS9lxVtVhkbTo9R1mV34vJOD2/l0+++ljRpNJHO91vqarq+pjPDy1sD32sb7vwZq7jlVkfhm8LcZsO70N6H/v4jD7OhqSXsbW8hnS8W4fP5Wrdwxx0lF2H1vL2dBTufbXw9xvpmf+qqjbOPmO9zuctp8L3ry+/9Ku4hkcefTzK33UhO6f9wsu/j/JVVQ/edyrKn9vO5/Krys4DrFdZ39Ct8nd++dwrfy7nh9kZvt3dbL9m1cNZzPQqpucgq6qWi/CcdQ997N5edo5x99SZKN96mLfs7ma/aZqF+zVVVc/+7KUo//Tf/SDKH+1/HOWrqvb23o7yJ0/lv0kfdeH/FwjPBlf1s98BAAAAwF/HpUuXhi4BAAAAAAAAAAAAAAAAAAAAAAAA4H+F/78GAAAAAAAAAAAAAAAAAADw13H58uWhS/iraUMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmakMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmmgxdQFXVaDSqren2LedXx8u8hsk0yu/dOIhrmE7HUf6D969H+a7Lm8N4kn3G7WdOxzX88aPDKL+1lbeng8O9KH/lD12Uf+yxb0b5qqqXXvh1lJ9eyO/l/LOrUf7xx78T5d9445UoX1W1WN+M8l995Im4hvl+1jdMRrtRftVlf7+qar0+F35C1r9WVXXdKsovlvk40cZbUX46ze7lerUf5auqui77DlV5Detw+jMK89M2i/JVVavKxqpFl/VNVVXjcTZ3Gq1PxDVUW0fxdZe1p08/+1OUr6o6e/5klJ+Ns+e6qqpWWZvs2nGU3z/6JMpXVe1u3Rbl22oU1zAbZ/O3rrsR5Q/nLcpXVbWWjbddl12Dqv9aG0Y1LLJ+oarqwrm7o/xqlV2H965cifJVVZ+///4ofzjP1lRVVbNJdi9HXZZvox7Wt+Nb36eoqrp2Pb+XJ3ZPRflpy8brqqq2yubSx13WnhbdUZSvqjqdrmn66GO3s77h+sG1KD8Z52Nd+hGzSfZMVVWNwi2b46PsA2azfC7frcOxrod5y7hln3F8mK9vn3gy27t68de/ifKPfPnrUb6q6uaNbF311FPfjWt49pfPRvl77rgY5efzj6N8VdWTX/5RlH/2xWfiGs6dz+bB4+18vP1g8UGUv3ot248+f/uFKF9Vtb/K1oarHtYTk3E2Bzw+zOYtOz28cZseZ2uaM7vp3lvVo195OMq/+da7UX57K3+m5gfzKH/qQrbPUFW112X3cu9Kvg86uidrDw899EiU397K2+PPf/FvUf7pp34Q17Czk+1jvvbqq2EF+fyvhXvaq/D9SFVVa1k/P53mfcNqnX2P2TTcR+3yteVyGS6Kwr6pqmq9yq7jZJLtM3Q9fIdxuMAdhWuqqqrVOvseeQVVrWVtsoV7uTXqY087q2GdT0GrKvuQVfpch3+/Km9P45a/i0/n8svwMuStsWodjpddD/dyPM6+yWKxiGvYmmX3cnGUrctmPawt2152VmlyIn8PvtjP3hves8jev95xVz73evvDLH98V/YevarqyYfui/LbD/wwrqEqm0PeuPq7KP/LF96I8lVV94fXcXWYz1wOwj2b+VG2TzCb5c/1OJz7HB9le29VVdNxNmaPwrl4H1Ov9DuMR/m8JZzKVx9X4uAgez8xnWbj9TpcX1dVTcKz5mm+qmocronS8y29rOvCGsLjLVVVlS4Nezlr1MvVzCpIpfcyXeNX9fCeJsz30RZS/bSlYa9Dlw9UNQpXyT1s+eR9bNo5VQ97Z+HG07qPjavwjHXX5XOndE877ht62E/emmVr5G6d/z5t1sLf6Z3I19hvvfP7KP/gA1+I8t959CtRvqrq+dezNfadD9wV1zAK1zTr0fDnMtLnet3DWLU9y95Dj8NnKn3XVVV1/UZ2zufMqexscVV+FvIwPJdRVXX69JkoPz/MzhdPg9+z/8WVKx9F+ZO7+e9vbx5n9+LZn/xr9vfn+XnS+y7eGeWPl/lvu1pl42X4iqaqqg7D83cAAAAA/19dunRp6BIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIHLp0qUof/ny5Z4q6V8bugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANlcbugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+k507WZbjPM8E/GXWcOYDgARIgKQgmqIsmpDMWbbboXCHHXZ43zv0DXjnm9CldPAKetEdYUuW3RrapCiKGkzBEgeRJgkCBDGdsaoye8GOaIcXDgffjM5S6Hn2b52vMv/8p/zrAAAAAAAAAAAAAAAAAAAAAKyvduwCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhfTd/3Y9dQzz7zdP+t//nfPnf+4OggrqFpJ1F+NcB17LtVlN/fOxvl20l2Daqqbt74JMpv7mzFNSy7zSj/619/GNfwu1/+WpRfnC6j/IcfvRvlq6oON7P2eGl6Pq7h8Se+FOW//91vRfmv/f5XonxVVbVNFD86zNpCVdXe7n6U77rsO3R91paqqmqS9Q19k32Hqqpu+WmUnzZ7cQ3pUNOE7bH6LstXVduk4+1pXMNkuhHlu3TIH2DqtVrdjvJteyYvos/a03Sal7BanWT5sH+aTnejfFXVYpE9E/N5Pk4cHt2K8n3fRvnNje0oX1XVNvMo33eLuIb40Q47+T58JqvyPnod1pY1wJg/nc6yEmZZDTdufhDlq6oWp9l4eeF8PpdP70Q67WiarG+qqjq4l+01bO9mc46qqnaSDZhtfCeqFqtsvIznsJXfy2mbXcd+gAnc0UnWnvpw3jKb55OvWTiBWy3z9cRymV2HSbgmms3yvbMuvAwnx/m8ZT7PxrrZLMtXVd26dTPKT9rsQv7zL/O9syefvBLlJ5N7cQ27e5ej/Ktvfi/K/9nX/zzKV1X94IffjfJnHn4krqEJm/Qn97I1elVVu5GNd+cvZPO3ax/kc9C9edbHLtMOsqrSWeje1k6UPz3K961mi2yse2g72wuuqlossnuxMc/2cq9deyvKV1XtP5r1DU28AVjVbWf7RqujbN+rqmp5Nxtvu3DP5/xmvuezs5M9l+/9yztxDV9/6U+j/M2b16L8z3/ykyhfVbU5C+9Fviyr1Sp7rnZ2sve/VVUHB4dRfr6R7UE2A+xbHR9nfcN0gI35jc3sXhwdH2UFDPCuarYZvida5fvyA+yexRW0YZvsw/23Jtyvqarqwo2nNF+VX8cmvJf9APOWdANvMskHijZsT+lVaIbYR11kezbLZd63TNrsOqZ7Z1VVq/AM3yTcj95a5euyk2V2Ly+t7sc1PD4Nv8fj4XmALz+Y5auqfpqtRw4P833QjT/5qyif7wZXHd36xyj/rVfeifK7u/mZhlX4XG7M8kjX4r8AACAASURBVLl8ev5uazPbqzgN5+FVVX249zUd4GzvNByz0+/QDTCHnU7DsyGDHGkI59GDFDHu/K0f4gxheGY/PW//mfRejvrnB/mINWiOg7yLT5+rsfNVVW34XE7CZ6oqX1+uw7mx+Ij0AP1b+lwuw32n1WqAvbP0PMAQTSG8mU24Pq6q6sL2sErnTmvw7nSIOWgX9i3pc53u3Q1hgO2WmrbZPLg7zedO91Z3o/z5809G+Y3wPEJVVbVZ//bhQfZ7yaqqL+9n7yfaada/HRzm+1Ztk04A8/aY9vPptvrWVr7XMZlmbXqA17e1CvekN+b5Gem0Od0If8dc4W8nqqo+vZ2dAVyG54Sqqs6dy85VXL+R/Z7oheezc5RVVbP0uQqfqaqq5VF2nuA0PG9VVdWHT/fumad/2Pf9i3EhAAAAv+GeeOKJ/pvf/ObYZQD/ytWrV8cuAQAAAAAAAAAAAAAAAAAAgH/jxRdfrFdffXX8f+ILAACwBl588cX+1VdfHbuM33ovv/zy2CWsBf+/DQAAAAAAAAAAAAAAAAAAgHX17/0fu/b/dzEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/OZoxy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurHbsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZXO3YBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvduwCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhf7dgFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+2rELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6ascuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWVzt2AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr3bsAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYX+3YBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvqZjF1BV1fd9nS6WwSe0cQ1d10f5ne3tvIaaRPnFKssf3Lsf5auqNnZ2o/x0vhnX8IufvRXlv/HHfxHX8IMffC/KP/LkxSj/6UF+L1/44nNRfnF6Etfw41e+HeVfevFKlO+bKF5VVScnp1H+6OhOXMP21jzKN7UR5aftVpSvqjpaHUb5kz5vj1uT/SjfdHEJ1YRtsu+zIpomH28rfa4GeDCjKUdVVaXtKW+Ps8m5KN+Gc46qqlVl7en09G5cQzVZ/9Y22bxllTemmrXZZxwdH8c1NLOsn99osvysn0X5qgpbY1XfruIaqs+eqz7Mt+kgUfmqaoChrvrK1mVDrA3D4bJOD7Pnend7Jyugqq69936UH2Iuf+nSI1H++CTr35q0KVXVxkbWP3Vd/lwuV4soP5/lz8Sisj5y1mbr/I3K91uOu6w9HS8+jWuYT8N1VYXrugHm8n04XPZdPlLMptl42YTT4C58Hqqq7h8cRPntAcaJtg23hPusPVdV3bp5K8o/eC7ba3jhmaeifFXVaz/+aZR//oU/jmv44ON3o/w3nv/LKP/9174T5auqzj78cJSfbuXriQ9ufpTVsJP10VVVzTz7Hu9+nH2Hyw8/GOWrqj65nY2X03netyzDseZwke3lbu3m7zdObmX7JTfu3o5rmIdD9oNb2XV44vFHswKq6t33P47ye1+8HNfw6G6273Tx/KW4hm+/mT2Xzz72RJS/fvRJlK+qun49mzOcfzC/jm+///Mo/9gj2bzjq1+L4lVV9bM3fhblN8Pn+jPZGvnwKN+rSPed0ncsAyyJ6nSR7RPUAGvD5eFRlF912d7Z5iw/4rJcZmu7tC1UVc2m2ffoB9j7Sp+JLiwif1M1gAGuY9ume4Bhvs2/RLpnk7aF/1vFAJ8x7l9vJ1kfO003rqpqFZ5Padt8nJhPsv5tcZyN+Uen2dmSqqovLbLPuPhofkamzmatcvmFbD3S/vKdKF9V1e5l85aNl/46rmESPt3XXvvvcQ0fH2b7Hbt7Z6L8ZIA97dk0a9Ozab5/l/bUTTpvGaB/PDgM+6d5vgfZ99n3SK/DEONM2haGqKENx+xugPVEuiBYLbN12WqVn5fa2cnedx2H36GqqgnP2aTtaYh5dB9+RhMf5qz8POga6MI10XI1wHgbtsfpAP1bHx60SdtTM8BBn/j43BD7LWF7SksYYt+qSfc6htgnCEsY4ChltfGeTfpc5tcx3QddDHAv0/NKbZpv8/2WxTJb37azfE00mYV9bHroq6oe2LwQ5W988HaU/52v5C/M+i67l81h+I6mqm6HTXIWni35+EZ+nuDsfnaec3c7X9+m66p0Hj3Euq47zZ7Lrsuf641wr2G+kd/L4/Ad8APns/NOd27nv2naDc8KTQZ4f/voF7JzEZcvZ/nD43xffjrNnqtV9nqkqqqWy3QPMR/z793Pfx8GAAAAMLSrV6+OXQIAAAAAAAAAAAAAAAAAAAAAAADAbwz/ww0AAAAAAAAAAAAAAAAAAIDfRu3YBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvtqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgfbVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mrHLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9dWOXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66sduwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1lc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK927AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF/t2AUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL7asQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH21YxcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqxy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurHbsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZXO3YBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvduwCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhf07ELqKrqur4Ojo4/d353by+uYTpJL0UT19A2kyh/5+79KH/m3PkoX1V1vFhG+V/96oO4hj946T9H+b/73t/ENTz97Fej/K9/9Mso/40/+EaUr6p6+1e/iPLT+Wlcw1effTrKHx0eRfnDoyxfVbW7vx/lH3r4YlzDhx9+FOUvXfxCVkDfZfnK+8dZbcQ1zGfhOLFYxDUsw0vZVHYduz7r46uq2raP8n2/HddQlY2XbZv99b7P22P6VPXxJ1StVrei/Gx6Nq6hq+xmdF2Wn0yz9lxVdXj/kyi/s3curmHVZX1DE96HZbOK8lVVq9WdKD+dPhDXUJNsPdC32TjRr/Lnuu/TNU1+L5smG2/7AdZlq1X2PWbTgyi/XOZj3bPPvhTlX3/9H+MaTk+zNn3mXDZO7O3uRvmqqrbJ+rfZNJw0VNXx0UmU//gw7xsubu+En5A9l6ddvrbsVrej/OYA85amyebS6Vz8NNh3+381ZPn9/bQtVa1WWd/ShpP5u+HeW1XVdD6P8pP5LK5hFe7fvXntx3EN585m+7nLJutbbt65G+Wrqp56+sko//obr8Y1TOfZvOHOrW9H+ctffDzKV1XNtx6K8qsuWwtUVe1tbkb5g2U+Vs22s72C+VaW/+RONlZWVS3CvuXo7r24hjP7Z6J812drgcPDfJzYC9vC5Dhvj3vzrSh/717Wnh44l+2pV1Udn83mHb965524hseuPB/lbxzn87ev/96VKL+6n829Hj5zKcpXVXWrrE0/uJ2/+/zoo3+J8u++/9Mof/lS9q6squrKlex9109//n5cQxPufc3abB5dlb+uSvfOmkm2D1tVNZuF64H0BUdV9V02Xk7Dufz9MF9VtRm+s9vZy9e3h0eHUT5d3372Gdm13Arn0cfH+bvTps2eq8kkf89zfJLt36XXse/z75BaLvN3A5P0/Wv499u0gKqKb0X8jqZqeyuby0/SDcCq6k6zteE8HLCf38ieyaqqupBdxwrXI1VVB6+8GeV33vp1lF++9EyUr6pqH/mvUX7SXY9r+M7/+Icov72dz99OFtmzHR5pqMUq30++cD57f3t4kO+XbIbj5eI0G6sm4Tvsqqrt7axvWQ1x7myR9bHT8D4MMYftwnf54evfqqrqw5lHM8CaJp3L9124vh3gXh4eZGuiyTTv31Lp1GmIqXz+GXkRaZvOf7/x2e9Qonx4GZoB5tHpvVx2+dneJjzbkfZu3QAPRfod+i4/Y5NKn6nJNJ/DLk6zddV0gBrSW9H0A6zz0zE/HC8HmDIMsN+RF5E+2+l96If4HUt4HVcD9C2LcP+tHWBNk/564dJD2Tu7f/pJflbp9597Ico/McAZmdd+9HqU/9KXHovy9w/zvbPzD2Zn7pcDnHefhefn2vBsyHIxwDmhcLycDPDecSvcTx7i7cQkfPd5FP7uc76Rry03NrPP2A73W6qqDu5nZ67S3/nt7ee/7T8+zu5lei63qmpzK7sXQ7wvm03HX5MAAAAA6+fq1atjlwAAAAAAAAAAAAAAAAAAAAAAAAD8Fnj55ZfHLmF0/v8bAAAAAAAAAAAAAAAAAAAAfD7t2AUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL7asQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH21YxcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqxy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurHbsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZXO3YBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvduwCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhf7dgFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+2rELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6ascuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWVzt2AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr+nYBVRVtW1b29s7nzs/mc7jGqbhZ9y7ey+uoatJlD9z5lyUf+e9D6N8VVW/2ojy584+FNfw5rU3ovylsw/ENRx/fBjln/vDP4zyr73y91G+qurKU49H+fnmmbiGk+PsOh4dHUT5ra3tKF9VtVotsnyf9QtVVbtn9qL8jVs3o/zFC49E+aqq2Srro+dNPtzdv/NplN/cnMU1rFbZ92gnWb6pNspXVfXVR/mT0+txDZvz/Sg/abPr0HV5W+j6rG/p6zSuYTrL5h15a6pqmuw6dN1RlF8umyhfVbW9k13HCvuFqqo2/IxlcxzluzbLV1VNJ9m8o++6uIZV2KpPlll7nPV5W9hos/6pr/w6TsKxquuyfuEzy6yG5edf21ZVTZtsrKyqWp5k3+G5Z5+Ja/jOP3w3yu/s70b5Idrj7Tu3o/zWTr6eODzN+sgL2/m6bNVl/VsbzjtOVidRvqpqY3o2ys8G2D5bhmPNqs/yk2n+HbY3sjY9RB+9WGTt6fBuNt6eeyDfM0rbwiefZn1TVdV7770T5R977FJcw3IZrg27bC6+tzfAnk/4XD595am4ho35+Sh/fPTLKD+fXYjyVVXd4k5WQ5vfywf2snXZ27/4cVzDhVn2XLXb4TuScC1QVTUJl8hbcQVV9+/cjfLbu1kV8638XdXxvftR/sFwvK6q2pxne9JtuP9Xq+y9QFXVE5ezZ2rZZ3OGqqqf/OyHUf6Fr301rmF+lL2zO5lmbWHa5+vb69ez+d/B/P24ht+5lLWn9z7IavjR9b+J8lVVf/JHfxnll/kSu679c3YdJtOsPVdV9V3Wnpar8ELkj0Q1lQ24zSTfmV922b5TTbK+ZbvLL2QX7kHeP8jHqtksuw59uB6pqlotV1H++Djbt2rbfO7UpO/sVtk1qKqahnsuqwFqyIV9S5u/L5vOw3dVYXseopOOr0KT99HT8JlYHuX9W3/7VpR/6Vy4h3gub491N9urePdv/3dcwvRc9o5k68//S/b3t/9TlK+qOn3/f0X57//og7iGjXDPZ7abv2O58ugXovzBUbY+PXs2/w6vvfFKlN8b4H3ZcpHNO/bDe3lylL+r2t7M9p3unuY13D/IzlKenmZ99NZ2vgPYhvOOdoh1WTjeTgYY89OzaxXm0/N/VVXHJ1mb3t/P+7fTcA6Z5rsB9s66cI3cNPncKW3R6ZnWqqpqsjVyG96LJvz7Q+gGOPuWLu3asG8ZYn2ct+kB1oZhP59exwFWp3V0ks29JpPNuIZ0z6bpBzihHLanNswP0kenY/4AY1UqHS+H+A5tuKd9uhzgTGv4NSYDPBOTcDt3Ea4nfu/yxayAqnrr7eyMzMWH8/NSzz7zXJR/4+evR/mnvvyVKF9V9e5b16L8pYfC305U1WQazjuW4W9pBuhbzu5nv2k6WeT7BKnlAPO3yTQ7r7QI+9jNjfwddBf+brTvw3evVTULn4kuHGjSd4ZVVU2bjbfpPHwIAxzTrjP7eZsEAAAA1svVq1fHLgEAAAAAAAAAAAAAAAAAAAAAAADgP8T/TwMAAAAAAAAAAAAAAAAAAAA+r3bsAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYX+3YBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvtqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgfbVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mrHLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9dWOXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66sduwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1lc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK927AIAAAAAAAAAAAAAAAAAAAAAAAAAAPg/7NtZr2XnmRfwZ609nPlUlWtwea7YTuzykATHNJ1uQI0QQkJCXICEVOKCb8MdHwAJ8RG4Q1wxddOD2kmcOE7bScd2bJftcs1VZ9hnD2txYfoayf8l9gb9fvf/fZ6z9lrv8Kx3AwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrnbdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwudp1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5mrXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm6tddwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK523QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnadRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq110AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJtrvO4Cqqratq3d3YNvnZ+dLeIazs5Oo3w7mcY11ORcFH/3g19F+ddf/n6Ur6q6fft2lH/qmUtxDR+8fyvKf+/1H8U1nBw/jvK/ePe/Rvkf/a3XonxV1WK5jPJn8wGey0VWw95B9kw1o60oX1W1WnVRfrF8FNewu3U1y+9k/8ODo3tRvqrqcD8bG5rsVqqqqq3t7Sg/W87iGnZ3s3tytciey8Ui/x+a6qP8dPpEXMNochZ+wl6UXnX5M1HNJIq3zQDrltCy8vtpdpp9l3vbu1F+tWqjfFVV12Xf5XSyimt4cHwzyk+mO1F+3Gb5b4yidN9kc11V1dGjz6P8dPtylG8nTZSvqmpG4XVY7cc1HJ9mY+R4nG9xJ+Nsvu3D9V/X5/djNcdR/PQ0/y7/4A/+XpT/6c/eifKHB4dRvqpqMs3uhbby5/KpCxej/PIsXfdUjUbZXHN3ni3Gz7fZXFlV1fdZDfMuv47VZOvgarJ1x3Saj49tuPTp+/yZSO3uZOuOxXwe1/DgwYMof+duvp94+cUXo/xylV+Hs1n2XM3D76KvfB198dz5KD8ZX4hr6FcPo/x4/EKUXyzuR/mqqq7L9tjdKFv3VFU9epQ9V88/+0xcw8NHYudrVwAAIABJREFUR1F+q83mmcl0gPk2nCj2Dr/9O6K/sdjK1m/Hj7NnqlZ5T/y5C9necL+yHmZVVb86ifJb4Xw7wHRb41FWw0vXXoprOHeSrUFXq3ztdBKupfe3s2fq7skA7zf2s/7d0XFew6dfZr2zZ64+nf39z/IXHL/9/L0o/+SV1+Mavttle5IPPvwwrmFnJ+sVdF04znfhvrCqzqZZb39rma+D4654F/bO0r9fVen2tG3zMXq1zP6TZoArceli9i59bz/bE315606Ur6qazbJzPuMBzvk0cQ8wzA/QbmnCvlMX3s9VVYvwM9JebtqnqKpq+2ycH4/y9459OMyfHOXXoZ+F74DPwvXbM89n+aqq27+M4k9+Lz/TsP1P/k34Cdm700/+878N/37Vx7ezns/eAD3to1X2XF566rm4hlQfji3z2QCb7LDnsxigX5IOcMuwhkm4Dq+qatrsnj48l70z/KaIbGxYLrJ5YrHI78fd3axP0ITPVFXVKtzTVHh2rqqqFtln9OH/MMQbv93drH93cprtBaqqVuH9EN9OzQDnfMLPaNJ32FWV3tPp7zeq8ku5WmXzTN/l/btVeFYoXTNUVY3a8PxdmB+Ns3zVAN9lXEFVE55DTPtO7QBjyyTsl6TfQ1V+BnA5QA3L8Mx9P8n+h9E4X4OmbcxuiFk/PEuZ/hPNAL3cPm24DDBGh+276gcY4ZarbL5Lv4nTAc4q7W6Hv+2a52PLqst+a/jqS69G+U8/+yjKV1Wdv5C9W7h1Lzs7V1X15Cj7fdn+Tta3GrV5Tzw9f7e3l/0PVVWPw7NKowHO7C8W2bmvnfB8St/lz/XZWfZdjkZZr6Oqams7WzecnGTfQzPA+429ney8U/o76Kqq5TzrfW3t5GfflgO0UgEAAIBh3bhxY90lAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABstHbdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwudp1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5mrXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm6tddwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK523QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnadRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq110AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJurXXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyudt0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC52nUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmatddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACbq113AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrnbdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwudp1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5mrXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm2u87gKqqrq+r5PTs2+d7/tRXEM73oryi9UyruFXP/sgyr/91ltRfjb79t/B3xiPslvqr977MK7hrR/9OKvhV7+IazjYW0T577/xapRfDnA/npweR/l2PIlrmG5tR/m+2ijfdVH8m8+o7LsYNZfiGqZN9lwum3mUn3ezKF9VdXx0FOX3RrtxDZNpdh3vHZ/GNZwtsu9iZ3snrKAJ81U7W3tRftWdxDV0/X6UPzu7HeXH4/w6tk02vo3abHytqlr24diwzJ7rqqrRKFu/VbiGbNs++/tVVZWtGR48vB9XMA3Hhuk4e66bbhrlq6pW/SrKL7rHcQ07O1ei/NYkXDtlw0JVVZ0usjn78aOP4hrOn3sqyo8GuA5Nk92TbWXXsR9g7dR12VzXNPkeu1tlz+X333wzyr/77s+jfFXV9devR/ntcd5y6YJeSVVVDbDuOA3vySfG2TPVdfnectVl65bFKu+XjNrsfkjz6fqxqursLB3f8l7F7DTbD2yF654h1l6PHj+M8i88m82VVVV7+9n6bTbP54lzhxej/Hu/zPqoV66+HOWrqran56N82+djS3XhWrzPnqm2za5BVdXBYTbOn5xke6qqqkk4V23v5nP+3l42Pn1687Mof+5K9kxWVW1Ps+u4XOTf5c522CdYZN/D6ix/rr/69Iso/9b33o5r+N3Nr6J8P8/6Jc9czceW1eqTKN+ffieu4aDJ1g2rVbZmqKqazbNx/uNH2Xd57YmsV1JVdfXK5Sh/NDuIa7j/9ddR/qt796L8D974fpSvqvqTn/x5lN/dzdYcVVWXLmbP1Y9/nM9Vf/pnfxnlm1H24nA0CeepqtoLm4CzsI9aVdWmfaM+u45d5X35vss+YzrJ37G04f8xxPuJZ65ejfLLLus7jQfo5W5vZc/V2Tx/JtLXp214HZom7//14Uc0o7xPkJ7tmM2y/UQbnqmoqupWWQ+y2vyAyml47qtp8vcTOzvZvup//ObTKP/3twYYXH74WhTfvvwv8xqO/jiK/8//8J+i/MF29p6pquofvPFSlP/5z2/FNey+/WKUH6KvfnwUnr8Lazhb5L2KaZOtfVaL/LzUKFz7nJxmNYyb/F3VwWF2Hc/Sd4ZVtTXN1k7TcAF3fJKf+ZrPs/l2PMDZty5d+wywBF312Tu3SXjOezzA+u9smf0P/QBHtvLVV7qQHuAMYZt9F/0Ae+xqss9I30FX5ffkqM2+i8lWvp9I5/w23VxW3i9ZzLPn+vQkXzPs7mVnxVcD/HBgtco+ow3vx3RcqKra3gnXLbP8uT6dZffDznbev5ufZZN2F47zAxw7qz6cMIfYE6WzXZwfYL7twrGhCefKqqpReDC2Ww4wvnXZM5FehpNZfh3PXcjeQ3/6ef57x1eu/+0ovwjPVYzCPX5VVdNk98K5i/lv5O7cy96ln25l51suX8rfQafD0yDvBsLHah7+vq2q6vAg60OmY/R8no+P03DdcTTAOngZjtH7+9k9vRrgbHAfvkMewmicraVPBzg3dvPm3fgzAAAA4P8nN27cWHcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8H7TrLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztugsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO16y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztesuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7XrLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FzjdRdQVdX3Xc2Xs2+dPzh4Mq7h/kmW//LmZ3ENb7/1wyh/NjuL8n23iPJVVc88/XSWfybLV1X9xV/8SZT/wZv5/dS2V6L8yem3fx6qquaLeZSvqtrZ3Y3yfR+XUNWMonjXh/nlUZSvqhqNL2cfMM7+h6qqZWXP9mK+jPIX9i9F+aqqRw+/jPI7Oy/ENawqu6mffvrZuIa//uCDKH/+ub0oP5pOo3xV1ai68BMuxjXM5vejfNM0UX46zsbXqqquz5ZwXa3iGvpVdh2n7WFcwzgcI1d9dh3C+De6bGw5OMifia5vo3wTfg+zs2zdU1XV9o+i/FZ7Ia6hb7Pnshll8+3ZANfx5PhxlL908TtxDU1lG7Ozs3yuaptsDdg22TPVNltRvqqqbbPnsm3T+brq8fFxWEM2377x5htRvqrqo48+jvKvvvLduIazcG83P873hoeH2ZzdrbK5ru+z8fGbD8nu6VFl92NVvm6pbGipVZffC6tVtrecTvI25G7Yq7h3/0GUv333TpSvqrp+/ZUov1zm/btF/Bl5r+LWnexavvRKdh2vbD8R5auqfvvlb6L8E+fzNejOJBsc+tV2lB+N8zXD3QcfRfnJOL+OuzvZdZgP0Fev8DOeONyP8ne+/DrKV1UdXs72pztb+Tr44e1sbFmdnkb587s7Ub6qaryf3dPvvJ+9H6mq+r1X/nGU//ro11H+izt3o3xV1aXD81F+tboZ17Cz+1SUbyu/DpNwDfrpz38W5ZvnrkX5qqpxOEY3k7xPcPX57N3lrc+z++mjz7K9aVXVtWefj/Iffnw7ruHl57N1w8HeS3ENb//otSj/zk+zdzTTSb63rD5dd+R77K2t7Lk6m2X/Q9/ljfmt7UmU39sdogeZ7qvytfjRSdZTPptnvYaDw+y9ZVXVfJFdx9PZvbiGJuxjdl2WD9vR/7uGsHc2QBGnJ9lafBrO+e0o/x+6sI/ZL/Mx+sLFbA2689RzcQ0v3ns/ys8uZ2e2+r/7D6N8VVVT17MP+PN/F9fwV+9kfafff/MHUX60n/UZqqp+8t/eifJ7/+hfxDXsHBxE+bbNx4Y797NzFReeyPoEezv5fNuE7w23trK1V1VV02XfRTjV1So811FVtVhkZ3tHeVu+uvBlUx+exZyOB7gXVtl+4GSAHuRB+N5wGf4PVVVdeE/2bZZPz85VVY3CMTbfEVU14aOdjgztaIifcKT7ify73NnJ1uLnzuXrjsePHkb5/f3sHfTF81k/uqrqNPzdQDPAmYbqs8+Yhf/DUXhurapqEZ6xGeK5nE6y+a5Lz7QO8QOO8DNGAyxc2lU2TywX+R77MNxPnJxk5yDnA5wHnUyztc8Q65ZJeFZoNst6RvF5rRridwPr/9lmP8DqqQl7gKtwYzbEfuLRw+ys+Qvh+7aqqg/e/0WUf+2NrOfz8ov5+7Y/fe+9KP/Wa/lvH86OszE2vR/vP8jWn1VV1WXnS+6H5yCrqvbT3ll6qLXy356mY1MXni2uqqpwj72zm52JqKp4g9uE70i6sHdXVXUyy9byu3vZ/VxVdf9hVsMnv/s8rqFv8rNnAAAAsClu3Lix7hIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPi/oF13AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrnbdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwudp1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5mrXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm6tddwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK523QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnadRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq110AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJurXXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyudt0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC52nUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmatddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACbq113AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrnbdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwudp1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5mrXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm2u87gKqqkbjUZ1/4vBb529+eTeuYXbcRvmXX3gxruHBgwdRfmtrK8q342mUr6r66Xt/GeW3trLvoarq7bdfjfKLeRfXcHZ2FOWPjrL8ufMXonxV1Sq8DG2Tf5ddt8ryfZYfjS5F+aqqts+G2a7p4xpO5ydRfms8ifLNMvseqqoOzz0T5T+6+UFcw7Vr34vyf/3hb+Madra3o3zbZA/2qM3uhaqq5VlWQ1eP4hom493sA7pRFF8ts3xVVV+LLN9k+aqq6fhiVsNyGdfQtk2UPz45jvLjJlt7ffMZ4fqrz7/LNtwS3Ll3K8p3o3yeuLh3NcpPu3xbNAvXLY+Os73AznQ/yldVXTr/VJSfLx7HNfR9NkZPxtm655sasvlu1KTz5QDzRJ+NsfN5th/55jNmUf7wXDbPTCb5dbx27VqU/9WHv45ruPLU5Sh/8Vy+N+yW2Z6k77L1X1P5nij9jNEAz2X1WQ2zs+yZGo/y/2E6zebLUZv3CVbhEvLBw2y+fe369ayAqlqFY3RXed+qCXsVd+/ei2u4cDlbv+2Mz0X5X372XpSvqnrucjZGf/zxJ3EN16+/HuX39759T76q6u7d30T5qqo7D7Lx7erl07iGLz//XZR/fJyvQZ/7zrNRfrvJ9sfPP509k1VVN2/difLLcb4va8N1x9OXsj1RzbL7uapqay+bL5vmSlzD+19k73lev/Z7Uf6z2btRvqrq0VHW82nbfA06mWZz/rjNeuLfyHoVf/T7fyfK/+S9fL7dv/BEmM/2llVVXbh+O/9kti+7cytfe53rsnniu889H9fw/m+zPfILV+dxDdeuvhzl33wjm/N//ZsvonxVVdNk9+NklN0LVVXLRTbfTcZZDYtF3k/e28net41H+Twxm51F+XD5V1VVt76+HeX39rJe7s5u9j1UVX19O9vnTwZYg6Z3Qxf2jNoBej5p/25+lo/Rae9qMg7X0f0A/ZawZ9N2+bvTx7e/jvJ3Hufn7w6ezNbil//wX4cV5O/LTv/7v4/y/XE+T1z/5/8sys//43+J8n88ytbhVVXP/dN/FeXTubKqahUeflsu8ufyNDwz9exuNt9+/sWnUb6qqlbZmYRmlc9V4/Ds2iI8Q7gMzwJUVZ2eZvuJdK6rqmoqnC/D/GiA88nz8KzR1ixftxyHi/HJKP8u07Pi6Tu7ZoCzwekydoD2XfXhar7vs3uhbfPxMd1PzOf5fJvukZ9+4bm4hoO97JlYLcOzmGH/sKqqW2Xj085Wvse+cyfbD0xG2Xz91NW8l/vp51mvYwjxGjQ8FNFMBnjfFv52YTTE+ZRw/bca4HxyH46xaa/j5DR/75j+nmdv/yCu4Sh8l741zdaQi0V+xjrtxY6GaOY22Z6kbfLncpSOL+H/0K3yfdl0kt1Pjx/k52qvHGa9q6++yt417e3nvbM//OEPovyfvfuTuIZnw/evJw+z8y19l++JDp7JzqdMp/nYkp6LmA2wxz45zvrJW9vZXqAf4N1AhV/Fzm7+m6Sj8DrOwjP/0wF+x5K+Y7kVvjOsqvr4k/C3/dt57+vR4/wcIgAAAAzlxo0b6y4BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID/B7TrLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuuwAAAAAAAAAAAAAAAAAAAAD+F/v2tSTHeZ4B+JuesLMJYQEiEhRIiqQCxRJlqSyHcjj3FeBKXT7wgV22Si7ZEi2JYjIARhB5QSx2d1KPD1y6Ab5T7nb5ec7f3a/TnwcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv0ZdF1BVdXw8r39/77Nvnb98cC2u4drVC1F+dnoc1zCdTqP8N0ffZPnjp1G+qupnP3s7yq9XbVzD8XH2LJbLVVzDcrGM8vtns/dxmd/GGo+y5uH45CSuYWuyG+Un4+ybatu8iWzC+/iH/2H8AAAgAElEQVTs8G5cw2RyEOXXtRXlB6NBlK+qWq6yb2p7shPX8Nv3fhPlp9tn4xpevflmlF/Ns/bt/sM7Ub6q6uD8zSg/GOTv03o9y2oY7kX52exRlK+qGo0mUX7YZN91VdWiXUT5ZpR3Vl/duxflz57Lvsud3fw+Lk/nUb5tt+Ma5sv7UX5nK+tvt6bnonxV1WSY1bBa5OOWxfJxlN/ePh/lDw+fRPmqqkFlf+P82Xxetl5kc5rlMv8mRqOsv1yF7eN4A2OndvUsyo9G+bjlwvns227D+7iYZe1rVVUbzuu2t7L+uqrq5Cib3zZns7lAVdVqmT2LQbOO8us2ew5VVU04dmoGw7iG1Tq8jnDoNBjmbUu63rII36WqqsUs+xvb21k/8fz58yhfVXXmbNbGtqu8ffv664dR/tqNV+Iapm02r3q2yPq6Vy++FuWrqj75/A9RfjTOxy3v/eZXUX6yla29XbycPceqqreuZOugnz7O59jfHGbr4nv7+3ENX97+JMrv7mVzoqPTbK2kqqrWWV+zWGdjhqqqs2ezZ3F8mM3rblx7OcpXVd1/ks3LhhvY9huNmyj/6aMPovzL596N8lVVnz36RZRfneRrPmfPpPOBfO2sGWQ1pHOBn7/74yhfVfXL/8jW5Ufj/JvYDtv5wWAc5V+6cjXKV1Xd//pBlB+/OIprePngUpT/4stvf5bgj5aLbCx985XsnX7rzXxe9rvf347yOztZG19VtT3N2sjVMnsOW+O8jW6X2bNoB3kbPZ1kNYzDsyVVVbNw3/B0nq2rt03eRg/CV7rdwBg0/QtpflAb2DtdZe/CIL6KqlETfpfhma1XruX7G08fZutGq1l+VmncZHssP//r1+Ma6uDPo/jRJ/8c5X/14RdRvqpqHa5b/e3VfO/zyd//W5T/z8vZ2ZJX3vlJlK+qOg3XGvZ283M+FZ4vWa7y9u3mtctR/sPfvx/ld/Y2cH4vPH9XbT52Wi6y+WnbZu/CcJiPW9Zhf7nYwJnWUbhXNGyy/bL1Bs60psfGVhsYtzThuGVnJ2/fTk9Po3wzyeZVi2W+f5t+E+0GXqgm/LbTa6hwH72q6iRcs2nTPeyq2h9l/cRolK9VbIVnM45XWT+z2kBft72T7Ru2G/j9xW44/hoPs2c5O83XfC5cyNZyHz7K5lRV+bhh2GT3cTNnrLP2aRPrBE14H/LWLb+X0+2sfVyH96CqarnIxpDzeX4+ZRq20W3Yxq43MWYIn0UTto9VVes2PH+XNw21Cn/Ps0r7qg20b8v0HOQGakjHoM8Psz2/8wfZGZ2qqqNnh1H+Jz/4UVzD3S+yMzbn0vPNy2xOVlV1HK6dTXfOxDWcHmfzidUq/yYGTbaX/uJF9izGkw2csRll6yWrDaz5DCq7j+vwN0ntKl+DvH07Oy/1/Dg/572zk73TTw7zZ/nazfxcKwAAAPzRrVu3ui4BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID/B5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv5quCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgv0ZdF1BVtTXZrjdv/uBb5yfj/DJeHL+I8tvbO3ENX331RZR/6cI0yt+4/p0oX1U1e/E8yg+bcVzDYr6K8pOtSVzD7u5elJ8vsmsYDvNv4vD5N1F+b3c3rmE8yu7jcjHM8u1JlK+qmjTzKL+3dzWuYZTdhlqusvfpNHyfq6pGw+wirly8EtewG77T091zcQ2LZRvlx8OtKL9/5kaUr6qq5jSKD5u8jW6XWX5dT6L8eCsfM1TbRPH1KstXVQ0n2ft4//H9uIbt3e0of/fuZ1H+rdffiPJVVdNR9l2ezLKxV1XVZHIxyjfr7P83y0X2B6pqucz622WbzQWqqkaTrJ1/cXIU5Z88zNqmqqrVOuuzz5/P+7pJOP6rZhbXsFxl3+Xp7DDKL+ZPo3xV1XSafderVfhhV9UyHLcMBtn72AyieFVV7e9l7+MmvokPP/owyj+8n/e3L128EOWbJnsX5rNw8FZV6fLXPLuEqqqahB3mzjQbQ65W+X08PMzap3XetMTrHbNZ1k/cu/d1lK+qasK1rxcv8n7ileuvRfl2ka1BVlU9W2frTgc756P8+x/9LspXVb32nbei/NZWdg1VVcfHt6P8vS+/ivL7G1hHPWqz+cDBTjZ2q6p6cSZb8xmOw8W3qnr1+nej/MMH96L8ap0PnhbhvOzMNG9bpoOwv93N+tvTk3xu+fyb4yj/6nduxjWMR9m3/dWTbE70+dEHUb6q6uaNv4jy9778ZVzD0VHW121P8/ntNGynB+EeS3N6JspXVf3kR99+/7iq6jfv/yGuYV1ZG7l9LpujX99A+3jptf0o//6DB3ENgxdZG7mzm93HqqovHz6L8tvb2Rjy6oWsv6+q+vE72fv40cfZmnhVfjbj6vWDKH/xcj6OrnCKfOdONvaqqtrdy/Y35m1+HuDxF9m3felytvb18HE+dmorG/9tYKmiKuwnBoMs3wzyPb82XMvdxKLPaJRdR9Nk38TNt96N8lVVL1/J5hN3fvtxXMMbf/k34V8I92iq6vH7/xLlH6yyMeTrP/yzKF9VdXScjeX/NVxvqao6885fRfmXmmwsv5jl+7eTSTYfmc2zdYaqquEkW4vd2snPdty9czfKj3eyNvpklp/FnI6y92HZ5v3EeJzNi9ZpXzfI1//acJ9muco3qwbhXtVwFI57wrNOVfnYqdJ8VY1H2XfVtvmzTIdfTdpPLPJ1q3Vl92G9gdH8bngeYBSuoz57nq2jVlUNBtl9vHCQz7Gn0+w+bG/na1+1zu7D6Ul2Vny1gTZ6Ms3WCTbxPi3Ds94ni2z8tr2TnzWvdda+DYf53udimb1Po7CGQbhOUZWvl2zibEjThGekN9BPLMNzreNwTrQdtgtVVaeD7Brms3xeNplkazbr8IVqNjD+S8dvy9UmfksTrp1tYE6zCq8jfZbtBtq35TKbl4038Du9tJW9Ep7l/PgPv47yVVVv/fBPovxqA3OiM9OzUX7RZut/587mZ4OPZ9nvqiYv8jWfcDpRbbuJNjbLD8N52XKRn6tN++z5PP/taht2Nafhma+PP8rPtA4GYRu7gd8DnRxnz/KdH2bnSauqVunDBAAAoDdu3brVdQkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPC/oum6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6q+m6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD6a9R1AVVV63Vbi8X8W+dPT47jGoajYZT/4IPfxTW8/faVKD8anovyp7NZlK+qWiyWUf7+/XtxDdevvhz+hXFcw3wxifLL5YsoP2iOonxV1bkz+2EN07iGxfLbtwtVVcs2ex8Hg0GUr6oaVPYurKuJa1iu11F+0BxG+WHtRfmqqvU6exar9VZcw+7u2Sh/7+vfxzVceelGlG9X2f/f2sCoYXayiPJHw6xdqKqaDrM+f7TcjfKDUfggqmowaMM/EJdQ7TKr4fLB1biGdXgh+29kz3I4zPu6WZt9WINx1sZXVc2X2Ts5HWfXcDo/jfL/Ixv7jIYHeQnrrG2ZhF3+Yp6P5Vdh2zKd5N/EapbVcDLLx/KL5bMoP2yyh7k9zeZ1VVVt+D4OmryvOjl5GOXH45ei/KDJ5gJVVRWOo+cn2byuquriS1n79ODBg7iG0SR7ny5cyK5hvLUd5auqjk9OshrCvq6qqtbZfGIweB7lDw+fRvmqqr3dnSg/m+ff5aPH2XUMh9mzHA2zOX5V1dFR9l1evfL9uIYmfKfn63z8tt9mY/GPPv0gyp87yNa9qqqqzcZf87CvrKqaHWXj4CsXszb68FF+DZcuZ33+fJmtM1RVXb10Mco/e/5NXMNqlvVVB2ey9bdxG64zVNXuNOvrVjv5d7mzytaNjtts/LdosnFTVdXb330tyv/iw9txDadhP/Hu669H+Qef343yVVV3Z7+K8lcvvRvXUG3WRo6G+Tz/0YPPovz+3rUov6x8LJ8uan/vjTfjEt774KMof7bJ1ioGO9m4qapqa5C1T3/6SrY3UVX1j7/Ovol07ayqamcr2yu6/emjKH96mo+jr1/P2qfvfT9f85mF13Hxys+yAtLNrqqqcXYNr76Rr0F+eufrKP/xnS/iGnbPZO3LapXt0UzG+Rz75Dhby93bzfex0287Hoq3+abfVtjINosNfJeL7D6eVFbD09v/FOWrqs6/kp35euMv/y6uoSpbk/7o1/8QV/DNaTZP3z+TzS0X82x+XVX16Kv7UX7nIFvrqKra2c/ap1W4hbxa5mu5g8qKmOzk+45PnmRrNsdPs7lAVdUgnGO3YX87CtfEq6qGYZ+9u53PDUfjbCz/8PGTKN9sYM1nsM46/cEGjnqnp0uW4cClGW5gYpeOQScbOBscnrNuwvMEVVWj8Lz7chWeq202cK52kN2HNvymqqpm4bOchefl4/N/VfXTn74T5YfDfE709DCb3969ezeu4fKlbPx15dr1KH/4JOtnqqpOw/Ml+/vZXn5V1ewk+yaWo+ybODnJ186acTbuuHw5X6t4+ChrI+ezbK8r7CKqKj4uFY97qqoWq2yevwrPxFZVpafVV+GN3NrAealhOI5tB/l9XC7CsdMoG7+Nxps4T5rdh3U49qqqWoX72FX5d5mOAIfhb7OaDfy2K7XawLNch89yFe6RXL2YnY+pqrp757+i/I0br8Y1nDuXrSHe/TxbM9rezd/HM9Ns7et4A2OnNvgtd1XV1iT/nd44/O3BfJbdh8Eg/y3OyXH6u/a8v93ayvb8PvkkO1sS34KqWq+zPvvGq3nbMgx/a/jgYf67+AcPs/0JAAAANuPWrVtdlwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP9nNF0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEB/NV0XAAAAAAAAAAAAAPDf7NvZkhznmR7gr7KWruoF3dgIAiBBcAFFiZJIzngsR8yZL4MXyDvwgcMHjnB4FJYsUcPVpGa4ieCCxr50d62ZPlDoBviWo8ozz3P+dn+Vlf/+FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtrsOkC/ma1Wv7k7P65c/H///zzD6P8f3jn1biGZduP8ovVSZQ/nc6ifFXV8fG9KH/96vW4hqY/jPK9Ji6h2nYa5YfDUZRvmkmUr6rquux97HXZZ6iqmi2eRfm2su9hPNiP8lVVTYXPsReXUNX89P61qmo+zZ7DKGyTVVVd2C7bNTzHu8f/J8ofHZ6Pa3hw926Uv3o562NXy3mUr6ra3z2M8rfvfhvX8MLFi1F+t589h9PlXpSvquq6bMzuuvy7HDRZP9/N8obZDLK/sQzmn1VVH338hyhfVfXiq9kc8mg/a1NVVf1wSXDn/g9R/vDcOMpXVU2Gl6N8t2zjGrp2FeWHYZN44418PdL0s3a9hmGi2lU2dxoOs/ljVVXX7ET5tE1Vl8+dluGX0etn8+iqqsEwm/s0g3Rhli/s2i4bJ47vZXO3qqrJJGuXt15/La7h66+/ifLf/ZCNE9euXYvyVVX7k2ysGTZ5u2x6j6P8wwdPo3y/n/WvVVU7k6x/nC2ysbKqajzJ5tKzabZ3du58vk/w3OVXovxqufn+bdjPa/jq+F+j/M4oex/PnmVtqqqqnWbzjoOwb6qqGoUbR4vTrE0c7uZ7kCcP7kf5/hrex9Uq659Ga6hhepK9k5fPZ3Ovwyv5+3j/OJv7rJ7m5xOLg90ov3uYnTXNmnyv4w/f3o7yT5b5eDuYZ+uJD/78eZT/+5+9FeWrqk4fPYnyf/7it3ENr9zIxvyvv87ehaqqZ4+zOeiNm9m+06jLP0O/l7Xro8mluIYbr96M8j/ceRDlZ8/l+1aH42we/U+ffRTXcPOFbG13+y/5+3QadpGjQbau+vr2w6yAqnp2mu1Jv3HrN3ENo1G2T7BcLKJ802R9W1VVrbIxv+m/FJcw2c36hv4azl8Hw+ydns/D/qnL4lVVF46OovxykW9q98N12Sj8Hro2W+NXVXWrrF0O+/mXueiy9+kw3A/ev3AhyldV1eD1LN9+F5fwh99ld9+6Ndw1Gvay/unO3e+j/Fvv5GPd6TRrE0dH+d2Qp8+yNc0w3DsbruGy0miSvU/ffPlFXMO5/axvGI3zu2/Vy/rINjyD7tawbzVfZp9hmF76qqqTp9k+ZvWy8Xa5hvsEvcraVW8Nl1q7sG234Xg93sn6pqqqLpxEzsN9r6qqtgvnPmm+qgbDbLxdzMP532ANPz0Ih5pmDWNVem+sDfdib916OcpXVTVN1i4/+/yPcQ3nzmXrshs3XoxruPPjj1F+spvN344uZPdRq6oe3c/ep9UiP2PpKrz7NgrHun4+Tkxn2X2nppevDc8fZTUcH2f5rs3HmW4Lxrp032g4yufy6Vx8Nsva5WCQt4l+eB90Hb8bmIfzjmYd71Mob1Zr+IFaqG3zNc2gyT5HE56lp2uqqjWsq/LHGGvC96nX5c9xb5D1b/fuHcc1XLyY/W7g7V+9E+V/+/5/j/JVVW++lp2dLs7O4hr64YC7WEO7TM3C+d94nI+3i/CsaTTM19iTcM9lJzwHv/6LN6N8VVUb3t/bGWd3S6qq/uXPn0X5c0f5Pe1f/zpfIwMAAFB14cKFevfddzddBgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/LvQbLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALZXs+kCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhezaYLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB7NZsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDt1Wy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2V7PpAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXs2mCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgezWbLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7dVsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACFVEUoAACAASURBVAAAtlez6QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F7NpgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHs1my4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgO3VbLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALZXs+kCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhezaYLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB7NZsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDtNdh0AX/Ta356KZ989sf4/9969WaUX7XDuIZVm+XbLqvh6bNHWQFVdf3GC1G+3+TPsTfIXuvZ2Ulcw7Dfj/K9Zj/Kt+1elK+qGoxmUX4xz9+n0WAnyveb81G+7RZRvqpqtsr+xsmz47iG/b1rUX44mET5rlZRvqpqNn+c1dA7i2u4fOlmlO9VXsP4UtYmHp3ei/J7B9ejfFVVt3oS5V+68lJcw9mzb7P8uayG3jIfZ7paZn+gl41Tf/0TvSi/WkPf0KvTKL83uRjlB03WP1ZVTR9lfcNpdXENtcqe4+F+Nu8Y9bPxuqqqC9/ptpnGNayW2dxn0L+QFZA366omW5CsVtn8saqqDRdFXe8grmFnlM3funRd1+Zz0OXqYZQf9ML3sar6g3BN1Au/hy4cK6uqumysun71al5D2M+3y3y8felGNvf5/e//d5R//ChfW+5PLkf52Tx/jifPsnnw/n7Wv83na1jfTrN+/vDwXFzD3btfRfmdnWxNdf36jShfVXV2mvVPXZdv5/bDMb9rw8GuqvqVrSfOTp9F+RevPR/lq6p2BtlnOHmcjddVVdNpNo8d74T7yU/yPrppmig/HOb7yW043vab7F2oqhrtjKP83XsPovzOKF/fdv1sbfgv334c17B/lO2D/vzqi1H+++9vR/mqqqePsn2j4WgU19ALp9LLaTbv+ODrD7ICqurtF34Z5dtFtmdUVfXJx59E+VfDc8uqqjfeeCPKf/PtX6L8s7N8DnrthWwuf/tZPt5eGF2K8m/+Klsb3j/Jzxb+y/u/i/K/uHkzruHV3d0of+XNo7iG9z/45yifnmP/8vWsTVZVffndv0b52So7H6mq6hZZuxyEA81wlO//5eNl3r99/dV3Ub5ZwxnLNN2ruJitsaez/LysH67zDw+zexlVVSdhP312mu23jLIlVVVVrZZZu2zXsC67Osja5cvvhH3s5OUsX1Und/8U5T/9JjvLr6raO5eduZ2d5udl01n2Pk0mWbt+/4/ZfnRV1eXL2b7RDz9+E9cw2c2+y4NRtoe4hqOF+urLL6L8ZJwffs4W4VlTL9/zadI7hF3Y0a/hbkiFe7mz2TyuYBmOVek32Q/vx1RVdV32N3phvqqqH+7Fdm3WOZye5evb9DMMB+vYT85M53mbGI3Ce7XxWX4+CW3jJ5m3ibSbb8I/MA7nPVVVDx9le1/jcbZfU1X19Em2tnvyJNvrqKq6+vyVKH/3OFujX34uO5uoqjo8PIzyDx/m64lePx0nwvO2cN5UVbW7m523nZ1lZ9BVed+wv5vtfZ2eZXdBq6p64dlp1+V3WtP3aRD+nqiqqg3nHfFvw8JnUFXV9MIiwmdQVTVI51/pHHYN72MvbNeDNTzH9J5O2qaqqlbp/C18Dvnsr6oXXu5N34Wqqn46lw7vfPXSfqGqmlU2VrWzfN4yGme/XX348H6Uf/vnv4nyVVVffp79FvrGy/lvu6rNzieS34L/zXyR9U/H4X2pw3P5OdGlS9n9kjbc96qqGoyzM5Zbr2dnJP/jf/6vKF9VNQzvrj1/JV9j/+JnWf92kh+x1IN7+X1MAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYdu+9996mS9gK77777qZLAAAAAAAAWItm0wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL2aTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPZqNl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANur2XQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyvZtMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC9mk0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2ajZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbq9l0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr2bTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvZpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9mo2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA26vZdAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK9m0wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL2aTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPZqNl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtrsOkCqqrmi1nd/v7PPzl/69YLcQ3Tk1mUP79/Oa6hadoo32+GUf7g8HyUr6qaLxdRvt/vxTU8PjmN8rujc3ENTW8vyvebrGkuVk+jfFXVDz/cjfIXLx3FNfTDLqq/WkX5rjeP8lVVy8r6loP9q3ENTfYYqprsM5xM74cFVC3Dz7C7dxjXMGiWUb7XZf1CVdXj6eMo//1x1q4v9/Npw9XJpSi/02V9fFVVO8z6+U+//DjK/+rFV6N8VVV1TRRfddmcoapqVVkfeTJ9ENewN876yH6TPcd07lZVdXKStevdvfy7vHz+xSi/WmXjRLvK+teqqkWb9Q1tL5vDVlUNBtlcutdl8+C2Swf8qvliGuV7bdamqqp2BjtRvqvsM1RVrRZpuwpraM/C/181GGRz8VXevdWgydrVdJqtaUbDvH8cDrK5T1P5+na5yL6Mts2/zK6y/uXv/+6dKP/hhx9G+aqqS+d3o/xi3sU17OyMw3zWPz55lu8TXDh/Icrf/u77uIZLF7PxdrJ7EOVPT/N5S7odO1hD/9ZV1kd3a5h3XLl8Jcqne4hPH+V7Fe0o+y53dkZxDat5Nu84OzmJ8qN+P8pXVaUj1TLdNKqqrpf18718yK9mlPXz43E21j1+ko8Tl557Lsr3Jvk5z2u/+FmU//0/fxTl20HeRw/Cv5G3iKoaZGu7XhfOnZ7mc9ivvv8iyr96/UZcw6WD8Iwk3Leqqrpz71GUP7qQtet1fIbvw7Oqh20+Vv1lnO2DXtq7FeUv7udzhuuXs3n0hTWM+U9nWds+Psne56qqt3/58yj/p08+ifKzeX7uePnwWpT//IvbcQ2v38wmP4vFfpTvurxNNL3jKN8f5N9lE64NJ/ljqH445l8+ys7bXnkhPwf/9ofsuzw5fRbXMAjvdgzD72Fxmp+dnt/P9ksu7uVnyJevhHOnyctR/POP/1v2/6vq8TRb1+1Nsv6xqqptw7l4OpevqmW6Jx3G9w+yfdiqqkdPsjno0WF+h/DKlexexf0H2Vn88Xf5nGH/YBLlu16+wl2G27mLtE1VVT/cd1ossg/RH+YbV4PwvGwd8+D0vKsfrmnSuyVVVV14H6Br8+8y/Qvz8H1cx554+j7tjvL9uzZ8kr34MmfVs3RvPzxr6g/z+V8vfI5rmLZU14Vn8eF52Wya329ZzLN2OR5n4/Vf/0a2njg+vhPX8PBhtm/U62XjxPGd/DM8d+VilN/dy9cTFY5V0/CdbtZw4NZvsr+xG87dqqpms6xvePgwO7MbDPJxJp07hd1rVVXNF+FvktYwUOyMs/Xlbj8bb9O+qaqqC59Dv8lr6A2yOWBX2Wdo1/BCNr30rnm+nliFa6LVOhpm+NuF8KusXvoH1vA3BmtoE80gvCsefoZ1rC1ny3tRvuln+6hVVR+9/09R/td/949Rfj7NfjtRVXX+8itR/tsff4hruHEtO0M+O8v3fO4eZ/uYaR+7M8nuW1VVPXiQ/R5osIaz+F7zMMqPJ9m85zf/8FqUr8p/mzUK72hXVZ2eZr/hePIov9PQreG3fgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP8f3nvvvU2XUO++++6mSwAAAAAAAP4NaDZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbq9l0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr2bTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvZpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9mo2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA26vZdAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK9m0wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL2aTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPZqNl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANur2XQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyvZtMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC9mk0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2ajZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbq9l0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr2bTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvZpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9hpsuoCqquFwUM8/f/En5/fGu3ENp88eRfmT2dO4hp3JXpRfzdsovzfJn+Ozk+w5Dvr5K3kufB+Gg0lcQ9tmn2O+OMn+/+pZlK+qunjhMMo3XfY+/9UySre9LN804yhfVbXT24/yXdfENayasyi/nN+J8juD7BlUVR0cnIvy8+xVqKqqxXIa5R8+uB3XcHh4Psq/9fO3ovyHn30c5auqDm5k7WrYy8eJ3Z2sfzray/Jf//BVlK+qeunFX0b51fR+XMN80UX5g73n4xoG/dMofzbLOofXXnslyldV9YfDKD9osnxVVZt9lbXssnZ9tsj7x/FONtbsNPk8uOln38WqzcaZ05NsvK+q6vf7UX48yedOq0XWLpfLeVxD0+9F+eFglBaQ5atq1WafYdXlz/HOnYdR/tKlS1G+1ws7tzVYLvNJaPopek32LlRVNb1sTbK7uxPlX3nlxShfVfXRR9n8642f5fOW+SLbs1m2WR+7s5OPdV98+XWUPzq6ENdw9fnrUb6r7Hu4e+9elK+q2ts7iPJt+Bmq8j5ydpbPOyaTrG9YLRZRfhjOe6qqnjzKxrr93XzuNJtlc8h2MQsryMfbLp37rGE/Of0Uqy5/Dr1VuLe/n/UtZ2vYO3t6mn2GK1fCeXRV7U6yPcR33no7yn/wab531oZzyN4a9pMXy6yPHU/C73INm7nnhtk4M5+m/WPVosvn4qnlahXlZ8ss/yAcK6uqHj/Kzl8Prl+La/hPF29G+d/d/SbKv3OUnQtUVfVX2Vj1p08/iWv4x7CPvXYhX0988vlnUf4//8N/jPL/9be/jfJVVa/dyPakx9N8vP3mL9k7/crLt6J82+bnjr15uEYOzxaqqq6/cCXK37+b3cuoqlossj3A4+9+zP7/QX6f4MJ+1kcuZ4/jGuL1QLjMH4XznqqqB/eyMfvyJHufq6rufPl9lP/uyedRfjbM+8dmJ/suunzLp6bTrF3PwjOaqqo2PHhswzY1PcnOj6uqXnn59Sh/cC4fqz795KMo34b7f8Nxvnc2X2brqsluvqd9cvYkyjdr2HdqK1sb9tIawjOeqqp0qBuEdyKq/nq/OLEK91vaNlsfV9UaOvo17EGG78POKBsvl2sYZ5pwnHm6hrP4bAeyatbLa0jPu9I9ozU062rCc5rBYA19dJc9h3l4xjINz3iqqnbG2VnTgwf5mmjQz2o4OMjnTrt7WQ29cCv34YP8DPncYdbHjnezO//r+BsP730X5c/WcAbdD/vYNXQtNZ9mL9RomI3XizXcnVuGZwMH4bllVVU4ja7pGs55VuH57c4o65sG4Ry4qqoLJ/Nd+kWs5W9k+X6Tr4nie4jhnKOqqt/PPkc696qqWrVZm1jDiib+CxV+l+0aPkU6F2/D7yFe5FdVE66rVuF9hKqqF65lZ8AfffinKP/mm9lveaqqxuEa+9xBfqf1LFyT9Nq8b9nbz9YDN25kz2E8zseJ4x+z31yuo12m69N0C3Edt2Nm02zfaDbNf0ud7gHur2FP+86d/Ld+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw/9p777236RIAAAAAAADYIs2mCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgezWbLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7dVsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtlez6QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F7NpgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHs1my4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgO3VbLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP/Lzr01yXGe9wF/uue0ZywAEgRJQTxIIiTrUI5Ljp24kqrkLre+xAfUV8iNK5WoSrlIxYpkOypREimQAikS5wWwu7Mz0925kJwPwH87M0r9fvfP7DPd7/F531kAAAAAAAAAAAAAAAAAAAAAAAAAAAB2V7vtBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXe22EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgd7XbTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3dVuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdle77QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F3tthMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1204AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgN3VbjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHbXdNsJVFVNJ5N67cbpV47frDdxDpNJE8V/+fj3cQ5vvfVOFD+dzKP4Zsif48n+UZZD7cU5NP0i/IQuzmG1eRZ+wiSKns9uhn+/atIOUXzfLeMcKs2h6cM/n40LVVVtn33GplnFOWzqVRTftDei+Nk07ZNVQ5+NT01dxTlUm40N55fP4xRuXLsexa9fraP497729Si+qurzx59F8XduvR/n0F9lY8PXb38tiv/do8+j+Kqqi+UXUfxesx/nsNjL+nbft3EOy022lO3rLIqftPm6ZTJk32Hosn5dVdWGr+LZiy+j+L2jr74P+L+a7F10q3zO30yzd3G+ytaP+/NsHV5VNWsPovhuna+jm0m2Du5H2Bs2Q9qvsue42eTtsWmy5zCbxSnUG7feCD8hm2fSZ1BV1fdZW9h0eQ5tm80TkzbrU1VVbZO1yU8/eRDF37//2yi+quoHP8jWkM+evYhzOD29FsW/evUyin/8+DyKr6p67WbWr2/eeD3O4WoZzjVt1q/3Fvka9uHD30Xxp9ezPXpV1eHBYRTfd3mtYnmRjZFH4XeYjDDZzU5Oovgnj7J1dFXVYhaO80O2P+42+X6kmYV1o7xbVhuuQYchXwcfn2b7ojasv91Y5HWCIaylnobzzB9yyN7F5vIyiv/GnTtRfFXVbz75NIqfDHmnaMOO1b3MarH/5i//PIqvqmqvsnlm2WXjY1XVZbgfaGuMvWEW/7sH2dln2+TzbTpPvPj8cZzDz8N1w8XDh1H8f76f7amqqv72X/8wiv/pNH+Xv/gsG9++M8L5xLe/eTeK/9mvPori/+O//3dRfFXV3/2XH0fx37iTP8flVTa4/Ox//yKK/+C9fG/Z7md1gv1Fth+pqlpfZfPl5UW+L2vD/cBiPxsbJqsR7mW8ytZvm8sR6nezrH63N8/ON558ke8th032HD55mp+D95OsPVxNsue4N8/vNMwPw3PDTd4nunAd207yOX8a3nfqw0Xs7dtvR/FVVdNp9h3+6R9/Gufw9tu3ovhnz7N+uR6hPTZNtrd8eZ6N8VV5DXAzwnNow3OaJjwnqhH2ln12fa+qy5/jEK5bmsq+RBpfVTXEOeTSz5jPsvvJF5f5fdImvOAyX+Z3CC/SenLcqaom4XPo+rxfpq6usj3N8io/n9gP9zTTafYelsu8TywW2VlV2+brv7Oz7Bx7Ms1rsbdvZ3fmX758GsXfuJG9h6qq397/JIq/+8H34hzaJlt3XDvNnsNqNcI8Ec633SafJ54+ye5mNOG6ZxKuw6uq0p9PPD/L6wQnx9kdm+lhPr6dn19E8X045zfpIU9VDUOWQxj+R1mbbNvsOUxGuE8whGunoc/nujasVYxR87laZ+uveBk8xqYo/JB+hE7RhXdS08fQjPAdluG9ioO9/PcXV8sshzuvZ7/L+u1H+Z3Wd7/xjSj+8DC7q15V9Q+//jCKf+eNfB28CQeHsxfZ74HS36BUVb35Vnbf6fnT9DfIVQfhXcqnT7IcTo6Po/iqfH+6WuVr+Vk436ZXOauq3r6d358DAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+NNy7d2/bKQAAAAAAAIyi3XYCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyudtsJAAAAAAAASonOhwAAIABJREFUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC72m0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDuaredAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q912AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsrnbbCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwu9ptJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA7mq3nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAu6vddgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K522wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLvabScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qt50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALur3XYCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyudtsJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC72m0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDuaredAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7a7rtBKqqur6rs5cvv3L8ermKc5jOF1H87TffjHN4/PhhFL+3OIjimyEKr6qqG6fXo/iuz5PommUUv7q6zHPoN1H80eGNKL7vJlF8VdV6nfWryaSJc5hMs+8xhEPc0OXtcRiyz+jWZ3EO08lpFj+fZwm0V1l8Vb188TSK32yycaGq6tr121H8u+/8qziHvruI4q82z7O/X7Movqrqzu0PovjVMpsrq6qmi9ej+OUy69e3Tm9F8VVVD588iOLfunkU5zC02XMYo1821Ufx0yZb//XZn6+qqiFct/RDPt92QzZfvnbzrSh+qDaKr6oauiy+GWFX1PXZXLWYXssSaPLnuO6zeWa1yvdl81k218znN+Mc2uZFFN/32X5ihC1RTafZcxyGcP1XVUNlX2SobHxswzmiqiodYdsmW4dXVS1mX71WUlW16cMBsqo+vn8/il9eZn3iu9/9ThRfVXV4mLXp6TTvE8+eZmNLF+5P3/5a3h73F+mcn9VKqqrmi6xnPnuevYe2zceWk5PjKP7wMKv/VVXVkH2Pk+PDOIWzs6ze8eRJtm65cf0kiq+qaiurWy0W+djy4uxZFH+8vxfFt22+H0lHhukINcjZPHsON07zMfb52aso/uRa1qbHqOW24Zbk5cu8Ln/2IhsbTsJ3uX+Qj4/ffCd7F4+ePIpzGIZsP3HzxmtR/Bj1ln6SNcimy5O4usr2yGOsQT/9fVZL3Z9n645VuOaoqmrarGgz2cuLPi/vZ7XYvb39KP7ND/J5ptps3fKt17O9QFXVq3U2zq9m2XxdVdU32XN48eo8iv/J//qnKL6q6j/927+O4v/rT/8+zuH4IGuTt0+zeeKj+1kdtqrqva9nc91k8s04h9Pr2X2Apw/z89fDaTZXvXyVnTuePc3rVic3sjO/vfQcvKrOzrP63dMXWfwknCurqvb3s+cwpJuBqurCexVNWBOf7Odr+aOwuH8VrhmqqvbCbvXqVdYeq6ouwvZw+zg750nPmaqqHj38OIq/cye/Q7har6P46Szr1xeXWR21quKzyzHGtz7sl3m1pOJabJrEMMIZcnovI30PVVVD+Bmz8A7iZJLfxUxLqeFUWVVVTXh+23VZNXcxy/v1ussmu80mX4P2YQ6TcI/+hxyyd7kXnk+sVvl+ZP9ghPOu0DBkbXo+z9r0xUVeE0/vhszm+dppL9xPXF1l9Zaqqv29bD2/v/duFH/24tdRfFXV/n72+4uPPvplnMO3vvWDKL6dZvW7g4N8T/Tiedie+nwF2IT3atMMmhHWf0N4UNOOsHY6v8ze5cEI88xskY2Rmy6rvbXrEc5vw3fRNGPsikbZWX1l6W95/vAZWfwYe6I+XMeGQ1NVVc3DWurFZXYfdIzmOAk3Zt0IB9lpv0r3ZUO4n6mq2tvPxthuhByaJvuM5y+y843pCD88ePIwO8s/vZGdM1VV/dWf/0UU/3f/4ydxDt9+Izt3fPo4e5f7e29E8VVVB3vZ+muxl5+DL6+yffrBUdavn7/I68mH4Z2rdpL3y/Sq0KPwfwNUVc3D2j4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPD/xr1797adAgAAf2J+9KMfbTsF61gAAAD+xbTbTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3dVuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdle77QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F3tthMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1204AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgN3VbjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHZXu+0EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhd7bYTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3tdtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDd1W47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB2V7vtBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXe22EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgd7XbTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3dVuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdle77QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F3TbSfwz4bhq8ceHBzmCUzaMHwSp9A2Wfx6dRHFv3Hr7SyBqurW2XPsm1Wcw9BusvgRusXx0a0ofrN5FcU3lbWFqqpN10fx09lxnEOfpVDrLutUTeXtsallFD+b3ohz6NfZcximwQBdVa/On0XxVVWrddYYbp7eiXPou3X2AZOsX1dVXVxmfXuxvx/F702y+Kqqps/G2GGeja9VVc8vH0XxJwdvRfGTvoviq6oOj7Mx9vIqbM9VtZhn/bIf8jG2bbL117TZi+JXI3yHYbjKPqDJ++XQZP2yGcK1U5/NM1VVm002Ps5mcQo1a7M5ewjHhq7ChVNVbfqsPfYjvMv5LNvbdd1ZnEPfZ2unrs/G2GHI32XTzKP4Lu3XVVXp3i4cH4ch25tWVfVdNsbOZ9leoKrq6iJ7jr/41S/jHK7dOIniv/Nnd7MERhhb2ibr19NJVmeoqnr27GkUf/fud6L4+fxaFF+V70f29/Pa2ZcPP4/iZ/Msh6Pjoyi+qmoT7m8vz/O95XSSPYfL9Rj7iWwB9vj58yh+0uT7stkkG1sOD/Oa9mp5GcVfhe9yP3yPVVXrMIdmjD32XrY3vAjn66qqa9eyekc3ZO+iqfw5dl32GU2Tz/mzcHO3WmbvcrE4iOKrqt64nu0trx/m/fLgIFv/rVfZu7wYYZ55cXEexb9+lD2DqqqTk0UU/8sPfx3nMNvP1i7tQbYnapdh3auqKhwahk3entpwvuun2frvk48fRvFVVU/OsnfxN+9/L85hs8n2Vb/67Is4h7Mvs884PsjG+bbCywBV9ZPffBLF//UP/zLO4cc//m9RfH89W/dMmrzm8/GnWVuYvpPn8NrJ+1H8nTdfxjk8/DQbX66fXo/iP/3kQRRfVfXs00+j+OPT0ziH81U2vk3D5nR0mNWCq/La/iq8W1JVNYT1u3g/scn3RJfhPHH5/EWcw6TN1i3dCHPV3TvfjOIfP30cxV+EddiqqhunWS11OsvPWJZX2f50tcri98O7JVVVq/A7tOlFyqoaumxsyGf8qiYc31Jduqmq/DlM2/xJpu1hGt4Nnk3zfh2WzmpIL1JWVRfO2V2frXsWI4yPm3Cf34bnI1VV80n2PS7D87aqqqOjrObTh+2pDftUVdWr8LxrNkJ7mk2zseXaSbafePjoSRRfVXVxkd1JGOPss9qsPZ2c5nek15usTabD/LWTbA1cVfXk8X+P4g8P8/sAH3/8YRT//vvfjeKbyu71VlXt74fnr/nSqQ4Ps7nq5XnWr1cXeV0+fQzJ78L+2SSca169zGtn6Xl+vgwe4UGGL6MZYV/WhPXcJj4oyp9j/hEj7AvjjpmnsFpm41O6Lxt24F2OMb7FPxwN6wzDCO1xvc72hvMR9tiTcF92fpHtyw738j3R8y+yM5rjG9kZTVXVoy++jOL/5vt/Eefw8w9/HsW/fprN15+FZ2VVVZs3s6LPZJqfTywW2f2U9D7pCD99qMtwHbuYZ/f/qqom0+yM5frpzTiHxXy79WQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPhTce/evW2nAAAAAAAAwB+1204AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgN3VbjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHZXu+0EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhd7bYTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3tdtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDd1W47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB2V7vtBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXe22EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgd7XbTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3dVuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdle77QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F3tthMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1204AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgN3VbjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHZXu+0EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhd020nUFU1mUzr5Nr1rxzfrzdxDhfLZRZ/mcVXVZ2cfPVnUFV1eHgUxa9X6yi+qmoyyeKbvo1zaIZZFD+f5zlUcxWFD+Gf77vwRVTVwcFJFL/Ju2VVM4/C++7z7M/XQRRfVdW2x1F83+bvsubZyzi/yJ7jbJaNbVVVxzezd7HZpL2qqmmzfr1encc5HB2E7ak/zOK7vGOvNy/DT+jjHKZ9F8V368dRfNNm76Gqan92K4rvV1/EOZyvs/HpaHoa59BOmii+G9I2/SqMr5o0N6P49ZCv35ar59kHzPaz+M0I67+sKVQz5PPtMGTj01DZ2LRZP4niq6raNuuX106ytVtVVdetovghXklXNeFnpO2xnebb9KbN2lN1+djSVzbG9n2Ww8F+Nlf+IYls/fb4YbaOrqq6PM9y+Pqdt+IcDg+ztfh6dRnFT6b5GP3saTZnX1xk36Gq6u7du1H8pM3Gpr7Pv8PeXvYuVqu8dnZ0nO2JlsuLKH51FY6vVbXZZOPbbIR5In0O61W+N+zC53DzZlZrePQw3xO9/lq2lh/D7dtvRPFPnz6N4vOVV9VJWNPu+jyLTZet5ReLvIbYhDXAcHs8ylz37FlWL3nrzTtxDm34HJ49fxbFz6ZZ/bCqauizfdUY+9vPHmTr2KPja1H83t5eFF9VtXeY1d+WQ9iYqurj338ZxQ972bqnqqoPB4f1MmvT83leJ7hKx6cR5on2KKt9NVdZrWOMPvHyyVkU/4vJP8Q5vHs72xNdPPx9nMPpUbbuSEeGVZfvJ44m2Tn4bx48jHP43g//Kor/2f/8+yj+9mn2HquqrjbZ+u8fP/wkzuH08HdR/A++/R/iHK5V9i42D7OzhXffezOKr6r6+EFWF18vszG6qurkIOuXe4tFFD+kl3Sq6uIqreXm57fNNHuOaV29G/I1w/JVVvs6WOTrvy9eZPPl9+/+MM7h/oPfRvFteJ9gEfapqqrLcB28HKF2tgkvXaXPYRr2yTE+ow/rNVVVV332Llcj3JGZTLJ90WSWjW/76/zM7zyca6ZpwaaqZuFZ0TT9DpP8TkPbZO9yGGG+Xcyzd9GHe5pluD+uqjo6yPboXZfP+ZNwfEvvI1RVDenaJbzUcHCQ18QXi3SuyZ9jmkN6T2iM2tkqXMt3h/nYkt4n6EaYb2fT9D5merc3P799993vR/EPHnwc5zD02Tj9yf0Po/h33s3PiZ4/yurykzaf819//bUovuuzWsdymfepdJ/fTse4D5rNVfMR7hpdXGR3jY5P0jv/UXhVVW3CMbYd4dyxDd9lP2Rr0D6cr6vyuWo2wh47Xb+NUPqKl19NGN+N0CnSdfR8hLrTVbhPb8LTqmlYZ6iqGsK6VTfC/eT1OjtDHrqsZnT2Iu/Xt25l+9vPf53VYauq3vuzD6L4q4v8N3Lvvf1+FP/lswdR/LV5vr89e5E9h9u3st/vVlVNw3Xs6iq7T3p0lJ9vXIV1+S783UFV/rv4Nrzn/cdPGeEzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgX9a9e/e2nQIAAPzJsY4GAADg/2ftthMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP4P+/a1JMd5ngH46560eRdYAASTwaxgWZTL5Sof+jpwgbwWH1mWbLpEUQwgCRKJALGLDRPbB7J9AXynqrvs5zn/Zt/t+fvPAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2HQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA4Wr7DgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAcLV9BwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABguNq+AwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXG3fAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYrrbvAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACGq+07AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADD1fYdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBwtX0HAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC42r4DAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBcbd8BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABiutu8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxX23cAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIZr3HeAqqquq9p0zc+uX67WW0jRRtXTyU6cYDKZRfXz+Saq36yz+qqqrs2+i7aZxBlGTfYcuy5vT1fXL6P6trL/oW32ovqqqlX4XjWjn/9O/4/rq8dR/Wx2GNU3zRa6yK6LyherszjC9eo8qt+b3YzqRzWK6ququlpE9YvNqzjD8moe1Z8c3YkzdKtlVD/usvpllz2Dqqrl+jKq350cxBn2dt6I6tfNT1mAZprVV9U061qqnb0eZ3h8/TCqP9hkbaGqalXZg7iYZxkOdm5F9VVV4dSpJuN8vF1swr5llM1bmi4fJ9o2nENu8ue4russQncV1e9MT6P6qqrwlar1Khuvq6oWq2ysGTX5d9nEn5E9yLbJ1qZVVU+f/hDV7x/sxxmu5qus/irsm27n69uXL7I55OVFNg+vqrp9ehzVT8b5vGM1z97L6V42Tpydh3Ovqjo7y8b8d+59EGdYLLIM6V5F3rdVvXierU+ns6wtVFXt7O5G9ZPDbM5wfZnPYXd2suewmGdzjqqqyTjb77g4z/u3UZPtpS4X2Xh748ZJVF9VdfYyeycO97P2XFW1GWVt+uAwG2cuLrM5bFXVap31T7NZvi9/cJi1h+Uqn3eswr359SYbr9s2XAxUVddl/8Nikc3/qqracLg7CufB5+cvsgBV1W2yvf1unX+XTXBeV1V1HY5Vky281+twb/8/v3gQZ7hx+7Wo/h/v3Isz/MdPj6L6zcVFVL8+z/fl0zOWdpafO1Z4NrAeZev8yRbO26anR1H9d4/zs6r90bdR/XsfvRNnePggeyfSr2Iyydfom8pCrC7yNc3mNDs3/PUvP4zqv/jiy6i+qmpnJxtv23G+Lnv+Mpv7PPrp0zjD3df+LqpvT7+O6s++zd7Jqqr338zOX7/67nmc4Sp8rw4n2RnJ9WYL96XCfaNwuP7vCNlzGI/Dfact7J1tNtma6NnL7J5RVdXvfvNPUf1nn/0+znB6lPWxPy7CNr3O34mdSTaHXG8hw2iUn58mFov8zK8N36vxNJ/LT8Ln2IX70VVVi2X2LJfhd3GRbpZU1STc85m0+f276ST7jFGbrcvGYX1V1WV43na1hfOJw8PsztU0nLc0la+JrufZO7HZwl3z9Dx/Ns3Py+K+ZZmtR1ar/H9YhfdLjg7zOw3jsI/88dmzqH403cI5UZe1x8ePn8QZ7ry9t9OgAAAgAElEQVSW7RPcvXs7zpD+HKarbG+/6bK9t6qqts0+4+aN7HuoqprPs/b01ZfZnf+To/y9PjnJzvwuL/I97Ta8N5be7WjbfC2xCdf5o1E+/9uE+x3NFubBm/Cezjy8nzyb5b8H2g33S1ZbOHdMf6OWro+no3wOehnu/4228l72/1vB9L1qw/ON0Rbu1aZXxefb2C8J72ylZ/lbOHaM++hNuB6pqhqPs/Zw6+bdLMAmbwuXZ9mdq8Mb+Tjx+ad/jOrf/eXfxhlm4QHDpAvvl7T5OLFcZvcqLrdw/+74ODz7bLLvYT7P/4fDw+w3wN8/zO4jVFXdDO+UNuFzrKpqt7APCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFVVn3zySVR///79LSUBAAAAAAAAAAAAAOD/urbvAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACGq+07AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADD1fYdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBwtX0HAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC42r4DAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBcbd8BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABiutu8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxX23cAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIar7TsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMPV9h0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+w4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fQcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMFzjvgNUVW0267p4df6z6/d2d+MMBwdHUf16vYkzbNbLqL4LIzRZ+V8/o2mj+k23hRCh9eos/ozx6CSqDx9jjdr8Qa4366j+1flVnGFv7zj8hFlU3XXZO1lVNR5n38WrF6/iDCc3wvbYjKL69XoR1VdVLa5WUf3VZd4eT07+JqrvNtdxhk1zENWfXTyI6kftNKqvqjo6Po3qF/O8f1u22Yh3uQ77x/l3UX1V1enBW1H97vxlnOFwdjeqf/D4yzjD7n7WJm/v3YzqR03eHrtRNoHbxtRp3O5lGTbZO9Vs4TkuVtlYMxrly6JNZRO4ptLvYQutocvG224LLbINVyXtKJu3VOX/x6jN2sJqOY/qq6punITz6HRBUlUHB9m85YcfHkb1//av30b1VVVvv5XtE7z99utxhnShP5nsxBGu2qxN/vD4WVS/Xue7FR988FFUv1rm78R4nM1buk32Pfz08qeovqpqMs3+h5dn+Rx0bz8bL5uwj94/PIzqq6qePXkS1R8c7McZ1qtsv+PoKNtnqKr66eWLqP7OrVtR/WKej7ent7L17bOnWVuoqhqNszG/DefBmy7vH/d3s/dqZy/rF6qqrhfZ/G8ymcQZFstsvKzmRlQ+m6X7sFV37mT903yevxOzabbOb0bZvOPwMO8fHz9+HNUfH2Vz2KqqkxtZe7i4uozqnz99GtVXVT14kO2/ffzbX8UZHoV7uY8us7GyqupeOGZ/9vCHqH5V+dnpOOxjd9p8n2A+ysaJcTgH3Wxhv2V5lZ1PTJv8u3x1/mNUf+/OvTjDxXG2LppfZnPIbbwT19fZXH4yyc95vvviL1H9hx99GNXffCufy7/4Lts3Oj7K1iNVVUf7WXv47E/ZmV9V1fTXWf+yO/sgqt+/m+/5dA+z59Dkr0Stn2dzn/Ykm79Nt3C+kV532mzh5tlokn1Iul+ynOd3GpbhOdG9d7Pz36qqzz/796j+tTt34gwvf8rWt+OwTTdN3rcsFtl52Wwnu6v01wzZmJ/W721hvyW8lhGft1VVrZvsu1yHd0Oqqsbh2WUbPsjxFt6JWmdzhtUq+x6qqi7Cz9iE9yC7LbSFNmzT6flGVdU6PHdswjO7+Rb25btwibyd68nZp3TpRe+qGoV9wzqsXy7yudP1dTaPfv3ua3GG09Ns7+zJ00dR/WqePYOqqnaU9Q2Tcd63/Pg028d887W34wzpe7lapXe28vvJ02m4Jjq8HWd4/CRr0x/94r2o/qsvv47qq6o+/vg3Uf1yC/OWTfgZ6b2M8Tgfb5fhfYLVMh8nxuE+wcXlRZzh1ml2H+DsPLsjM51u4fdA4bxjs8nnLRWuSUbjbE01C9+pqqpF2KavrvPfkIzCMX8b92rTyfgmPiPp/8eG7RbW2E34XqUZ8tlfVXpVaAvHt7W7l60HDg6y72Exz/vHyTR7EPNwvK6qunOS/R774bdfxxnuvZOdNR3sZHP5Lx7mv+366P3sd1VX83yc2Ambw7jN9rSvr/M56GKezd9unGZ3xqqqrq+ytd3+QX6/eBnu7QMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMC2fPLJJ1H9/fv3t5QEAAAAAAAAAAAAAICha/sOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBwtX0HAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC42r4DAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBcbd8BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABiutu8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxX23cAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIar7TsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMPV9h0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+w4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fQcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMFxt3wEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADFfbdwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAhqvtOwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2HQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA4Rr3HaCqquu6Wi2XP7t+58aNOEPThR/QpR9QtV4uovq2bbL6ZgvNocsybDarOMKyfn5bqqqaTe7EGZpN+gHZc+gqa0tVVfP5ZVR/cHAUZ8hfq6wtLBYXaYBar7N/4vatvD2uwubQtdn/0DXrLEBVTcY7Uf3No+M4w3ictYf1Ju9jzy++ieqb2Siqn433ovqqqvV1Vj+etnGGs8sfovq9yW5WP877x6vFk6h+PL4dZ5h286j+7dtvxxm+efYgqt/bz9r01SobK6uq5uurqH40yvrHqqrZaD+q32yy8XYTT8SrlutwsMu7lmqaSRahzeprE3awVVVdNontKv8uR232ZTRhfVXVcp216eVl9l0c7mXjTFXVJlyXtaOwPVbVi2c/RvVXr7K514fv34rqq6r29w6i+tUyX9+Ox1mbPr94FWd49DT7Lnem2Vh17+1fRPVVVfOrrD1Nw/+hqurqKvsuXjzP5n8HR/kcdDLN+oaTkzzDkyePo/o33ngjql+t8vXtYbg+XczzPZ/pdBbVr8I9zKqqvbCPff7iRVR/fHQY1VdVLebZmujgMM9wPc/mLetwLr93kO+37IRtYZ3uw1ZVE+59rVb5eNs0WXtYhxsuqy2cDTRNNm+ZzfJ90LbJnkPXZXtn25hH37x5GtVfX+d72tPdaVR/cJDtt3z94M9RfVXV62+G+06jfH37m53svf70PJv3VFV99vmXUf1slrXp3f1sz6mqqgvX2PN1vi4bjbK+oQsPuzbBGfr/Zlhk87e33sj76DdPs/7t6vzbOMM7r92N6v/01V+i+tk461+rqlarbPLThuN1VVUb/h9/+OOnUf0//8Pvovqqqn85exnVv3z1PM5wfHAS1e/t5nsVn/8le69++5tszO/Gb0b1VVXH72ZjzevLP8UZribZeHk0Ctfos6y+qmp5na1vV+GaqqqqHWV72j88zM5/33k334N8/uJZVP/946/iDO04e44//pjtt1Tl93w24VlVm03dqqoqe4pVlxf5GXIb/iPjcbbOv7rKzrCr8rEq3Y+uqmrCs8uuy/eDN122JknvnY3G+XOssI/ebPINvC78jG4Trsu2cDd4HK4t076pKj8bOA73tOfh2rSqarMM38stfJdN+G104VhXVdU2WYadabaua8K/X1V1dJidLzx8+CjOcOt2dn/uvfffi+q/+SabP1ZVvQrvVczC+6RVVTs7Wd/y/ffZndiqqjfe+G1UPxln7bHrsjsVVVWXl0+j+nYL96Xef/9XUf2fP/t9VP/uO/l90j/8/o9R/cd//3Gc4dWL7LtM9+UXWzjLX4e/50nXI1VVi0W2VzEN92uqqi7DddH+fnYOfnZ2HtVXVe3uZPcQmy0ssttw7rRYZOdEaVuqytfo27jTWuH8K58F52vsbczFU+k8Oj3z++tnZPVNuEbfxpyhqWw90W3hfspimY23XZOtBdotjHXHx+He2Rae4/wyG/NXz7Pztqqqh99m64HDk+w35e+89TdRfVXVo0fh+cRb2Tl6VdVmk73b1+GdhC1s/8X90zbmf/HZwGW+r76/n98pBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgKqq+/fv9x0BAAAAAAAAAAAAAID/J9q+AwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXG3fAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYrrbvAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACGq+07AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADD1fYdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBwtX0HAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC42r4DAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBcbd8BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABiutu8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxX23cAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIar7TsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwH+xb2dLllzXeYBXZp6hph4BNAA25kkmDYkiCdJS4MLvgQfEUzjC4XBIJIN2kCIpskGIFGCAagw9VldX1Rky0xcI+UbhG/xpnxOK77tfp1dl7tx77bV3AwAAAAAAAAAAsL/aXScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qd50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPtrtusEqqq6rqurV6986/jNZp3n0DRRfFNtnMNivojiu24exfd9H8VXVY3jGMW3bT4k2zZ7DpshH0/hq6xhu8niJ/gmlsvnsh9ozuIcmnA8rC4vo/h0PFdVtU02GMYxn1uadhvF9/3DKH42fyaKr6pq48ewinPY9AdR/NOzr+Icum4ZxR8d3Izihz4bS1VVm/Eiij/9+tM4h2vXX4zi591hFN+0XRRfVTWss3n+onkS53C4OIriu8qfw7M3no3iPz3Nvsvjg+ybrKo6Xnz7Griqqglr2KqqsRmyHLpskn7y+HEUX1V1ciV7jm2Tr7f9mD3HcQjXqvDfr8r3NF2Xj8emzf6ObZ/V0VVV/SqbYw8PsvlxmGBvuVxme6JPPvkkzmGzytb8557JashFuCerqmoqG4+Lg6xmqKp6cvY0iv/88y/iHG6/9GoUf+XKS1H8tj+N4quq2u4kil+v78c5nD/N1rurV69F8bMJPop+m+0Hulne8zk+zubY+w/uRfFHR8dRfFW+vz04yOb4qqonp9l3tZygDm7arG5Ix9Nmm/dBF12WQ5O3nerul3+O4l9/860ofjnB3LLeZO9ivsj6NVVV5+d3o/jDw7z3VZV922ndst3m+7L5IusnD1OcT4RHXkP8XeYf9iKcY+eLCY79wgnqcpX15V984fkovirf52/zI5a6mJ1H8atHeR18+4UXovjHZ4+i+M15ti+sqpodZGvNbJv3S06CM+yqqtMH2RnL9jJ/js+/cCOKv341X28v1tnfsZ2g93V6lr2Ld975YRT/D7/+aRRfVbVcZPvby3V+Xpb2AG/dyPa3//WXv4ziq6re//73o/i//9nfxTlcXmbrxGw2QS0eFj93/vBxFP8f3snrlm2TnfndeiWrW6qqVudZ3+js62x+fHCazW1VVX2X9VuaWd6rOH2UPYfvfu+vo/g/3PltFF9VdXI1q+WPD/L1drXKzkg26/yMpQuPgBfz7DmuJ/gbDg7CvWW+uaw+PO9Ke2eLCXo+XXiG3E9wPyV+jhOcfT73XHanYRWeW371VdYT/0Z4hpxf+orvJIxhz6ad4J7PxWVWix9O0Jffhn3xzSb7Lqe4Y9206buc4D5oODd0E4yn9F7rEO6xt+GZYVXVfJGeE+V9go/+8Kco/i/e+UEUf3j0dRRfVXV2lj3Hk+P87HMxD++dhecbVVUPH/5zFH/jRtaTnuD6Xl1cZHdDrl3LepjfyPYkx8fZednnf87vWD93K3uXf/z4n+Ic3nz95Sj+cpWdDXTppqyqxvCMZIo7rel9grHyHIZwvb0Ma/kpJpd+CM/iJxhP6dXc9L/zDOEzqKpqm+w5LCfo+Ww22X5iHZ7fVlXNZtlzmKX3xia4Y9OG31U/yf8vC+e3PqudNmF8Vd7zmWJ+O7/Iej6zp1k/+sbVrKdeVXVxHvYx8zZBzcO75teuZeeWVVXdeTY/rcOz9Ca8/1dV9drLb0fxn3/xxziHt17N7myl/ZK2yZ/jYp6Nx/UEvYrlIjzvmuD/JNUEe2QAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP79+fDDD+Pf+OCDDybIBAAAAP6tdtcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2l0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+anedAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7q911AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3bXCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv9pdJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/mp3nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+6vddQIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K921wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/aXScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qd50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPur3XUCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvdtcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2l0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+anedAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7a7brBKqq2qap5WLxreMvV5dxDk07RvFd8+3z/z85NPMofhyaLH7M4quqhnGI4pumi3NoxuxdtLM+zuH+6b9E8UfzK1H8yfxqFF9VNTRPo/jt2MY5rC7Oo/jjo4Mofhzy8Thus+cw9Ns8h3oSxc9m17MEsmnhG+FwWm3z59jU/Sj++PhanEPbhHPsmM1vm+1ZFF9VtQ5/4/lb78Q5NH223vVjVjOs+9Movqrq4DCrGR48eRjn0LbZejvrs+dYVXVjfhjF94t1FL+Y5Wtd9dlz7JtNnMLYZr8xbLO56fj4JIqvyuvYKZaqJqyDhzFbq5oJavl0eziO+XjcbLK9XdfkW9yTg3BuabK5oQnn16qqOx/dieI366wOr6p66YXno/hZWPfMZ8sovqpqNs/2A3e/+jLO4XyVzQ1vvPG9OIdZm83TY7+K4rfb7JusqhqGrPZJ6/CqqpvPPBPF99uslh8rr71W62yeHyvfl/XhHjldLc/Ps15JVdV8lq1VaXxV1dFR9l2dh/2aqqomfBndLNsTnZ/n/eRxkfWdjq/k/bvLdfZt//7Ox1H8e+/9MIqvqhrDPc1qnfW9qqqWB7ei+GHI+8lNuCtpwxp0MX82iq+qGoaL7AfCv+Eb6RyZrrf5WAjbTtX3eQ6V1g1DNp5vXMv7BE3YUN7MjuMcfv5PH0Xxz9zI6seqqmevZWvNva/vRoqqu+IAACAASURBVPEnz0zREw/32LO8Dn7w1VdR/Nhn38Trr9+O4quqDsPncHn+KM6hnR1F8UcH+dywXWdz5Oppdv77o3e/H8VXVf38V7+J4m/ezOeWx0+z+ivcWtbyJJ+j+032Tfzt374f5/CL//nzKL4N70RUVQ3heX4b9ox+dyfrYVZV/eW72d5w22R7gaqq2Um2R/7yfz2O4i+32VlXVdV2lfVBD4/y8Xj79mtR/B9+/w9R/PIgvxvStdlvrM+zPmpVxfcqurAnXlU1hnvk1Tob07OwZ1RVtQ17sXkXsqrrsncxhvuyYYK95TCEAzK831JVtdlmhce8y3sVQ5jD4TKbYw+W+XnZ07CXOsUF5WaWfRND2HCZ4iR+Mc/mp3VaSFdVE/4l6f52s8nPidrwu2zb/LuehWt+NROc2a2y9XI+z77MJm1iVtWD+9ne8tr1G3EO52fZfdAhvE965Ur+N1R4x7nf5DXodgjHY9gzqqraXGa9q3tfZ/u6cYKV4iTud0xx+y37Lm+/lN0TevLkQRT/jWyeX4fza1XVvXvZ3NCE/yfp1nN5r+PLr7+I4qc4O23Dd5mvVLl1uL+dQnpu2HV5/ZbWgF2X1dHh9vgbTfY3tG3eq2jC87I27DNU5Wd2aSU+xRXpWfochilml+wP2YbfdR/eda+q6sIx3Yd7y6qqZXhu+PRp1us4XEzQ7Qi3+V2brzOLZfZlLpf5c7h2JTu7/M1Hn0TxL73xbhRfVfFFyINlvjd8cpb9H7VXXvlOFH92mt+rXV1mH8XBwQTrbbhYLeb5YtVPUEsDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPDvzwcffLDrFAAAAOD/qt11AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3bXCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv9pdJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/mp3nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+6vddQIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K921wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/aXScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qd50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPur3XUCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvdtcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2l0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+anedAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7q911AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3bXCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv9pdJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/mp3nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+2u26wSqqoahr/Xlk28d3wzbOIemno3i54tNnMNQ2W9sthdZAs0yi6+qpj0If6HLc2jGKH7cPoxzOJnfiOLn8+zTHNoJxuMwRPHnT8PxWFVHR0dR/NBnY2Ho87mlbbJ3udk+ynPorkfx81k2NzTNKoqvqtpswvnx4jLO4fjkmSi+6/LnsLrMxlPbnEfxs9k8iq+qms1vRvGX6z7OYTHP1pr1+ssovm2Oo/gpfuPq0bU4hy/u/i6Kf/WV/xjnsFln8/yVRbZeV5PXDGOXvct0rauq6sOyoW3C+C78gapq2ix+fZnXLV2XzS3zbhHFN3kZXduw9rm8WMc5zGfZc2hn+RZ3O2bfVRvuRz7+6DdRfFXVGL7Lt994I85htcrqjvkye5d95XPL3btfRfHNBHvs1195J4rvt/k60Va4rxqz8dhUtjetqmrbcKEY87mlCcdk12XvYbXO5+jtOtxXzfLFatZl72K5yPY0jx49juKrqpq057PJ57c2LODaCb7Loc9+4+gw6xm1Q763PDzM5vmH97+Oc7j94nNR/N0vs7Xut7/J65a33n4zip9PMLek/eQhrB+rqoYh6xvNZuFal26qqqoZ0p503neqyv6OccjeZT/m82Mf1vLLsI6uqlqHdcNieRjFt022L6yqqjGbGzZ9vuZfP74SxZ8/Oo1zOA97+y/eys5OHzz59me//+o4XPMfPczPWLarrA5+5y+yPXbb5XP0+SZbZw6PXo9z6FcPovg27L1V5eevY5/NjxcX+TnRT/7mx1H8f/u7/x7n8PzVrAYdTrL9yH9+890ovqrqwYNsPNYE+7Ifv/efovif/uzv4xyasF+SVsHLRX5eduej30fxb7/9dpxD12bz/PMvZnPLo9P8OT56nJ13pfvjqqpH9z6P4o+Ps7tKm3COr6oaw/3AsAf9lvjQbwJ9ePbZVt7zOTjIxnQb9jCrqs7Psxr08Cj7Ji4u8rPT09NsT3P9en6noQnvIU5wFF9PzrLzstUqm582E5wN3Lya7W/vrfI6eBn+xmKR9RqmOGMZw7uYae1WVdWHfcx1uM7kK13+HKfYY2/D++ptk6+3XdgXT+9iziboyx8eZj3Ex4/zns8Lt1+M4tvKavFnbmb3Uauqrl29G8WfPsrOiaqqPvs066Vux/ybODrKxlNT2Xc9m+Cu0iK8x9h1V+Mczs7+GMVfnKfPMf0/KFV3v/giin/91dtxDp/885+i+MPDkyi+bfMzllnYi11v8//HEptgezv04f4y3E+k9zqq8rtKU+wn+vA5zsOez3aC8Thus/ltHPNeRXxPe4Jvog/v2Qzhc1gu83UiPQefzfM7Dek+fwwnl2aCPdEmvNPQTVA7jeF4TP//7f0H+Xr74q2sBzm2ef23Hc6i+LgfXVX9RfYu33ztpSj+t7/7ZRRfVfXXP3k/il8uXohz+MVv/zGKv/Vi9i4XE3zXwyK9vxenUMMm+5H4/l5Vde0EfwgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD/R+2uEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgf7W7TgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dXuOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9le76wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F/trhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH+1u04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3V7joBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPZXu+sEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhf7a4TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/tbtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID91e46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD2V7vrBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX+2uEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgf7W7TgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dXuOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9tds1wlUVdU4Vr9Zf+vwk4OjOIW2exDFX55fxDnMltez+O4kih8mGA5DLbIfGDdxDuNwGcUvmhtxDk07RPFjk8Wv+nw8ri+zd3Ht5EqcQzVt+gNR9GbzNPz3q5puFcW33TNxDv2QPYd2CMfzeB7FV1V1zUEUf+XwZpzDWNm7XG2WcQ7d7CyKbyt7jsOYjaWqqrHP4tt2jHO42DyM4uezZ6P4bkzntqoKn+NBuE5VVTXhePrs7h/jHF59/qUovs1KhhoX+dxytvo6ip+1eR28mGc15FjbKH7bf/t9wL/aXGS1z5WTwziHfpvNkf0m/S7z7/rJxeMo/niZ13+LJlsv10O+n3h4mj2HP3/2pyj+rdduR/FVVYeLbEyP6/w5Hi6zdzmEc8tnf/6XKL6q6sqNbM1/9vp34hxW51nd0M3y2qlP9+lNFt+EY6Gqqm26KL4fsviqqiFc77bbrHCZtXktf+1KVndcXGR7qqqqzWX2G08eZXuBg0XY96qqfp39DWcX+R778DCr5efzeZzD5WX2dyy6bH48Psrrv80me5fHR3mfYLnI3uULL3wvin90mvUpqqo262x+XB5kz6CqahyytaapfJ+/2mTfxHabNQpmE3zXXZeeL+Tr7TiGtU/Yj24qf46LRZbDkyfZWldVdfVKdlaVvsuwHf2NMfuRqyd5LX//3sdR/OIgH083r2Q9n01Yy3/26WdRfFVVfxj25c/z2um7330rip9XNjd9+TBfb7+8ez+Kf/XVvA5+9fnXovhHT76Ic5iH81MTz295zXD+KOtbvf/ee3EOP//1r6L4H7wS1qATrHWLJqtb1pvwkKbiY5760Y9+HOfwy1/9jyi+C3sNx0fZOlVV9fg0W/Pv3LkT5/Du934Yxb/6+g+i+Ke//1kUX1V1EtYMT59m60xV1cEi+y77PvyqpjgHD7cjw5DPLWNYd9SQ95NrzNbLsJSvbXohoSp+mWmvo6pqEfYhhz57kG2b3yFs22wsnJ+Hh/lVdXgY9gCn2J+G00s3z8bCGJ6PVFXde5zVoGPYt6qq2oTfxOYyvE86y7+JbdjwaNPBVFVDOM9vwnc5wSpTFc5vswneZVp3jOH5RlVV16VzbHYvdjbLz1iWy6z3NV/kvbOHD7I69qP+11H80WH+Xb/88mtR/M1nvx/n0DS/i+LT841vksi+q20f3mnIX2V1XVpD5v2Se/fCs6rwzv2sy7/r557L7vmcT3Cn4fZLL0fxn36S9dXnswnuqqeDeoqDnjCHKc5vh/DvSKeGCaaWeH7q+7yCS/sl50+zueXgIK9b0nbJeoI+wWyW1X/zCergMexqp2f5q1XeJ1gssjlyFd4TqqqqsK/ehnVPGl9VtVplz2E+wf27JhzTi3CdaMZ8PN57kK0zN/L/+lpD2Muddfm7TBtwXdht+Ju/eieKr6r61T9me8PvhPu6qqqf/NVfRvH/5ae/iOLff/fNKL6qqu2ydxm2jKqqartO799N0FdvJumgAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAv/Hhhx/uOoX64IMPdp0CAAAA/w+0u04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3V7joBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPZXu+sEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhf7a4TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/tbtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID91e46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD2V7vrBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX+2uEwAAAAAAAAAA+N/s3EuvXed5H/D/WnufK3lISpSoSLFk17LkOLEbJ3YuaAdFUaDTdNIOPMmgQD5DP0tmmQhoJ0E7Klpk2ABB7MRNHUVRZEVOYskWSfFyyHPbl9WB5FkGlf7b3jvu7zehSOhZ51m39/K871kAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyucdsJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC7xm0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDuGredAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7a9x2AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsrnHbCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwu8ZtJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA7hq3nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAu2vcdgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K75thNIknEcc3x4/Jnjl5dP6hwuL0+r+Osn1+scnp4tqvhrN25W8VfL7hokyWr9URU/G/frHObpjjHu1SlkuV5V8Y8eParij46OqvgkuXate6bXU3cNkmRaLav4xbKLH8exik+Svf2D7gBDn8Ny2d2Li/MfV/EHB89V8UkyzIYqfr06r3OY1p+9n0qSxeX9Oofx4Nkqfp2rKn6auvvwse4Yq+WDOoP5rOsvZ+ne62EDl3G56vqJ1brv8195+YtV/NkG3onzcgw4H7t7OSvHHElyfHCril+tu74uSda5rOKn9bqKv7rsfn6SHB4eVvGrVXcOHx9jquLHcVbFLxf9s3DruHsel+WzkCTZ6xrJ93/wfp3C3Xt3q/ivfuX1Kn5/7J6lJFmXhzg8uVbn0I7F3/vbv6/iX37l1So+SQ4Ob1Txy6u+fWunJEO6tuXjg3Tv5TR1D+Q09W3LfN5ehw3Mb9s6wcNu/HfzmWeq+CR5fNqNIWf7fdvygw+6dv4LL9+p4h/cu1fFJ8lzt7v+dpj6Pv/0tHuerpc1oyS5VdZS1+W44/LiaRWfJLN5Nx+Y9SWfTMuLKn5x0bXRJ9e7cXjSj6Ofls9zkrqvOynr8klyWNYaVmUdta0fJsl63a1vDGO/XNXWc5fLsyr+8KB/JxbL7jpeXXXxH+fQtbHzsn3sZ0R9HfPsSV87e+FON+64dliuLSQ5P+v6icPj7hxOTvpzuCzrRl/+clfDTJLMuoXDH37Y1UEffPS4ik+S68fdWPxHH3xQ57Ced+/l5w5frHM4m37YHWDqxvJHh31/uyoPsV70OfzWr/9GFT9ddGtVbd0rSZblQdZlrSNJhnJOc3LrpM7hoKyrr9fde333XrcGnSTjrOsnrp88X+fw9vffruKfv92tpX/p9W9U8Uny5l/+cRX/0ku/UOdw/8Ou5tK+lesNrLddXXZ7EvYPNjB2umr3A/Tt26zc23H7Zlcz+ujBwyo+SS6WXdvSrvklyVCWxff2ujn2bNY/C3t73Ry9rf8lyTB05zHf6zcRPinnlwdlreHwsK+3nJZrA/0aTZJyreiqbB9Xi77ecv1Gt+64iX2M7Vh6We6rGDewD3JV7klt17CTZNUeY9G3se36aTsXuNzAO7FXPg/jrG/fZrOufTo769aaHj7o16qePOnGoF/5Sj8neub2L1fxy0W//vreD/6iit/b6/bc7+/3awP373fX4fy8qwUnydFRNydZzrvrsIlx9NnT7p3YxDrPRVn7eu31L1Xx777zXhWfJMdtP3Herbclff1tter7qtm862vasddsA+9Ev+eq3/A+tGPAdt9a99OTJItyb+7RUd+2tGeyid8AGcujDOW9XG/gbq7K/Xub+CWQtv62C9dxftDVS1abWGMpF8za2tlq2Z9Du+f+3kf9fqlnyz2lY1vETLJadLXYw5OujT2/7MZuSTKfunNo9wYn/Z6tr3/pV6r4t/7uvSo+Sb72arcfYLWB3m5vr7uXqw3sv9s/7H9HDQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAnz9vvPHGtlPYiPY8vvWtb20oEwAAADZp3HYCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyucdsJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC7xm0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDuGredAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7a94ED8PwXpLTJKsky2mavjkMw7NJ/nOSLyR5L8l/mKbpQZcmAAAAAAAAAAAAAAAAAAAAAAAAAD8PfMcOAAAAAAAAAAAAAAAAAAAAAAAAgE/Dd+wAAAAAAAAAAAAAAAAAAAAAdsO4gWP862mavj5N0zc/+ft/SvJH0zS9luSPPvk7AAAAAAAAAAAAAAAAAAAAAAAAAPyE79gBAAAAAAAAAAAAAAAAAAAAAAAA8Gn4jh0AAAAAAAAAAAAAAAAAAADAlo0/hWP+TpI/+OS//yDJv/sp/AwAAAAAAAAAAAAAAAAAAAAAAAAAfn74jh0AAAAAAAAAAAAAAAAAAAAAAAAAn4bv2AEAAAAAAAAAAAAAAAAAAAD8jI1l/JTkfwzD8J1hGH7vk397YZqmD5Lkkz/v/GOBwzD83jAM3x6G4dv37j8o0wAAAAAAAAAAAAAAAAAAAAAAAADgn4iNfMfu7t27P6N0AQAAAAAAAAAAAAAAAAAAAAAAANgy37EDAAAAAAAAAAAAAAAAAAAA2AHzMv5fTtP0/jAMd5L8z2EY3vp/DZym6feT/H6S/NrXvzqVeQAAAAAAAAAAAAAAAAAAAAAAAADwT8NGvmP3zW9+03fsAAAAAAAAAAAAAAAAAAAAAAAAAP7/4Dt2AAAAAAAAAAAAAAAAAAAAADtgbIKnaXr/kz8/TPKHSX4zyY+HYXgxST7588M2SQAAAAAAAAAAAAAAAAAAAAAAAAB+PviOHQAAAAAAAAAAAAAAAAAAAAAAAACfhu/YAQAAAAAAAAAAAAAAAAAAAOyG8bMGDsNwbRiGk5/8d5J/m+R7Sf5bkt/95H/73ST/tU0SAAAAAAAAAAAAAAAAAAAAAAAAgH/6fMcOAAAAAAAAAAAAAAAAAAAAAAAAgE/Dd+wAAAAAAAAAAAAAAAAAAAAAdse8iH0hyR8Ow/CT47wxTdN/H4bhT5P8l2EY/mOSv0vy7/s0AQAAAAAAAAAAAAAAAAAAAAAAAPg54Dt2AAAAAAAAAAAAAAAAAAAAAAAAAHwavmMHAAAAAAAAAAAAAAAAAAAAsCPmnzVwmqZ3k/zqP/Lv95P8myYpAAAAAAAAAAAAAAAAAAAAAAAAAH7++I4dAAAAAAAAAAAAAAAAAAAAAAAAAJ+GVSpAiQAAIABJREFU79gBAAAAAAAAAAAAAAAAAAAA7I5x2wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLvGbScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO6abzuBJBkyZJbxM8c/fXy/zuH45FoVv7g8q3OYjUMVP03ddVivV1V8kkzjXhU/ZFbnMBu6Y1wuL+ocHp0/quJPrt+o4g/Gwyo+SZbLyyp+nE11Do9PH1bxN27erOJn434VnyTLZften9Y5XF50z+Ph4XNV/GzcRFfTtU/nV/17PaRr548Ou+cxSVarJ1X8MOvalml9XsV/fIzuXsxnz9Y5jOney2HqrsNq1Y8ZhuGgip/P79Q5rJZPq/ij/Vt1Dvfu/7CKP7nZtU/Tel3FJ8l86u7l1VXXLiTJMssq/trh9Sr+cL8ft2Tq7sVQjh+TZFW2b+uh6+sO9vrrOJTjloPDfuz07e/+WRV/tIEcfuPXv17FLy+69nEsxz1JMsy7ednDp905JMnTJ90xXv78F6v4+XhcxSfJ6rJsG8q2KUmmctwxTX3bMGvnl8Nnr/d8rI1Pnpw+ruKvXe+fp8Wy629v3OjG8leLvm3ZO+xqZ3/xve/XObzyuX9Wxb/39+9X8d/42i9X8Uly78NuDHvrRjf2SpJh6p6HWf9aZn/eHaQdil9eLboDJLl2XLaPG6jFXpx2/e3T825+ely2TUlydNS1seuDbtyTJE+edvOq1aIfg87m7TG6cct66mrBSTKrG4d+XjaUNZ+Lciw/30AD2V7Hk5P+vZzPu1rFNHX1lqEePybjrHuelouupp4kQ7lEslr0fdXevOur3n3nu1X84f5RFZ8kr736ahV/edHXYt//8b0q/t79rp85POjeySSZynnVUTkXSJLTu92a3z/c7td5Xjju6uLD/KqKXy66fipJprJtGZb9GHR1VdaNhnLtdAN1gvW6O8Yw69c+52X97s//7M/7HMrtQk+edO3b7Wf76/irv/avqvi3336zzuHRo249/+2/eaeKf+f7b1XxSTKW46+ri75tuX58UsVPdV19A3X5sbuOT876tfiL87KenH6fz9f++WtV/MmNrm04/YuuFpwki3IsPi/7uqSviq/LW3l1tYG9Ie3ApZzjJ8li0dU7lst+XrYuC5lXV905rFZ9+zaWe1oPj/q1qsuLbj4wK9/L+QbGf+dn3fx0vt/PDWfleSxX3fO8N++vY9u+LRbdel2SrMq2YW+vvw7j2NW+2r7u6qqbHyfJ5VV3L8YNvJftIV586YUqfm+v37/3tFzfePT4e3UON2+8XsWfnfd7pE9Pu/5uPu/6mcUG6sk3yjXg55/v99Wen3fX4exp1za0e/6Tvp2fzfu1qrt3uznJzfJZuP1s/yzcu3u3ij866NcGZmV/ud7Enq1yTvK0HP+NG5hbLsvL0K69JnU5uN4bstzA+K8dv63KPWNJPy8bNrCO3dYQN7BCUh+hbRv6DPr6Wx1f12uS/f1uf8uqnFsmyVX5brfz/E3saRjK93oT87L79z+q4oepb99evHO7im/rf+38OkmevdWNYx8+6n8vfv7MM1V82zaMQz/+e/y4m9/evL2BOfaDbk/DJvb5bOJ3JgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2D1vvPHGtlPYCd/61re2nQIAAAA/BeO2EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgd43bTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3TVuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdte47QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F3jthMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHeN204AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgN01bjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHbXuO0EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhd47YTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3jdtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDdNW47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB217jtBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXeO2EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgd43bTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3TVuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdtd82wkkSYZZZns3P3P4M8+/UKdwuVxU8fPZWOcwnx9V8U/OHlbxR9eeqeKTZJ39Ln69rHM4Wz6p4k9PT+scnnnmdhU/ZqjiV+vLKj5J1utVFT9NszqHmze7Z3IYuhyGYarik2S5fFrG9+/EfO96FT8MXfs2TVdVfJIsV+sqfr3q3qkkuXGju47rVX8d9vZuVPGLxYMqfkj/Xrfv5TjrnoUkWU3dMRaX51X88f5BFZ8kq3IIt97AEHA268ZOT5++X+dw8+adKn6xeFTFHx7113Eq2/nDw+fqHB4+/kEVPxxdq+LnB33bslx045blqotPknG2V8Xvzbv42X4XnyT37t+v4t/93rt1Di+8+AtV/Cu/+FKdw+Lyooofxu6ZXk798/joo4+6AwzdvC5Jnnuua6PHdo697vqpJFmX86rzi7M6h+vXujHo1E9psp66d6LVzkeSZJh17+Xloh/Lz8sx4LTu+tt7H/Rjrx99cLeKf/3V1+scbj/b1VsW5Zjhr97r+7rXP/+5Kv6D975f53DnzvNVfDsnSpKprDvN591YvO5nkpw+7mqxN066OX6STOV5PH3c9VV91SoZZ9293EA3kZu3blXxjx/39eSTk248P8668dtsE4OGbOBmlIaheypv3eza6LPzH1bxSTJddXXM/f1+LD8r25ZlPaXp639DWQ7eO+jGHEmyXPy4ir9YHNc5XF09ruKX5bzqlRdfruKTZJgfVvEfPOhqHUny6EG37ni0gfeyNZbvxJC+VvHgUXcvPvfKb9U5zOddP7FadhdySt/f1kdoG8hsotbQ5tD3E7NZdxL7R13blCTf+c6fVvGzsV+fOH3StW+/9vWulvvsrdeq+CT50fvvVPF3f9z3E9PUPdM3b3bzkYuLbq0rSQ4PurrVowfd/DhJjsq1opMb3Rx7LOv6SXJ23u0NWW1grer4WjeGnJVz9CQZh67WcLD3ahX/m9/o14navua73/2TOoPFVVl/W3dj0OPDvq9r+/zVuh871e9VP3TKspwkH5Rt9GLRr5e1e9cW5b7cJJnNu3Z6KvcJtbWSpF9DHtuJXZJVWZdvc5jP++u4XHRtwyb2Yh4fd/3t1VW/t3cq27d5+U61+1uSJGP3PGxi/LYu92Ysyzb2lZf7OdHb3//zKv5HP+7GsEly88YHVfyNG8/WOdy+3c0HTk66ednZWb+n4tGjbl61WvXt261yvexzL/9iFX/v7r0qPkmuXy/b6HLPWJJ88YvddXjrzW6t6Su/1P38JDl72tUaZmNfE1+tu306l+fb/92Fg3ZtYAPzkXY+MG0gibHs8/f3u1rF2Xm/v6Xd9b+3gXWiad09j8sNzMvaeznbwPitNZRrJJvYETG2+xgvu/nEwcEGaj7lQtEGmrd2OlH/vmRbp0j6Z+Fg7O/lw3It/eR6t6c1SR4+6erJ+/OufTs+7PdltPWW55/r96f87bvdetmXf/mrVfxrL79SxSfJn/7v71bxv/1L/fjv/7z5D1X8atHPJ77x6/3vGwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPwsjdtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDdNW47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB217jtBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXeO2EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgd43bTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3TVuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdte47QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F3jthMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHeN204AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgN01bjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHbXuO0EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhd47YTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3jdtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDdNW47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB217jtBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXeO2EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgd823nUCSTNOYxeroM8fPxg2cxmxWhT88Pa9T2D8aq/ija3eq+NVqXcUnyTjrziFleJKsxqsq/s7zz9U5jFfd87TMoopfTV18kozDwVbjk2TMsjxC1zY8ePBh+fOTvb1VFX909Eydw3LVPY8Zhip8Wl92Pz/JbNyv4q9dv1nnME1TF19nkKwWd6v47k5upr+d1l1Dv9zA83R68aSKv7Z33CVQXoMkydD1ddN4UaewXHbncXzU97fzso1dLbpn+s2/fKuKT5KvfvVrVfxy+bjO4c7zn6vi33rrzSr+pZe6MWySjEPX183GvTqHvb2ur5rPD6v4v/6bv67ik+T+o4+q+F/68ut1Djev3ajiL8779m1/7Nq3p1ddG/3Rg66/T5I7zz1fxc/H63UO63XXRq9Txq/6Z2G97I6xv9e91x8rx/L1nCqZyvlpew7D0LfR+0fdvVhvYI794PRpFf+Dv3tQxd+4Vo5hk3z59V+p4o+P+hwePHxYxb9w59kq/u33up+fJOeLbnZ4eHRS53D/Xvc8vfRCP5Y/u+zeifnQXcehnOMnydF+N/776KP7dQ4Hh917tSqrFbN5Xydo68ltvSZJVqu2fvfZ1zZ+4snTbn3h+rWuFjuUc6okmaa+z26VQ9DM5o+q+KMNtNFPnpxW8bN5fy/Hsawirso66tSfw7J8FsbxrM5hb78bd1xc9uOO4+u3qvjXbnXxi4t+XvbX77xXxd//qKsFJ8mN466/Hds1lvTrt9fLOdG9h/fqHP7Fb3+jir846+/l5VU3fsvU3cthAytF7dhnLPdEJMlq2T2T7Tuxv9efw145jP3jP/lfdQ6zsp786LSfT3z9V7t5/rXjrq97/4fvVPFJcvdu118e7PVrdheXXf3t9LSbo19d9mun18qazc0b1+ocPrzX9TVDObc8OurP4bJcG2hr6kny4osvVvE3b/bXYb0q1xdWZSPdbopIknJ/ys0N7E959la3zvP237xbxQ+bWN8Yuz57XdZrkuTa9W6e/vRpPzc8POiu5VmZw3rdzyf29rqazzT1OcznZQ7ldZiX1yBJZrOufVtvYOPZctGtd7X3YVauwyfJqiz6zDcwJ7oo6x2Hh/2+2kfletn1a12f37YLSbIo7+XVVb9+u5q6sfTDR91YPunXTl/+/Jeq+MUGrmPS7Tu7uPhRncErr7xWHqEbRO7ttc9C8vRptzawX65bJsnZWTfuuH27W0Oeb2B947Jso69f7/dLPX7UrTV94QtdXf7DD/ua0Rdf7d6pt978qzqHF3+x21O6/rBfY3n8pKtJHxx0fX67hp309eRNzCfasvhy2fXXBxtoH9vruChrRkkytRdyA/sqhrZkU47FN3AK9frEJt6Jdr/S0WG3P2UT59DOsYcNFPDaY6zrWsUG9tiU8WNZZ0iSW7f+L/t21iTXXd4B+O3T68xopJFGC17k3VDYwQYMBkKl4JLPoA/I90iKIoYk2LGxMTa2ZVv7Lo80S0/36VyouEtu/DuV00U9z/2v552z/PeTfa/4zTf5dyzp/PLgIBvDLvIj1rW1lY0hHz/Kv0m/sJvVcPnzT6P8MxdfiPJVVW/94M0o/97H78U1bIdrNquNvG1ow74KAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID1dOnSpSj/29/+tqNKAAAAoHtN3wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL6avgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH01fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpq+i4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXV9F0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOur6bsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZX03cBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvpu8CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhfTd8FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+mr4LAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9NX0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6avouAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11fRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq+m7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWV9N3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr1HfBVRV1WBV1bTfOj5f5P/GeDqL8oPDVVzDdGsryh+3iyg/HOfX8f79e1kNw0Fcw8kT2XVctfm9PK55+AvZdRg10/DvVw0GTZZvlnENVSej9OHRrSg/nWTtQlXV1onNKD8Y5O/lYnkc5Q8Osut4YvOpKF9VtWyz/6Ftj+IawteyVqtv38/9XdtmRQya7L1uRnkb/fjRoyi/F+arqs6cPRflh2H7uGjz9rFpwmdhmfd1TTOO8u0qb9/a8FoOwkf6+RcuZj9QVd/sPYzyJ09m/UxVVRv2E89efCbKf3H5cpSvqnr9tdej/HKRt9HjaTb++tO770b5+dFBlK+q+ulbb2Q/sMrax6qq4/lhlB9P87bl7t07Uf7W7dtR/ruvvBLlq6oGg2wc3S7vxzWMRtnzcHC4H+XHow7WCSbZ3LJd5WOnWqXj2LyGVfhuN8N07JStdVTVk3WnwOFRfh0/+uhGlH/xuQtRfmfndJSvyp+md9//U1zDL3/x0yh/9WrWRr/y3ItRvqrq/T9/GOV//cu34hr+8LvfRfmtzUlcw5ndU1F+7/E3UX46ztfOjo+y9mk2y6/jo4NsDLh9MhszbITr2VVVg8Ewyq9W+fw2nObXdJL9D1VV40n2fywXj6N8u9qJ8lVVs1n4PyzTNfWqdpn1VstlODfsYPg328jWpO/ey8fyZ3ezNjJd027SBZuqSpe+OtgmqiZsn8bjbA2zqqpts7Zhtcrat69u343yVVWP97L14JPhHk1VVcVr+9kzPR3n/czNW9ej/Ntvvx3XMD/I2vlV2MZXVTWVrieH6/LpoKOqVpWtEzz8JpubVlWd2nk6yi+X2Th40eZjhnd+/06UH4VrHVVV7Xwvyj/3bHYfqqom0+xe3LqTtS2H+/m9PDzI+rpf/PxncQ23wvXkr76+GuXHO9tRvqpqMsr6mtsP8734U6eydYJr17M1n5Pb+R7LbGMjym9vZ9egqurOnQdhPp9PvPLqa9kPDNP14GwP+4msfbr7MB8Hn959LspfeOo7Uf7s7pkoX1V19Vp21uh4nu8NpOtGs418PvHNw+y9nEzCsdMiOwtQVbVcZveig+NStQzPhqTnYhfL/JzPbDPrJw4Psn30qqo2vJfprTwIz6Z0UUUXaz7LRfY8dLGmnY6dKiyhg2XQasJzjIujfD4xCs8HLxbZOPqvn/9HlK+qev6lbOw16+Cc95Urf47yq1Xe5184n+2lP3yYffuwFbbxVVVPfScbv22dOBHXcPPmzSifnvM5dz5f67j69ZdR/sGDbA+6qmpQWfv24GFWw2yaj2G//OqLKP/CS8/GNfztb9l84tln8zn2frjutFh0cN4ptGqzsdNknJ9pmB9n1yFdl0/HHFX59xddjJ3SH+lg+zUdQlYbTg7HXZzzmWfrmNPwu9Oqqvk8G8cOwjlR/kZUtWHb0sV+WfpMp21D28G8Lp2jD8PviaoqPjA128zPjR3NsznJRvheHnSw3rK1mY3F07apqqoJ++zd7WxO08X/0C6zOfb5s9k3TVVVOzvZdZxOOzjT0OTrHQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8L+5dOlS3yUAAADwD6rpuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1lfTdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK+m7wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF9N3wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL6avgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH01fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpq+i4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXV9F0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJMsubAAAgAElEQVQAAAAAAAAAAAAAAAAAAAAAAOur6bsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZX03cBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvpu8CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhfTd8FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+mr4LAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9NX0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6avouAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11fRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADra9R3AU8Mqg1KGYy24gqOFm2UP3FyN67hYH4Y5Y/bRZS/d/d+lK+qOnPmbJTf2ToV1zA8HkT5+Sq7D1VVx6ujKD9uNqL8qJlF+aqqdpW9E8vlMq5htboT5cej7DqsqonyVVWr1STKLxb7cQ3Hx99E+dnsXJRvl6soX1XVrrL2bTXI8k9qyNqWQQfP06AZR/nhaBjlHz3ei/JVVYtl1sae3T0T19C02XVYVPY8HRwdRPmqqs1p1r41WRNfVVXDUdbOLxZ5f3v/3uMov719MsrPZtmzVFW19yhr5w/28+dpmDVvtb29HeUvfOfprICq+vSzy1H+QQfj4GactfMnT2XX8Uc/fD3KV1UtDrJ3ajjOxj1VVauwu7xy5asOasheipdfye7Fqp1G+aqqwSibjwyG2Xykqmp/P3uvmppH+UEHyx1tm/3GYNDBnCi8Dl0s+wwG4ZwmnBsehG1TVdWde4+i/M1beX/7xuuvRvlZOP67fuN6lK+qmi+z6/DrX/0qruHLzz6O8nfvZ2OvV1/N1/9efO6VKP9v7/xXXMMvf/7LKP/xe+/ENWxtb0b5cTi/fbyXz28nw6x9HE3zNnrnTDZHni+yNnoyydcg4/W3Qb7eUqvsOjRNXsPRUTZHbsLrMBrm/e3xPNunWVW+WNGEz9Nx+E5UB+O/yTSbD5zYyvfL7t/PxvI7O9l68nCYr7e0q2xNetDBvKyprJ9o22xdv6pqGM7trt7MxpB73+Trf7ON7H9In4WqqsEg+42d7RNR/tbtm1G+quoXP3kzys8P07lp1WqVjX2aTvqJcK8ofJzCrdcnmqx92j55sYMisguxbB9E+ff++89RvqqqCecTLz13Ia7h2QvZ/PLdjz6Pa/jkk0+i/HSSvdc/fvNnUb6q6sbVy1H+D+/8Ma7hmYvPRPmXXnw+yl+/diXKV1UtF1k7P+lgb+DwKGujL1zIxqC3b+f7RG1lewtdzC0nk6yfePw4P59y9Vq2T7N79nSUH8/ytYo7d+9F+XTPsKrqwV52L7a2sjHoo8fZmnpV1Soc/Bwv8nM+h+Fe/MZGdh2r8nd7GObzlYq8huPj47iGdpmNO2azbG55dJTPiebhb3SxXhIeDak23PObd/AspO9UF/1tM8l+I30WqqrGo+ydWITroBvhGmZV1WyajSEPj7IzEVVV7TLra15++btRfvfMi1G+qura/atR/unT2XymqurOnXDPbdVB21BZG7m7m327sGrz/2E7XEPs4p0YheslaX+5MetgLbcJ91/bfAHv0V625zabZuOWZbrXVVUHB9m9XC7TUUfVhQvZdfjww2zdq6rq9OlsLz4dO21s5uf32jZrW/Yf5+elRsN03JL118fzvI1Ov7+oDvaqxuHYaTLJvkGpyr8vS6/CsoN1gml4/q7toI2dDMN7Ee5bdrF32i7DZ6GDcxWD8IzMIDwn3sV1XLbpb+Tz21G41jCb5W3L/XvZWuwwHP+d2MzX/9J3YtpBG70Iv9ts59l7ef3mZ1G+quql770W5c+fy/dv3//wgyj/459kZ4OrqhaH+T4NAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/eC5dutR3CQAAAPB/avouAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11fRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq+m7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWV9N3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr6bvAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYX03fBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvpq+CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgfTV9FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mr6LgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9dX0XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66vpuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1lfTdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK+m7wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF9N3wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL6avgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH2N+i7giUU1g3vfPr3cjCsYDNrsB1aDvIbVca/52XQS5auqNjemUb5dzuMaVm14Lwf5azGorSw/HEb5thZRvqpqVasoP1iF9+HJj2TxJvzzabtQVQ8e3oryzSBvW3ZO7Ub55TKrYbk8jPJPZPdi0ObXcTjO3ssObmXVMosfHR5E+WGTXYOqqo2tU9kPdHAhF+EzeXSU9VXTSd7fjkfZvWjCNr6q6vA4u46P9vfjGs7s7GQ/EF6GxSIbe1VVjSfjKH/zxvW4hrO7WT/x6PadKL//OGubqqouXrwY5ScdvJeLefZOvPLi81F+f/9RlK+qapps8HR4mPf516/diPIntrbjGp566pkoP59nY/FmnI9B2zZrny5f/iyu4dlnsus4Gc6i/OFR3rZMx9k7Mah83NKuwhqG+Rx7GfZ3g1F2L6/d/PbrRX83HJyI8v/0/afiGibjrM//66d/jfLf//73onxV1SzsLz9473dxDZNpNm45dyF7Fj7+5NMoX1X16ksvRPlzZ7L2tarq088/jPIvf+/NuIaP//J+lH/xhew6bGxla3dVVYvjbEIx2cjv5WKQjQFn42yOfrD/OMpXVa0q67On03BeWFVNk7Vv9+5l639VVSdObET5YZP1t22bjxna1f0oPxqejmtYrfai/HSa7Q083s+v43AUti2TbI+mqmq1ytadlstsTjQI9wWqqlZtNvYaDPN9or2D21F+Nu3incj6iafOvxTlHz36IMpXVbo1kC6pV1XVKFyTvnLtiyj/L//8qyhfVXW0n/W3yw72WJpBF3cj01Y6zw/3LTvYJ1o12Y8Mhnkbe/PG1Sh/9atsTXu5zJ+lt9/+YfYDq/w63nqYraW2HZz02Rhmc+zDw2zN6MrN7Fmqqjp1KtsbeOONbBxeVfXBh3+J8ufPn43yu2cuRPmqqstffB7l58cP4hpWla3Z7O1lfd3WVv4sPHqU1XByO6/hOFwXP3sm3Muvqvlh1k5f/fpKlD+a5/u301l2L86ezt7rqqobN25G+ecuPh3lb9+6G+WrqubhvTi7ez6u4cGDh1H+6Cjf+xyG+6/p2GfcwT74QXq2Iz3AV1XL8Dzo0dFRXEOqDf+HLuYT01n2PKTHQY+X+T74Ypm1LZPwjE5V1XyerQGOwz3Dqqr9g6x9Ss+GHB3n66CzcTapObub97e372bnnT7+yydR/sIzeT/z4UcfR/nf/OY3cQ0/ePMHUf6Pf/j3uIavr2Tzy3RN+uxuPo7+26fZOZ3pLNsnqqo6d+5clJ9tZPuv8fcfVdW22b1cHOffX6Tjr8Nw3NK2+drZbDP7NuuLL7+Ma3j9te9G+dt3srlAVd7nb5/IzjGmz3NVvow56mDslJ6fS8ct6VyiqmpvL9uD3tzMz6c04dzweNHB947hvRiEk5pVumlYVYtF1s6Pwu/8qvLvcdK9+OMO+rr0zP3RPJ+jD4bZ8zgaZfORtoN9okXYzyyOO9h7DdvILr6L2jmVjaUfPsjOKrUdfA/UhmOnrc18LD/fy9bvjsI9v3OnT0b5qqorX2bnKp6+mH2LU1X185/+LMr//j//Na7hrR9l42AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID/b03fBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvpq+CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgfTV9FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mr6LgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9dX0XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66vpuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1lfTdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK+m7wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF9N3wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL6avgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH01fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpq+i4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXV9F0AAAAAAAAAAAAAAAAAAAAAAADwP+zb2bMk5Xkn4DezlrP2ru5GQIsGLBYBDi0WEsKyI+w/2r4Yh2cmNFoMthYQe7MKAacXejvn1JaZvlDMzD2/ClVdPM/975y3Kr/89gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7dVuugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtle76QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F7tpgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHuNN11AVdVQ4+r6898437b9GqposnTTxhVMJ9nnSB/mfDYP/0LVfHYS5Zd9/ix3RtmzaMffvC3+X6P2IMp3/WmUP109iPJVVZNmEuWno7x76fouyvf9MsrPF7MoX1XVtqsov797Lq6huuxZ9l3WNwxN3rfUMIriTZivquq7rD3OFln/WJX30+fOZu1pHWPdqM2exXyZ9Y9VVYtV9m7v7O5F+VHl7XEYsvFyFfavVVWjcLw9eyYbK6uq+i7r59sh+/9dH/6Bqvrq6FaUPzjIv8cbNz6K8mfDvuWpp/8mylflc8gvv/gyruGH338hyi9OsvnbEPavVVW3vr4X5R88yOegjz/6WJSfttO4hiGcurThcHn79hfZH6iqo6PPo/zlKxfiGqbTnSjfL7P1xM40W+NXVXXLbP42nuTtsSqdf+Xfw2yR/Y23/vBelL/22BNRvqrqzGE2f1uH9278Mcq//PIrUf7uraMoX1X1wY23o/zjjz0V13D/+E6Uv3wlq2G2/DDKV1W9/2E293r+mWfiGj76KNx3WiziGi5ffTTK3/jgsyj/zLN533Jw9nKUvxu256qqrx9kz/L69SejfN/fjvJVVatV9jdGo924hr7PxtuDgzNxDatV9ixH07NRfhiy9XVVVVPZPuhq9VVeQ5ON+V24tjzYz9tCH+75pJ+hqmo0zubiXbhfMx7l+1bj0X6UP13m3+N4N9uX77psjV5VVU32PYy6+1H+hy/9KMpXVf3PX/yvKH/50qW4hpu3/xTlf/LD56P8cg3nt32XjXVNvrSspsn2Uod8K7b6PvwgYR/dhPmqqsluNvf57IuP4xo+/fBGlL/22LUo/+T1fG15nM7Fw7GyquqTL/8c5dvmYlxDupF59Uo2B/3wRr4vf3r8TpR/4rFvxzVcuXw1yt86yr6H8Sjfl3/6yWyN/MYf83sVP375xSj/7vtZ33TnTj73moyzc5rj4/wcvA3H2+kkm8NWVTVtNlbt72dnC4e7+dnp7DSbf927czeuYdxk7enoy5tRvl3DueOF89k4cXKc37FZLbP15XKez8V39rI2PZtlfWw7yp/l/mH2Xq3jrtHsNPseui6bi4/SA+Cq6sM9m6Zdw8KssnHi+Pg4yrdt9j5UVU0n2Vx8tcz2MKuqpuNsvJzP873YVdimd6fZOXazhjXR6Wk291lN8mc5Sc/zw77hyz9n68Kqqgtnsvvuv/nl/4lr2NvP5n+74V5HVdXQZ+0h3ROfTvL+bRXuSd+9m83/qqru38/mX3t72X70JOxfq6om4ZpmvJfXcPt2tu+0WGRz0P39/H7MapWNVecv5PfO3nr7/Sj/4gvZXc6qqj/8/o0on87/Vl0+1qXnjnt7eXsKtyrq9p3sPsHOGj7DOOyflst8/lfpemAdvwEZZzWMxlkNwxruQaa/T2vWcGDWhb9JGoXr/HV8htk8W6OP1vBbw/TcsEvXhmvYJ2jCDzGs4Xcsk53sWaS/savKx4kzh9k9ndOTfA/yQZ+d04xG+XvZh2uiSdi3HH2V3/naCX930IVz2Kqqm0fZPesXnv1BXMMHH2XzYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgL+2dtMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC92k0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2ajddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbq910AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr3bTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvdpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9mo3XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA26vddAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK920wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL3aTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPZqN10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANur3XQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyvdtMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC92k0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2ajddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADba7zpAqqqauirhsWGi2iidN/nFQw1RPmmyR7n+XPno3xV1a2bX0b5c2fOxTVMdvaj/GK1jGtoR1l7fnD/bpQfj7P2XFXVj7LvoW+7vIbhMMq37SzKT8aTKF9VtTPK2mPTjOIalmH/Oho/zApY7Wb5qqo27GSbvD12ffg31jBO7OzsRPkm7Bq6bpX9garqVtn32Lb5O7G/k/UtTZt9kcMaJg2np2n/lk8B23H2LJohm/dUVa267Lvsu6yG+8dh/1hVBwdZH3n1yuW4hhqy77EdZW3h+Ph+lK+q+u1vfxfln7r+3biGTz/9OMo//fQTUf72l0dRvqrq5Dib/12/dj2uoa02y7dZvqpqNWTfw2oVrm2HfLx97tlno/x4ko+3d+9ka5qzh2ej/DraQtNkc68Ha+jfLly6FOU//Swfqz795FaUf+a7WR977uyZKF9V9clnH0f5yU4+b/npT/8pyr//3mtR/vhB3haef+aZKN/nX2O1lfUNi5M/RfknHn8yyldVnT38Ksr/6fPsM1RVXb58Jcr/9s034xr+4dW/i/LDkK0tV800yldV3T05ifJvvv1hXMP589mzvHf//Sh/7sz1KF9VNZtnY3Y/5PugQ7h31jR7cQ1VWZteLI6j/Hicz53Gk2wftEvn0VXVddlcvmmzviE946mq6vr0ncjXE+NRVkMzDveD17An3g/zKD+d5GcDo/BsYNWv4dx0yPYQmyb7DPfufh3lq6q+92w2B3373T/GNfzs5Vei/Ow0mzNMx/nasqmDKD8M+Xs5hAuCJtwzqqoah3v76c7+eA19y61bH0X520d5e3rqqWwf87FHno/yp4vPonxV1fEy6x/ffSvv3x5/5NHsDzT5WdN8kc0bHhxnc9gnroXfQVXdvpXN35o2fy8fPsz2QXf3Lkb5W0fvRfmqqj48A37xhey9rqq6czs74/jpT34W5f/t3/8tyldVdcts/taH65mqqq6yd+L44RrOPg+zecMinAb3XbYWqMrP0rvw7LWqar7I5pD7+9+K8g8f3InyVVWr8J1YhuNUVdVymY1VfXgfoaqqW4br/PB+SbeGjflR+E6s4x5jer1kFt6x2d3N776lz3I6zectaXuYTsN7kJXtYVZVrZbZ+W2tYf9uFu5jruO8LF1fzsMBd7KG9pjeNVou1zB3Cu+DpncAd3fyvuXOvXtR/m9/8GJcwx/feSvKX7qQ/3YhHSdu387mPovT06yAqlousja9v5fdia2qms2yvmG1zPr59H50VdXubtYYxmHfVJX30YtwHn18nK0lqqqmO9lnODyT3/NJL7y/9c67cQk//vt/jvL/9ev/HeXn83x9Owrv3Kd3/quqRuG54yR9p+ab/p1iVdfl32Mb/o113KUchc8iXaNPp/lvH8ajbO9stoYxPz2Hjved8iV6tU3enlLpXDz9HsfT/N7Z7jSb+6zW8tuu7G+M1nJPO/sb6Tizt5+vyx7cy86JJtN8DroI5/JDn3UO0938M+zsZv3jJx/l87/nXvhhlF+Ed0OqqnZG+RoZAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgr6nddAEAAAAAAAAAAAAAAAAAABgScJcAACAASURBVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK920wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL3aTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPZqN10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANur3XQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyvdtMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC92k0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2ajddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbq910AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr3bTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvdpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9mo3XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA26vddAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK920wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL3aTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPYab7qAvxiqhvk3Tw+jNdTQbDhfVUNawiSKj8dtWEDV+bNno/zx8UlcQ1XWHnb39uIKZot7WQ272bPcnexE+aqqYeijfD90cQ0npzej/LmzV6N836+ifFVVDdl71Q+zvIZ2keW77J0Yt3nfUqOsg1yF7bmqqu2yfn53ZzeuoQm/yvk8a09Nk4+3k2nWPzV9Pt424bNcLLKxarZ4GOWrqvZ2s/eyHeXfY9tkf6PPX8uazbP+bTb/5vPPqqqDg/0oX1XVhn3krVtHcQ3zRdY3jNqsbzg9zed/j1z9VpS/dfPzuIZlOG/489FXUX5vZxrlq6oeuXwtyverdEGTt6fVsIxrOJkfR/n0WVy6cC7KV1X1XfYsll3eSe/tZXOf2fx+lN+Z5nOvdG25d5j1TVVVr/3ug6yGyUFcw4vf+26U39/Pxsvfv/GHKF9V9exzz0T5ixcuxDW8/tr/iPLTSbZP8J3vPBblq6ruP7wb5fem2WeoqhoH+4dVVX2XrUcWx9l4XVV1+VtPRPmbN/8zrmFv/9tR/tHHss9QVfWLX78W5V99+ftR/qtbd6J8VdXX97+O8o88nj2Hqqq7X2fj5bvvZPm/+9GjUb6qqqnDKD+sY++ssrl822afoaoq7SKHPl1X5fsE3Spb3w7hPupfZOuBJtzrSPfUq6r6Pju2W0cNQ5vu7Wf7Vl2ft4WmOY3y43QjtqqaZfZit5Wv89tx1kcul9k7NRrln+HMXjZ/+/FLL8Q1LE6z9jRqsve6W+b78uM2awtdn5+dNul52Ro2lLvwfOHgXNYeP/j4nShfVXX0xe0o/6MfvBTXMBlnc5/VMtuLfe/GrShfVXU6z8a669eyfdSqqpPwzG6yhj62wnnD8SzbR236fJ/gwoWLUf7TTz6Ja6guuxuSnn2++pNXo3xV1X+8/tso/8Yffh/X8LNXfxDlT06y9jwa5fO/PjyeGK+hhukk2xdfrvI19sMH2X7JwWE2zuyHZxNVVd0qe5jtGp7lEJ47zmfZPmq3Cu8ZVdV4lM1jd6ZrWBM12feYnrdV5ddB+/DMbtXnn2E8yeZO4/EazgbG2bpqJ7yztVjkdwiXy+y9WseaaBX2b7u72ZqoH/I7Nnt72dypXcOez+w0+x5XXd6e0jtbQ3gv4+FJfs9nL3wv+1V+Pzm9s5Ve5jx+kK2pqqouXczuJHzy8cdxDQcH2fzt3r3srKqq6vyZrIZ0jX30ZXbXvapqtsj6lr29fMzf3cv66fksG+tWTf5ez8L7BKNwDltVtVxmn6MJ++huDXOGtDW1o/wnanv72X2nu19n+zVVVUeffxjl0/tSi0W+Luu6rD2O2nzeMm6zPnY/bAvr+H1aE475p8vsnKmqqgvX+fPwvn1V1blwbdf1WXuM525V1Ydr5Oka9irS93LIh/xYEz6LdazL0p81tenvkNfwO5ihzR5ms4a2kLbHdryG33aFv2tK7/m0k3z+t7uf7svnv31YhH9jEa5HdnfzfflFeD5x8Uy+7/TuG9l52dPP52fxT167Hv8NAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAv6Z20wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL3aTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPZqN10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANur3XQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyvdtMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC92k0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2ajddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbq910AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr3bTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvdpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9mo3XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA26vddAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK920wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL3aTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPZqN10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANur3XQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyv8aYL+H+a9htHh2EdBfRRuv3m5f//vzFkNTTNNMqP1vAZ9nb2ovxQo7iG2XwR5Y9u3YpruH79yewPZE2h+lX4B6qq71dRfqguruH8+StRfrnaifKTaRPlq6pOTrL2NGrzd2LSZl39MGRtYZU26KqaPZxF+d3drC1UVVU41ozGeXtahe92F76Wh4dZH19VNfTZZxiavG/pm6yG1WIZ5Xem+fc4ne5G+aby9rhcZuPt8cP7cQ2zedY/XbpyNco3acdQVZ9//qfsDzT5s9zf389KCOdvi2X2HKuqmiZ7FtO9SVxDLbIaLhyejfKTyeUoX1XV9SdRvp3ky8tFn/WxR199Eddw9Wr2XbZD9l4uFtm8p6oq7ebbNu9bmvBvTHayse50kc9BhyFbY7/97jtxDY9c+XaUP3/ufFxDOhH+z9/9V5T/+c9/FuWrqu7e/TrK/+qXv4hruHLlXJR//FrWFrpw7vaXvzGP8rfv5Pst+zvZ2u7cxew5fP7Fn6N8VdXQHET5J75zLa7hzTffjPJ/+8L34xr6cIH6+7c/ivJnz+brsuqyse7Kpaw9VlU99zcvRflf/+ZXUf611/8jyldV/fSVn0f5+SzfO+vDPcShO41raMIDhqbN1jRdn69v2zYba5omm/9VVbWVPcu+vxvlR+3FKF9VNRqF+5hDvi5rmnTeEK7z1/AZhiF7J44Xx3ENo1HWP43CM7+qqqbJxrvxKNsn6Pr8Wa6GbM4Qbhn95W+EQ03fZ+/UkG7sV1WNsj52Ms33KlZdOPcJx5mqqp2wSb7++m+i/BC256qqF1/6XpTv2/yl6MI7Badd1h5nJ9n+YVXVtccfj/L3Hmb9Y1XVwUHWR/er/FmuwjO76Th7qY5P8r7lcD/7Hh8P20JV1Uc3HkT5n/zouSg/NPkc9B//6R+i/L/867/ENfz6tWwv9ZVXsjX6qMnnLfMue6dGk/zS1mKerU/bNZzF74R7+9VlY/6Zs9l5W1XVYpneL8nHqqbORPm+z57lubPZ/6+qunc/6x8Xi7w9Hh5mnyNuz1V1Os/21ZM7tVVV7RoWRctl1qabNdxp6FbZXsNonO0T3A/bc1XV7l7Wnvpw7lZV1YcXre8/eBjlD/az85GqqpPTrG+YhG2hqqoN7wCulms4x07vru1l+07tsIZ73rOsf0zXI1VVo1H2LJfpuizs46uqXngpO7P75a/+Pa5hspu9V6en+RnLJHyWTfj7jfEk71tm4VizCsfKqnzuMxlnfcOqy+fRy/BOw2QNzzKVXtlaR//Yhfc5b948imvY38vutF68mO+XfPrpZ1F+FJ7/jtfwLKuyGtK1ZVXVSdjPt+H3sLOG35AswrnXeLSGe7WrcF22hh88PnyQjVUXLlyI8rN5vp+8s5PNg/s1/N6xSX8fli7z1/AD3Db8DGn/WFXVddlYld+Ryb/HYQtqaMM9myGcR1flzzLddhrW8D2m8+jTk/zcMZ03pPPgdI1fVXGTnrf5emLcZm36qzX8jqXC3w0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8tbWbLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7dVuugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtle76QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F7tpgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHu1my4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgO3VbroAAAAAAAAAAAAAAID/Zt/OeuS6zzsBv+fU0hvZbG6iRFKiJIqK5ZGtzMgeWNlmkgGCAPkG+oD6CAPMglzEE3kS27KtzZK1RztJiWSzt+qqOicXTpDLAPodpGowz3P/O/32Wf57AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvtpVFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mpXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66tddQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK921QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL7aVRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqV10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurXXUBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvdtUFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+2lUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6Gq+6gKqqpmmqadrvnO/7foAaujCf11CVXWPUjqJ8t1xG+aqq6r/7c6yq2t7eiUs4Or0X5c/tnYtrODw4iPJbG1tRvqkmyldVNeEl0nxVVd8fR/nFYj/KzxfZ+1xVNRqfyfIDtC1teInT7iTKz5fZc6yq2tjYjvLjZhrXsOhPo/zsNLuPVVWjdiPK72zvRvn5aXYPqqqayvrbrlnENSxrHuW3djajfJf/C9Utsw97NpvFNRwdPYjy589l7WNV1d757Fksstex7n37TXaBytv5ZZeP38Zhd3fn7p3s74+ytq2qarbI3unNrexdqqr6g1vPRfm2m0T5RZ/3M11l/eXh7Ciu4e6921H+6pVH4hpOT7Kxy8YkHLeE87qqqq6ytqHr886qCZcb2ia7D/sH+fv48cefR/lbTz8d1zAeZ/cxbaOrqppx1lf96Z/9WZT/8IPfRvmqquOj7H147rln4hoWYV+V/g+bG/mcaDLN3sfD24dxDbu72RhyNsva+EsXLkT5qqqPPnk/yv/ghf8Y17AxzcYdH33ySVzDjSeeiPKvv5O1DRem+Tfx1PWsbZif5vOJ0/CzunXzqSj/5Vd5P/Pbt1+L8reeeSGuoZpsTtItsrXgqqqmPRteIGuj+z6fW/Z91tc1Tb5O0ISL0qM2m0/0fT4Gbdt0jySbj/xe2Lj0WX4SjoGrqrou+66nm/kGx/2HWRt5ZjPfqxpX9j71XdY2tU2+VtGH63d95fs86RvZLbN19bR9raoaN9na13yR798uwjZyYyNfL3nn3Tei/O5udh/+4Nb3onxV1SdfZGPxeZ/tj1RV7e5m86quz9rY7z13K8pXVX3y2ddRfjLO5lRVVbPT7Fk03QB7yKPsWfRhDdNwblpVdRLud3326adxDbvnsjHk//1lNr+9dCGfoz///A+i/H/587+Oa/g/f/c3Uf7VV9+N8n/y0vejfFXVm2+8FeUP7udzy3TNpw/3oKuqHt6/H+XHk2z0devZa1G+qmr7/NUof+9O3rYsTrIxZLqWm55hrKp6/Hr2LGazfNyyv599V90y3y+bjLNx7Nmz2Rh0OcB50PRs7v7DfG9gezs7SzkJ25Zze3tRvqqqDye4zQDf5bjL3scrT1yP8keH+drZQXiNfoBDrelx9ckkHwfPF1n7dHKc9TNDjOXHo+y7XAwwbhlNsu9y2WXrTpub+XmpL7/IzjR0y3DxraqW4fs4GeVrPmd2sv2F46Osr5qf5OugOztZn5/8DudfpPdhcyNbg2zSxeCqSsexy2U+Bk33qrqwo+m6/D6m3eX8NB9HHy6z9zE9b1VVtRWeKR2H32XT5t/1ySzr8xeLfOzUddl3lf7GLf0mq/Kx+BB7n/N5dh/T3xpW5evB6dm36QDnfMajcBw7yPu02gsM8svXsK9K5zP/XMVK80P8jjm9xBC/2WxHWV/TDzDuSNeuphvhmvgAY9DFInuY21v5OZ+0n5jPszHD5kY+v037/CF+77i1la1BfnPny7iGS5fy38IAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8e2pXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66tddQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK921QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL7aVRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqV10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurXXUBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvdtUFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+2lUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6alddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq111AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr3bVBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvtpVFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mpXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66tddQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK921QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL7aVRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPoar7qAqqq+76vvu++cb5p+wGq+m75vB7hK9jiOTz6K8qP2fJSvqhqNsmssZidxDefO7EX546PDuIaj4+wabdNE+Y3JZpSvqppOt6J832f/Q1XVw4P7Wf7hgyh//fqTUb6qatllbcPp6VFeQy2j/MOHD6P8pcuXonxVVd9l7XzXLeIaqrJ3etRM4wpG7SjLZ/FaLr97X/0vFovTKD8a50OX6Wg7ysf3YYBxy91732YXyB9lnTt7Lsq3zSSuYbnM3qe0bbh48UqUr6ranF6M8t/e/zKu4d79r6P89vZOlN9/eBDlq6p2d7Px37VrN+IaumXW37ZN2FcF86l/vURWw8Y4nxNtT7Nx7Dd3w/axqs7vZWOX41n2TZ3ZuhzlqwYYiw/QTzTh2OeDjz6N8qcn+fv4vVtPRvnNzXxe9vHHH0b5Rx/L+6pLlx+J8h++/1qUf7Cfta9VVTcevxrlJwO0b+NR9k103TzKLxf5nGg8ysbi1x5/PK7h/fc/iPLPPvtslB+1+btw5dFrUf7d370b1/B4+Cwe7OfjtwcPsjWbm09k47f3P3onyldVXbuW3cdJl7WvVVWLefYsLpx/LMrf/Safj9y9lw08Hpzci2vY2zgT5bsmm9dVVc3mn2c19Nlax2iU3YPfXyMb+5ycZPegqmpjmrWxTbsR5fvK8lVV80X2To/abL2mqmo0yv6PrrJFyNnp3ShfVTWeZN/lZJyvW128kM3tTo/zcXDTZmPIvkvvQ34fmybrJ/o+Hwen3/Z4kq2dfftNPvY6t5vdh3ac7/mNx9m6+IcfvBfX8Nij2djnQrgefPd+vm7Vttnc8vJuPgadTLNvuwv3/PbO5uOWDz/OzlWc2cnHf4tFOA4O92+rqibheYD5abZHMwn3Lauq9vezueX589neQlXV7m7Wzl84fzbK7+/nc6Kf/u3PovzzLzwT1/AX/+2vo/xbr/80yn/w/hdRvqrqhR+8GOXv3M7WxKuq3nsvWzu7eD7fn9gO1zHHk2zc8ek/5s/yWnjOZ2/3+biGbvF6lH9wP2sf56cDNNKjbE4znuZz7I3NbBw8O5nFNXR9eN4pPF7yyJX8u77xZPZOv/7rV+Ma9h9mZzFPT7O2qR3lewPzsIbNjfybuHgxmw/cfObp/h5lCgAAIABJREFUKH/n69tRvqrqV79+I8rvnMnnE6fhOHiQs28b2dxwPs/a6PQsZ1XVMlzzGWLP7uAgO5s7nmbr8l2XH8z44vNsDHn2TDafqao6nmX3cTLJ1xDv38vmRXvndqN8W0P8jiUbB08GaFtG4QHj6SSrYXaar4nP5ll/m96Dqqo2vEa3zMawTZO3j+k5yCHuYx+2kfmKdt7XzOfZs5wPcM6nabJnMciv9MLfRTVhfoh+pgnfhbYdYs8vq+HwMP+N3Cg8N/bgXrZWceHihShfVbVowzZ2gDFo+k2kbWw3xFnzcK1jHaTPshngHqSXGOI5xPOqAb6J5SJrI9P8EPOyVFP5fUyfZR+28YO0C+H/kO5BV1XN59maz8W9bM+vquqdt34VXwMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPi3vfLKK1H+5ZdfHqgSAAAAAACA//e1qy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXVrroAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZXu+oCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhf7aoLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9tasuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11a66AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWV7vqAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYX+2qCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgfbWrLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9dWuugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1le76gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF/tqgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH21qy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXVrroAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZXu+oCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhf41UXMIS+X8bXaNutML8Z17BY3I/yk/HFKN/XJMr/3jxKT8d5DV3XZjVMpnENbfhltaPsf2iaJiugqvr+NMqfnBzFNVS/iOKXL12K8vPT7H2uqur77J0+OTmOa9jayt6nixeytmV+0kX5qqpqs2s0zQA11ChKj9u8bem67J2cL7PvuqoP81WTSXYfmybvJ0aVPYtFkz2Hr+58EeWrqk5PTqL8Uzeeimto++w+zE724xpG42z8Np1cifLjUfb3q6rG4Rj07M5eXMO9b+9G+dliFuWvXb8W5auqLuw9GuVPjvJ+og+/iX6UjXuaJmtfq6rGbTaGPJnl45bL585H+SHa2Nk8a2M3N7Kx07IbYBwd9pdDzA3feOvDKL+zeTbK37p5NcpXVc1Os/btN6+/Ftfw0o/+U5RP/4eqqtd+/ndR/saTN6P81at5f/vN3dtRfmcza5uqqvrK5mUPj7Jn2Q6wTrCzsx3lm7Cfqaq6/EjW53/+xZdR/vrVx6J8VdX2max9G21k71JVVVMbUf7mjfyb+MVv3o7yT994MsrfuP50lK+q+vufvx7l/+LHP45ruD/L2sijw2wu8NyzP4ryVVX/+6f/I8r/5u134hr+6Plb2QWa/JuYbjwZ5WezD6J802TtQlVV32fXmE7ztYpll/X5oyYbyzfNAOsEo2yev1hk33VVVdtm9yHdemza/JvqumzdaTHL59htuB48meTv0+niXpRP38d0zFFV1ffZHL0dYm+gy96HLsyfP5+PQdP9tr7P55bvvfNulL/++PW4hs1p9k7+/c9/HeXPXz4T5auqnryezbGbRX48pK1sbjfdyGoYYt/xT370R1H+v//s1biGR3Z3o/yi8jMy3SzbN1wssjXxSZuvQV7YOxflNzfyvmo0yt7Jr778Ksrv7ebfxOE4+67ffOOjuIbLV7Jxywt/+JdR/jf/8D+jfFXVm29max2PXN6Ja9jaycaQz33/h3EN1WZtQxeeO9u/9zDKV1X96ufZs/zJH+f7t1euZWsVh0dvRvn5PF/LPTwKz6c02VygqmoUrkkPcSa1wrFTmr9y+ZHw71dVZc9iFp5vqarq+6y/Oz3N8pNpfubrzJlsPrBcZPO6qqrj4+xZfPhetgY5HWDsdfHihSh/eJSfadjYys6Knwn326qqRuEB5YODwyh/fJR/112XtbFDnJEejbNnmfYzGxt52zI/Tc9z5m3LZvh/5E8yX0tN99K7Lj9Xm/Z1W5v571ia8Hxwuk4wwGdd00m21pD+D1VVJ7NsLbUPn8PWVr63EL/Tbf5NzML7WANsDWyGfX4bnhM6PMzPEE7CNfFmkFY6nZdl71O3zF+G9C6Mmvycz2yRjZ0mo3xvYBHey3Qt9mSAsXy3zN6n8TRf027DZzEKf2vYd0P8riqT9xJVbfhdtek5xrBtGuIaJyfpb8Oq+mW45zfAeknaxi7C9ZJuma//jcfZd53uvVZV9eHvSCbhPtEynOMPIf6uBzCf5eO3K+fzMwUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/Xl555ZVVl1Avv/zyqksAAAAAAID/77WrLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9dWuugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1le76gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF/tqgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH21qy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXVrroAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZXu+oCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhf7aoLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9tasuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11a66AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWV7vqAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYX+2qCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgfbWrLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9dWuugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1le76gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF/jVRfwr5qV/vW+n0f5rhuiijaLNxtZvB9lf7+qqrJrTKfTuILF4jTKj6dn4hqWtYzyJ8cnUX4R/v2qqtksu4/V5d/09vbZKN/32d/v+/w+dn3WOGxuZN91VdVkkn2X3SK7D0Pcx+qz96lpBmjfmuyFWiyO4xKWXXYvuzA/HufDhnaUXWOIGhbL7D588P7vovzFixeifFXVk49fi/JHhw/jGhbzRZQfj/LvcjS+GuXbJmtbNrby9/Gzz9+N8p9//nlcw2NXH43yj+4+EeXH47yvm4fvY9OE456qqsr6/MUiy7dtPiFp2+ybmEz24hpmp3ei/NXHbsY1fHX7wyjfNtl9mI/yOdE33x5F+c/+8eu4hltPPR7lz57ZifL7+3lf9/WdT6P8n//Xl+IaPvvk4yh/+87duIYz4bPYPZvlh1hwuXLlsSh/+87tuIa93ew+bGyk445wzamqDo+z/nJrazuu4fKl7Fne+TbrZ2YDrP81XTa33Jycj2s4PMre6YPjzbiGZ57JnuWbb2Xj6Bd/+EKUr8rnlv/w5htxDX/4/ez/OD7K2pY7d/L5yEs/+cso/4tf/jSu4RdvZu/Tn770x3ENBw+z/YlReynKd8u8r+uW2Rx9Og0Xc6uq77M2cj6/F+XH4TpsVVXfp23subiG45NsPrC5lbXxo3H+Lty/n80Hjgbo9B/Zuxjlm3G21lFVNRpnY9DF4n7290f5OmjTZOPYthlg33H5bZRv2mydYBLPBap+9262pj0a5Xt+Vx+7HuWXi7yG19/N+vxqJ1H87DRvo7twD3hrmo/ll2EzPQ+b2EW4b1lVtTzK1s5e/MHzcQ1vv/VWlO+6vJ/ow/np2a2sjT23m50FqKo6Ps6e5WSaj9++/iobO918KrsP5869GOWrqi5d/HWUf+PtD+Iavr6d9bc/e/V/Rfkffv/ZKF9V9cvXsvv48DD/rv/zj/8qyu/v58/yJBxL37mbzU9PTvKx/Is/+VGUf+vtX8Y13Lz5H6L8jSeyPZp33s32yqqqjo+ys28b03wPucLzKX2br2n3i+w+tE32Tv92gDXIZpnVcPDwIK4hfZbpGLYqX6vY3sre6SHGwQcH2Tz/4GE2dtrby+dEp/Nsryo9O1dVNQ7385vwrFJVVR+eSW3b9Kx6Fq+qmoyzOXY7yvc++/C8e/ocjo7z86ST8VaUPz2d5TWEa1cDfBLx/xE2LfGe4e9rCH/7MM7nt5vhbzj68Ix12+b/QxPW0Kc/PKiqcdi+zRfZ3LAL13uqqtrwbO9ogLPB6d5A+vuNqvy3NOOwr9reyecjTfhddQOc2Xqwvx/lz57N1s7m82wffgijATq7jc1wjpxNTauqqgnPKKffdfo7mqqqWThmmIZr4lVVy2V4NqTL7uN4nI+j07FPH64zVFX14Xn3vs/uwxC/gE577MlkgN92hXPDfNSRXyNtWybT/JtI34jlAOOWLr6TWX6Ied0onufnRUzGWTt/Msvn2Ecn+TUAAAAAAAAAAAAAAAAAAAAA/ol9O22yozzPAPx0n2VmNKORRkILAoyMAQMGKmDwEieu5FP+g36gfkYSVyVgHIOxMUvYESC0on2WM2fJB+zvLt9d1e34uqrm433mOX3efrd+GwAAAAAAAAAAAAAAAAAAAAD+Hly8ePFv/v9fuHChg0oyfV/HLqTfYQi/AwAAAAAA/K1r+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOFq+y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOEa913Ad5o//SX5zGq1CD9hGdfQNJMo34b5VZTu5kP29m7FJVy//ln2Ae2RuIbLl29nH9BkF3LZQXv84Q+fiPJb61txDfP5PP6MRN4vVK3C7mk8zu7rqqrloo3yB7P9KD8eRfGqqlqtsg9ZVV5EU4dRfrHcy2tosu8xDn+M0Shvj234He7euxfX8PWVy1H+sUfPRvkj06NRvqpqcZi1x3t3w3Gqqo4dfyzKTyYPxTVMx9k4sT7NxvzXfvNalK+quvsga9MvvfxiXMPW5nqUf/eP70X5p59+OspXVTU1i/L379+Ma9jaOhblJ5O1sIIu1kRZvm2zOUNVVdNsRvn7d7+Jazh3+kyUv3Eva4+XLuftcbZ7P8r/8KnzcQ0728ej/IcffhDlT5/O+raqqpdf/EGU//3bv45rmE6z+dczzz4Z13Djxp0o/83lr6L8o+eyOUdV1eFhtrZb38jXt3v72XpgI5yKj6Yb2QdU1ezBQZaf5XsVo2m2njhz5tEof+lK1p6rqk4dy9YDq8N8zN/YyMa6bzsYb0/uZPf2z1/ZifKv//bNKF9V9fKLL0X52/fz9e21G1mb3No4HeWnk3xHuV1k1+HF57Lfoarq/U8/ivJv/yFvTz96Nvse8/1w76s5leWrar64EuVns3zMH42zsWY03o7yy0X+fKMdZftOk3H+fGM0zsaa27e/jvJNm491k+k0ym9tpGv0qu0j2fr2yo1P4ho2t7P21Iyydd1ymY91aXNYdbBfMp5k12FvP+sbbnybrfGrqjaPZu3x3NmsLVVVffzhx1H+m6vfxjWcOXsuyh/dzubyX13L+seqqq/CNfYv//GXcQ37h9l4exDmm1F+xGWxzPYJzoyyZ69VVR+thQv93ew5UVXVapXt5+4cPxnlZ7NsH7WqanMzm/t88ll4tqSqjm1l13F9mvWxi0W2d1dVtX4kWw+88mrWFqqq3njjjSi/t383yv/qv34T5auqzj+erWmeOH8+ruHu/WwOORrn8+D3fvf7KP/Uk9+L8ieffDbKV1XtHmbPoJ9+OjtvVVX1ztt/jPI/ejF7NvDY4/n874vPsrnPfJbvOy2WD7J8B4cpF/NsvBtXNu9o8m35mu1lzwaaRV7Eka3sud9sHu4ZhfsMVVX372Xt8bCDudP6etaox+Psd9jdzc8TTCfZPLqL6zg7yO6Jtsn3KhbhfTUeZ216OsnXZXv72W9xfCc7o1NVtVhm98SDB9l9PZ3kfUt6xjrdR62qmi+y9enGej4HTQ88zefZd2jbfJ9g50T27LOW+Xg7CfvYZVhDO+rgsHmoi/cWmnBPetRm1yH9HbpwOMv3rdL2OO9gDrpYhPPgtax/W1vLz77NF9k+6P5+Pn9bC69D2qabDuZe8cHaDsTXMWwLVVXL8N6O5+Id/JTpmL0bzv+qqtY3sns73WdYLLo4a57dE928uxrOv9J5Swd9SwdNOjafZ31DJ98hbBDpM790XVjVwXqgg/VELGzTTZN/h/QTFmF7/k7WHtI5bFU37+ACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDfgwsXLvRdAgOhLQAAAAAAQP/avgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjavgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLjGfRfwnVWtVsu/Ot00+ddYrVbxZ/Qt/Q5N28Q1rE0nUf63b34c17C9fSzK37r9bVzD2tp6lN86uhnlr177OspXVd27eyfKr69N4xrG0+wz5ofzKN+O2ihfVbVaLbIa8tuy7t2/H+VHbXYd2nHWL1RVrZq/foyoqlou9uMa9vZ2o/z2VnZfV1WtmqxBLBbpOBHFq6rq1t1bWQ1Ndk9VVT31xCNRfjk/EuVnB7ejfFXVaHE0yp8+9Xxcw3i6FuXbsG+pqtrbexDlX3/j11F+kg919cqPn81qGGe/Q1XV/m42lz596myU/9/334nyVVVPPvlElN/azO6pqqom7CSXy1lcQy77DqvK5l5VVeNJWEO7Edfw4CCr4fPPvoryO9s7Ub6q6vEX/iHKLxb5ePvbt16P8j9/NfsOs/1sPVNV9dG770b5cWVz2Kqq9bCfPwjHyqqqo+H6dHEkmzvd2bsX5auq1tezGtbW8r5l90HWz+/Ns/a0tZbvna2Hc58rV6/HNTz8cHZPLMLh9syJc9kHVNXVK1ej/CPn8hrmi+zHfOhYtqaqqtrbz/auVuvZdfjJyz+N8lVV73/4QZQ//dBDcQ0ffvp5lH/ppew6rjf5Xsd8cRDlt7byPno0DfvIWb44vH37iyh/4li2JprNDqN8VdVodSLKt+MbcQ2rOh7lm8p+y2W4F1xVNW6yvbN5uG9VVTVdy9Z26bzn4XNnonxV1bX1O+8IAAAgAElEQVRrWXu6dPlSXEP7wjNR/sTOD+IabtzOvsex7a0ov1zmDzjG06xNtzWKa9jdvxblv/wymwcf38mee1ZVHd3OxuwPPvo0ruHu3Wx9+vwLL8Y1XL2a/ZbXbn4Z5Y8fz/d8Ln/1TZT/5NIncQ2PPpLNO6bhs662zde3zTj7jINZNoetqnr+mew5zX+//p9xDWvjbO7z7Y2sfzuyle/Lf3Up659O7ORrmofPZuuqVZudLZkv8n351So8DzDKzwP88y9+EeV/9R//HuU3N/Px9s7dvSj/zjt/jGs4enw7yn/xxUdxDT/92ctRfjzOnjvuH96N8lVVTZN9xmye929PP5P1LW++lf2Wzz33WJSvqvr++VNR/uq1fD/51q1sPdC2+X5JhWfPRk3WxzYH+TPoR0+ejPLX7+XPee48yM5sjcNzjE1wtvnPJpNsDnr+8fy+vHkzez5x61Z2BnGS7sNW1WQSrvM7+C03NrL5295efo4x3c8dT7J8U/mezxCu43iS9bFtm7XH0Si/J+aH4W+5ytcT83m2L76/n/+Wk3Cdn75/0cU7KItF2D910L/t7mVrmvSs0UMn82enqfSeqqqahfOvZdicujiXG27fVXUwTizTC9GBJryWy7BvWCzz546p9ExsFxbh3lf6HkxV1Sh8F6aLvqUqa0/jcKzMK6i4g3sQvstTla/LRh283LWcZ+1hFL5j14XFMpt3dPGeXvpLpPOWfOZVVeE40cV9HY/5HQzXh2EfOV0Lz1gf5OuR+TIbq5pRfl/HvVP4W3bw6mu815DO3aq6eDc/LqFGo/yMCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwF/qwoULUf7ixYsdVQIAAAAAAPwta/suAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhGvddQFVV0zTVtn99KU01cQ3LWkb5Ji+hVqssv1xl32HcwZeYTNoo39QirmE2243yy+VBXMNLL/84yl++/GWUP3t6J8pXVZ09cyrK3/z227iGEzsPRfkmbNNN2C9UVS2W8yi/f5jfE1ubm1G+Da/jYhF2blW1Wu5H+d29u3ENRzay67hc5X1s246ifNNkbfr6zRtRvqpqbX0a5Xe2T8Q1LA8Psw9Y3Y7ik8la9v+rarK2FeWXq424htUya09ffPlpXMOlL7+I8jsnj0b5Jx7/fpSvqqplOFblQ1U1q2zus1rOovxTT56P8lX5mF9t3ken490q/B2aNpuH/+lTovRiEfavVTWZZkvU3f38pnj3/ax/eur896L80c2sj6+qun79WpT/6pvP4xr+9Zc/ifLfXMr6+K/DfFXVzlY2Xh45eiSu4f5etr5dzLJ5dFXVapT1DQeLbE0z72DPpx1Novy4zfJVVdP17N6+dTtbY6+t5euyUXgdzpw9E9dw5cbVKP/oufNRfnmYrcmqqo4dOxbl7zzI1iNVVVvrZ6N8u+yiPWVr7N2D+1H+1DTfO9s+Ga5P88tY33vs8Sj/1ttvRfl/+kk23ldVjZvsQrz9uzfjGmbpPsE42/+rqvrk42zMPv7Sw2EF+XpiPM7W2IfzfN4yXsvWp01lezbLcI1fVTWbZfdEU/n+3fzwZJQ/fSrrY2/duhXlq6pOn340yl++dieu4b0PPo/y//bTV+MaDlfnovxqkc29JuPs/39XxF4U3zvI1sdVVVeuZO3h+eefjfLXrl2P8lVV7/zhvSg/Gmf7+lVVTz2VXYePP/kwrmG1zMb87z+RrWnOnD0f5auqbl67GeU//Tzflz91Mru3t8brWQEdnGmI539tfk8cCfcqvveD83ENB7eyfafZvax//OLrz6N8VdULT2RrouMP5ft37Shb384Osz3xUQePBsZNdh3ayubhVVWffJitT//ln34W5V977TdRvqqqwrNGzWb+HPybq9lc+vjJ03EN0yPZOLEb7ol3cS5jVNn+XRPuqVdVjcbbUf7VV7I1+v/8+g9RvqrquReejvKPPPZMXMPs4N0of7CXPxuIH+iHz4C31sK5V1WdCs/5fHn5XlzDRvj8dHMrPGMzztvCeJyN+Q/u59fxcJa1x7Vp1hbSswBVVeNxdk88/tgjcQ2372TPaeYdnAcdjbLnVatwvAyPqv/5U6L0MnwGXVW1DM9irsLnZffuPYjyVVVbW9mcYVX5udrJJOsbZgfZ/l9V1Sg897VzItvTvns7309ehTfWcpHfmJNJ1k8fWcuesdy/nz3/rcr7x/TsXFXVdJpdh4ODcG3ZwXeYhPOWySSfOx3Os+evy3AvuCp/f2IVvhy26OC+Tu+JaTj/q6oahWua2Sy8J5p882w6zdr04WG+d5aekU77+KqqNryWhwfZfZmuR6qq5uEccq2D90bn86w9pOuqpoOzIbXKrmPbdNAew/lfui5bhu/RVFV8bqyL/m0R3hPpWqAqf0fucJb1LV3MWw7CsaqLQ4TpvCN9qT1+l6eq2nDO0MFRzPjeXoXnIKuqVh28Ww8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPCXunjxYt8lAAAAAAAA/w+0fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHC1fRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPB/7NtJl1zltSbgHSea7JSZUqpBCNBFYGxa0wjLLnA18/oH/ECGdWdVsyp7lY0xBmMECGyuQHSShdrsM6M5UYO7at3pXbyxKmKVn2f+Ru6Mc87X7PMFAAAAAACLq5l3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsrmbeBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuJp5FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA4urNu4B/0/745LSJ/3qn0wk/YRTXUDWI0k2T5afT/ShfVfX1N9ej/Oap1biG27fvR/mXX3klruHocBzlP//8X6L888/9NMpXVbWTaZTfOnUyrmFndzvKr29sRvnd3YMoX1XVhGPLibW1uIZkfK2q6nazqWL/YDfKV1WNhsdRfnNjK66h02TXcjjK54lpOFXt7u1E+bW1layAqur3u1F+d/dBXMPBbjbfPXL+8Sjfa05H+aqqTi9b+6yu5GunP7z7bpQfj4ZxDa9dfjHK93vZ+HYczvdVVU0nW79NJkdxDTXNPuPMVjbfttNszVFVNQyH2KaTPxNLy9m6YTzM1sFtON/P4jP6y/la/utvv4/y9+/l645Xnn8uyve62Vx3++/Zd1BVNa3DKH/ltZfiGq5d/SjK7z/M9nVrq/m6pZ1k4/xknM8T6yey/cCD+9n3WFV1YvNMlO8PlqP84UF2P1dV3d2/F+UvPvFkXMO0ze6Hc6ez67C9k+2vq6o2TmZzfmeSjY9VVWe3zkX5w8Nsvu73T0T5qqq19VNRfn8v3xO1bbY37Pey57qqqplm9/T4MJsvt/PlXz1x7nyUf+/DP8c1vPpCtid6+PBhlL/21y+ifFXVynK2L9s8md1LVVXHP3wZ5f/LG/81ruE3v/2fUf69P70f5d988xdRvqrq6CDbW/YHF+IaJpNs7dNpsmei6S1F+aqqbpONseGSo6qqJm3WO1tby+brXv9mlK+qGrdZ3+nJf3o6rmE/7MW+93HWe6uqeu65X0f54+2w19HcjvJVVQ8fZuvYpUH+XB4eZePbtWufRfnnX8zm+6qq+/f3onx/0I9r+PyLT6L8+ol8DfrzF65E+Zu3svHpm69vRPmqqrTV0O3nx0O+v3ktyj9z6bUoPxmn5zqqur3sM9q8pV2TdhLln3kyPw/wx+/eifLHB9k8cemJS1G+qmpc2fpteeWxuIaDcJ7o9bN7odvk/Za93WzdcvtWNsZXVT158fUoP2rXo/yLP38myldVXfvsVpSfDvP+XbeTzZdnzmZr+aqq3/7mf0T5S089EeUffzy/luPjbMKdxbvPaWXvBtpOtif65RvZuqmq6t13r0b5y5fz81I/+9kbUf7jT38f17AcvjfsTLM9zeg4P0/wu+vfZR8wg7lqfZCtYw/Cc2eD7izOE2TvLm/fvhPX0O9ne7tReEZmeSXfo1e4HTj/WL4GPf9YVsTVj/J3A/sH4VnvcK6axZ5oOsnWwTOYbms0St9DZ2NTfyk7M1ZVNQq/xzY9kFpVNc3OGi2H42NV1TSsYRQePBuE42tV1UG4x+6Ga46q/GzvOGxcpeftq6om4TmfdpKfv1vqZ892t5ddh3YGg3T6CdMZXMsmPCPdjvJrOQ0nm36TzRNpD7MqP6c9mcEz0QnP5qbjWzODtfxwmH2PK6v5udpuk/0f0za/lv1Bdk92OtkzdXic7euqqibh9zAJ115V+T09HoXzbfjbsFlI5+uqqqaTrb8Gg2y+Tq9DVX4+uQ3fM1Xlc107g7El3eenH5CuYavyPc3RUX5GOv3tQi/8XVVnBpv09G6aRZ+gCb/H9P1vVf5cAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/zjefvvteZcAAAAAAABQVVXNvAsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHE18y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMXVzLsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABZXM+8CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhczbwLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBxNfMuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDF1cy7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWVzPvAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXM28CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgcTXzLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAxdXMuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFlcz7wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWFzNvAsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHE18y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMXVzLsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABZXM+8CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhcvXkXUFVV02nVdBLEm7iETqcbfsJxXMO0DqP8eLwX5ZtOfjs8euHZKD8aH8U1dHvfRvmDg7yGrZMbUX5tdTPKf3k9+w6qqn75y1ei/N7uTlzDyspKlN/Zy2pYWV6L8lVVg+5ylJ9MRnENTdNG+d39bGyZTsdRvqpqcyN7JmqczxOjyq7FaAbXcnyUfcbq6mqUb/KvsW7duhnlx8NpXMOli9lctbSUjU1NN7sOVVXHo+y5/N3v/hDXcP78hSg/bg7iGr77LpvvHj93PsoPBieifFXVZNyP8tP2x6+h/+1Dss+YTrI1ZKfy57qdZHNds5TXMB6vR/lpux/le4NsbKqqanqDKP/h1c/jGpaXsjHymaeeiWvodDpR/tpnH0f5n1w6G+WrqlaWz0T5G9f/FtfQGQ+j/PkzW1F+f283yldV9QbZGN2dweJpbyf7P05unYtruPvgQZQ/d+GxKN/rpv2aqvEkm+tu370T13B6M9vTdNtsrurM4H7cOczWb6dOnIxrmB5l1/I43NdNZrAnqjb7kOUZrEHH4/tRfljZmqGqqgn7oJsnTkf5Hw5uR/mqquVptm55+fkX4ho+uPpRlH/txZei/LW/fRHlq6r29rPncimbrquq6uWXrkT53fvZXFlVdfm17H745Nr1KP/hX/4c5auqXn3pjSg/nEHvrJ1mY+Rw9F1YQT7Xra5kPeluL58ndh9m91Ovl+2PO51TUb6qajz6Ico/fvqJuIbffZ2NkS/89Lm4hh/uZPv0C5tPZ3//wfdRvqrqxEa2R75961Zcw3iUvePY28vW0X9678MoX5W/Bx9t53vsp59+PMqf3crHhqPDbA169mw2Nty6la+dfv3rN6P8e3/633ENN29ma5+11S+j/CPn8v5fG/YJwnb0v9bQZj3I5jDvl1y58h+i/Lt/+F9RfnfnbpSvqhqcfjTKv/ve+3ENL76UzdmjYTZP9Hv5vXD/Qfb+9ifPXI5rGIVHro6GN7K/P8362VVVr72azXV//347rmHvOFu3HB1lc2VV1ZVf/DrK/+XqH6P8k//0apSvqpo22Tu7Wby/nVa2rxqNs7GlmUG/5cUXszH6j+9k90JV1Zv/OetVPDWDfVmF5znXNy9G+f/+z/8tyldVraxkvYbl1byf3F8NzxDuZnuatpOfJ9jefhjle72luIbRKJvvwtfo1e3m55OPjrO56sGDrGdUVbW6ml2LSZt/D5Nx+L5rkt3To1G+Kep0svdlab6qqtfL5uxR2NLu9MKHqqpGbfiOZSkfWwbhluQ47Nf8q+ye3t/L7oWVpXyuO3c2O+ezvZ2f2e822cUch2NTt58vQsfhg9m2+fjWC3/7MJlmNRwf5/vbYXgtR+H5lqqq5ZXsuVpZzX6/MYsatk5l7w1nMdfdu5f1cndn8G7g8CDbn/Z68//JYzesIT23VpX/pqhJF/NVNQjH6V4/m2cG0xmso8NxfjjMx9j0exyPs/5ffwZjS1V2P7XhfqSqahT+Rq3bZP/DLH770ITXYhbrlmn4b7Qz6IP2wl5BJ7yWw2H+P4zCNWh6Hary8a0Nx7dZnPNO74U2XEfPpIa4gqp2PIPfhwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP8Q3nrrrfgz3n777RlUAgAAAAAA/KNr5l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIurmXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyuZt4FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC4mnkXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDiauZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLq5l3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsrmbeBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuJp5FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA4mrmXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAi6uZdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK5m3gUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLiaeRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOJq5l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIurmXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyuZt4FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC4evMuoKpqWm217cGPziZyFN4AACAASURBVPd6Z+MaOs1elF9a2oxrePfd32c1LJ+I8gcHO1G+qqptR1H+3CMX4hp++rOfR/nf/P63cQ3T3ndRftDrRPknH/9JlK+quv/gTpRfW1mPa2g7wyi/vpo9E9NpE+WrqtrpJMoPR9l3UFU1DZ/LTqeN8stLa1G+qqqdZjUMlvJrubezH+V7g3zKPXUym2sehM/13t5ulK+qWupn1+LpS6/HNYRDbHV6q1H+628/ywqoqkn2WNdofBTXcOv2t1F+6/RyXMNkMo3yf/zggyh/+fVfRPmqql53Jco3TTeuoZ1k12IyDR+qSvNVS0vh+NTJ1gxVVeM2m6t6S1kND3d//H7q/7r26V+i/NbWmbiGR89le7s2vA5VVZ99kY3TLzx7Kcrvbd+L8lVVD+5nn7G8vBTX0F/LxpZ0Hbx1Lr8fh8fHWX6S7QWqqjrdbJzfP8zHhpPhGnT/IKthY3MryldVrYzGUf7uvfy5XO5l13JzPdtjr67le/T7D7O+0XgpX4N2u9m+qjM5FeUPDm5F+aqqjbXzUb6tcDNQVf1BNt9ORttxDdXPnu3+9DDKnz35SJSvqhoeZfd00wziGl5/9XKU/+zap1H+0sUnonxV1bV/+WuUf+nll+Iamjaca8a34xqmbdY/O3cu+x/u3sn211VV3//wVZQ/d+65uIZmks3Zg172fmL/6O9RvqpqPM76Tu0k62FWVfX72fg0GmXv26ryfd3wOFuLf7P9ZVzDExdOR/nbd7JeblXVeJzNl2c2smt548aNKF9VtRGug7e383efJ09ma8izZ7Pn+s69m1G+qmo4zPZlw3wJWku97EPSHmZV1bQN17HT7H48sbaR/f2quvl9Nj69+kq2fqyq+uCD96P8l+HYcPJUvpZfC3uxNc56RlVVNc3WX9M263VU5b39N9/8j1H+46tZP7qq6u6dcC2eLzvqq+vZc3npUtZP7jT5O+iLF5+J8qNR/p5ne/uLKD/tZO+gT59+OcpXVU3b7F3VI4/lPe3vP/owyt/f/jquYTTMxsjNjaxvdTR8GOWrqqrpR/FZPJeTUboAC98hd/L/YXUt61W8duXZuIZ33/skyr/86tNxDZsnsvMAn7z/hyi/fmIG7/z62Ti/spL3QZvw7NqJE1kNR0f52iv9Hnb38nd+S4NsX7W5mb0z3NnNz511w/dtn/81W3NUVW1tZX2Cvf0ZvGMJz9ksLWX342SU34/pUaHVlbxPsLQcvos/yPZ1l57Kz3lf/+pGlF+bwdmQ+/fvRvn1EzM4QxiunXrdbD+xv5/35TvpBjXsM1RVNeFzubaW9UFncT755EY2V00m+Zy/vp6t/5bb7Jm4dy/fE43a7H5aP5H/buAwPO905kx+1mhtLbuWJ09n+/yDvfm/39h5kK9beuHZt07edsqFA2RvBue8J+Ownxyf864ajbO5Kj3au7qajy27e9m7z5WVbK6rqpqM0992ZeuWSTjGV1VNw992LS3P4J1f+m+Ej0Q3HNuqqoaT7Ix0O4P1Xyf8ItJ7oapq0mZnO9L/YSa/xQkvxSxqSNfy4/C8e/r3q6omYf+v25tBX36S1TCDR6KmM/htFQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwL/XW2+9Ne8SAAAAAACA/w808y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMXVzLsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABZXM+8CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhczbwLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBxNfMuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDF1cy7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWVzPvAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXM28CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgcTXzLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAxdXMuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFlcz7wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWFzNvAsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHE18y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMXVzLsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABZXM+8CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhcvXkXUFXV6XSr39v80fl2+iCuYdpuRfmdnRnUMO1E+XbSRvmNjdNRvqpqeXk5yj/cuRvXcDx8GOV/dfnZuIbrX/w9yt9/cCfK3733Q5Svqrp0KXsmut1+XMPoKHuulpdPZH+/nUT5qqq2yZ7LXr8b19DthJ8xHUfxfncp+/tVNe1kNdy+lz2TVVWD8FoMeoO4hrt3sjHy3t3se3j0wtNRvqpqc+OpKN9Udi9UVQ2WV6L8hx+9E1aQPxMPtrNr+cILP4trOHnykSh/48sP4xrWT2bj/PFRtvb64M8fRPmqqitXfhnlm2629qqq6lQ2Pk3aYVjBDObb8VqUbzrp/1C1srYe5b/46usof/d2vo5+8fmXovy0pnEN9x/cj/KjyUFcwxu/fCXKf3X9iyi/v5N9B1VVnSYb3/r9Jq7hxNpqlD/cy8aG4/EoyldV9ZazPc3w8CiuYbCUjfP9cN1TVbW+uRHld4+yazEa5fPEylK2/rr42IW4hps3s/Xb8kp2Lbsz2Jed2zof5Xf3sl5HVdXaatq7yub85UH2PFRV7e7ciPIry5fiGjptNj413WyMr6raH2W9q36T9a2acd63Opxkfat+1jKqqqrVfvZsn300G99G43yP/vTF7J7+4MO/xTW88YvXo/xklPd8RsfZev6x81nP5uatvJ/8zbfZXLe1dSauoWmzPkHTzdbBayv5O5bR6NvsA6Yn4xqWl7PPmLbZ+u9O2AOtqjr/SDa+jVfz8a0J+/J3u/lzubb0WJT/+NonUf6Vl7M+Q1XVO++8F+Ufu/BEXMPycjbOf/f9V1H+yq+yeaqq6uOrV6P888/l3+PqSta/Gw134xp6zY8/j1BVdXSQjdGrq/ne8vjhjSi/u5P3zp5/4adR/uon2frt02t/ifJVVb+6/J+ifC9/fVud9GzINO/FVtjPHR9n/8MLz16O8lVVN77Oxrfj47wP+vjjF6P8p9euR/n8HU0+13zxt/x92SNnsjFy4+STUf54uBflq/L9xKTJ9jNVVa+H+9tvvsnXoPcf3ory/aWs//bpJx9H+aqql167EuU7bTY+VlWNhtmeZDrNjoS243yya+tslG+W8v7d5cvZ/fTB+/m644kL2bmKc2dPRfm1tbxvtRa+8xuN80bow51snD57JrsX7j84jvJVVRsb2Tu/9Y2853NwkP0fvV42tnQ6+dqr18vGhln0tG//cC/Kr63m72/397JnIj1rvrmRr1t297N3VdNp/g55bz/7jJWVbHz84XZ+pvXRc9k8087ge3ywnZ1xGSzlz8TBMOtJj0fZ2LAyg3MZ6fjW7ebrt+FxNk8cHR1G+dNb2bqnqqoTLsW3H+Y9yN2dnSj/yPlsf7y+kZ1hrKq692A7yk8r3xOtrGb95G+/uxnX0B9ka5/dvf0oPxrmPZ/D/ayGSZv3IJfCM1vDUfY9HB5mY1NVVTdcBzczGKM74XO1tpqf85mke7tw3TGL/UT6ruroOD8Pmv4fg0H2TB0P8/3tMFx7NU3+TKS92H43e657M3hRdHyU3k/5fDvtZON8O4N5ojrZ2NK02b0wi/txHM5VaS+4Kl+3TMMhftLM4F4IaxgM8j5ouqfpzuB+GvTzvjgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD/S828CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgcTXzLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAxdXMuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFlcz7wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWFzNvAsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+Dzv31i1XdZ4J+KtVx33W3mJLQlJAIBoLAgaMCE6wR0aPdPwj/AP9C3KX7ox2O8YGRDAGGXMQZ4xknbW1T3XMBcMjd33ht9pV7vE892/tT7XWmvObc80SAAAAACyvZtEFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC8mkUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDyahZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq1l0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr2bRBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvJpFFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8moWXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tZdAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK9m0QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLyaRRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPJqFl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMurs+gC/mTWagXpQfz3p7MHUb7X24pr2N4eRfknLj4d5d96890oX1W1+8hzUf7gILsOVVW3bv4xyrdaR3ENk/Ewyj/91KUo//kXv4/yVVXr609F+b379+Ia2p1Ho/zxMKthWu0oX1V1uJ/dT1tbG3ENTU3DT8jGt72H2TNZVbV/uBflT2zvxDX0ur0on45NVVX7+3ei/MWnXozyg8HZKF9V1W4eRvlZexzX8O+/ejPKrwzWovxw9IcoX1X10os/iPKddt63HO1Povz5c1nfUlX10bUPo3x3pYnyzUHeSr/5H+9E+R+++g9xDU0760FbrWyemU1mUb6qatbOrkVrsBLX8MZbb0f5ppL1UNV/e/LJKF9V1YrWZFXXr38b17C1na3tHt3K+seqqo8//ijKd9rZ99gOe46qqm4veyZ6nW5cw8Fh1gevrGd98GSc9wwr6+tRvt1bjWvodrJrOcym66qqavf7UX6tkz3Xh0f5tWzCpd1knD3XVVW7u6ei/MO9bL/k1Kns71dVHYfXot/Pnqmqqtv3rkf5nRPZPNGufHycdLNe/OHhrbiGrXB8a43yZ2J8nPWQe+1sbXnvRr5vdWb3ZJQfjfNBetjJ5tvtE9m/4f2r2XqmqurZp7K14cZK/m7gP975RZR/5aXX4hrqKJvzD/ezeeLll1+O8lVVv37jjSj/zm/ei2v4ux++GuWPD7Jnql35+nbQy/bfxtP7cQ0P9rIxcm016+VPnT4T5auqhqNsjG1a2Z5RVVUT7lWcP/v9uIb3f5/tg156Knvn98FHV6N8VdX6RrZnc+/B7biGrbAHvHAh60G/+OzTKF9V9cILP4ryB+G7iar8HfDqSr6nPR4fRvlWk9Vw/dtsz6mq6vHHvxflb976Kq7hxInsHfLFC9m98LvffxPlq6re+eDXUf75v/1hXENN9qN4K37/W9VKjws1WQ3jSXamoqpqdzfbFz88zJ+J9957P8pvbu1G+Va68VVVb/z6N1H+0vcuxDVsrGVnZKYV7pc0+Tu/Tnczys9ad+Marn7wSfYBs3zPZxRuSr/2D89E+f/zi2yMr6r66tq1KH/vQX727ZXLr0T5B/ezGqZzWN/OKrsXWq38fdlsltXwyiv5fsm7v8nOYw7CdzRnzjwS5auqrl37Isqff/x8XMN4lvUNOzvZPmi3m60lqqo+/Twb53dO5vug4/BMa4XnCVpNPs9Mp1kP2h9kz1RVxd/DdJz38p3wff7w6DjKj0fZOaOq/N/Q7ebv7JrwTMHhfnamdTrLrkNV1XSa/Rvu3TuIa+gPsr7h4V7eB/fa2f2QntnqdvJ1WaedfUbT5L3TdJL1Tiv97FztUTg2VVWdOpWtscejfK/i1Kms//rk06z3eniQf48bm9tRfj8cH6uqDsNzZ0fH+fdwcpB9Dw/2sv2/yRzm2244Pna6ef82C5eXrVY2PnY6+fg4jz42NZ1mY/T+fnbGpio/XzydZH1wL5xnqqp6TfZMtMP5uqpqMsn6t4f72dgStj1VVdXtZc/VaJjPt+129j6/3Q/Xt+HYVFXV74ff4xzOnY3CNVGTH6uo6TSbKJrwzH76TFZVNeH42MxjvyTs5ZvwmZrN8r2OYXhPt8dzeC4H2f7bPH67MEr37wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP7CmkUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDyahZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq1l0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr2bRBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvJpFFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8moWXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tZdAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK9m0QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLyaRRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPJqFl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMurWXQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyvZtEFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC8mkUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDyahZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq1l0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr86iC/iT6az1Z2dbNYj//mTyRfYBs9W4hicv/vcoPxlPovyzzz4b5auqPvzw3Si/dWItrmFjbTvK9/uX4hru3X09yn97/fMov3UiildV1WiUPVe93kpcw3SW3dOzcIibjEZRvqpqYzO7p2ezuITqdLNreevWl1F+PGqifFXVo48+GuWPjvNrefPmH6P8Sj8uoc6e/VH4Cdlz2W4Pw79fdffOvSj/u49+F9cwWFmP8qPp3Sj/gxd+HOWrqibjbHCYTMZxDd1WO8o3s3yy+pvzF6L8g6PsftzcPR3lq6q+vZndTz//91/ENfz41ZeifGuWjfNNk88Th+Psnv7lL7Metqrq/O7JKH9695EoP5lmfVNV1bsfvB/lf/jqi3ENX336cZS/ef2buIadnWw90elk4+O08rVlP6yhNZvGNbTCeWJa2diwsr4V5auqbt7JxuhzZ7MetqpqOgmvxRzWE3fu70X5Eyey8XHQz+6lqqqD/ftRfmU1G6O/k61Jer1ulP/jja+jfFXVqZ0LUb7dzRdFK9PsfhyPjqN8t5XvQa6uZPfT8Syf6w4PD6L8ejvfvzuxsRPlb+3divI7OxtRvqpqrZt9xqg/h72K+9lexfbm41H+pefy/eR3fns1yj/z9NNxDd/e6GX5m9neWVXV5sr5KN+tbHw7PsjyVVXPPPtclP/k4w/jGt7+7a+j/MvPvxrlRw/yPrrpH0b5mzdvxjVshL102oLOYTlS7Xb4+nOWjQtVVZNJ1r8dPMjWI1VV33/276P8m2/8PMr/zblsnqmq+uoP2T7BxScei2vYWM36lqayfYZvvn07yldV3b79SZTf2jwV1zBpsrXdaPznnyX4k1Zln9HvZwPUo2fORfmqqsn4KMrvbD8R13D7Rta/nXnkmSj/8PH8/caNB9na8uoHb8U1PPPEy1G+abJ7oaqqFZzRqapKp+zjYb6nXa2HUfzddz+KS7h06WKUv3s3W98+fJCvLb/39PNR/uuvr8c1nDqdvQPePZWNb003f1d1+3bWt3x27UZcQzt8NzAe5mPL//inn0T5n//bv0T5djs/q3TrVrb/dvbsk3ENr7+evQN+6aUfRPnWLD9SOp1mew3TWb6f3GrCMzJhD1tV9dpr/xzl338v6zs2N7O1aVXVY49diPJNJ5/zO52sB1zdOBvm8/XI7TtXovzeXn5mqxO+pzk6yuaJVv411mSadaGdObw7HQ6zazE8zq/l2mp2puDoKBujZ+Faoqqq18nmmml4Xr6qanycjS3PPJfNt79771dRvqpq7372TLz6arYnXlX19tu/jPLtOZwbG/Sz/dwmvKWbOYwtk3F2LUdzODc26GfvgCfh+ZZ5nCG8c/tOlF9bzc8DbJ3K+o5HD7L3RNdvZt9BVdWDvQdRPu05qqqOj7O5qtfN3/NsbWXvy27evB3lx8N8z2dnO3s/0e3ma8Nx+BuOJhxkO3NoQkfhb4qG4zn08u3wPOgcfjma1jANf7tw/37+7vTEVvbOrx/2HFVVw2F2T66uZGuB/YP9KF9VNZlm9/RquJ6pqpqGa8NZmJ9O8t5rNg2byHkcrAh/sDiP7yF9V1Xh/l18HaqqP8h6n1433787Gma90zx68VS6LhuN894p/Q1Iq51/j51Wfj8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8JTWLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dUsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAllez6AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF7NogsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHk1iy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOXVLLoAAAAAAAAAAAAAAAAAAAAAVM+lqQAAIABJREFUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJZXs+gCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhezaILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB5NYsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDl1Sy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWV7PoAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXs2iCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgeTWLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dUsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAllez6AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF7NogsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHm1ZrPZomuoF198cfav/+tfg0/I/w3tponys+m3cQ2zejTK97r97O/PjqJ8VVWnk12L6fQ4rmE6bUX54TD7Hquq+v1OlG81D7ICWutZvqqmk70o39RGXMN4mt1Pk/B+Gg4fRvnvahhF+abJ7qWqquPDwyi/ttaN8iuD/JnaP8jyh4c34hrW1zej/NrK03EN1YTXcnU7yv/qjWSu/s7RUfZct7v5M/HEk9n4tL15KcqPjydR/jvZ99iEfU9V1XQ6jvJp71VVNW2tRvnD42+i/MrqVpSvqlrpZWPLF998ENdw9eqXUf6ffvKTKP/Zp19E+aqqWzeyXvz82bNxDel8t7eX9V537t2M8lVV33/huSj/9ZefxTUcH+5H+Y2NvAcdjbP+rd/vRfl2ux3lq6qOwv6vaWVrqqqqw6OshvRarqxlc0RV1WQyDfP5nL+xkc0186jh8CC7lsejrGfYObkb5auq9vezsWU8zr/HrY1szq9pdj/e27ub/f2q6vbWovzaWrYeqaqqWXYtJuP7Ub7TPhnlq6qmlfXBvWyaqaqqa9c+ifKPPf5YXEO6f9c02V7FrVu/j/JVVbsnn4ry4bZXVeXjU9PK+p5OJxzbqurOw2zP5vYfs+e6qurMqUei/Eeffh7X8MLz2f3Unw2i/GSW93+D1Wyu+uzrr+Ia7tzO7of1zZUov7M+h7kutL6W78W2WtmaZDJJx/h8TVSVfka+b1Wz7DOms2yMrqrq9LKxYX0z24v97W/ej/JVVdXK5vztU/m1PLF2Psp3KhsfW02+vv34k7ei/LnHLsQ19MO93Em4JvpO9i483S+ZzfLxrRXW0ITPVFXVaJp9j7duZ/uY55742yhfVfXGW/8zyk/G2fhaVfXEhTNR/tyZZ+MaeuH5kGkrW9R8fO1alK+q+ubrz6P8313O76fPP8/eNQ3C/eSLT2fvLauq3rryZpTf3Mj37waDbJ748puvo3y3m2+4PHx4L8r3etl6pKpqMMjmms4c5onhcXbOZhpuxQ4G+bmzF174UZQ/Gmbv/Kqq3nnnoyjf7Wb3wrnz+fr29Onno/xR+M6wqmoW9pCdOZxp6Haya3F8mI0tr7/+b1G+qurHr70a5fuDfHzrr5/KPiDd+2ryPcjrf7ge5T/4KD9XMQjPNAyPw/PFc9jz6XSyuWo0zPdbNjez97ftdj623L51J8qvr2fv4mfhe/Sqqtks+4xp2jRUVb+fPROH4aHW/iDfl59Ms2fieDiMa5hOs8/YnMM5n274XM3Cl3atObz0m4XnQTud/FztKLwf1tez3y5MwrMA38nGlnaTP5fb29k8cX8vXFPN4Z3fl99kZzFn83jHEjo6yteGTXg/DIdZDWdOn47yVVVrK9k5n+2t/Iz0/btZL308Cq9l2HNUVU3DzxhPsrNzVVWdcG3Zm8PeV3qk9G54L4xG+Txxcjvb7+h2872z9JachXPdZA7340F4Nng2h15+dTV87zjOvodmDuu6VjhfzuPX4GkPOg6/x6r8nHY3/H1Zq/LeaR7n/lPjcB90HJ41b82hj674t/35nN8Jr2War6rqhPtnz//gH9+ezWaX40IAAAD+yl2+fHl25cqVRZcBAAAAAAAAAAAAAAAAAAAAsNQuX75cV65cmcN/KggAAPDXz/9jBwAAAAAAAAAAAMD/D372s58t9O//9Kc/XejfBwAAAADg/73/2/9j1/yliwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgr0ez6AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF7NogsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHk1iy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOXVLLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJZXs+gCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhezaILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB5NYsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDl1Sy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWV7PoAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXs2iCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgeTWLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dUsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAllez6AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF7NogsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHl1Fl1AVVW1qlpNK4iP4hKms3GUb1rn4hpqdjuKTydrYQHTMF81CS/FdJpfy6Z9Isp3WnfjGmoyiOLT6VaWn8O1bFU/rGGS19DKhqh2ez3KDwb5v+Hh/nGUv3/vTlzD7u5ulO9121H+3v1sbKuqmkyze3rn5FNxDb3ORpRvhfNMVdVklj2XH3x4JcofHM6ifFVVp599D09dfCyuYX1wPsrP0smu9ef3PP/1EU2Un9UcamiyMXqS307VaY6i/Gr3dJQ/PhhG+aqq6Sj7jJO7l+IanryU9S3/+xevR/nN1Wy+rqo6fzbrxXdOZL1XVdX7V9+L8k9/70KUP3P6YpSvqvr46vtRvt/vxjWs9LO5rtPJ+pbvPiMb34bhcz0a5z1obzVbGw6H+fi2tpE9V6NJ+D0c5b1Xt9fLPqCdb7nce5jNdZurq3ENWxvZ93DzdrYeSNcCVVUrg2yfYDS6H9dwdHAQ5Vd72bXc2TkV5auqrt+5EeVXBtkYX//Jvn02S1rf6QG+++nuc2bODMwME2CAIZggiV2BAiBWaW2Xt/Y78AH1EfxibdWWjBYJWUIEJUYChCYQhsnphA5+oXL5ve6u7Xbtdb2/z/n1E/75STKZd33NMDlR5fcWt6t8kmwN3b1c3O/724cfeaTKf3bj07qGx0+fq/Kj3W5Ccfz4U1U+Sb64fbHKP3z8bF3DZFH2NeNy/W/UtW1JcuzBbix//WbfRs/LCeqzTz1Z1/Duu3+o8t9/9ZtV/mC/H7dcv/JxlX/isX6P5cLFS1V+XOxTJcmdrX5v4bEzz1X52b07dQ0p13wmZduyLNe9kn7tbBX7ZaPyb4zaNj7J4qCbF+2VzfyZM93eRJLcvHm3yl/4c7/HsvN8t3Y2nnTXYX7Q7TMlydNPdWuIH3zcrXslyYvPdH3V/rK/DvNFt9awTDkfKfc9k2RZ7jUtFv34bTLt5hM7R7sabl27XOWT5Ntf/06Vf+tXb9U1/PliN686e7abUyVJFt3e5zDunsc7d/qx/HjcrVudP9+Nw5Pk9Olu3/HE8W6t4tbNfs/vpZd+WOUvXu77ib39bv/13GPdO3H5075t+c53v1fljx/p1jCT5Oc//0mV3znSryfv7X9R5V959ftdAe3eQpI33/jXKv+1F16ta3jxxW6t4d13z1f5+3f7sfzbb/+4yn/nlf9c17C7W44h+6lh9ve7efqnn/+uyr/yyktVPkk++OCjKv+Vrz1f1zC/3Y07dg53Y4bb169U+SSZlnvQ02k/n9jd696JncPlmdhlP24ZT7p52Xy2gjPSs+55vHunn99ubx+u8uNxd65i76Dvb9tzFcO4X0Mcyn3oRVnC7kF/eG4Ydddx51B/xmZ7q5tbzlbwPC2W3b1cLsp7sYL2bVn+hrafSZJx+V7t7XXnW4aybUqS8dD9hhVMJ/LFF916R7uGOdnqzxMcPdKdO7tz735dQ/vtwmTcjVuS5G57zqccO925favKJ8lsr+snJuU7lSQZdW3sonwnhhX8hknZPq3gs4GMyj8yn69g77P8HWfLs0rXrt3oCkiyvV22DSv49mFeLjYsyntZj3uSbE+7vma0gk+ZF+W8rB07tePPJBnK8ynLFTyPi3JOtILmLeVlqGto58dJsmxvxgpu5qQcyx+U38gts4I5enkzlytopA8O+u/aW8MKzkwBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwH8/rr79e5X/0ox+tqBIAAAAAAP4jGtZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACba1h3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrmHdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuYZ1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5hrWXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm2tYdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK5h3QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLmGdRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOYa1l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJtrWHcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyuYd0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC5hnUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmGtZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACba1h3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrmHdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuSbrLuD/Gf3NyWHYqv/7cjlU+dFyVtewWOxU+eVyUeVHo3GVX0UNyxyua5gvtqv8YtTdhyQZFc9zkkwn8yq/OOie5yTZm3W/YevQCpqXxbL8AwdVerl8oPz/yZHD96r8/u60rmFavtpXv7xS5Y8eOdoVkOTwzrkqP4z66zgad+/EMn0/8dt3f1Xln3i6u47HTxyp8klyeOdUlZ8f9M/TeOjahnnX1WW5bNu2ZDS07Xz3PCdJyp8xrKCEUbqbMZT9xDBawb0s24aDcTfuSZI/X7lZ5V/4T09V+eWsbx+PHOnGkG+9+8u6hm994++7P3CwX8V/85vfdP8/yUPHH6zy43bQkSSjrnGYzcpGOsnxEyer/P3dbvy3t7db5ZPkYL9r39r5TJKMJ934axi1fV3fRi+W3bxs53A/drp27UaX39urazj2wPEq/9DJh6v8tevXq3ySHD9ezm+3+rWK+7P7VX42dM9jVtA+njnWjeUvXrpU1/D4492cpu0nRst+reNgfqvKTybdO5kko3RrqceOdM9Ckly9+nmVf+hY17aM5/06wc6kWze6fbsbhyfJ0Z2Hqvxi0bWP7ZgjScaTO1X+hWe+Vtfwv995u8q/9NW/q2t4+Ez3TP/i/d9V+W/+3UtVPkkeOHq2yl++cL6u4ZknH6vyH354ocof7Hf9fZI8ebabIy+m/bhlMe/H0o3RCsby/XxgFfOJcvxVzo+TZDLu5untks3pU907mSRXr79V5Z97+pm6hnd+99sq/w/f7tYZsruCPehyjn32kafrGv70lw+r/FNPPlnXsCyHLu3S/rJcZ0iSjLo5yWh0qC5hsbhW5Y/snK7yly//oconyWTcXYdnnn2uruHCJ90c+Z1fvVPX8P3XflDl33//vSp/53Y3F0iSnZ1u7PPgsf5syPZW17hM6vNOfdtyb7dbq7h0oWsXkuT0qW4+8dlnX1T5J891a05J8tH5rn2at5vQSfb3yr9xpH8vX/7Wf6ny81m7pt2v+bz66g+r/Js//0ldw+lTXX95aLtrWxbp9iaSZH+vGzz925v/Wtfw4osvVPnde/0eS9LtAT/1dPdO7e93Z76SZG/+lyr/i192Z52S5OVvdvcyi+6d+ORCt56dJONJN5Y/erg/I33jVvdML8v1krZtSpL9ve6d2t7u+4mDeTf+mi36Pn8yas9pd1ZxpmE86dYqVnHubDbrnqeDg+5ZmE5X8CPKC1GvYSaZl+/EZNKfNZqMuzZ2Xi6Ezmb9vGxa9hOLRV9Dvape/oHFCtrH9les4joOQ/dMj8uz6ivYWshDJ7ozCbu7fT8xL9+r0QbssbRW0LRkKPvb+3vdOcgkOXOmm9/OrnZt9O5uP697cKc7G7Kov4lK9vfbcUt/tqP9VvDxc935lgePHavySfLRRx9X+YdOdL8hSVIei51udd8N7K/gWVjMuzZ2vuj3PpflmYZZOYbd3u6/39grz/au4JOk2ngFfeWkPGs+L8dvixVcyPr7sFXczPJvjMsx7HIVn6eV84FVPI/L8vu0VRx3WpTtEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPwtXn/99XWXAAAAAADA/8eGdRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOYa1l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJtrWHcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyuYd0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC5hnUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmGtZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACba1h3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrmHdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuYZ1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5hrWXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm2tYdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK5h3QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLmGdRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOYa1l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJtrWHcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyuYd0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC5Jusu4K9GGUZDER/XFQwZVflR9usaZoud7g8Md7r8Cq5jlmUJwwpqGPa6+DCtS1guF1X+/t2/VPnrV65U+SR59ImvV/n7s3ldw5CiXUgylE3c1uRelU+S5eJwlT+81V/HL698WuVPn3qmyg+jk1U+SbYnB1V+a6u7D0ny+z+9U+Uvf97dhyTJsmsj79+7WuUfPvNclU+S/fvde709mfU17JZ/YNz2VV0fkSTLsr8dj7v7sJIi2nyS5aL8G/Nu/DZ94KHu/yf5uGyjL/y6a5uS5Omzj1b54w8+WOUvXb5U5ZPki2uXq/wPX/1GXcPFixer/OVL3W84dbp/HseTrn3b2tqqazh06FCVH437sfzFS917ee7cY1V+GPo2+s6dbm44DP1SwXTSPQ/zUdfnN0sM/9d02j1P83k/bjl54kSVv3b9Zl3DeLpd5Wfzbuxz9GjXzyTJ9aufV/mTJ7v3OkkOHenmJHfv363yR7ePVPkkGc+6F+vUyb6vunKzu5cPn3i2yo8O+n7m3v61robpA3UN7ZLwKp6nz2919/Ig3TrBMOrHLUe2jlX5i599WNcwTLv15O1pN/aaTvv1lsWsa98Obvfjlm+8+PdV/hdv9/OyF5//apW/u9utiX/4lz9U+SR5/tHnq/zpE0/UNcxmX1b5117+ZpV//ze/r/JJ8v57v6zyX//6f61r2Nu9X+WHodtvW5b7dav6G63RqLwOK1g7my+6OcmknBPdL8ewSfLCV16u8m+99UZdw+FD3fjrt79/r8p/8ytdP5Ukd+fdWP7YsbN1DbdudePgq9e7fJKcOt7tV80X3Z7dsnwn/2oFCx6lUbox4HLZ9TPnHnuhyifJr995s8q/9O2ubUqSzz7v9vMX97o5UZL89I1/qfKvvfZqlb9y5bMqnyR7u91+/nzezw0vXez2mq4f6uaGw3Y3r0uSy593e8iPPtztMyVJ5ter+A++9/0q/5M3/keVT5Izp7rrcPdu1z4mybNPd230yRP9eYDZfjcGXCzbdad+HL0o9/O/+1o/L/vZz35c5b//w3+q8vcO+nHLzs5HVf6zT7u2KUnefff9Kv/A0b6fePnl/1blP/30d1X+xo3+Op441a3t377Zn3374wefVPlHzx2v8vfu979hPuvGLdvT/lzt0cPlnl+5VnGw161hJsmhct/y3gpqGJf74ItybpkkB2V3N7t9u8ovFv3Zt3E5v13Fddzb68byk0m3PzGpzyD212GygrZle9q9E7NZP+7Ybde0ywMm5VJwkmS61a3F7pfPc5K0y+rtmnZ9FjTJctn9iFWc89na6mqYlu+dpUEEAAAgAElEQVRUu66fJEPZPh3a7vrrJBmVe01Hjx6tazjY79bf9va79/LmrVtVPkmW5Rz53m6/z3P8oe6czn7bT4zKb+yS3LvfjSEn5fgxSWbzciy+gm+7Du90604f/PGPVf67r32nyifJl1926/JXr3XnEZJkuzxnffhwd05oXp7lXIV27JUko/JbmLZ9vL/bfpDUX4flCr5Jar/nWS76ezkM3e9o5xOTyfrPlqzCqLyX43L8Ny+/o06SRdk+Tab9GcL6vVrBOZ/2OgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPx7G9ZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACba1h3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrmHdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuYZ1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5hrWXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm2tYdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK5h3QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLmGdRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOYa1l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJtrWHcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyuYd0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC5hnUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmGtZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACba1h3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrmHdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuSbrLuCvllkul397fDFfRQllvL+Uw9DlR6PtKj87+LIrIMlkcrzKj0blRUgyX8Hj0BqGcZWfTE5V+du3L1T5JLl08d0qf/bRl+sakvtVejTar/I3b96o8kly49bNKr817R/oM2e+VdawVeWHUdnAJtk6/ECVf/NnP65rmM27NnYy7vuJp59+pMo/dOLJKr9Y9L9hPFl0NSy7fJKUTXSW7aBh1MVX8SeWi/46LuddG7tc9BeiHTXslG3Lhxd+V1aQXP38XpX/1te+UtfQPg/v/ea9Kv/kM49X+SR5/InTVf78h3+qa9i9v1vlT5zqxtHTQ11/nSTb211fNx6XDWySUfk3hqHvq44dP1nlr9+4VeVPnTxW5ZNka9rdy2tXr9U17O12/cR02j0LW1vdNUiSO/fuVPmjO0frGtphx6lTXfuYJDdudc/08Qe66zAM/b3cPtX1NXsHXRufJFvb0yo/nXT5W7dvV/kkOXOye54OL/p34lo5x97bv17ld7YOV/kk2Zk+VeXv3v+iruHQdrfutJzfrWs4ffr5Kv/ZF3+o8mdOPlflk2S57Mby5x4/V9fw6Wddn/3Yo917OZv387rRuGvnF6O+jZ7vPljlX3zhq3UN5893c5Knn3iq+/8fdu9Uktw42bXRh6f983RocqL7A2UJzzzbrd0lyZ8/7takr974uK7hoeNnqvxsv50b9utWGbV/o1/TrvY9k4xG/TvR/orZbFYW0N/LO7e7edkr3361ruFnv+7Wvo6ffLjKn7/8SZVPkifOPlHlD/b6+cST556q8uc/6Puq7bKv2dnZqfKLFbRvo2XZNqxgL75dmR+V12Gx6ObHSfLkE91+2Ucfnq9rePXb363yb/6vf6lrWC67Pvujj/5c5b/3Wt9Gv/HTn1f5L6906wRJMjvo9vPLri47R/v1lmV55mr7UD8ve/SRF6v8xQtvV/nFQd9Gf/rpZ1X+7KP9fOJPH3fzgQdO9DXMl9362ZC97v/P+7H8eNz1NXsreJ5efuUHVf6Nn3b9xHde+8cqnyRnH36lys8O3qpruHat29+4dat7HpPkf/74v1f5r321G8s/+1z3LCX9GcIrX1yqa/jBP3TnEN/6+TtV/uwj3fphktwul9Vns34sPx53beRy1u3/Hsz79nEy6c5FjNpDY0n2drszrUfKuWWSLBbdvVyU92K81Z9PGQ3lb1iU61ZJtra6sfR8dlBW0J8NHsp5/nTSn7GZTNr3ahVrsd0z3a7FruA4aH1+bxVnttpzsaNyzWi+gvd6VvZVW1v9utOinGPPy/zunX4M++CD3djnzOnuPEKSfPLJX6r8Ks7sT8vvJ46Wazbj8pxQ0p8Vmkz7Gj74Y7fHMZQf2d0vz/UmyaS8F7t3ywXAJJPyLOVk2r8T/fcTXY/5xr/9tPv/SX7wj/9c5X/xZv9N0sGsbKd325FHP7fc3iqfp3IfPUkODrqx+P5+lx9WsJefSXcvJiuY37bjlv5O9trvkNu5RJKMyr6qndclyWjc/Y32bMgqXom2z5+V7UKSjFeyl95ZxVkhAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAf0/DugsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHMN6y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM01rLsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbXsO4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhcw7oLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBzDesuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDNNay7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA217DuAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXMO6CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgcw3rLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/8PenT3JVZ9pAv7yZGbt2nckQGwC05IAN6YNjDtmLibmX56OiTDt6W7aYAEDiMVgJJDYBKoSkkqlqqzMc+aC8G1PBO8JZ07H89y/qa/O8tsPAAAAAAAALK5m3gUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLiaeRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOJq5l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIurmXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyuZt4FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC4mnkXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDiGs27gKqq6qqq6355vJv1UEQTpQddfimbZhrluy7LD4eHonxVVds+iPKj4TCvoQvvZfgsVFVVN4jibbsa5R8/fybKV1XduHE9yo/ar+Ma7t7fi/LbO5Mov3n3fpSvqjpyPHuvzpz5dVxD22bt03A0jvJbmz9E+aqqz999I8rvz/K2ZXU162uee/aluIaq9Si9+7CN8kujX95X/1Xb7kf5wSBrX6sq7fJ76CV6+BtCXZvfy2F4IYbNUlzDdCl7t994909R/sSho1G+qurC+cei/P5+1tdVVX12/S9R/tXXXonydzd/jPJVVR9/dDXKHzl6OK5hvJz1t9Np1j5uHNyI8n1oemghm7Rx6aGGQ+G7/f132Th4MsnmdVVV43D8dub0I3ENX3/7TZQ/cPB4VkAP07qVlZUoP9nL3uuqqpX15Sg/a7PxX1VVG6zXVFVt3/8pyh9YPhHlq6pqHN7LafY3VFU93M3WS9bXD0T57el2lK+qureT/cbScnYfqqoeOX0uyn/zzbUof+7sM1G+qmoyydY6lsb5uGVn+6sov7b6aFzDzwvCv9zxY49H+R9vfxblq6oeOfV0lJ/N8jb61ImTUX6ydzesIB+DNk221jHt0r+hqqZbUfzgajhuqaqTJ09F+d3dh1H+/KNPRPmqqqufZPOy37x0Oa6hm2bPUzfLxm/ra33MLW9G+evXduIaDr90LMoPBtl8pCpvH9P9supjDTLU9bCGOAh/YzDI+uumydflw+lIzfbzyeHTz5yP8re+24zyP97P+qmqqrMnsr5qOMjXcme72c08/1g2F6iq+vyLj7MaHj8f5ZeXsv3fqqq2Dc8D9LBg0nXp3C57nmaz78J/v+rY0ex5Wl7Nr+OPt7I+/+LF1+IaPnjvD1H+/t2sfdtczt+Jly5fivKffp6diaiqGgyyfZpB2F/u7ORnGs6dyeaWj567ENfwwftvR/mtzew+PHY2m0tUVT3+xAtR/q0r/xrX8OyF7EzCp3/+Mq7h1Ons3T5z8vko/2A7nxOle+n5XlfVcJTtDbz26n+N8teufRjlq6qOh2PQUyfytYrDh7JzPn/+c7bWUVWVHoW8fv12lD97Nvv3q6qa4VqUn0zyMw0P97IL+eLlrK96/733o3xV1YXnsrMh9x/m7dv2vWyv6tCBbK/qu618fnt/J1sHPbCRr2kPwsWKPs75pOeTd/eyvarxOF8nGDZpfxuXULNpdi+aQdbnp3P8qqrhMBsz9HGOcbqfn4tIjUfZA5GuQfYjK2LYw/cX6WVIr+NwkP8N6dL+6mp+pmF7O5unt3vZHsmlS9laSVXVtWtfRvk+3qkTx7P5xMPd3biGSRuu+YT7Ez0c865jx7M1n3v3s/FjVVUXnhXfvJOtQa6v5muQ6Zym6eEc46DJGrj9Sd5fd+G+YXoGcW09H8t/fDX7buCV134X1/DmH34f5ds2a9+Wetmryu7lLDwvX1XVhc9Tesa6j2+aBuF8YjTOv2Oe7mfXMb0PffzGMGxk2y4/n9KE86phOJ+pqhqE12F/P9yD7mGSPghnJH3MTdMpSR/XIV1rAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+Ftr5l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIurmXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyuZt4FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC4mnkXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDiauZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLq5l3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsrmbeBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuJp5FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA4mrmXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAi6uZdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK5m3gUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLiaeRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOJq5l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIurmXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyuZt4FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC4RvMu4K9m1f3ibDNo8gKaYRRvB21eQ/vLr0FVVRfmm0EUr6qqnZ29KH9gOI1raGoc/kJ+L2dt9jytjLN7OejhnTiwthblNzdvxzU82Muuw9ffbkX55y8+F+WrqtY3no3yXT2MaxivHIjym3e/jfJf3fwiyldVzWbZ3/DI6ZW4hnOP/l2Un0234xqqC9vIsGmYzbJ38mdZZzMY5J1V/gthf931cB3TccdgFpfQjY5H+Z8e3opr+ODdq1H+wlNPR/nhMB9K/3jnTpSf1H5cw+uv/32Uv/5F1s7f+i5/Fs49eirKHzx0KK5hNMzGf3e2snHL3u4kyldVra5m/eX6Wn4d93azsc94OR8Ht13Wxp46fTrKb97+PspXVZ068UiU78K+rqrqxMmTUf7u9t0of+zI0ShfVVVtOGoY5dfxwX72TiyN8nHwmeNZG/vtdzei/Mpq3tcNw4HwgZXDcQ1bP21G+XSevxrO8auq7tz9KcqfPX0mrmE6yeZEx8Pn+eonH0X5qqpLFy9F+dkkn9GsrhyL8nt7+fx2OF7O8sPsOiwt5e/195vZOPbk0RNxDZUupQ6Wovje/v2wgKrl8cEoP6zsWaqqqibrayY9XIezp89G+fc+/FOUf+Lck1G+qurY4Wwc/NGnH8Y1vPj8K1F+P51WTfNxy3MXfhvlr7zzr3EN7713Jcr/w+u/i/I79/O+LpuhV6Xrfz/Lxm99rCF24aVM70T671dVdeGeXTvIr+PGWjaG/HGU7bE8//ivonxV1Xvvvx/lX/3tb+Iadh+Eaz5LeZ9//ny2Z3fjxvUo//STeX/bhGvSXeV7A8Nh1mHu74X7RM1qlK+qmrXZQHppOVt7q6ram2TrwePxTlzD5RcuR/kP3v9LlB+Ps7WSqqonnngiyh8+uBHXsHUvW8ccjbIxw+5uviZ+8FC25/fJx+/GNdzezMbSzz+b/Q2nT+ZnQ3Z2szb29df/Ma7h399+K8ofPphdx6qqmmXz/H/7479F+X/83WtRvqpq++6DKN92+YykDWc1+/vZ+t3x40eifFXVykq2PzFr8zn2bJataS/3sOz0yiuvR/k3/vnfo/wf3/p9lK+q6trsLOb6Rr5nt3EoW9O+fyd7np68kK3dVVV98NHXUf6ly9n5lqqqc49kf0e6VrGTv9b1/a3vovxklLfRw1H2Tiw1PZx3D9edJuFC6NJSeka7qg3b+dmshweqlzXAX27Y5Gds1payM/ujpodvH8LL2IbfPlRVzdrs72jCM6lND+91vh7cw3nQsISlcPC0v9/D8xg6fCTfQ96b7Eb59Iz0zZvZmKOqajLJ+okm/C6rqmp5KdvH7qOG6TRbQ5yF7dtwnPe3Ow+y+W16lrOqqg0bl0MHs3WGnQf5+ZbRMGvn++gn1lazdfGfHub3ctpmfc1sP3unBiv5JP2nn7K13Ht3foxreO5X2TrkRx9/EuWbWd4+puOOHraQ4/cq/f423cOuqmpn4XVsejhPkH4X1cOcKv6N8IHq49Ou6Sxr3/bDMUdV1TgcO62vr0f5B+GYo6pqFK7ZDHr4MD5tG9oe2ob0u08AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIC/tWbeBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuJp5FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA4mrmXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAi6uZdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK5m3gUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLiaeRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOJq5l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIurmXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyuZt4FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC4mnkXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDiauZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLq5l3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsrmbeBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuJp5FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA4mrmXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAi6uZdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK5B13XzrqFeePHF7p9+/79+cX40GMU1TMP8pH0Q19CE+eFgEOVHaQFVdWfzhyh/4tjxuIamW4/yXc3iGqZt9kyO25+i/P6DL6N8VdX2ziTK37l7P65hWuMof/7pF6P82uqxKF9VVW3Wxq4fPBCX8Obbb0T5u/ez9m0wbqN8VdXT5x+N8o8cvxjXsL+fXYcuvwyxwSDt8/OOog3fiabJaxg2WX/Zhjezj7HXaJy1j+PxUlzDR3/5JMrvPUxHX1Wnjmft9MZ6Nmb48JOPo3xV1dPPPhXlDx/ciGu4cf2jKN8MV6L8uXNPRPmqqnt3szHoaJS/E+Pxcvwbidu3b8W/cfTooSg/Gmb5qqpmsB/l7z24E9cwXj4S5QcVtvOzvH28s5WNW86ePhXXMGuyv2N7N5tPtJN88HV4LXum23E+t/x+K3u3j64fjWsYt9m4Y6+y9/rOzr0oX1X1yLGz2Q9MsvFjVdW024vyD/a2o/wgHAP//BtZvunyGlbD/nYalnD3QXYfqqqaLmsfjxw8F9fQzbILMRjkaz5dO8xqCNeM2nE2hq2q+ubHL6L8ycP5Ouh6sxrlp8PsPtx58HWUr6raWDoR5VfDa1BVNRhmfdWsfRjX0HYHsxq6u1H+/av5/Pby8y9E+a9u5s/T2nq2pn3u9KUo34brh1VVg0H2PPXR57/5p7ej/PqR7GZrwbYAACAASURBVHn+9Qv/LcpXVc12srlh1+VrkF0b/kZ+K6vCfcP0eQr/+aqqanu5EJlhOL/dWMveiX/+l99H+aqqlbVsr6nr8r7u15eejfI7D3vYZBlkY8Ctrayvmuzl1/HcuWei/PaDzbiG/Un2ThzaeDzKD4b52ZDJNBv/jcdZvqrq4e5ult/5Ma7hxNFsbf7WretR/ttv8+fx2JHDUf7vfvVcXMP/fvMPUX4SLlasLGfz46qqvd2dKD9NF1yq6qkns/MAp05mz3M3y9buqqq6JmufZuE+elXVylo2Bt26k+23VVV9dSNb0376yQtR/sOr70X5qqqLF7PzJesb+Z7h1ubNKH9gI2sfV5bydavbm9nYaXPzu7iG8+dfjvIPd76Ja1jfOB3lb4fX4f69bK2kqmo8Tsdf+X5ZG85JHn/819m/P8vHf6NuK8p/+O6VuIZLL2bXYbSaPc9ff5WtOVVV3fo22zdcWsv3Bobh+Gt/P3+e9qfZexUfXevh7Ft6BLCXdadw/NW22X04spE/jyvD7LxT28O9nIW/0ce9jBdTw8vQ9TCWT3+hj+u4N8nGDasr2Z5d2+VjhmH4MUzXw0HvjY3sOty7l51J6Ho4l7EUnsuYTfPrOBxlY9C9Sd7fpufVB+FefB/rBGkNcYddVbdu3Y7ya+H4bbgA3x30Mf6b7WdrV8s9fDeQXsr0e8fdSb5+t7q+ltUQrqNWVf3m77N52Zdf3YjyP/yQ7y0MwrHXoIdvktJvYWazbNyRzgWqqro26y+bYX4d076uj/lE+hODsG2ZzfJxSxeO5nvo8qsJr8PqatY+9jGOnoTjtz7ey3SdoJ9xRzZ+e/m1//5O13XZwjgAAMB/Ai+//HJ35Up+zgIAAAAAAAAAAAAAAAAAAADgP7OXX365rly5Mv//WSQAAMAC8N+xAwAAAAAAAAAAAAAAAAAAAPh/+4/+O3bN37oYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP7/0cy7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWVzPvAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXM28CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgcTXzLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAxdXMuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFlcz7wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWFzNvAsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHE18y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMXVzLsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABZXM+8CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhczbwLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBxNfMuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDF1cy7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWVzPvAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXKN5F1BVVYOmarDxi+N7+3fiEtpuO8ovL52IaxgOB1F+3GT56Ww3yldVnThxMvuBbi2uoe2y52E4PBLXsDrcifI/fP95lN99OInyVVX7szbKrx/65e/0Xz3x1H+J8rt7XZQfLQ2j/M+/sRTl37ryRlzD3sPsOjz26NEof+r001G+qqoZHIrysy5v3waD7Dpm6b/WkLXzg0H2THdd/lc08d8Ql1Bdl7VvzSh7r2ezvI2eDZoo//Zbf4xrOHI4ey/PnAzHDFXVtrMo/8Fnn0b5V175dZSvqprtZGPQ77/+LK7h2NHzUX51bTXKTyfTKF9VtbZ6Nsrv7Hwd11Bd1kAtL2Xj4KNHj0f5qqqtzR+i/OlTB+MaYl32PFZVbW/fjfLHj5zJCgjndVVVhw5l85Ht3QdxDcsr2b1YWzoQ5e9N7kf5qqqHlbVPw2zIUVVVxw9l7/aD+1k/U1U1WF2P8qPROMov7y9H+aqqrTubUf7owWxOVFXVtNkYcm0puw/3dn6K8lVVqweyGoY9TIpm7X6UXwr72xMH8/W/b2/djPK761kbX1U1HqxE+aUm72/bsLvrwln2oLK5RFXVY2cei/JXr34Y1/Dii5ej/Ox+dh0Pr4Xjnqp6uPd99gNNXsNgP1svWR5l7WNV1aDL+qqVcbamffnyS1G+quqrL7+M8seOHotruHbzepQ/cTKbEy330T522dhp2EP79sIL2Xrup59tRfnvv8/bx1NHn4ry7Sxbe6uqGlS2BtjHenL6G10b9rdNH9cxrKGHBeXZNKvhwU62P/EPr74a5auq3nvn/0T5jY18TvTFje+i/COnH4lraCd7Uf7IwWx+eu36vShfVfX1N99G+f02n09srGbzifE4uw9703yPZXklG//duHEtruHw4cNR/ujR5+IaJpPseTr3WFbDT/ffifJVVZt3fozyf/ki7ydeffV/RPk//Mv/jPLTWb7HcurUqSi/uZWf2Ro0WX87HmVrRtNwLbiqqgvHHW24z1RVtb2dzQfW17Nnoarq0sVsfvrx1Y+zArp8DHrzxkdR/ty5fOx05PDjUX7WZv31Vzc/ifJVVXt72SbJ1lY+v714Mdu77Np8j+XDD69G+b1wDPu711+J8lVVn3+ejX3WN7JxT1XVtes3ovwzF7Kx/MPd7D5UVU32s3fiwvPPxDVceeeDKH/5UtbfPv7oxShfVXXr1ptRflAP4xqWh9nz1M7yVZ+98OzZUnimdTrtYSO8srFPugddVTWdZNcxPU86C8+9VVXN4nF0fkZ6GJ7F7OFIas3Cdcy0hKaHddDwlehlHXQUPg+zcH46HOXXcbKX9dkrK1n7WFU1nWbX4dixbL9s83a2R1NV1bbZez1IH+iqamdhGxm2TVX5OzEOv0OZTPN+YnklG7esbWTn96qqtsJ1o/S97qONTs+qj3qoYWU5m+d3PawhtuF+WfpOjYb5569NeDZ3aSk/x/jHt/8U5X/7+mtR/k54jrKqelh/y8eg6XuZjgCHw/y9bsKxT9dDf5v+RFM9jIPDwfhuOK9bDufHVVWz8PvbXiZF4U9M9rPr2Ecbnbax02m2blVVNQvH8n2ckelhqwgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOBvqpl3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsrmbeBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuJp5FwAAAAAAAAAAAAAAAAAAAAAAAAAAAMD/ZedOm+MqzzQAP326Wy2ptVjGSzCLDQk7ZsckGSqZSjJVM392fsDUZKqyQzAECAQIScxmvGMkYUvqdT4w8we4u3L6w3V9v1tPnz7nXZ7z2gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq2m7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWV9N2AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr6btAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXk3bBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvJq2CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgeTVtFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8mraLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dW0XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tpuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAllfTdgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK+m7QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF5N2wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLx6bRdQVVXzSc3mN79zvOnmX2PQnI7yTc3iGuaTLD+ZZ/mmu5p9QFXNZuMsP9+La5jOsgux1rkS17C/+3WW/yb7++PZQfYBVXXmzFNRfnPz4biG0fhOlF9fOx7lP7vyQZSvqrp27asov7d/N67h3NnvRfkzZx6N8rNxN8p/6yhKT2d5DZ3KPqPbXcA8Me9E+U41Wb4TTjQL+IzwEnz7GbP0t8iKuHuYj9F/fv/tKP/w2QfiGjY3NqL8Z19cjmtYX8uey5++8FyU//zq51G+qurW/ndfA1dVPfTg03ENvflKlB8dZuu/TncQ5auqmk64Zlg9FtcwmYRjSzhX9bvZ71hVtbW5HeW/+WY/rmFjPduTDNdPxDX0p9lzOTocRfluuOaoqhqsZtfhaHI7rqHma1G8O+9H+e1jO1G+qurSl59G+dM798Q1rHay+2Gwmu/z74yzPUl3mv2We1/nY0u6hNza3IxrmE2y32LQy/K9bj62HBweRvnhIJ/zp9Nw3RGO0f0FtFJPnzwT5T/67OO4hscffiL7gFH2XFdVzSr7LaedrJHan2f746qqzih7ru69L7sXqqre//tfovz5+5+N8kej7Hesqur2sjXo7bvX4xqOD7PfYjzK+lZVVf3+elbDUTZGr63m+4nhRrb+a5q86XP/mfuj/J/+9FGU/+kPs556VdXB3WxvOQl76lVV6+vZdRysZz3xzz/Jn+tjGyejfKeyvldVVb9ptwdZVYtppkZ/fwH95Jbz335GtgZMe0bz2TTKV1Wde/hslL95Pe8TfH4567dsDLN5pqpqs5+tAXv97H3b449m7y2rqn772mtRfriVj29nH8jmiYODW1G+u5KtH6uqPvnsb1F+cyPvE6ytZeu/2TQ8XFJV02k2Sl699vco3x8Mo3xV1Z3r2bpjfz9bR1dVXb+RXYdzD2XnKr68fDXKV1Xt7mYHVBbRd/rk0qWshiZbd2yE7z2rqpomm6tmlfdbeuG7ov4CzjS89+f3onw37BldePGhKF9VdeVqNrZ8/NfduIamyc4DnDyVvSc6dSo/8zWZZL3Yr29/GNdw69YXUf7dd96PaxisZn3xn//s36L8r3/131G+qmoyzubLTpPPVSdOZHuaGzezsWlr+7EoX1U1nYbvDfv5Ovj557M90ZuvvxvlX7jwfJSvqnr5lVej/Bt//GVcQ6/J3p0O+gs4x7iejS37+1kPsdvL+8mTcfjOL287VRN+yHA9W/8toHVWs7D51e3l92PaBp1M8wsxCy9m08nGx0X8ltNp1gOcLqCH2DTh+eLwPc90Ab2O7e2sZ9NZQEN5bz/bD0zDfvJgJT+XkR+xzi/kJL4f8v3tSjhnr65m7xYOvs7f+R0dZgPUYfgOuqpqI5wvx+Nsbzke52NLp8J/n7aWv9+o8JnoLeDfXM4m4fotnPMXcJygRkfZ/bQ+zPr6VVUr/ey3eP+drGf02KN5z+ftt7N+yXCYn+2dhGNDum6ZL2ABOJ1nc1XTLGAtH37GLPz3u1VV6XZgdZCdq51O8zVDJ9xP9BYwvqVr+TS/gC1RzcJFaGcBp0O64Xw5nuTrjskCPgMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOCfqWm7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWV9N2AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr6btAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXk3bBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvJq2CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgeTVtFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8mraLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dW0XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tpuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAllfTdgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK+m7QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF5N2wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLyatgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHk1bRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPJq2i4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOXVtF0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMur13YBVVWdTlOD3tp3zve6K3ENs2kT5efTeVzDvCZZvjOL8p1Ofjv0uv0of/XarbiG0fggyn9140pcw/HNY1G+6R9G+UfO/SLKV1WtrGS/5WyW3c9VVf3B8Sh/6dN3o/yN66MoX1U1nR5F+fPnn41r2BjuRPnpOPv73SYfH6fz8DPm07iG+TwbY+eVX4cKr0Mn/POzWX4du71srhkv4DKuDLej/D8uZWPL7u3woaqqpx9/JMqvrAziGt55/89R/vEnfxDXsL5+Osp/8Ml7Ub7fz9dO3z/7aJTvxE92Vc3SNWT2YM4XsGaYN93wE7K9wLcfkX2PWbgX6HeytVtV1XDtnih/9yhfy4+z27G6C9jh9mozyo+nt6N8t38iyldVVScb5we9bB1eVXVwdCPKb2zdlxUwyufb+05+L8rfuJbvLb936mSUn8/yeWIyyR7M23vZ2DAbL2AtH85VX+19Fddwcidbt6Qbs+H6/dnfr6q9O59G+W4411VVdcIe4J27d6P8cDNfR1cn+w4/OPtYXMLly9lv+eAD+Vq+xtnaZXTnTpSf9fJ5or+yEeWPb2X9mqqq+SR7rq7uXYvy22vpOryqG/a0Nwb5u4FO7UX5+QLW4tPKruW8ye7pyTzrqVdVPfhANtf86d134hq+/2A2Pt137wNR/vdvfRjlq6peei7rB08OFnA/Hl2O8i+cfyHKv/7H16J8VdV7f/kgyr/6L/8a1zC6m70bGIdjfFXVPO2rd8L9RJqvRfS0w0ZDVVUn6xs1TZafLaD/d/JEtse+cuVSXMNTjzwZ5T/4KOvlVlX98EI2xvZ72TN1eDd/ri+8kn2Hixezvn5V1e7uzSi/NdyK8jdvZWvYqqqT92T9t/X1rH9YVXV4mK3fms71uIbhRnam4fMvs/7fqVP5nui+e38c5S/+8bdxDaNZdqbg5RdezP7+Qb6Wv34j7O138vFtsJaNDTdu7kf5nZ38fkyP4DWd735u7v+Nx1lP+je/yefbM2eyMfbhh7I1w+ECnontzWGUv3496zNUVa2vZ+/sPvkkmy83d85E+aqqnWPZvbC1nT+Xb1zMeg3nn8r7oJ9/9lmU/+V//WeU71TeO/vZL/4jyo/HWV++quqNN38f5VdWsp7PP/7xuyhfVfWTV1+J8nt7+Xw7G2X9u2deWI/yF9/8Q5SvqvrRD7P13ysv5+dq33r7V1H+xLFsjK+qGu1m+4mNYdaPnlXebzmYZu+Apwvo+UzDd5ejSdaL3drK1hxVVeNR1oNcxHnQTnjmalZ5DbPwbG83PHfWbRbQB41bsXkN8RnnMN508/eO/ZVs7bO+nu/LjsbZc5l3xXNpT3sSjvFV+TPRX8Ahwt3d3Sh/cJjdj73eAt75hfNlr5/XMBp9E+az3ttwmM+36XU8DL9DVVU/nSfiCqoG4Tg9Ds/5DLbyvnwTni8ZL+BM6mb8PbIx9uAwvx+fePyJKP/hhx/HNQxWszN883g/sYB/1BRaxPpvOk3/DUn+7y9WV/PeVWIR5zKmk3Dts4DbKd0T5fdCfj824f3UCdewVfn36C7gx0z/7SoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMA/W9N2AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr6btAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXk3bBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvJq2CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgeTVtFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8mraLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dW0XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tpuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAllfTdgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK+m7QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF5N2wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLyatgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHk1bRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPJq2i4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOXVtF0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMur13YBVVU1r5qPv3v86GgSl9B0Olm+aeIa5jWL8tM6ivKd2TzKV1U18+w67OxsxzV8eeV2lG+6+W/ZHWT5sw+9GuUP52+f5AAAIABJREFUj7J7qaqqmWXPxEp/Na7hD3/4nyg/m3ej/HCYPxMvPv3jKH80CgbH/zOfZffDbJaNsbNpFK+qqk6T3Y8Vxquq5vPsfkjzVflc1anwO0wXMN+GY+xgLRxgq+r3b/wuym+vb0b5h889EOWrqsaT7MF696/vxTW8eOG5KD8f5ffT5UtvR/l7T5yO8r0FzHU1yZ6J9LmuqppOR63WkK6Bq6rm85XsA5p+XEPThL9FJ1vLz6b5ZNeZZ9vDlZUzcQ0Hoy+j/OoC1vLNPLsfVgYnovy0DqJ8VVVnms2XvXAdXVU1ngyj/OfXL0X5s8fy+bbpZM/EqRPZvVBVdTC6G+Vv3vw6rqETjpFNuBhfXcD6785hdh1vfX0rrmHQz77HsWHWL+lM8rHlxHa2dtrbvRLXsLZ6LMqvrGf34+Vbl6N8VdWZk49G+UEnX7cMN7K105WvrsU17AzvjfKb4b7scLwb5auqRuNsHb0yy+fbExsno/zFv30Q5Z9/7KEoX1XVzLPxcbWTzxOz6Y3sAzr5bzmrcH/ZZD3E69fz8W1zM7sfzz/9RFzDmxezfsczT52P8vt38/n2408/jvKP3v9kXMNsel+UP9q9HuXv2VmP8lVVt3ezPfYbF1+La3jp2R9F+ck0v5/m86z/1oR9+c4i3p2G7zcq7KkvQvod4p5TVd3Zz/aGTz35SlzDa6/9Oso//8yLcQ1vvfN+lD/74PEov7N1KspXVX35xWdZDce24hquXc3WDdvfz9byp0/tRPmqqqOj7B3L6Cgfo2fh2YxON38/cfdgP8qfe/BclJ9Ns79fVdWEBzMeXsCe5ou/fxHl333rzSh/7pFHonxV1ZfXsvVbdwFz/myePZff3Mn+/u7XeR/12PGsf7e/l70fqar668fZZ6wN8j32cD0bn9K3hoOVjfATqi5fyebbZ5/O30+89fbfovwjj2R7wy8+zca2qqqPDrLvMFzN57qf/fzfo/w3e5/ENWxsZGPDQXKotqpW17L3dVVVu19djfKdbr5+e/65n0T5m199FOWHd/Kx5de/yc4qPfFkvicapON8k737fPmll7K/X1UXX78Y5S/8KDvLWVX11Pnno/xsshfXMD7K3l0ehGdSV4f5MxGfpczbJTUN92WzCs98dfJ19PZW1kudjvMLOR9n/bdebwFn9rvZu8/JJHsmRqPsnWFVfq62283fVU3Dw95pr2OygPPyhweHUf7U6bx/N51m13F//5soPxnnh/ZXVsKzc738TMPhKDxLOc/PpK6uhWNseC8cHeXPRBOODfsH+bpldJQ9l71+dj8dhn+/qmplkO1PD0YLeOcXvrMbLWCMXRtmz8QzFy5E+Yuvvx7lq6o2T94T5dO5rqrq4DC7J3d2srNzvX543r6qtjezd03bm/l+Ir2O6dppAbfCAvY0+XvwWfjvw+ZhX7+qqtfLzmmnc11vEe83KrwOCzjSMA3PJKR79PR3+PZDwvMpC9hj5/8/QL4G7SzgMwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP6ZmrYLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB5NW0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDyatouAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDl1bRdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq2m7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWV9N2AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr6btAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXk3bBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvJq2CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgeTVtFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8mraLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dW0XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tpuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAllfTdgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK+m7QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF5N2wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/8vOfW3JdZ7pAf72rtToRs6JUaAADpg5HCqPxmvZF8EL5E3Ya6yRLAqkmTmMkEiARGBCJDpUV/IBLfuc756pOnie87f6qx3+XA0AAAAAAAAAAAAAAAAAAAAAAACrq7/sAn40r1rs/OR0r7ceV7BI8808rqGpNsoPahT+/fxxaJrsM3rtwbiG0Si7jo8+/WJcw7CffY/pNLuXGxvZNaiqerB5P8p/+NHbcQ1b27tR/uFHDkX5Rx56PspXVe3szKL8bJa2TlX9XpZvmibKLxb5d4g/oYMaVsEs/B7TRdZXjfbuifJVVXc3t6P8B+/kbcsTj5+L8r1e1sZev3kzyldV9QZZ+/jPL/8iruHqt99G+Zu3bsU1PHbqdPYB83D81oYNbFU1i+x56qR1y5r5+AO6GYNmV2KxmOQ1pBdyPsjiXTyPTTqG7GLcshHl57NxXEMbjn1m07UoP5/n93LWux3l2+HJuIZ97YEo3+xmbfT98Q9RvqpqfZSNffr97L2uqtrcehDl57NpXMOgDfuqcAw676Czm0+zeVkX04n0Xo5G2fM06uVj+ekkuxDrG4fjGsa72XyiN8jWWw7vPRLlq6pm02wcvNvk93J9z8NRvjfOx/LzyZ0o34z2RvnRIF+DnM2yMeTuLHueq6rG060o//RTT0b5ZtzB9kKTtdHVz8fy4+2sr9rc/iau4fjRbPy1mGb3YtDPxrBVVbs7WV83GOZt7HPPX4zy//7Bh1H+0Ycfi/JVVddvfh3lb21lc4GqqkMb2Vi+rf1RfmNP9ixVVZ049VCU/+zjL+Iarn/zeZQ/ezrrr6uqdraysfzuNFuDjJecquLBeBc1pHOa1Hya//15uA66s5mNOaqq/uW3/xLl/+ef/hjXcPhw1tfc/PZelH9w/6efh/i7o0ez9u3A/nxedvXq5Sh/8+tsj+TkyVNRvqqqFuE6wTzfi18bpuOvYVzDzk76TGZtQ9vL5nVVVfPJV1H+4bMX4hq+u3Ejyt9+kK1pP/jwkyhfVfX73/0myv/xT3+Oa2jbbO1rGu7z/O1Kdh+rqo6E7fzVL/M95MEgGzu98MLP4ho2NrK+anPzWpT//rt8PnH6ocej/GyR97e//y+PRvl//cNrUf6RR7K/X1V1Mtwj+TocM1RVvffepSg/GuR7dlub2Trow4+cifKXL/81yldVndnNxl979+2La9jcyvrLjY2sfbtwId9vu/T661H+m5tZ+1hVtW9/Njc8dep8lJ9s53vQF57K9oDfff/duIYXn/91lJ/l04na3s3WpMMjEbVvI9tvq6ra3sru5XZ4LvdH2W8Pjh7L1uX3beS/fZhPs5vZxRmb6SJbQ5x3cEZ6nh4qCOO9Xj5mSK/CbJa/E7P0LGVobS3fB98ZZ8/jnTt34xoGg2wcvL2dzS3Tv19VNZmk73X+LI2G2drXzjhv39K2ZbFIdyg6+P1F+B262GMZ9LP+sh+2sW0vP9MwDp+nvXvy9q0XPg/9tfw8wBfXsnn6ndvZPvZueIaxqmoU9nWzDt7LnXG2jjkNx07bO/kZm1u3r0b5n114Iq7h44+ydfG0r+p10LbMwjOtXbTS6feYdnA+ebKbPZOjtQ4m2aGNcG63s9PBvCy9F+FCQbrOUFU1C79D28G8rMJhbBe/7Wp7nZy0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+E/TLrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFZXu+wCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhd7bILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1tcsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1S67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWV7vsAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXe2yCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgdbXLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA1dUuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVle77AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF3tsgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHW1yy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNXVLrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFZXu+wCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhd7bILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB19ZddwN+17SLI5n9/nuZ/evn/T6/Jbkevmig/r1mUr6qaLcZRvu1txzWcPvl0lG8W+Wsxnwyi/P4Doyj/8advRvmqqtHwcJS/c/deXMPzL2b3ct/66Sg/m+bP43yWtS69Nnuvq6qa8CPa8APmaQEd6KCJDlvYqqaD69D2s/apHWT5q9evRPmqqps3vovy5x7/WVxDr5cNHD6/+kWUP3f+8ShfVbV377Eof+XmV3ENO5tbUf6ZRx+Na5jNdqP8eDdr53vVi/JVVW2bfcZiPo1rSFvJpsm+Qxvmf5SNYxeLLq5j9j2aJhv/LeKeqmqRzqsWeY876O2L8pPJ13EN1cvG8v3wve73hlG+qurag+xebA+y/rqq6vja8Sh/YM+hKH/z3rUoX1XV74VjryZ/Jw4fyOZlO1s7cQ2zsK+ZhSsui3nevs1n2b1YpItGVXX71q0ovzvN7uWZ42ejfFVVP1wvmVXevs3bzSifrp3t6a9H+aqq7d2bUb5Z24hr6DfZ2Gk4OhDXsDP+PvuAZn8U3618Qfn2ztUov3eQ9XVVVQfXTkX5ZjebU1Xl4+jJPFtPTtvHqqpmcDDKj9o9cQ03v74R5c8ez9ZLDh04EeWrqhbhvZxM78Y1zGZZXzUJN3ru3r8f5auqTp/MxtGfXP5rXMMvX3opys/GWZ9/5FDePg4H2dzywIF8n+jatWxOcuhg1jZVVfXmWfuU7m+0HaxVdLBFEotLCNdLmg6uY7+frXV0sORTW5uTKP/MC8/HNVz+9HKUH/aysfix43ujfFVVLx0Hb+cT3IfPXojyn356Kcpvbf4Q5auqNtaz9vGHzWxuWlU1mWRj8Y2NfG44Gq5F+eksG781vXyOPdnN3qs7338Z1/D0s7+M8q+//lqUX3SwE3739p0o/9KLL8Y1/O8334nyg37WX04nHazlHsmex/378/W7I0cfjfKzWT6/vX374yj/zc1sHfXxc1k/VVW1aLJ1+V4/XW+p+sO/vRHlz5x5OMpfuZ7vsRwL5zT792fzuqqq8U52pmE0yNY6qqouPPlylJ/Ms/567Ua25lRV9d4HH0T5F1/I5/mDQTYOriZcgxznZxp+99tfR/l338vahaqqwSA7S/naX/4tyr/8cnYNqqo2Dj0W5S+M8nnZlc/fivLHTmTr+lVVFy48GeU/+jD7DpOwfa2qOvdYtib9YCvvb2eLbAx56kz2PPba7JxQVdUn//5eVkMHa29tuHA0m3Xw24XwM3rh2ZB+eK63qmoyDc9lhGu5VVVNuBjbC3/QszvJ1g+rqtrwO3z1ZT4O3hOuO/V62bhjPM7bx1543j393UFV1Xic7QH3B/n5lMkk3AsPDxs1HZxpmM/TGnLDfni+OGxj07apqqodZX12ek68qmoStpH98DtUVa3vy+Zlj118Icp/+fn7Ub6qamcavhMdtG9N2DZcv5Gdke6Fe4ZVVbu72Xxge5z/Tu+5F56L8pf+ks2x19fy6xj/krmD/dv0jHQX70Q6lt8K9+yOHDkS5auqtreyZ7rp4GbOZtm4ZRCOndJxeFXV7m46H+igjQ5/a9jFvexkAAYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPCfqF12AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsrnbZBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwutplFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA6mqXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6tddgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK522QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLraZRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOpql10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKurXXYBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyudtkFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC62mUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDqapddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACrq112AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsrnbZBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwutplFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA6uovu4D/b/aTk/PFOP7rvd6eKL+YNXEN85pn+cVWlG/Cv19VNZtNo/x8cTCuYc+e9SjfX8vvZTU//XmuqvrLG/8a5e/f343yVVV7930T5V/+p+fiGnrt0Sg/GW9G+cUiu48/fkYb5eeLuISq8DPSErr4Cs0i+5S2yd/rpteL8vPwO/xYQ5Z/5/23ovz6YH9WQFVdOHcuyo/HO3ENf/v8iyj/0i//McqPd/O25dtvPovyezdOxTVsDPdG+eluNmaoqmp7oyi/NszGf9Pp7ShfVdW0B6L8orJ+5scissalabL2Lc13YbHoYPwX9niLeCyeX8fFIpseLhaTuIZaZNeh3z8RlzCb3ovy09F2lB8ssratqmqxk7Wxn36c9TNVVSd/dSzKp/3E0QPZXKKq6v7tu1H+0KGsja+q2h5nz9PG3o28hu1wrWGW9VXjnXz8NxgNshrGefu2vZXdy7U9Wdtw74esbauqOrgvW7PpYk6Ujt+2d7L70O/lz0K7dijK39m6FtdwcONMlF/r53Oa0eh4lP/im79G+eNH8jXIw+F17GAkX9Vm/eVkkc0Fdme3onxV1d072frdsSOn4xqaJmtj+8Hext/NRln7dnf7TpRfH2Zr6lVV7TydY38b1/Dx5ZtR/qmnno3yt+/k78T6WnYvTh09Gdfw9jt/jvL/+Nzvo/xsN38et7Z+iPLnHn85ruHSG/89yr/1VraWW1X1q3/+bZQf3B1G+UUnaz7ZOsHyV3yqqoP9iVT6HboYy0+nWX/Z9vJjDUdPZGPQnfvZuOWdDy5H+aqqX7yUrX3NJ/ke8vZ2NgY9cybbJ/r666tRvqpqdDobtzQdtC7zWfZO7O7m8/x+fy38hGy9pSpf8xkOs/W3+TQ7E1FVNR5nfdWTF89H+XffejvKV1V9dT0bRz9x7rG4hhPHj0T523eytdzRnvy9vnsvW3c6fTqf306nWV91/foncQ3pCOzixRej/HTewXxi80aUf/fNbN2qquqxx34e5b/6KusvBx2cKE3PId69k7fRo7Vsj2RrN78QvX427tgKx6DPPpPNC6vysfzrr/+PuIZnns3OIa6vZ+vy6T56VdWDB9l1fPqpX8U13Lv3ZZT/4X62rv72m/lax7knsv7y4N587exY+BEffZzPDZ+6eDHKn7+QtQ2bWx9H+aqqfYez+e2+w9nY60fpODbrq7784vPw7+dn9qvNd6viM85NXkPby8ag6VeYTvNzkIv0jHSbz2kGw2w9eBjmN7ceRPmqqvE4/01RahaOnapd8qH/qnhNu23Dw+5VtTvJ3qvZIl8Hnc2yizmfh/sbHbzXaQ1p21SV79Ok66hNB3s0aTvfNPnv9PqDbC12czM7/1dVtbaetfPXvvgwyvfXsvl1VdX2JDv31evgvez3szZyOs2+w7yDH6gNB9mzsL2Z7w1c/fKrKH/+fLYu/9mn+Rnr0TDbo5mH5+2rqmbhO9FFX5XuAS8q+w6DYbrXVbUTjkGbeQdj+fC9THvsDoYM1Qt/szmb5+f3mnSO3MF72c2AHgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGD5Xn311WWXsBJeeeWVZZcAAAAAAAAAAP/h2mUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDqapddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACrq112AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsrnbZBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwutplFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA6mqXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6tddgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK522QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLraZRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOpql10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABHfGLXAAAgAElEQVQAAAAAAAAAAAAAAAAAAAAAAKurXXYBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyudtkFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC62mUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDqapddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACrq112AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsrnbZBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuvrLLqCqqmkW1TSLn5yfzXbjGoaD9Sg/n/XiGub1069BVdW0NqP8oN0X5auqBs3hKD9am8c1VDOM4vMmu45VVW+++ZcoP96ZRflTZw9F+aqqRx/+hyjfzgdxDfPpdvgBWQ2LRZP9/R+LCGvooIL0M8J80+TXsQkvRBedXdPPPmVnOo1reP3SG1H+0bMPRfmNPWtRvqrq9p07UX4y34prWBtlbcMnH74X5W/fuR/lq6ou/sMLUX7Yy8cti/C9bKuDGrLusqraLN0cTAuo6fSHKN80e+IammYj/IRJ+PfjGxk/jx10VR302el3yMfR+XfI3qmqqqYJ38saxzUMhvuj/I0fvo7yp9dPR/mqqrPHT0X50TC/l9/d+ibKH9yfzS2H4bywqmrvRjZH3hnnz2N/EI5kd/P1ksEgu5ZbW/ei/GiUj0GHa6Mof+9e1l9XVfV6e6N8U1lnNdqTXYOqqq9vfxvlTx47HtdQ8+w6tG3Wvv2wlT8LB/dl/cyRtZNxDQ/uX4/yowOPxDXMJtm1PLQ3u47DyvqZqqqahms+wXr4300WWQ2T3ey9Xhvka5BnTmT3cjzO1wl6vaxt6Xewhnj8ePZu/+2rz6P84FC+lru2yOano7VsDFtVdf5iWMMwuw4Pncjb6LfeezfKP/3kxbiG6SQbQ/716gdR/vGHnovyVVXtJGsfd3fyPv/lF38X5f/4+h/iGv7X63+K8r979r9F+Z1xuMdTVYt0vSTd4KjqZuEokK57dfEZ6XpNVVU4bKkOhk519sTDUf7Sl69F+UceOhflq6reef/tKP9Pz+Vt7M52tp67NjwS5U8ez9dbPv7osyj/xM/ze7m2lq23zBb5dWia7IxMv5+eL+liTTvbcxsOj8Y1TBd3o/zevcei/BPnfx7lq6puXP8+yl+5ciWu4cIT56P8G2+9GeW3trO9rqqqps3WQb9990Zcw2SSdZjnn3giruHI4bNRvmmycxUffZidqaiqGgwPRPmjR/J10Gs3rkT5Xjh4OnMyO1tSVfXNzctR/udP5jV8fiXrJ86ceSyu4dKlP0f5X/3iN1H+wWYXZzGzud2hw2fiEt7/4J0o/5tf/dcon85nfpSdkRnv5EWMhtn624svZPvYf37tUpSvqrp3J+uzb1zL5lRVVed+9kz2AU22lltVdfmzD6P8+Sd/HeXX1rOxW1XV3bvZXtV8lp+Xms/eivLbW9l7/f332VyiKl/T7uR88ixrn+bxAeeq2Sxbq+ilZ5W6OCPdhvvgXZwHDddSJ5NwXtXBdVzfk611zGb5Oe/0eUzHHV08j7PwvZ5O8/Ogu+Hz1Ovle5/pec60je338l8/LJb9I5LKf0cyD9+p6qB9TN+qLn5LM51k7VPbz9+JxTxrG9Lze1sdnMVswnNjFfbX//dDwnz4ToX3sapqNs3ahj2j/Bzj99/divInjp2I8idP52sd1766FuXTuUBV1TA8GzzvYsEk7KvS73Dr+2x/pCq/Dul3qKoahL93nIbjvy70wz67i/8vsJiHY/kO3okuzocAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArIJXXnkl/oxXX321g0oAAAAAAAAAgP9o7bILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1tcsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1S67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWV7vsAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXe2yCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgdbXLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA1dUuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVle77AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF3tsgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+D/v20W1HlaYJ+DtxzDW6VxYZEBIIBEJJ4pWYzKrsQc37B/AD+Q096LWqCwpvlXhIKAECJKGUQbruuOgB1dMe8Maqc1at55m/cb8bZu8dX+wDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMurWXQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyvZtEFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC8mkUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDyahZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq1l0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr2bRBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvAaLLqCqqm371bb7fne+6d+Ma5hMb0X5toNTOQtrGA0fjvJNbxblq6qGg2mUX1ndH9fwzruvZQdo2riG2WwS5R9/PLuWG/sejPJVVdNJdj80bXYOqqrm8+xaDPrZ3+/Ns/x/HqWLg4QVZDXM2+xEdHIG+tnFbAf5GH3txo0o/+0338Q1PHz6gSh/YHMzyn/6xSdRvqrqkXNnovzRo3+Ia/j6i3ei/N5udj8dPpQ/FRv7VqN8+FhXVdVs3mQ1tB2MDr1snmgrm6vaNl87Nc1KVkPlFzM9D9Vm67+2zcfoNl++5cK1dK+XncfZLBvjq6r6g90oP+9gbEmv5TRcP1ZVzebZtTiwnr3T7OxtR/mqqpW1UZQ/cuBYXMPeOLuf9sbZeRgN16N8VdVoMIzy2+P8nejHn36K8r0Optu1UTZXra9n+arsOlRV7exk9+PmwXyM3b67FeWHw+w8tB1MlqujbGz5/ofv4xr2rf/+/mFVVRM+FGur2TmoqprPsnX0cJC9C1RVjTayueqb6/n77f3HTkX5zbVDUb6d5APkoMnWDDvtr3EN43Yc5ff2sjXs+koH7yPz7Llqetm4UFW1tXUlym/svzeuYXc7u59OHb8/yl++fDnKV1U9EPatJnv5c7lvdDDKTydZ/683OBzlq6qefOpClP/bR+/FNZw/dy7Kf/LV51H+0IHvonxV1cHV7J1mtJo9k1VV00k2Rj/77JNxDZ9+9m2U/+bnj6L8A8cei/JVVW1la5/pJH/HTlfSvXANugxtr06qCD+6zTtoPO1uZe9lL730QpR/6803o3xV1cGNbK774UrWZ6iquufgkSjf72fj4+Zmdg6qqvatZb2Kq1d+jms4ceJ4lO8Ps3fLqqq2l42RbWU19Hrhx/zfiohMJvleo9FKNlfdvZPdTydOZGu3qqrtrez99Or1bHytquo1X0X5Z557Osq/+uobUb6qahLusen38z5oG+5VOnTwQFzDzu7dKP/u+3+L8qcfOBvlq6p+/DF7R97buxPXcOhQ9k7TNNn9eOP636N8VdWzz/01ys8q78Weeyyb6y5ezN6JqqouPPdSlH/t9X+N8o+eOx/lq6q++iK7H+49kffO9nazfvDFi9k4f/78M1G+qmowyPqYs2neq5iH38Hv3sney1544c9Rvqrqu+8+jfKDQXYvVVV98OEHUf6hM1kvt6rq2NHTUf4/Lr0f5R96+PkoX1W1vX1flN/a+iGu4e6dbO20u/VLlD99OruOVVW3b9+O8rdu5r2zQT/rfaW9s6qqpsneLwfh/uQ0X1U1Czd0drEfYB4eow1f0rvZbR/2YjvYdzYN5+x0z/8g3FtSVXG/pe3gag7CPVtd7Cdtmqz31UVPOzUcZntz+/0OepDhczWucH9yB9dhY2Mjyu/tZj3xqqo74feNtfV8L+U8nLO3trP9e7MO9uxvbmbXMh3jq6pms/D/CK/DZNLF/xDmO5hv19bXovyHf8t+F3XyZPY+U1U1XMm+VXWxjp6n67cu1vLxXBN/zQ/zVf3+4ufbdC3fhL8N63fxTjTN3tH74dqtKr8b0utQVdV28WM/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/0LNogsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHk1iy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOXVLLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJZXs+gCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhezaILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB5NYsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDl1Sy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWV7PoAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXs2iCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgeTWLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dUsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAllez6AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF7NogsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHk1iy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOXVLLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJZXs+gCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFheg0UX8JtZte3t352+c+fXuIJff/05yt93371xDaujk1F+2LRZAb0my1dV02TH+Pjj1+IaDh+6J8pf/un7uIZnn3khPMIoSreznfDvV1Wb3U+9Xj8uYTDIzkMv/Pv9fv5MtPN5doBe+l9U9cJnOy2hia9E1XBtPcq/d/GjuIbVQTZlnjt7Nq6hbbP76bMvPovyzz3zdJSvqho02f3wxqv/K65h1g6j/KlTJ6L8yXvze2E2mUb5XgdjSzrn17yDMbadZQfohflK81W9Zi3Kz+e7eQ01CY8QznW1Eua7EK6ju6ggLKHf385rmIdr0PSZrHyu6+KdJl26rPbCe3olfaaq0tPYzvO1/MogOw/zefZOM5vk92MTzhP71rM1bFVVr59di34Ha/F+P1s7NU12Q167+vv7Rf/PvJetnfqjfGw5fuJYlP/H9X9E+cl4HOWrqlZG2XN99OjRuIbt3bDfEb6jr6/k65bdvWz91k/7f1W1WqtR/uyRM3ENNcueq/ksu6en+VRX1+9ejfKr4fhaVbUxOhzl1/dl+dnsRpSvqmr62f047OA8zlez8WlnLz8PK4MjUX44z+b8g4f2R/mqqktXvo3yp449GtdQ4XzX9LPzMGvzvvxsnPUJ/vj4E3ENP/30Q5Q/fV/2reurr7+L8lVVzz+1EeXH4824htk0+9a0tpY/E8eOXonyl3/M1qD37LsW5auq+oNsrmo6WDvFvYY030G/JdVBOznuSfcqX8Cl36v2trJx/qmn/hjlq6q++/ZylP/lWr5u2VjP3otW+9lcNxnn7+iPnXs4yr/97gdxDWnL5vDhg3EJ+zbSMTLrJ3fxbaBpsu+383kXffVDUX51lPUqtu5+GeWrqh47/3yUf/PNf4truH7rbpRf/fmXKP+nPz0X5auq3n3n3Si/fyN/Jg4eyd5pPv34k7iGX7f2ovyZhx+L8t9881WUr6oajrJew+nT2TxTVfXj5UtR/sEHs3vhxIk/Rfmqqp1xNtk1vbynPRhm88TzFy7ENVz85OMov7ZxIMp/8Xk+T6R7MVc66KuvrmY9xIcf/kOUf+ut/x3lq6r+5V/+Z5Tf6eDb5yB8L2un2Vp8vNPBftJ+tgYdDm/FNaysZO80P/yY7VWvqjp+f9Y32rf5YJR/4418/ffiC/8c5Uf9B+MaZuMvovzWzeyZ+u5S1oetqrrnaPZuuLqa9VGrqqaT7L0q3d9cVdWEx0jfjmezfJ9P2ifo4jzOw2/p83AvZXodu9A0+Vw1Cueq8STby5nuGftNBw3hUH+QvZdNp+me2HyP9GyWPRPT8F7oQtPLv8VPw/3u6djQS/e6V9XebtbrmIyzc1BVNeiHfdDwfqyqGo6y8W0S7vNJr0NVVZP+xq2D4bEJ38uGw3Cfdwf/RBP+HqgX5quq9sJ35NFq9l73/eWfonxV/lx38XugXrgQnk3z8S0dpdNnKr2fq/J19O5u/nug6mX3Uzo+DsP7uapqnO6r7aCG1LyDMbaDKRsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgv42XX345yr/yyisdVQIAAAAAAAAA/P80iy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOXVLLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJZXs+gCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhezaILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB5NYsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDl1Sy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWV7PoAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXs2iCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgeTWLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dUsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAllez6AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF7NogsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHk1iy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOXVLLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJZXs+gCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFheg0UXUFXVzue1u7P9u/N7O3fjGh584JEo38434hoGg9XsAL29KD6ejrO/X1UffXgxys9m/biGY8e2ovxfXvpzXMN4bx7l5/M2y7e9KF/123MZ5fNLWdVm56F6YT79+1XVSy9FfimrKvs/2nCmGFeTHaCq3nrzjSh/8vjxuIb9m5tR/ubtW3ENt7fuRPm//DUb3678/GOUr6r66ssvo/xzzz4d19BrR1F+Mp2Ef7+TATJLdzC+Nb3s/+gN8gFuMsnWPpPJbpQfDA9F+aqq2SwbG/r9g3kN06yG4fBYlJ/P87V8vGSIK6iqXjrfZc/UvM3Gpqqqdr4T5XtNNr7+51GydHwd8hracIzuheNrVdX3P/4U5U89cCauoddfyfKz7P14vnspyldVDQb3ZTXMZ3ENp+7Navj5ypW4hmYwjPJ7u9nYcuBgtg6vqrpx+2Z2gHbxY8vBAweifNhm+E34gjsN115VVXvb2f3U9LNruddmvZKqqu3ZNMrvjvOVy/61rI85m+Qt5bzXkPUxt369mhVQVQc374/ys0leQ6pp0jVoNjZVVU0m16P8aOVEXMOgvxbl++FzXVXVTrNj7LVZfnM9f7/d3snG6Gu/XI5ruO/e7Lm8di17Lm/evBHlq6rOPfJYlG9n+bplUtl8d2iUreXvP5GtgauqPvj48yh/4bnn4xra6dEoP979e1zDmdMPRfkffv4wyn/2Vf4/vPjiP0X56V4+Ro8n2bqjnWfPZdtJ5yr85tfJ97L0GPl5SL+fpr39ftgrqapqBtl8e/bBs3ENn335cZR/7tkno3yvzfc0TOfZvfDEE4/HNXz+xddR/tDhfP02D89DVdj7avJrOQu/E1UHvdi93eydZnVtX5Tf2c3Hlt2d7H949tnn4href/+dKH/16i9R/tix7FtXVdXh8LncDvteVVXzu9kxdnfzb03DQbb2ufx9Nj4ePLA/yldVHTiQXcvvL30V13DhQjhn9+6N4uNx3sudpZ9Iwm8TVXlffLKXz1VteB7GYb/l+NGTWQFVtbqaPdfDYT5XrYQ1bGxmvYbnX/hrlK+qeu+9/xPl//h4vqe12vS5yq7Dr3ezMb6qan09q+HIPS/ENZw/n+Vffe31uIZ/f/W1KH/i3uz762CY71X68su3ovz5R/Pn8uTJR6P87VvvZ/kO9pPubN+O8oeP5L3Ypp+9W/b7+XfHeJt22PuaxQufql4/7Ds1+beBXrp4CuNd7LHph+exi31nTXhLr4R7Grroo/bC+2k2y/dVzMPfsfTiH3BU9QfZxZyGY0P6Lb+qahrud5+F16Gq4lsy3eeTXseqqtks3LOfDpBVNQ/3K6XvplVVvXCcTofY/eHeuaqqeTg+tR2cyEF4T87DGkad9FvC8a2D+TZ9JtLHcjTMz+MwvBfaDubbwSCba6bjvHdW4fqtDef8+FNZB3qdfAfP9kXMZ9maoemHv4mvfJy/cSPfs7W6kv0fXeyr6OK9CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDfvPzyy1H+lVde6agSAAAAAAAAAPjvrVl0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr2bRBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvJpFFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8moWXQAAAAAAAAAAAAAAAAi5bhIAACAASURBVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tZdAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK9m0QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLyaRRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPJqFl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMurWXQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyvZtEFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC8mkUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDyahZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq1l0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr2bRBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvJpFFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8hosuoCqquq1NejPfnf8vuN/zGuYNlF8fW09r2EwieKT+e8/h1VVH178KMp3UcNj507HNRxYOxnlp+NeXEM7m2f5ts3y8yxfVdX0+guvoZc9ltWr9Fp28D+EJfSa8CRUVdPPjnH19vUo//Xfv4vyVVUPnToV5fet52P0x59/FuXPnjsb13Dm0Uei/Jdffhrlb9y6EeWrqk4+cF94hHyMnk/GUX5lsBrlx7vZXFnVwdiSHqCqZm32f7SVzZW/yeaq0WhflJ+3d6N8VVXTz8andr4d1zAY7I/y8/mvUb7XjKL8b0WEz1V4P1dV9Sqds8O1V5uNbb8dZDc8wDAuIT6PHYxv+Royla9B72xvRfkPP7kY1zAb70X5hx55OMqvrxyP8lVV2+N/RPn9+7Lxtapq+072XB4+dCSu4frNm1F+ZZStnTY7WMuvrGU13LqdzXVVVeO9bJxeD/+H7Z3smazK15BrqytxDWuj7H745Wb2XP9w5ecoX1V1//GHovxwnq1hq6pqkvUgR8NpXMKtvTtR/uqtrFdx6viZKF9VNZhl53E4PBbXMJtlc35vnj2XbeVr+dk8G9+2drLnuqpqbZDNlyu9fK6a9bLnahquYWcd9MTvu+dElL/04zdxDR9/kfXv+k22Fj9/7okoX1W1t3Mryg8qvx8feSjrY7774XtR/pnzT0b5qqpZ+I3lm0tZH7Wq6pHTT0f5yV7eq9jbyubL//GXv0T5N99+PcpXVb319htR/p9f/Ke4huk0W0vP0rZVJ22K7JnooN3Sgbxf0qY9n/RiTLP1Y1XVuUcvRPl33n41ruHEsXuj/AcXP4nyF57OekZVVTUNvy2srMUlPPBAti/iypVrcQ2b+zejfBM+Ev1OxpbsIPv2ZeegqmplNfveNZtmffXNjaNRvqpqeyfrd6ytpd9/q849mvVLvv02+x9ef/2tKF9V9eQTf4jyl779Oq5hezvrQa6u5N95xuOshn4vm/Mne+m3rqprl7+K8i9eyO7nqqpmeCDKT2fZXDcLe0ZVVb3wWjbpRFNVs7B/9/Y778Q1bKzdE+UPbh6O8psb+bql6Wf3U3ovVFWFnz7r2vX/iPL3HMnnugfPPB7l3373X+Ma/vzSS1F+vJftkVlfz7/ftm3WT14ZhTdTVf37q1nvq4vtCINBtq9iZzv76UBb+Xl86qkXo/ynH/1bXMPZR7Ia/vDEC1H+44/ejvJVVdt3sm8kN/5xNa5h30a6L6KD/aBhA67fZHPdPPzNQFVVL9xzPw2//1ZV9cK95vF5nOfnsR+uW2Yd1DANe4CjUfb9tR9ex6qqWXg/jif5/pT0WqyuZGuGqnwd3PSz+XYwyP5+VdVkmn2Dbjr4HctoJXu/3An3W+1u5euW9GdR43G+xyZ9JgbDDvb2TrP5dhbO11389mF9LXtHTvf/VVUNwrFlOs1uyMEw/xnxeJLVkK4Zqqr64V7ztdXw90BhD7SqahL+pml3J++DVrivoovf6Y3DveZNOF82vfyZaMLz2Ovgd1XplJ3mp9P8mVjrZWP0IFx7VVVNw7VTF/sqhh3M2QAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP+VmkUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDyahZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq1l0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/2XfzpblqK40AK/MqjqzZiGJGSPABgTGwmC7w23cbkc/BA/oF/Blh5sIDyFjtRksbAaBAAmQmISmozPUkH1B+AX4y5158X33f511sjL3sHIXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMV9t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAM17jvAqqqRqP12jpw5jvnZ9PdvIhxm8XXV+IS/nTufJRfLPai/MbGWpSvqnr00cei/NrqibiGxexOlO+67F5YhqbJ8qNR+AFV1XX95pfzIYss3ubP9f5sJ8qvr+XD9Dvvvh3lF/PsOpx+8IEoX1W1vroa5d/4+4W4hrPP/yjKN0t4KN44/0qU7+bZOP/C8z+O8lVV+3vZnL2Y5dexHY2yGiqsoQnHpqrq0hqWMUaHH9IsoYj0E7oumy/TfFVVLWZRfAkVVNdl9+QiHN+6ebaGrapqK3uum6VcyfzZTjQ1iT+jHWVz/mx+I65hPDoW5ePxsaqqm0fxNlzMN+lmoKp+9OwPo/yHn1yJa9i5ld0PVy5/FOWfe+a5KF9VtX8nWzvt7WVjfFXVvMnu6ckkGx+rqg5ubkT5Nryl11bzfdn6evY/bN/J9nVVVavjbG8XTtdL6fnc2b4d5Vc27o1rqO5mFN9Yy+6Fe7ZORfmqqnGbzdnjSb7m2A17qTvhvq6q6ouvrkf5E8dPRvlb33we5auq7jkW3tPLWD6GPZvF4m6UX1nJ+jVVVesbR6L8+5cuxjXcf2o9yjdLuA6LebYG3d3L5qqVSd6DnE6zdcvDDz4S13Dl08+i/EMPPZkVMM/Hx1GbfReLRT647O1k+/TnzmR91AtvvR7lq6oee/TxKH/182lcw7Ubl6P8kc28rz7psnH+zo0vo/yT3/9elK+q+vjS1Sh/8cO/xzU8eH92T1dla9h5OEdULaHXsIReRWwJNXSLtI+ZfxepOzezfdnPf/YfcQ1/OPf7KL++fiDKf/zp11G+quqhk1kPctzm5wlWVvJ+burK5WztdP/990X546fysyG3bmVjbNy4qqp52JIeNenYkq9B19eOR/nLl9+Ka3jsseej/FcHsz7DbJavo9999/0o/9IvfhHX8Mrvfhvl96dZ76yqamUl61WshsPj/v5+9gFVNZ1n4/ylj7J1dFXVyfuyXsXKStYnaJpsrvy2hmx/+867ec/nxo1vovyJ43lPO11CHjl+NMp/8Xk231dVnTx5OMp/+um1uIannjob5T/++FKUv3X9iyhfVfXY49n/sLGePxN/fe21KP/889lc1S3yPurKJFt8vfbXN+IaDh8+GOVPP/ZUXMP6RvZc/v6P/x3l7z31cJSvqrq9neVPf//FuIbz5/8Q5V984d+j/DNnXojyVVXnzv0u+4CwV1JVdetmti9bW8vWPVVVm5ubUX42zfrB41G+x58vskXDMrp381l4jjF81dQ0eb9lPk/PQeZ7w7bNzuns7mXvaNbX8vl2Gt4Lm1v53vLuTtbvSK9jVdV4kj3b6bv0uzvZO56qqjbsY3ZL6MvPw/PF6TuSZYwtW+E8c/t21tevqvCEdFUbnlv7VvZdpvdjela9qmonHBtmS3hPtBeOsath7y0d26qqRuH9NN3L+3dt2Nufz7LvcrSE90SLcHwah7+JqsrH2PE4r2E0yvYDu9Psftrbz8+GrIV90HT9WFW1shr+liY8q759J39XtbubfcZmeNa9qupWOGdPljDGzsJ5AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDlefnll+PP+M1vftN7DQAAAAAAAADwr9b2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAw9X2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwzXuu4CqqqbpajLZ+875rtbjGu7sfRXlL5x/Na5h0bVRfmXSRfkfPft8lK+q2r45i/KL6e24hkVNonzXLeIa2qaJPyPRVP73s7upapF+wBKqSL+GrhllH1BVXZP9D+dePR/XcPDAwSh/6sSRKH/r9p0oX1V15erlKP/Ll/49ruH6V1ej/EcfvR/XcPp7P4jym2urUX62vRPlq6rGXbb06EbZXFlVNVuE43w4TyxjiujiMXYZ89RSBvqeZdehafL7sat59gHNEJbz2b0wX3z3fcA/te1mlF/G2qkJr0PXZevoZgnrlqayz5iM74lrWCzuRvmm8uey0s8IB+luno+ve3ezOfvBk/fFNXzW7kf5zXYrKyCd76tqJaxhZ38J+9twmJ9M8rHh0GY2xu7uZvfjYhbOlVXVhAuwB+97OK7h+vVsT3Pw0PEoP++WMNeN1qL8zVufxTUcOXAsyh89eCArYJ7PM024ftvbvxnXMA5rWBuH17Gq1k9kY+xkJdvf3pptR/mqquk8G5/GS9iWNZVdh+nsyyg/GWc9p6qq/f1s7XP//fkYvX3nWvYBzeG4hq7NrsOize7H7Z1bUb6qamstuw7dLF+3nLrnZJS/ff1SlD+w+VCUr6pqmux9V9dme8uqqkW4J1mbrET5E/dm32NV1Y1b2Vr85D3Z2quq6p1LH0T5o88tYY+9l823zSLr7W+uZOvHqqq1teyevn49n/MPHcnWseuT7B1LVd47G4d99UXekB7Ge8ewn5v2/9olrP/CJWjdvpH13qqqnj37XJT/8P2Po/xXX16P8lVVRzaz8wSzad6rOHwwW0s/9eSTcQ2vvX4hyk/Dns2VK9m716qqY8ezNeju/m5cw2qTrX1Gq9l1XMy/ifJVVdWdiOLHj+X95M8/z8aGJ554Mcr/5fz/RPmqqtl+1hO/dOliXMPPfvafUf7VV8/FNbThhNeE+dXV7JmsqurChcf+NH8/sbae7ZFn02yua9t8zXDtWjZn3/gmH9+2tsIeZLi/rao6eTLraV+8+FaUP3v22ShfVTVus37y5SufxDW8+eYfo/zmRrYvu7mdn337w2e/jfLjlfyM9A+feynKn/vzK1H+mTP5/Xjx0/ei/FNPnYlrmIyy53o2zcfYL77I+ph3t7N+y9VrH0X5qvz9bdPk5xgff+LpKP+XV/8U5X/64q+jfFXVmWeyc///eOvNuIZ7Tx2K8hc/uBLXMJ9l9/Shg9necjbL13+zcI89HufvWBZh46lrs97beJKfg5xOw9+xLOE3JItwP7GxuRHll3Ey+Njh7Lm+/vXXcQ2jUXZPj8f5Wn4enj3bn2W9/WWcB53Pp1kNiyX8Jinc58/m4XOdP9a1s5OtO5Zx1nx1ku3zmyX8/mI/nG/T39ilz2RV1d40eybacGyqqurCkTq9Cnd38p741kY2V82WMFul91N6JnUZ53Ln4f+wtpqdGftWtm6ZheNCVdXt29n7/G6UXcf1sH9YVdWF79L3w7GpqmpjI1v7rK1l9/Tebv4/zNMDAc0yfg+ezZeTcb6nmS3hfgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgOF5++eW+SwAAAAAAAACAf7m27wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK627wIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGK5x3wVUVXXV1H63+p3zi/GtuIY3//xalB+NRnENTz/9cJQ/cviRKL+zM43yVVXjSRPlZ11cQjVt9iGL+SKvIbsM1XXZ/9BVWEBVjdo2rCH/MhdN9lw1K+tR/vadS1G+quofFz6N8o889GBcw9bWZpT/5NMrUf7oPUeifFXVC4+9FOU/+OD1uIbpXjZG/uCJp+MamkrnmjDfLOG5DvPp+Pit/se3WPxdDOA6dvlcVc0sq6H2wwLypXQTXsdq5nENi9rNPqDLxpZJcyD7+1U1m1+P8uPJ4biGplaifLfYi/LtEsborrJnqpbxXC9hHZsLr2X6Lyxjvg3vp8V+OC5U1cnjj0b5vdlXUX4+T8f4qrbNvszNA9k6vKrqk6uXo/z6se/ea/mnZpHdk+sbB6P83d3bUb6qamsjuw7dPJyvq+rw4ZNRfnv3bpRfXd2I8lVVNc2eiUNb+d5w3GbfZTOaRPn5EtZet7evRvl2tBbX0E6ydctiCfN1uhafzbej/NbWqShfVbW3fyPKj8fZ+FhV1Y6yOXt1nPWdtve+jvJVVRvr2fjULmF/u7aWzdnTeT42jMJ/Y6XJ9qezNtwLVNV8ns3Z7ShfO62MszHy+t1sHd21+TOxtZHtkZt5PkY3ld3T01k2Rp84no/RH17+JMofXEIP8r57svXfa6//Ma7hxed/EeWb3a0ovz/7OMpXVT38yE+j/N8u5NfxvXfeiPI/+bf/ivJ3buT343y2E+WX8d6xmmxf1SxlDdpzz2cJ2nDR0LT5eYCaHYriB45k679DW9nYVFX19gdvR/mf/PhMXEPab+nid4ZVP3gy+z8uf3wxyjdNtjetqjp0KLsfd3azdUtVVRuupdOhpR0dDz+harr/RZRfXX08rqFts/Xb9t3PovzZs2ejfFXV397MziRcvXotruHAwazXcPrx03ENlz7Iztl0i+yZ2tvL3w088vADUX7rYD5XNV22z9/fy/a3F976R5T/VjbnHz+e95MPH8k+Y7HIzxC+++7/Rvmf//xXUf7atezcWlXVO2+/H+WPHc2fibM//kmUP3/uXJSfz/Pe2dHj90X5mzezMxFVVeNxtgY9cvRYlH/t9Xxs+fWvfhnld3fydfTGZraC+/vbH8Y1XLnyeZQ/80w25z/wwJNRvqrqr6+/EuUPbN0b13Dx0kdR/vCJ7KzRhff+FOWrqp44nY2P33/qubiGlTbrO733QXY+uapqHs7ZR49l6+irn38Z5auqjoZrn7vb+f52Os3mu8UiG2MXGiZMZQAAIABJREFUYa+kqmrRZffCeJydJ6iqmoW/Q9nZzdbya2tLOCcUnpdaWct7PmnHJLwVqqrq7k42vq2uZO8tm/QHSVVVXfbOb76E9+DT/Wyf3oa/aVpdzZ+Jnd3wXMZqfs5nOsvG6JVJPr6Nw/cTK+F12A+vQVX+W8H0XqiqGoffRRcOcGm+quqbWzej/PoSnok2vI7zaTY2TZYwtqTPdbeEvlX66jT9H6qqdnbDeWKc9VHXN/PrOA+vwzic66qqFuEZl7bN1vKbW/n55PR2Ongw/03SO+9me7vJSv77snF4TwMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPx/a/suAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDhavsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADg/9i5s2XJyjM9wN9aOey5JqqgCgSUQExiKARIQoIe1JYjuk/svgpfg6/DJz5zqH0FPnM42jLqRpagkVCoRAFCzDVBFTXvIffOYfkAHNHRJ93Nm1amI54nQiFpR725v1z5r3/9U24AAAAAAAAAAAAAAAAAAAAAAAAAAJZXf9EFVFUdHOzVxcu/+9r5C5e/iGtY31yJ8k8//nhcQ693OMpv3x5F+cGgF+WrqqrtsnjTxiXMulmUbyp7D1VV1TVhPoyH16Cqqu1n3UNTc6hhfRDlf3PuzSg/3Qs/x6p65OHTUX7QH8Y1vPPeuSh/5syzUb7f5H3Le++8HuU3Dm3FNZy8+77sBaZ5/9a02bWcjMP+scnvifQqdHPooquy9zGP65BLP8t51BB+ml3eN8y6cVhDlm/abPxYVdWE13FW07iGrjmI8m2zGuWbWd4g+/1jUX7S3clraI5kLxCOH7s5dJBNk/Uty9BHz8dc3sjXlw8ZqpmFfcssH8t305tRfhD2Lbs7O1G+qmptNevnuzmM/44cyvq3g/3wWVlVK+EYdBze171hvnQ12tuO8muD9biGprcZ5dt2L8rPJvl9fezQ8SjfzbIxR1VVpf1bk42dxtOsLVVVrazdHeUn42txDU2bXcfJHPq3fj/rY9tmEuVns90oX1U17GdrDaPR5biG1eED2Qv0wjFo2Jaqqm7ezsYMh9bzPno4XIvyO3t5e0rnhiu97Hk9WJ3HGDicY89hTXuyn7Xpe07dH+Uvfv5plK+qOrSV9S3dQX5fprf2ZJqNW9ruUFZAVT12+sEo/8ab2d5CVdWZJ5+K8vv7+3ENZ999J8o//e3novxkN1wrqapulu0Bv/DcS3ENr73+d1H+9ddfifIvfOfHUb6qqtvPxuKTaf6cSLv5rpnHsyrdGwh/+xwW5tN9ourmsBe//3mUP3k4mxO9ee5slK+qOv3Ao1kNb2V7r1VVzz/1dJSfTPL2tLqSjTsefDDbOz137pMoX1V19uzbUf7pZx6Ja0j7t16TrRlNu3yfKN3vms7y+e1wJesbLl9+K8qfuvfhKF9V9fgTWXv6/bv5PXHx0vko/+jj345ruHw5aw+729na/jxGDJ+cvxTlV1byPeSHH87a5Nmz70b5Q+HzuqpqcyPb5zl+4mRcw5WrWXts23zN50c/+ndR/tWf/88ovz/KzpNWVZ155skof2RrI67hF69k87Kd8DqcOfNElK+q+vj81Sh/Mly3qqp64403ovyssnX5Xi/vpT+98Ico/8D92VpHVdWv3vxZlL9583pcww9e/EH4Ctma+K3r+Xt44rEXovztnWxuWlW1vZPNifZG2Vh8d5Tv5X/4aTZH/taD4T5TVY12srWKZ555Jq7hgw/fj/LvffBhlH/00dNRvqoqndq1Tb5fdnCQrUl3s6yf7+ZxVimsodfLz6eMp9la7Opa1kenZ4urqm7dvhXlD83hzH563mk8zsYtVVVrq9mcZhqe0xkMs+/RVFV1/fBsyCQfv6Utsgm/XzaZ5Gtng0H2fZ7pHPq3NtzAvX37dlzDkaPZvl83zT6LSficqqqahvtdw0H+nJiE12F/kvVv8zih3Qu/a1jh+Zaqqtvb2Rm+zfB5u7eXr7cMh9ka4mSSzyemYR+5Msy/75i2yfS81Y1r2bm1qqrjx7Lvg8/CfqGq6iA8D7AfniFci8ewuRs38nO16Q5DM4czDeOwnwcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPhjaxddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq110AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr3bRBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvNpFFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8moXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tddAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK920QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLzaRRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPJqF10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMurXXQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyvdtEFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC82kUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDyahddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq110AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr3bRBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvNpFFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8uovuoCqqtmsavd272vnD21sxDV8+/Eno3wzjUuoqjZK977+Jayqqq6bZS9QVbMuK2I6y2uopsnileWrqroufIHwPXRhvqpqHObnUcObv3wjyh/a2ozy954+EeWrqvZHkyj/4YV34xpe/pOXo/z1a9ej/PlLl6N8VdW9990f5Zt2ENcwGWf906Cf9fFfCu+rNq0h7dyqZmEH2XVzuI5t+qzJ8vN43nZhW5jPsy5tD+mTpqppwqFsm+XH42vZ76+qtj2S5XvDuIYmvi/D399kz8qqqm6WfZazaX5PHNSdKL86XI3y3Rymdl1ln8V0uhPXsDLcivKTvDnV/n72WfZ62bNqOFyJ8l/KnjXNHCa4bWVzw3RquDLMx3/j6UGUX+2vxTVsrGTrHdPwPVRVHRyMonyvzdrToLL+sapq0mYPq73ZzbiG0c6NKL+5kc2J4qlAVVX6nOjnn+X23udRfjDej/JH109H+aqqvYOsPfaHR+MappOsPfZ7d8U1pNPLaTh+29nL7+vNrew6NL1DcQ27+9n7WOtlz6r1tXwMemM3mxvuh/d1VVWvy/q34TBcmK+q7e1sDNqsZX1sv5ePQbtpNj89mFyNaxgM747y44Psszx+5GSUr6r6/LMLUf7UPdmYoapqGn6WNcsGHt1sL/v9VTWZZG36heefj2v41Ru/ivJnnj4T13D299n+wo2bn0b5I2v5PTGbXYzyu7vZfKaq6qmnHovyb731YZR/+6N/iPJVVY+ffi7KDyf5Wu5+uGiTrmFWVbXp3mW+hBjL1+XnsBcfnmmYhG3hxe99P8pXVb366itR/rFv5X30R+c/jvKnTp6KaxhPsz5yfSPr5/uDj6N8VdU47J/acJ+oqmo6y9r09nY2R+/187llE84NB4N8Xjab7kb5kyezcfD775+L8lVVjz32wyj/0EP5Wu5772drZ598+lFcw/Pfy8bSr/ztz6L8cJivy08nWZve3c3vibO/zdrk8ePZeafVtfw6njiRPavefvvXcQ1nzjwT5be28nNjr/yv/xblmybbJ/rzP/23Ub6q6taNrG/46SuvxTWsrWbX4U9e+kGUHwzy/Y1Pz2fn565eyc+nVGXPmsOH7onyOzvbUb6qan3jWJT/+c//e1zDWthH/umf5fflaC8bB89hih0bjbI95I3VfE701JPZPs8vX3s1yt97Mltzqqq6dOH9KP9O2Jaqqp759otRfm3jVlzDNOzfPv74kyh/49btKF9VNRxkZ1y6Wb5XtXU424cejbLPoWnzxbd+eDBiMofvsbS9bK1hZzebH29urkf5qqpeP2tPTS//LNfWs/FXO8rnZWuHD0f5a1e/iPLTOazLd2GbbudwXw7C/q1ps/Y4mcP3/CbT7EW2DmVnYquq7tzJzhOsrM7jPEB2HfphW1hv8/7tzp1sTjKP71804YGp9L5cWcm/dzAZZ2vi+6P8PMAg/ALt+CAbt8xjStXNsleZzWHcktbQD8/LV1XddSwbg169Fp6DDPumqoon2dPZHB5WXdbPzybp/m/eP6bfKb/6RX4edGsrG//tH+Tjt176BwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+yNpFFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8moXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tddAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK920QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLzaRRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPJqF10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMurXXQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyvdtEFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC82kUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDyahddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADLq110AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsr3bRBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvNpFFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8moXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy6tddAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALK/+oguoqur1mto63Hzt/H33PBfXMB1Po/w4zFdVNe1BlO/1uijfdW2Ur6qappeh6cU1VHYZqpvln2X79ZtzVVX1BsMoPw1/f1XVtRs3ovzv3303ruHh0w9E+c2NjSj/6YWLUb6q6viJzSj//Hd+GNdw8fwHUf7a9awtPPjgQ1G+qmo2yfqnZjqIa+j3sxtrOp3ENVSbdXC9Nutju24Oz7qwk56Fffw8aqhKr8Mc2kI4hOu6OTxvw+vYNPl1aMJxQ1dZ39L2jkT5qqrJ9HaUH7bH4xrabiXKd2Gb7ubQFnrNWpTv97biGu7sfB7l95vsOdO2+bOuF3YNo1HWnquq2iZrj03YFqry65A+87su/yzbZpbVED8rq5oubNPh43ZlJZtTVVXd3tmJ8tNeXkOvydpDO4c59niWtel+l7XHYZPNqaqqxuH4bXec92+Ht7L5bS+8J5o5rPlMZtlnubv9cVzD+tpdUb4dHI3yV3cuR/mqqsMbx7IXmOTLuV0djvJt7cY1VJP1kV2b5Yf547amk70oPxhk7bmqajq7GubDeV3YL3z5IlkHd/nKZ3EJRw5n84Gdne24hq1DWQ3be9m45fBGNg6vqhr0VqP8ZJbPsQ9mt6L8Su9ElO93+Xzk2NGsLezu5+OWfrje0YbzsunsiyhfVTWbZs+J2XQ/ruHZM89E+T988FFcw8MPZGPQc+fejvIvPJvPR3rtfdkLdJ/ENQwH90f5B+6/GeUvfpH18VVVN3eyfZ5jvTmsVaRz5DlsDjThS8wqXW+Zh/A8wByqaNtwTpLOLW/lffQPv/9ClP/1m2fjGg4dyuaGn39xPa7h+pUrUf4b990d5Y8cDefHVXXoUHYe4MqVa3ENR49ka1fDQXi4I9z//fI1svt6Nss+h6qqrsvaY79/Msp/85uPRPmqqr29bNyxsnpPXMORo9l84MLl7HOoquq12fzypZdejvK/+MX/jvJVVcNwf2EyGuc1DLLx19Gj2brTcCVfJ3j73GtR/nsv/Zu4hiuXL0T51157Pa7hnhPZfn56buy9934Z5auq3v/gUpR/4IG8f3vyqWz8trudzYle+3l+HVc3srawtZmfq3ji6T+P8r/5TTYOPnlP3hY+eD973h69K1v/q6qqbhTFRwdz2L9ND2p3aXvKzxCm5xgP5vC8Tc+kvvTij6P82d/+IspXVR0/fm+UX13N1vWrqn77u59F+We/k62jVlVtbWVr0t+4P7uOo/3s+x9VVdPwXMXeXn5PVGX35Wwa7jvmRxoqXTubxznvfj8by6+E9+U8xvL9QXiuNv0iTVUNetlaxc52vn+bfqdoGB5KODjI+5Yu7Fum4X09D+nZt+k0P9PQhgdK79zJ22Pat3Rd/lnu7mZnZNbCYcdoPxuHV1X1e1n/NhjkZ7amk/BZE36WbeV99DC8DmHXVFVVo1HWHleG4b7lHLrHg+k8xm+hsD2ND/L30A+f+fffdyrKX/4sP3c2GmV7l+nzuqpqtpr1b7NZ9pzZvpPv3968nZ35Ggzy+W03y/rI4TxqmEcnCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8EfULroAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJZXu+gCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhe7aILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB5tYsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDl1S66AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWV7voAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXu2iCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgebWLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dUuugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlle76AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF7togsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHm1iy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOXVLroAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJZXu+gCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhe7aILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB59RddQFXVoL9aJ+9+8mvnZ5OduIbZrMteoIlLqC58kaZtwwLCfFVVeBmrpnEJTZcV0Q6GcQ2T2UGU7w2yz+LcW7+L8lVV23e2o/zDpx+Ma9ja3Ijy7/3h3Sj/+JNfv1/6v9bXs2724oV34hpGe1l7evD+b0X5ftOL8lVVsza7r5tuEtdQlb2PtplDHxvqulmYzx92XTeI8v3BnbiG8Xglyre97D00zRwGDZW1p26W19Dv70b56XQzrqELBx5dOO6Yx0fZ761H+ckkvyf6veyeOMiGPTWb5X302lo4H+jyadHG+rEov7ubjb02NvP3kD4nNrfuj2u4ceNilD9y9J64hqYN+/lp1reM5zInyvL9OYxb9vb3ovxgkPVNvTlM0tfXsz766udX4hoObx2J8pvhe6iqOrKe1XB993qUvza5HeWrqo6tZO/h1Op9cQ3jcXZjzirrow/a/ShfVfXZnatRfrOf9a9VVcMuG0PujUZRfjqHcfR4kg2eVtr8vq5p9j4O5jDFHq5kLzKdZvfEYCVft5pNvojyTWXjv6qq9bWtKL+7m/WxvV5+TzTh/HZzK59b7o+z+3JzM68hbdMba2tRfjLLfn9VVX8law/tbDWuoQvnl71euNZR+d5CM8teo52N4xoOwuXcjTabC/T7J7ICqurgIBxDzmFNO11v2Tycz8tmYd/yzQdOR/mz73wU5auqvv/de6P8aPt4XEN1n0Xxb9z7aJT/+NI/RPmBrtzzAAAgAElEQVSqqrffzvYNX37xxbiG5iB7TkzDdasvxRvZkXnsDcT7POmZiKo5XMasj52Fa29VVaNRdh0ffOjhuIadW9l84Oq1m3ENa5uHo/zKajYOvvtY/syfhXvA5y98HNcwHGZrLpvr2bxuPL0W5auqenVXlG+a7FxHVVXXZO1xPM6uQ9NkezxVVV1le3bbu7fiGk4/lJ3tuHYtW8utqrp08VKUv/uubC33mw/laz4XLlyO8keO5Ot3m+HZtUuffhDl23xKVD/6i7+O8r9682dxDZcuZet33/3us3ENhzeyPvLVv/sfUX5nlK9BPv/CU1H+2LGsb6qqOn/+t1H+o0+yNZ9mkK9bra5l/fxTz/xZXMPOXjZ2moSHQ7rwXG9Vvib96KNPxDW8+evXo/xnl7P2XFV16lR2X+7vZ3OieZx8m6XnvOfwrJqE08s7d7J76pFHXs4KqKqm+TTK//rNLF9V9fC3Honyr7/x93EN333hx1G+Nzga5T/95PdRvqpqNMqeNU0THuCrqgrXnWbhXlM/PK9VVTUJ18Tnsfe5upKd4bt9JxszzMLvsFRVDQbZe9jcytcJ2nAP+cSJfN1pGj4oBqPsOk6m+cGMZhruNTX5uvwwnN9OZtnn0LZzuI5N+lnm+7fpcaXhMNu3rMrHgE2bvcI8zmWk99V4krendJ+n10v3kPN5Wbrf1R/kg/nJOHuNg3F2X67M4Z5aGWb948FBfh70YD8bNzRzaE+z8J7Y2cu+Q7K6lq/5TMK9y/4cxqDT8LzU7ig757Mdfg+mqmoQ3hPz6N/6/eyZn/fRVdPwbC8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMAfW7voAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXu2iCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgebWLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5dUuugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlle76AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF7tP/cPmqb5L03TXGma5q1/9LNjTdP8bdM0f/jqv49+9fOmaZr/1DTN+03TnG2a5rn/l8UDAAAAAAAAAAAAAAAAAAAAAAAAsHz8HTsAAAAAAAAAAAAAAAAAAAAAAAAA/jX8HTsAAAAAAAAAAAAAAAAAAACA5df+C/7NT6rqL//Jz/5jVf2067pHquqnX/3/qqq/qqpHvvrPf6iq/zyfMgEAAAAAAAAAAAAAAAAAAAAAAAD4/8hPyt+xAwAAAAAAAAAAAAAAAAAAAAAAAOBf7ifl79gBAAAAAAAAAAAAAAAAAAAALLX2n/sHXdf9fVVd/yc//vdV9Tdf/e+/qaq//kc//6/dl16rqiNN05yaV7EAAAAAAAAAAAAAAAAAAAAAAAAALD9/xw4AAAAAAAAAAAAAAAAAAAAAAACAfw1/xw4AAAAAAAAAAAD4P+zcSa9c95kf4Pecmu7IS0ocRJGSNViDLVvyIA/dVtsCGgiMLLLLIps0ggDZ5ENkm8+QLxAgqySLBGgj6YbjOJZFS5ZkDZZlDSYlUSN5eeeaThZWAANx0DB/ZVc5eJ6NjOv7K7731Dn/uQoAAAAAAIDV195m7kLXde9XVX323/Of/fxSVV39nd+79tnP/i9N0/yrpmmuNE1z5eOPP77NMgAAAAAAAAAAAAAAAAAAAAAAAAD4M7HQ77H76KOP/qjFAgAAAAAAAAAAAAAAAAAAAAAAALB0vscOAAAAAAAAAAAAAAAAAAAAYIW0C3695vf8rPt9v9h13b/ruu7JruuePHv27ILLAAAAAAAAAAAAAAAAAAAAAAAAAODPxG19j925c+f+yGUBAAAAAAAAAAAAAAAAAAAAAAAAsKJ8jx0AAAAAAAAAAAAAAAAAAADAErS3mfugaZqLVVWf/ffDz35+raru+Z3fu1xV791+eQAAAAAAAAAAAAAAAAAAAAAAAAD8f8L32AEAAAAAAAAAAAAAAAAAAAAAAADwh/A9dgAAAAAAAAAAAAAAAAAAAAArpL3N3H+uqr/57H//TVX9p9/5+T9vfuvbVbXbdd37YY0AAAAAAAAAAAAAAAAAAAAAAAAA/PnzPXYAAAAAAAAAAAAAAAAAAAAAAAAA/CF8jx0AAAAAAAAAAAAAAAAAAADACun/Q7/QNM2/r6qnq+ps0zTXqurfVNW/rar/0DTNv6yq31TVP/3s1/9LVf3jqnqjqg6r6l/8EWoGAAAAAAAAAAAAAAAAAAAAAAAAYIX5HjsAAAAAAAAAAAAAAAAAAAAAAAAA/hC+xw4AAAAAAAAAAAAAAAAAAABg9fX/oV/ouu6f/T/+r7/+Pb/bVdW/TosCAAAAAAAAAAAAAAAAAAAAAAAA4M+X77EDAAAAAAAAAAAAAAAAAAAAAAAA4A/he+wAAAAAAAAAAAAAAAAAAAAAVl+77AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF3tsgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHX1l11AVVV18+omB7cdn816eQ1NGG/meQltVkSXVxC/Qnwd8z+iemENXdvGNaR3w09++pMov7N1Kqyg6pEHH4zyR8dHcQ2vv/lKlP/2t74Z5Xf3bkT5qqrXXnszyl+6O3sfqqrO3rEW5ccn0yjfzfNnqm2zp6ptZ3ENcSvfDOIa0irm8yzfNHk/0bZZQz+brS+ghtsfc1RVNc12mM/vha7L7umuzZ7rqqrZfDPKL6C7ra7L7un0OjYLGEq37UaUH5+8F9fQ72X3ZK+XPZeDQT6WPzq8HuU31s/HNbRNdh22t7L2cTLdj/JVVf3+TpRveidxDWsbW1H+g0+ye6Gqams7q2EW9rezWT5uGbbZc7U+GMU19IdZG3kyP84KOM4nl4Nedh3PnbsjruHqtatRfnruzriGwSi9H7Jxx52ju8J/v2rUZn3dZJI/l7WejaV3D3ej/NosH4Ped/r+KL/f3YpreGcvG/u889qvo/zlS3dH+aqq01vZfGI+ze/HNhyMp+Oeqqr3P3wnyt957nKUbyu/jk2bzYkm43zdqd/P+prRIHsvT06y+XVV1alT2Rh0dz9vW8Yn2bjjaJavg547m81J0nX1vYPD7AWqqmuy8V+vycbhVVWjcI69u/t2lB+sZ21TVdUwbGMHbT6Wv3GUjUHX1u+J8k2Xty1NM4zy09k4rqGdZW3LhfMPxDU899yzUf5Lj3wxyh8cnY3yVVUvvfLTKP/4w9+IazjYz8bys/HNKP/0k/nf8F+f/R9R/kc/fSau4Xt/8XSUPzkO1wmqajqeRPl0L38RW/Hzedjpd4s4UZD+Idl6yyL2FqrL5sinwzFsVdUH17M2+u4Ll+Iafn3trSj/pUezMezkMOuvq6qacB300qVsraOq6u13XozyGxvZ3LI/yM+GzKbZulOvzdcJmsrONMzn6d5nPgYdDLN1o48/ejWuYX0ju45ffiwb/1VV/fz57Jl47vnnovy5s+eifFXVzk72XN36NBv/VVX11rJ7ejrNxk5fe+KxKF9VdeWnfxvl9w7y8d/3v//9KL9/lO+//s8fZ3OajV42P/2r73w3yldVtWtZX/XslR/ENTSVrRt14f7Ew488HOWrqs6dz17j1deuxDUcht1d12Vt0/33X8gKqKoPf/JulH/p5y/ENWxtZOugly9/Na7hFy9l8/wvfOHJKD+d5eel0jNbizgx3/ayCWYTnuWcLuBsSL+9GOWf/Fo2fqyqevZK1tc99PmvxDWMT7K1irbNxn+XLz8U5auq3ngjmw+Mhtn+SFVVfxBex/hDIPkZwps3s/HbcJC3b/3wz9jeyt7L9ExtVdV0kq2jHi5g37G/nV3Ig4N8np92NYNhtvY1X8Ba7nCY7Rve2s3nRNNpeE+GnyHZ3sr3Ttte9l4en+TroCfH2dxwEWdS08+RdOG52sNxfj55fT0b+0ym+XO5Fp7FjPeqFtC2pJ9Jmi/gfuyFZ3vjz+8u4DqejMMzCQv4/O1wGJ6rnWZjhqqq8TS7Dm14LyzibxgOsxq2t7K1t6qqts3GsZPwc6PpedTfSvfB8wrG4XmCfj+fT0yn+Wf9AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/pTaZRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOpql10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKurXXYBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyudtkFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC62mUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDqapddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACrq112AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsrnbZBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwutplFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA6mqXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6tddgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK522QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLraZRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOpql10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKurXXYBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyu/rILqKrqqqqr7rbzbe/2s//HbJ69RtPEJdRsNs9q6PWi/Dz896uqmsouRNdkf0NVVbu2HuX3Dt+Na3jxhTej/KULF6L8mdM7Ub6q6u2r70T502e34xqe/Mb3ovy7774S5W/t7Uf5qqpLd12K8mvD7H6uqppNs/xoNIry0/E4K6Cq2i7rrrpmEd1d2tdM8grCEppK29i8n5h3s+wFFvBeNpW1T+PJp1G+18vb6F6bPZfz+V5cQ9dl93Tby9/LfASYPROz2UFeQW8zyq+Nsn6mqqrrsvuh12YdTdvLB9Jb2+ei/PjkJK6hbbN8k04o2mGWr6rJPLsOvTYfy1d4HXv9vIYPP/wwym9tZc/11uZWlK+qOtzPnuvhYAHvZXhPDwZZP/HutXxet72djRk2NzbiGu66mM0NP/roZlzDuXNZ+7KzdT7Kd5O8x5+G45Z5LxzDVtW1q1ej/ObpbG44WL8Y5auquu4we4FJ/kycGh5F+c21rH27+XHWR1RV9e99IsrPm4/yGsJxQ5d22FV11/l7o/zbV7O1t88/8HCUr6qajgdRvg3nAlVVxyfZM9Frsza218/ndUfHx1G+v4Aa4tfo8vWS6TTra9bXsjZ2ZydbZ6iqOj7O1gCHo+x+rqrqwj2OzY0Ho/zewXtRvqpqsHl/lG/7+XXc6rI5ycE4G4Nub5yK8lVV3Swcv+VD0JpMsjFos4A59re//o0o/8zzP4vyX/tyNu6pqnrp1Wyf5v3d38Q1nNn8XJSf7GdriPuHN6J8VdV992RriLsf3IprePX1l6P85x94KK6hnWTj2Hm4SZPuoy/iNZIzGYt7jXDstIA2ug3XrY4P8/72K49/O8r/+Cc/iGt46HOPRvlfvPqrKP/I5x+J8lXxcnLNTvLn8sK5rJ94+523ovyluy9H+aqqYXgmoevy8wDz9DxAvI+9gH3LaXYd7r6QPZNVVQd7b0T5M3d8Ia7hwYfuifK/ej07q3RzN98H/95fPR3l//6//W1cw0H4WK2FZ+defOG1rICqOnXnWpR/6lv/JK7h3TeeifLX3sjux6qqM1vZdXj8K/8oyu8dXovyVVUvXHk+yo/WT8c1VJPtY//lU9+J8sNBvlbx3//uP0b5O+/M17S3tnaj/De//nSUf+utn0f5qqq7L2bP1Icf5nunZy89FuWvPPujuIavfi1bc3n55f8V5R999MkoX1U1mWZj8UWcT2nCCWYX7w1k+yNVVbN59hrjST4neuqpv47yJyf5vuMgnNNce++5KL+1ne17VlU9+HA2Fn/z19lcoKrq1E7WZx8fZWuIo1F+9m17O3uN0TCvYWM966uGo+x88fUPrkf5qqrRMNs3vP/+bK+rqur69ezv6Iefq6qqOg7PlKZ9Vfr5jaqqg4Nsj2U4zNdL5ml3GX5uYHyS7+WHW/G1Hp5VqqqqLnuN8WQBnxVMz4OGbct0nn8WZ7SWnfOZL+BsyPgkO3Pfa7KxU3xWvSre7Ur30auqBmGfnX4uq00/NFBV43F2HSbTRXw+Lbune738OqTPVRd/yC5/JnrhuGNvPzyXWwvYQw477OEgH0f3w7HTbJ6f8z4Jx3+L+CjNYJg/VwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAH9K7bILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1tcsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1S67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWV7vsAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXe2yCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgdbXLLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA1dUuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVle77AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF3tsgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHW1yy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNXVLrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFZXu+wCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhd7bILAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1tcsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1S67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWV7vsAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYXf1lF1BV1TRNtb3e7b9Al9fQa5ooP5/nRTTVZjXM5lkBC7iObXYZa7S5Ftfw0isvRfmbN3bjGh743D1R/tTWqSj/wssvRvmqqi996YtRfmd7O67hrTeej/JteEM++MCDUb6q6ujgOMpPJ7O4hrbdiPLj8VGU77Vh21RVvd4wfIWwcaqq6k6yeJj/7Ytk3XYXd/v5e9k0k+wFFtBXzWsQ5dtmJ8pPJreifFVVO7oryi9g2FLzWfZe9nvZuKeqqq1g/FhV87Bt6MJrUFXV9kdRft5l/UxVVduuh68Q3lBd3rZMJ9lzXW1+Hbuwfeu69G8I81U1n2XX4fgwfyZu7d+I8ufPX4hrGAyzazk5yfr8m59+GuWrqja3suf68PggruHwKBtDTqfZOPiOs3dG+aqq/f39KH+ym7ctW+vZWP78uUtxDTU7jOLtPLsf+728bdk92Yvye5PsGlRV3XP3vVF+rcvGDNePPojyVVWjfjYG3Rjm89uNOpvlH8n+/VPbedtyeJD1dQuY3VYTroN28wWM37psLH/p7vNR/vDgZpSvqmpqM8oP19JxeNXJ5OMov76WtS1tL99eOD7Mxh2bW9n7UFW1uZm9Rj/Z2/jMjU+zNenB2XRdPV8oGA2y++FwfwHj4I2sbei32Xt5x+mLUb6qajrLxi3jebqOWrU9OBPlPz65HuX3j/L57eYga2PTvYWqqi5cSx00+XWocTaWfuLxr0T513/9RpSvqrr/3stR/pU38xqefCIbA25tnovy733wyyhfVXX5QrZecrSb751OjsdR/saNvJ/YWc/W9rt0HbNbyGg+SrfhXKCqquvScUOYX8RlDN/KQZuPnfZuZHtF3/jmd+MaXnnptSg/Dp/rj3ffi/JVVWc2sjZ6EO+PVK2vZzWsrWXX4datbJ2hqurc2Wzdqqt8/S7V72dj+abJx9FV4XmAaV7D6VMPRPnr770a13DvfU9E+fffy9Yx0zM6VVVv/PKVKP/UU38R1/DDH/44yq+Ft9OFc3dkL1BV62ETu3v12biGtWE2v/36U9nZuaqqXrjv+OabP4vyH36Q7/kNB9kNtTbKn8vHv/Z0lL+1l61VvPDzK1G+qmo0ytatzp7Lz9ic3s7u6Rd//oMof/5Cdqa2qurUqcej/KWL+ZmtZ3+WnWm9595s7FVV9avX347yd5zJ9vxefz1rm6qqHn3021F+PF7AubNwbpeOg5tFHIRssnFwr3c6LuHwMJuob2zleyzPXvlRlN8/yN7Lrz45jfJVVa//KlvHHA3y9eTRKHuNjbVs7HV0lI9b7rxjK8rPZ/lz2Qv3FyaTbL1lZyd/rm/ezPrLo8MFnGltsnb++Cg/s390nJ1929rKPkszm+Vty8ZGNjGbj/Jn4mA/e7ab8FzswWH2TFXl89uNjbyvm8+yvfjxOH8mxuHnmtKthdEoO99SVTUOz/YuZpcnuxBpDb02H0enNUzifaaKb6h5ePZtsICxV9Nk7fwCrmL1+lnbsoDbqU4m2Vi8N8+KCIccVVW1sZGd8967lZ0TqqpqwjHoYJit/y3imTgJ9x37g7y/HYSvMV/A+G0xZwoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+dNplFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA6mqXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6tddgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK522QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLraZRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOpql10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKurXXYBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyudtkFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC62mUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABkUEm4AACAASURBVAAAAAAAAAAAAAAAAAAAAAAAAMDqapddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACrq112AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsrnbZBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwutplFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA6mqXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6tddgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK7+sguoquq6rmbz+W3nm2oWUUQUX0AF0TWoqpp3WX6wNojyVVW94XqUf+bZZ+MaTm9vRfkvPPRQXMNkchLlX/7lL6L8U099M8pXVZ0c7UX5q1dfi2s4vbMZ5Tc2T0X5k5NelP+t01G612bPdVXVfH4Q5fu9UZRvKmsXqqoms0+zGtrsXqqq6vWGWQ2zrJ+pqmrizmYa15DL+prpbBZX0Otlz3b6PvR7a9kLVNV8lvUzbZO3b4NRNox8//3rcQ2XLl2M8vNpdh16/bx9i5/LvGGoeTwOzvqqpsn7uvS5HvS24xom02zsNJ3uRvnxpI3yVVVr69m4ZTp5L67h7J0XonzT5c/E5jDrq8ZtVsPeNO+vb93M7qetzY24hvHJOMqnff7B3n6Ur6raWMvGwWvDLF9Vtb6WvRdNm41hq6rG4+y92J1l7eO16x9H+aqqi2eyueFdm2fiGmZddh3H0yx/en0nyldVdceHUX7e5MuQbdjGVps9lx/c+DD796vqzKmzUb4Nx25VVUfHWV/TtJO4hl4vW79rKhu/nXTvR/mqqjacD0yn+bjlzE42ftvduxXlZwuYo++cuSPK3/z0k7yG01kbuYjrsHUqeyY+3b0R5Xe28znRaJC186NR3ldNK1sv6XfhvGq2gJ2iJpuPnEzzcfBokD2X28M7o/zu7tUoX1W1dvpylO/38vXkmmX97fWP8j2WC3c9HOWH4Zr49k7etlS49/nY/fme35UrV6L8d7/zVJS/69I9Ub6qaj7J7scvPfqNuIbnnv9xlH/zV9laR1XVk09+Jcof7WXt/KC/iBMF4XxgEccqlvwKCzkbsoi3ItQL57fH+9kcvarqwl13Rfm9cAz61lv5PtHOE+ej/HyajR+rqtZG2VrDffc+EuVfePHlKF9Vtb2V7cWvrWfr+lVVTZPNT+fzbH7ctvm9UOF8ou1la+q/lc2rJuN8z+7qb34Z5b/45ay/fv6nz0T5qqpPbtyM8mfOZnOqqqpHH3ssyr/95htR/uat7Jmsqpp02Xxg7yjfL7vvvmx+2h/kg4aXXvxhlN/fz8ZOJydHUb6q6vMPXIryFy89Edfwm9+8GOXfvZbu5edt9Le++XiUT/d/q6pefvnvo/z9n/tylD9z5sEoX1X17nvPRfnXfvlRXMPFC1n7tnMq30N+++3s7zh9OlszOjzI91jeeis7K/6FR/8yruHWrayNbMIzW/PK9/IH/WwfvG3zWf7hUXY++Zm/+1lcw/nz2XW4I9wneu2F7Mx/VdXaerY3cO5Mfqbh8CAbAw562T7RdJLvt62vZWcIRwv4LM3R8XGUn4ZnQ+b5Y12bm9k++Cef5Od84mOxTX4hdk6lexxZDUdH+Rh0OMj6mm4Bq8FrG9n91KZtyzyfWx6F56UWcdZ8Fj7cbZt/bqAfHvvq97O1s+FgAZ937GWNy3CUfwbkk4+zdfVeL7uO83ne36bj4Pj8X+XbPG2bXcfZAq5j2k8M+vlz3Qsf7KOjfK+qF7ZP0/DM/foob1sODrPrMBzlc8P5As6uJY6OsjFwVdUo3G9bxLglbd96i3guw3YeAAAAAAAAAAAA4H+zc29NclXnGYC/vbp7ZjQzGnRACCiEEGBjIWwMxGBiO5VK5S8nlUq5kopjg2PKRtgIjAAjEBbiIAmd5tDT3TsXlJN73i52XzzP/dvzaffa69wCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPiutaELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1taELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB1jYcu4P913zrZ933+58PPaN23r/9v1tayr2M8mkT5W7s3o3xV1dt/uBjlHzt9Oq7hgZ2jUf769c/iGtY2svbw6is/ifJ3b38Z5auqbn19J8qfevCRuIb0rZpND8NP2AjzVV0tonzr5nENs8VelF8br2d/f9aifFXVeO1ElN+dfh7XsDl+KMp3lT3Hbz5kmsW77J1YLEZRfhmfsZhn71RV1WiUvVetZb1Ta0eifFXVdJq1hdEo/y7T6dfp0w/HNRxO96N817I5w2i0GeWrqrrK2mMXj5ZVffwZWWPo+/y9TmuYz5exLNqK0ulcfrKWj7fzedYetzbz93rv/tdRfmd7O65h0rJn2Y2z9nR7kb8T6Xi5d+9+XMMD2ztR/t5eNoedhWNlVdXWsWNRfj2cR1dVLaZhexjP4hr6yuYNV/9yKcqfPftMlK+q2t7M+obDab4u253di/LbXdaexktYl/WjgyjfVTbWVVX1i6xNr29m7/XNvRtRvqrq4Kts3+nE0WzOUVU1Wjse5ff2b8U1bLasTY/6rG+ajE9F+aqqg3n2HNYnJ+MaZgfZO7EdjtfXvrge5auqtsL52/ZWPv+7eyfro9c28jF/NMn6yCPhOv9guhvlq6rWx1n/NAn7pqqq6Tw74+j7bD+4LfLxtk2y73K2yM8GZovsvRrPs+dw4tjjUb6q6vZeth+8s5nPW0aLbA65sZmPE1e/uBLlHz39ZJR/4pH8nOjNt9+O8s9+73xcw8lj2fnEH//8VpS/8PTzUb6qatRnc4aD+/nZ6ROPZ/tGH/7lr3ENb158I8q/9MI/R/nD3Xy/ZR7uJy9lLza8F9FVPl7G0rsdy9i/C8eJcbgHWVV1+kR4r+LmlSj/4Mn8bsibf/xjlH/lh/k4sbubtYeuz86anjyXr2+vXs3mkE89ld+r6MN1/tokW9fNZkvYt+qztWHX5Xu5tcj2Ks498VxcwuUP34zyRw+yvuHHL7wQ5auq3vnTO1H+8vsfxDVceO6lKH9051qUv3UjP2PZCC8U3LqdnRlWVd155/dRfn83O6uqqmpd1kf286yGV1/O7iBWVa1vZnuIr73+73ENR3eyvmFzM7sv9dOf/mOUr6r68P0/RPnFYXY/pqrqwvl/ivJtlM1Bf/Pav0T5qqr74TbmhfP5XsXxY+HdkEk2D6+q+slL2Tz2f36XtcczZ/Lz29ksm/u8/tov4xpeePHvo3xfa1kBS/jdweZWNs68/35257+q6vJ7V6L8L37+clzDjS+z86ovr2dzp4dP5nu5R3eyO6XzeT5OLMJ7Nvdm2X2CCu/bV1VtbWZ99N29u3ENi0V4jzHcd1pbX8Jd9fCKzME0bQtVm5v5XkPqILyfnF6yXlvLn8HubvZeh9coq6pqKxyrpmF7OhbO3aqqZrPspbhzN9u3+ka2dzUK5/LfyNr0eBzey11Ce1yEfezeEvYJ0ilgOoOcz/M9yBZ+Gcs430gfRBf+DmYRrme+MfzvmOeH2X5J+hyrqo49kK2RDw7yeUcqbdNd2BaqqqYH4W8NwxrW1sL18RIs4/8XaOHkpw/XAlVV86X8tgoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOC704YuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDV1YYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDVNR66gKqq6rrqWvvW8b7v4xL6fpF9QFD/30w2sq/j46tXovy1a3eifFXV02cfj/KbGxtxDe9efi/KP3P+2biGzSObUf7zL96P8mvj7O9XVZ08cTzKzw+ncQ1t9ECUH7UTWX6UvxOzw6xv6Pu8bxm1rD0swi62a7PsA6qqwuewNsrac1XV/t71KD8ePRTXMB6Ponw61i3SsbKqui77N4zGXVxD32efsQhfiq7yeUvr8ucwtNbl/du80j42G6u6Lp9KL8L2uAxdl7bp7Dl0tR7lq6pm81tRfrSEcSJt0/NF2BbyLrqqshrScaqqan39SJTfmx7GNRyGn9G17Dlsbm5F+aqqm3u7Ub5P22NV9ftZDV047zh9+uEoX1U17iZRvm9L2HKZzKP4Z59fi0vY2cnWZeefeS7Kz2f5eqLrs/eyW8Z3Of0iii8mWf84bvl42xbZc5jOv8prGB+L8otwmHj4eLbvVVV148Zfovy8jsY1dOHEYWvzwbiGW7c+ifLHds5E+TbK3qmqqo0ue463796Mazi6sxPl+0U2zuxs5POWw2k2ZxhP8v3kOsjWhnfvZf+Gqqqt7XQ/N1vX3d/dC/9+1dbmdvYBi3zMn7TwnehvhwVk41RVVdfCdVmXjxOffvpulD9z5nyUT/fUq6o2w7lTLfJ3Il2mHzlyKq+hz/r5+TQ7Izlo2ZqqqurCsxei/KVLl/Iansna9EdXr0b5zz7Pzgyrqh479UyUb7N8z+foZnZmd+F8fvZ56d0Po/zFd38V5X/8zM+ifFVVHYbv9eIgryE94gi3nZZwNSS/G7KEc54Kz3n6eT53mk7vR/nnz/80yv/nr38Z5auqfnAu69/+cCm7W1JV9aNnn84+4DD7Ltcm2fq4qurcuWwe/fHHH8Q1PHnuqSi/mGdzyK6WcKehsj46vRNRVdX32ebX9OBeXMOTT2bv5eUPsvb0vaez+WNV1fe+fzbKX/xTtv9XVfXny29F+Rd+9GqUf+2//zXKV1V9dTNbT2zt5PtOu3ezNt0qnwdXl/UNP/vFz6P83m4+//vNb16P8uNJfj7x2KPZeuDUqeys6uLFX0f5qqoTJ05G+Qcfz9pCVdXB/qdR/ndvZH3TEq6d1UsvPhHlNzfy9jgJu4YrV/K9iukse7ef/2E2h337nStRvqpqezvbxzx2bC2uoQv3UmfhuuzEsXwv97XXs72K8Tifg/7sZy9G+Wt//TiuYRTefXvszCNRfryEe5D372dr9LW1fC92Ms7uA4zCPZ+t7Xz+dzec/62v533LJL3nvYQ7Mqn0Z1GTSd4eZ+F+yWgJ9xjTf8fBfjZe7+1n/UJVvou5jPvN6W8P0n/DwTR/p0aj8LcPo/ze2TzcdjoI70RUVaX/jHS43N/Lz2/X17P1QL+Es4H0fGI2z2rYCJ9BVX6nYRTesa6qmh5m+6DzefY9jMJnUJWvkQ/TjqGquvCsamszv3+XjvmL8DmkfXxVVb8Iv8wl/DZsNsuew9Zm1jek/UJVPuYv4zd2fbgfnN7Rqaqaz5byoyAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDvTBu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWVxu6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABW13joAv5P1751tO/n+Z8fjaJ8G2f5qqpfv/5GlN8+shnln3zidJSvqjo8XET5t959K67hlZdfjfLTg7txDZ9f/yTKt24ryu9sH4/yVVV9fxjlR6M+rqHrws/oD6L4fLaW/f2qGrWshr4mcQ2tZX1DX7OsgC5rS98UkfWxky5/jrN+O8vP78U1jCfZd1l9Nuz3/X7296tqNOqifKtvP1/4m8Ui+4z5PGvTfZc9g6qq1vLnkOrC76Lr8rlTdWmbnmZ/v8/7lurD7zIdK6sqbk7Z9K/6PvyAqhq1Y1F+sYQ+ejI5ktWQLs2W8hzTxpC3x0Wf9ZEH03xtOAsf5eIwm/+Nl7C2nKxvRPk7d+7ENRxfy+bSDz/0UJSfjNejfFVVH86d9g/Ccaaq9qfhd9HlfUO/yOY+3SJ7jt18N8pXVc0q/C6WMPdanzwa5ef9F1G+rxNRvqqqVdY/deF4XVU1nd2O8qNw/tjCtURV1bGdM1H+k8/ej2t46tz3o/y9u9lYV1V1cJiNVXvzr6P8Wn8qyldVtXn2b6j+RlzDp9f/GuUff/ixKH98ayfKV1VN+2wv9s7uXlzDwTQbJ27cuBnXsD/N3qvDabZnc2QjW89UVV3/8qso/+hDeQ01y8aq0eSBKL87zZ5BVdXGevZeba1ne5hVVdOdR6L81/evR/ljW2ejfFVVHWbrkXk4B66q6kbZXu447B+rqh44kp37zRdZm+5G+RnLIlykP3fhmbiGDz74KMqffij7Hi5/cDnKV1Wd2LkW5dfG+RlyV59F+SPrj8c1PP5Ytq767EZ2Xjbv70f5qqq+z96rlu5HV74D2McfsIS9jiXsY6a64H5M1XL+DYeH2V7s9Ha2b/UPr7wS5auqfvvGxSjft/yc5+adbD3w8APZ+nSWbmhX1Xic7dk8eDIfJ7766ssof/qhJ6L83n62z1BV1bqsj+5auM9QVYuwa5jP8rGqqwej/GNnsr2zT6++E+Wrqs6eeS7KP3gqm3NUVV3/ItsHffe9rH98+ZV/iPJVVa/99vUov7uXn7E88mh21nTt42wOW1X13I+ej/Iff5LN5W/fyffO0vt7P3kxewZVVXfvZGvki7//tyh/9uzfRfmqqs2j2TnRR1d/F9dw9UrWP506kY1VP/hB9gyqquaLbO7TVb4Heent97IawrvqVVVtlJ2Fv33papR/4mw23ldVnXvyh1H+/v0l3J1r2b56+k3+16/+I/yEqsU8O1vYOZWf83z0YfZOnDye7ctX5Xcp09dytITmuH30aJS/E67Rq6paeK21VXjnaz+ft6yHd5VGLe+j790L7yGGX8TaZAl3WsN3ahn3m/f2svawjBq2trLf86TbmHv7+X2pI0eyd2IZ+07pfnBr2T2fcPpYVVV37mT7JVub+Rx0Ns/6hsPDJfwGJHyt5rPs/HV9bQm/BwprmEzys8+NjWwun/aP/TJ+Rhy+14slvJj9PPuMPqyhLWG8bS17kG0Jv0lK5w2LeX5nfxTOfeKf0qSb6lU1m2dnyH18eJrf+0rPLZdz9Jp9SLeE+V8L2+Mi/F19VdVsCe8VAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAd6kNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAz3LVTAAAIABJREFUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAq6sNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD/sm+vXXKV55mAn73r1N1qqdVSS0gIgTgYAz4kVljEs9YwHzKT+dGzspKVweOJjQFjxw4Bh5MBSeisVh/qsHfNByZ/gLuWqz5c1/e7+uld737PBQAAAAAAAAAAAAAAAAAAAMDmatddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACbq113AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrnbdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwuYbrLuA/LZf99842g0H896fzeZT/1a/fjWu4/uzVKL975kyUv3v3YZSvqhqMj6L8z//2f8Y1HB19GuXHw924hsuXXoryR0+Po3zTNFG+qqqpSfYB7VZcw3yetcnh8GJcQ6wdR/G+W+YltF2Ub5rv3z9XVS2XbZSvqur77H+oWsQ1bE2y9jSb34lr6PtZlG/bbLxcLnaifFVV02TjxHx+Lq5hMMjG/CZs0stK23P+Xq1gmKjlMnyOK3gv2zadymZj3fHxrfDvV43GF6L8eJSNM1VV/SIcJ9qwQa2gPVZlY1XThPOeqprNn0b5QRvWkHZOVVXhONPn05ZqgnVhVdVolK8NDx9n3+X29naUny/y/vHMTjZmT0ajuIb9vb0o34br/D6c91RVHT49ifJ3bn8e1/DKyz+J8lvjw7iGxTx7Dn3YObTt2ShfVbXo7mY11OW4hmGb9dNtcz7KPz2+HeWrqra2s32rdpDvEzSzrD22zfrXloNwyD44fyWu4csvv4jy9+4+iWsYDbO5/P7FbO+t7/P/oWmzMX//YvZOVVU9+fNnUX4+P43yzSDbj66qaprsOQ7afKz79k7WR+6cyfeT79zO1pe7Z7L5X7qsq6q6dOlSlH/yND+f2Nvdj/J9heN15Xtns9k0ym/v5PsE++ezvYqj8LtczB9E+aqqQZPNQZsmewZVVbNFth88Hmbzv6qqtg3nTm02Dz6efhPlq6q2Jtl4OWiyPcyqqmeuZv3b6VH2Pbx0I5v3VFW9//tPovxbb2bPoKqqltmY/+Tw3+MSnnvuZpT//NY/R/l3f/t+lK+q+vnP/3uUnz7Jx9v0yK5ts32n5UrON/JzmlRT6WZqvhm7gu3cyHyeV/DSyz+I8o/u34tr+OrL+1F+70fZGfRomI91fZftd5w9m49V33z9XpQ/OX0c5UeTbC1RVdU02fp0nh3RVFV+H6BWcF7WVDbW7Iyz/eCjSb6f/Phxtk/w+htvxTUcHv1jlL97L+vfrl3J9yCvP/9slP/66/ws/sGD8HxilF+t/fiTj6P8YJDNo5d9tv9XVfXf3v6bKP/xx/lc/vg4G+9ef+PvovxomJ87/uq9/xXlHx9ma8uqqhvPZ+/2888dRPlwu6aqqk6Psjb9p08/imvY3srGywePs3lLVdUgbJM/+9mbUX5rlJ8NPD7M3uvxdn7uePt2Nl5+9eXXUX48yRe4u2eyu5TpuWVV1QvXr0X5+SomwsusgxmG55ZN+PerqqbT7GxgMc/PsZt0Xz18DMM+v6u0tZN9xulp9j1UVW1tZ2dFo3H4HFZwObgLNwD78P5fVdVkkp13rWLfaxHulwzDe4z7W/k50TQ8d5ytoG958iSb++yeDce6FfzWcDIOz19X0CC7RTZ3yn+LU7UML3uPhmEfHY6VVVWjFdy5T/V91kduTbL1yCreibR/XMUd6XS87E6zOehsls9hmyb/LlJdl/UN4xXsnd0L9zHTTnZ3N7/ztQjf69k0b0/pbxfS9Uh6578qX5e14R3tqqpF2j+tYC6+in1IAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAv6R23QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnadRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq110AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJurXXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyudt0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC52nUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmatddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACbq113AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrnbdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwudp1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5mrXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm6tddwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK523QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnadRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq110AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJtruO4Cqqqapqnx8PuX8tWdO3ENn3zypyj/yos34hr2zp6N8p99/nmUv3JlJ8pXVT176SdR/tMvfhPX8O2Dx1H+9R++GtewOL0f5Xd39qJ83y+j/HfaKN3UIK5gOLwY5bvuKMq37STKV1U1tRV+wjSuoWqxgs9IrGKoaVbwGWEFzZMoP2jTtlBVy+y9Wi6z72I4PI3yVVXdIqthMMhrWFY23rVtH1awgv9hOY7yzSpeqWUXxfswX1XVttlY1fVZDaNxNk5VVZ1OH0T5yeggrqG67DnGs474naqqJvuMZpD30YuTu1F+tD0KK0jzVf0ymzM0y7xzGY+ycWLe5+3p4CB7tx88yN7r8Tifg57dzdaWeWuq6sP522CQjXVf3bkV5auqnp4eR/lrz74R19BNs7FqZ5Kv848W2ZpkuZyH+awtVFWNRtkaez7P1pZVVYM2e7PaMD8cX4ryVVVHi2y/5exWXsMwXFc1TfZONbWCeUuXzZ52ty/kNYTzr2/vZ+vjqqqT+SzKD8I9m77P9u6q8jnk6UlcQl2/di3K3/7myyh/5dJLUb6qqprsObbhfk1V1dZWNtacHOfjxO5ONmaPR9k4celSvrZsmqx/6yqbM1RVdU3Wt1SftYVhs5v9/ap69PTPUb7PV+k1CPfOdsbnony3zNZUVVXNMKyhy/flm3Y7yj94mLWFqqqDC2E/nW0Z1XCSzcOrqhaLb6N82+Vz0L3d/Sh/59uPovxzz1yP8lVV164+H+U/+MOv4hpevn41yp8e5+PE7z/8pyj/o1ey/+EPn+b92/u/fSfKv/XTt+MaTo7CiWy6f9eEnVNVLePxchVn8dlnrOKcp22zD0nvJMxO8+d4fjdbI9+/m4+3Lz6fjbcf/iEbJ966+eMoX1XVd9l6olvkC9xrz/4gyn/+5z9G+es3zkf5qqpunu5bHcY1tIPsbGDR53dLll22rlossudwcCHbK6mq+vrWZ1H+6ORf4xpe++HrUf799z6M8h/+7vdRvqrq4kE2F9/by/cqHj3Izm+H4VnV//+UKL01zuY+r72WjxPvvpetB/bO5WvDH//oZ1H+6DhbW/7y/+bv9XCctYWfv/VaXMNomO2rL7rs7PSLT7Pvoarq8FG2Ntzazc9OD0/Ds88mv0t58803o/yoDe87deE+bFXt7WV7qb/64N24hqMn2bzj/H7WnubTfB7d91l7HE3yse7oMDunGQ7zGyrT0+w+5ii8q9Qt8nl0t8j2S9L/oaqqluFeRXhPqFvBna+uC+8QrmDfaTbL3stB+F0eHa3gfsswew6DYf4bkq1JNm+ZTvNznidPsv4treHy5ctRvqpqPs/6p61Jfq92a5Kdl03CGu7ffxjlq6oq3QddxW+7wv5pa7KCG6HhPe3UJOwXqvJ3YtDm/Vsfjnfp3ZDZPD9vS+cMq3Byks3/0nva02m+JkrPicajfC6fnjU9DsfKqqquy97LixezPcT5Iv8uB4Osb2jDfFXVbLaKNvn9zVfQt5yG67rt7WzOUVW1DPu3lXSPK/mxHwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwF9Ou+4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztesuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7XrLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztugsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO16y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztesuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA213DdBVRVHR8f1XsfvP+9823bxjX85LUfRvmu6+IafvfH30X5t/72ZpTv54MoX1X15Tf/EX9G6qUXbkT5+/duxTVcfeb1KD+b91F+NFpG+aqqvk/b9CKuoSprk02TdXHLZf4c54tZlB+P8/7t5ORplO+63Si/eybvH7s++y7C+Hef0TdRvm3zPnZZ6XOYR/l2mbfHJnwOyxX0Lf3yKPuAZfpdboX5quEg+x+6bieuYdGF7TEeZ6q67jDKn93di/LLQf5O9P12lF/02ThTVTWcZG0y/y6zeU9V1Tzr3mo0CvuFqtrevhrl+/5JlF/FmihdHi5X8F324fxrPJnENTx5mrWHs2eyvuVc2DdVVS1m0yjft9m8p6qqX2bt4bMvPovy5/YuRfmqqmev3ojy3exxXMNweS78hHwiPByfifKzWdZJb23l7bHCteFgmM/lu8VJlB8Ox1F+Msr7x8cPHkX5Qf8grmF3O1ufLhbZvKXrs/61qmo4OB/lm2U+/9uZZOuBN374RlzDaJit7ZpwfToaX4jyVVW3bn0T5Q8OsvljVdWyy/rI/f1svLz/8NsoX1V18WJWw5mwX6iq2j+/H+UfPc7H/MPDcD0QDpfHR8fZB1TVbJ71T+f38nnwoycPo/zumaxvGA7yI7eDgytR/tatz+MaLh/8IPuAZbZf09ZB9veraja9l33AIB8n2vCcZraCI5aHh/ej/PkL2XcxO8nmwFVVjx9lfeyl/WweXVU1mp+N8j95/cdR/l9+816Ur6r6qzeyGqbTfB5870H2Xb76Utg3VdXiQjj/WmZ7uTeu52v0ts/WE3cfZ3PYqqqz29lexeI42zPqm3wPsh2kZ1UrOHgM985WYQVH4ZF2BXuQ05NsHvvTH/1NXMO//PoXUf5gLxtvP/zwoyhfVXXzp9k4MRytYO9smjXIZ66+FOX/47N/j/JVVS9cvxHlB20256iqqmU6/8rX2Ok9nWpOo3jfZ/djqqqeu/ZclP/www/iGq4/90qUf/XV7H/405++jvJVVXfvZuuR//F3fx/X8M47/xjl03PLqqquy/ZLjo6y/P9+5/9E+aqqm2/+NMqf37se1/Bvf3w3yn/55e0of+OFbL+mqurGjRej/PFRtt9SVdW12Xv5bx9lz3GylZ05VlU9Dc/BZyf5/t2589mYfXX/WlzD7YfZGvvyQbb3tbubnzv+4pfZPLpt8vXEjeuXo/zDe9kZydXL+R5kLbOzz9k0m3tV5WcDgxXcd2qbbMxuK2tP22fy/u3kJOvfxuF9glWYTbO20K7gjCW9nzIY5jUcn2Tv1Wn4Tu1fyM49q6oWXfYcmxXs+czD32b1fb73NgnvIe5sZ/cyDg/z+d/2dranvRX+D1VVR+FdzJPwrGn/fLanXlV1Gr7Xs2l4wbmqTsMxezrN70ifPZftG63iN5epJpxDDsKzhaqq7jT7Loc72Xu9iu8hvSved3kfvbOT9U/TcN6yCk04B53N8v8hPac5Ps77ljPhd5n/dmEF95PDLcTlCuYtFfdP2XNYxe9v0z62afK15XCYfcZikV/06VbQRwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPwltesuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7XrLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztugsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO16y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztesuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXMN1F1BVNRgMa//8+e+d39/7/tn/NJvNovzXt7+Ka3j7v/6XKP/w4YMo//Qwy1dVLZs2yl+7di2uYT49jvKT0eW4htnsTpQfjZ6J8n3XRfnvZJ+xrHlcQdOMovxgMI7yfd9H+e8so/RsltcwHp+J8t3iNCtgmf397yzCfP4c+66J8qNB1p6rqvome68Wy/S9zN6pqqo2fK+7ZdoWqpbLbJxoKmvTw2E+/Vp0Z6N804bvdVWNB4P0E+IaukU2fzs9eRLlJ1t5/zYZ7UT50/lhXMMy7J7i/rGdZAVU1Wh4P8o3dRDX0LZZe+y67J1ownl4VVXbpn10Pv9b9Fk///Rx9l5XVe2eORfl22XWzy9n+Xe5NdmN8kfhmqqq6vg4+4xnnr0S5XfG+T5BP83a9KjN2lJVVddlz7Gb5/OOptmK8lvb2ZyhW+TtcRh+F4N43lM1nWZ7LoM+m3dko/V39nYvRPnZ7Nu4hlmXtce+z+Ydg7yLruk02zOaDPN5S7o+HQyyvY6qqqOn96L8zk42j+4ra0tVVfsXsnXZV199Ftfw4guvRPnRMHsOu/lQV6fTp1F+MszXE2e2sz42nfdUVZ07m7WnUbjX0Db5SDFPz1i+zs9YLh5kfeRXX38R5V+88WqUr6qaz7M++tLFq3ENpyfZd7G7k53zLLp8nJlM9qP8k6O8PU4G2VnTlWd/ENdw527Wpu/eux3lt7fyefTVq89H+ePjbO5VVTXs96L89DDbi/3ZX9+M8lVVH/z2gyj/2ksvxzV8/Gk25j89ysfb3XG2punD87Ln91+I8lVV//DuP0f5Kwc34hp2X8neiclWNtbNFvk5eBMu7pbLFZwhL1exUs+kU8AmPX9dwXPcGmX/xNEK9pNv3vx5lH//g3ej/O52vjC7/+hWlN/bze/YVJOdkWxvX4ryO7vZPkVV1Ucf/WuUv/lXWVuqqjo9yfrY4WAF/VvYt8y7bF++XU6zAqpq2Wdr7FdefjGu4ZOP/hDlX3z1r6P8vYf5GfThg2z+9+knv49rePPNt6L8L375i7iGcZutcffPZ/38cJTvnZ09l+01/Prdd+IajsP1wNtvvx3lmzqJ8lVV1WX902IF57effX43yp89m60FHjzJn+P4THYOfnAlmzNUVT19mn0Xj47z53DpmWz+dTjNavjNr38T5auqhmH/eO1yfl724E62b3TxfHa2sJzm85Y2fI7V5Xcxd7ays6bxKL/T0M+zOeR0mu35LFdwZ3/1Ark6AAAgAElEQVQ0zObyR0fZ3KuqamuyHeXns+x72NrJ/n5VVddla5pZ2JaqqiaTbP616LP2ND3N+5Y+3PPZ2s7noOm5Y7/Mz5pWcD0kMhqt4o511p6OnuZ9S9NmT7JdZvluBX30ss/a03AF987OhHdktrby93KxyOYNo3HYplewpT4I3+zZLO9jJ+FzSPvHVbSFLpxDdm3+XnZhe2zDO/fDQd4gl332Gc0K7vmMw7tGu2fy39KMRlkfuQznf6s4rUtnHcsVzFviQ7+whlX8C8NheNd8Jb+lTp9D/iBW0h4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+gtp1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5mrXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm6tddwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK523QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnadRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq110AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8P/btrEmu+swT8Jvn5FarVNoQCBthwNiYHgOy293RHk9PzNeei2l3mF7oAAOWwSwGATZIQmupKjMrM0/OBdFfgF+GMy+e5/536s2z/PcCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALZXs+kCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhezaYLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB7NZsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDt1Wy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2V7PpAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXs2mCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgezWbLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7dVsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtlez6QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F79TRdQVdVv27pwdP575z+79Vlcw87eOMq/8rOX4hq+/uarKP/o4cMof/XqpShfVbVcdFH+4cP7cQ3j0TDK95pBXMN83ovyy+5elB/0v//39N9W1cbXSPXCGprsMdSyW2UXqKpaZdfo9cMfUVWLWkT5/XO7Uf7k+CTKV1W1zSjKD5q8u5vMT6N8r83ax6qqXthtN5W1j13lv2FVs+wCvbyNbnt7Ub5pJ1F+scz+flVV02Tt42qVfxNd2kausrapqmoU9vmn3VmUXy7D97mqml7Wzre9w7iG6fTbKL+zsx/lu8qeQ1VV22R9VXX5s1ytsmfZb8P3ebqG/naYtfOrZT5u6feyPv/c3k5cQ9pGtoOsr7p7L5sLVFX9+d1Po/wo/A1VVS/97MUoPwy/69k0n1v2mwtRflVrmE+EfX46H6mqapvsGk04Mev18/exW2Zt7JPTL+MadnevRvlll7XzTS8f/7VNlj84eD6uYTL9Oso3NY/yvQrHHFXVDrP5QNfm33V8H5b5+zQYZmPI6WIa5XfH+bxsb3wuyu/vZXPLqqqz8D4Mwza2WWVr6lVVj04fR/nBQf4+7u5mv+PZwdNxDXfvZ/OyyTR7n05Oj6N8VdV8ns7z8/nE2Sxr3w4Ps7bpm9v5mOGpS9eifH8N+xurcba/MI3HLXl/282XUf7wIN8v67rsWczP8rWKK5ezMeiXX9yM8pcuvBLlq6rm82zsszNax97nnSjftleifDfN185e+enLUf7B3WwPuqrq4oWjKP+nj/PzAH/3arbu1M2zcUdXD6J8VdUvXv+7KP/VF4/iGt5+660o/79+/c9RfvYo/w29eNyRz8s2X0HVKt3HDv9+rwkXGipf+krXraqq5rOsnX7++Wy95Ns7+XryBx//Jcq/8drFuIZBuP+6WmVjr0sXnoryVVXTk6x9Oj17EtcwGmVr2t0832uazbL7cLbIvqnBGs7YjIbZWHx/Lx+D3muzPY67d7J9old++vMoX1X19n/+Nsp/9ddsraSq6uAoG/+9+uprcQ0f/SmbVx1Ps/fxZJKvQb755ptRftDP+/xfh2PIaXgfhsP8HOWnn9yO8o/Ds8FVVf1htg56Ms3WW1ZrWP/b3Q9/w0l2/q+q6vB8tjewu5Of8/niw6yd3x1l628XDrO916qqWmbv0+lxPse+di1bO5uG+xtr+CTied3OGt7H4TD7IU+e5OPg8Tg7KzSdZf1tfI6yqtJL9Hp5f5uuNjThgYL5Ij9Pugx/w3ye7TNVVTVttoaYnond3cv3WGZn2R70WbhWUlXV72fjr1n4XVd99z9uiXTdabHMz+yPwvZxHd/ldJK9T234HOZd/hsGw2zdaRnuW1blbeyg8j3k0/BMQtrn7+zmZ4N3drJ1gsUazkin/3PZhu1jv7+GM4Thdzk5zdcqZuFe+s446y+X4Xymqmo2z35Du4b9jWWX/Y5h2D5+d41s7JO+T/01nJdfrqHPTq1WWQ1dF7ZN7ebfx3X8f1p6PiVtH6uqmjXsnwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPwtNZsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDt1Wy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2V7PpAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXs2mCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgezWbLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7dVsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtlez6QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F7NpgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHs1my4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgO3VbLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALZXs+kCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhezaYLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB7NZsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDt1Wy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2V7PpAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXs2mCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABge/U3XUBV1XQ2rY8++eB753/2P34c17AzPojy//kfb8Y1PPvstSj/1FMXo/yq66J8VdViMYvyZ9MsX1XV9LL8/sF+XEOvN4jyp5M7Ub7tH0X572TNw6qauIJmleW7LrtA0+S/oRfeh14/vAlV9fY772Q19LIaXnj+B1G+qmpvnLVv6TdZVbW7O47yx5NHcQ2jQfZtt6vsPix70yhfVbVcZdcYNHtxDf02a9/mXdZPrCq/j02bvY/dIv8mmt4yu0Car6qTyZMov1gtovxqGQ46qmp3sJvV0Gb3oKqqbbPvajKdRPn+MJ+StO1hdoHVcVzDajUKrzCM0oNR1i5UVZ3MsjHoqMnH0ek3sViexTX0wxoenD6O8jc/+v5z4/92dCEbO12/8lRcw+dffRblX//RG1F+urgQ5auqutU8vELeT/TarM/uFulvqGrDaVE6Fp/nQ4ZaVTYW39+/lNfQZe1T02b9xGqVv4/hFLtms7y/bZpw3BA+h67L5yPNKLvGn7/4JK7h0mHW1x3tPh3XMBxla7GPT7PvernMx6DNMmvfnrp8Na7h4eN7UX6wm42je8s2yldV7e1m38Tte7fjGn5w9Zko31tDZ3XhXLbm8+XpaZQfjfJn+ehh1s4fHJyLa0jfp9E4+657TTY/rqpaLE6i/KCfz8uafnYf7z/8Isqf39+J8lVVTbguv1rL2ln2XQ37+Z7do+P7UX5nfDnKz8+y97mqatCG70O4Jl5V1bTZuKWabA2yWeVt9Dhcs3k4/Dau4WiU7l3me3Zvv/t+lP+n11+O8pN5Pi87Nzwf5T86+zSu4eKFK1H+zbd+F+Vv3PhllK+qOn2UjZ3WsYdc4Ty9l79OsV4v3AdPD3ZU1WqVLVaE8e8ss4tcOZetxX7+5edRvqrqlZdejfLv3/xjXMNz18J98HDN6OQ4axeqqq4//1qUv3M3X/N55krWT6zyIWi14dhnZ5zNR5omHzv1wrH8kydfxTW88KOfRPlbX70b5aen+bmzn//8n6L8B3/497iGmzdvRfkbv/hVXMOFS9l6x7172TroYJTtLVRVTSfZesff//I3cQ2T0+y77A+yueGHf7oZ5auqJpNszDDvsva1qmpyku1jP/fD7Azg/eP8N6Trd3v74Ry/qh49ytZBj7/N10teuv5ilP/04+ydfvpyts9UVTUaZmdc2jX0+YuzrH0b9LMxaJtuxFfVKhzAPXyYv4/7+2Eb3c/X7yan2bNMp4ardCO9qpome5ZrmWOHl+gPsm9iMs3P1aaPYryT7088eZKd5+zCPn+5zPvb8U52DnK8hjHoYpH9jt01PMt03ekk3L89OsrnZekc+fg4Gz9WVQ2H2fu0s5ONO2az/Ozc2Vl21mg0Ts8WV3Xh//rN5/l9OH6cvQ+j+IzzGs6+hfcxXROvqlrDMDYyn+f9xCAcv83XcMYm/X+gSbjW0a5hn2gZ9vlteLa4ah3jhvy7TNvYQbjms1zD/1Ivu/SdXsNmVbpfVtl96Kfneivvq9axd9qk7fwaNh675RoOzQMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPwNNZsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDt1Wy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2V7PpAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXs2mCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgezWbLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7dVsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtlez6QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F7NpgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHs1my4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgO3VbLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALZXs+kCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhezaYLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB7NZsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDt1Wy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2V7PpAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXv1NF1BVNR4P66UfX//e+W6e1/Dx529F+Refvx7X0O+3Ub6tLsqfTk+jfFVVv81eqcPD/biG2ewsyt+7dzuu4eLFi1F+Z+dalJ8vHkb5qqrBYCfK92oQ19A22TexXE7Dvz+O8lVVvepF+a6XfddVVctuFeVfeO5HUb7XNFG+qqrtZ+1TtziMa6hl9j4O+2uoobsfxe9Nsjb6aHcvyldV9VZZ23J89lVcw+HwenyNRK/ygcsq/K6r0nzVapW1T72seayqqiYcyg7C/M44e5+rqhZn2fuQ9xJV1WTvw+wsG3s9OH4U5auqnrqYjTt2Bvm4ZbnM7uOyy+7jYpH1EVVV4+Yoyu+M87HTcjGL8l0v/y5niwdR/oObN6P85fPnonxV1Wg/m1d9cOvTuIYbr/4sys/OsndhHX1dE/ZVeX9d1QuH0s0wX/b56NYnUf7S0ZUof+HgIMpXVc3m2Vi+uklcQ9tmbWytwjWbcOxWVdWG89v8i6jqNdk7PV+G96G/yPJV9c7v34vys3k+n7i4dz3KL9ts3FJVtVhk3+X+OGsbTk5PonxVVS+c1AzH+Rh07zAbN9y+czfKX754KcpXVY0G2RjyqDsf1/DN7W+i/MULF+IadkbZ+/DDZ5+O8vfu59/19ed2o/zpaTr+q2rbcADXZf3EuXAcXlX18MFxlG/O5W1Lb5X12hcOsv2RNlynqKrqessov2rXMAY9y9rY+3fyef6Vq09F+cP9bOw1m+bj6EVl12h7+XdZq3AcHLYtq1XePk6XWTv/9JWX4xp+//7vovxL11+Ka1gssvvw+48+i/KvvvhClK+q+uBP2brTwW7WX1dVHR6Gc+xV9l1+8/Vfsr9fVZcuPRPlV/N8brhcZH3VGrZY1rNRE+jC9rGqahWOW9YhLWEa7rG88cYvsgKq6rf/+u9R/rlnno1r+PLrbA/4uWezNcjrP3wxyldVLVfDKH/hXH4fHzz4MMqfP3gurqFX2VrFcpmtg6br+lVVg36219R1a9irmmX7p5cv/jjKf/XXj6N8VdW1Z16J8j/+ST4GffudbL/r3ff/K67hxo1fR/k7t/9vlO/183WCfrjX9PY7/xbX8PrPfxrl//hBttfVdfnZt9PJ4yi/sxOOw6vqV2/8Y5R/+Cg7k7qo/Hxytdl68tdffB2XcHQu2/Pbv5TPyz75+P0o/6Pr2fpds8q/ieEwGzudnDyJa+jC/fy2zb7LeTgvrMrHPqM17FWl+2XLeX4fRqPwvFI4rzsL53Xf2ewcvSqf33bhmYTd/fx88skk+7+BdawyjMMzpem53LR9raqah+/0cJCfVeqHbexkmr0LVVX74b7fIDyTenqaj51OT7JrDNbwPqXn5yaTbJ+oCf+/raqq7Wdjn24NJ73ny2xNug3/V7Gqai9sp3vhQcj5Gs5LpeOWtp+/T036v1VxZ5WPOR4/zs40rMLz9lX5d5Xu3y634HzyMmwXqqoWi+wa6xjBpt/VIrwP6bywqmoU9peTSd7nN+F5qSY9rL6GbyJ9p9M5elVVr5f9jrSfqarqr2E9FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4G+p2XQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyvZtMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC9mk0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2ajZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbq9l0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr2bTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvZpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9mo2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA26vZdAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK9m0wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL2aTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPZqNl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANur2XQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyvZtMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC9mk0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2ajZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbq7/pAqqqzs7O6i9f3vre+cXZPK7hJy+/HOVnkwdxDbPTsyg/Gu9E+d3RIMpXVS27VZTv99u4huFgP8p/8OFHcQ2zafYsn/3B9Si/WmXP4TtdlD6bT+MKRsPsna7VIor3qpf9/arqwm9iHY/y4tUrUf6zLz+L8r+88XqUr6rqVdY+zbtJXMOyy9qntpd3uTs7l6P8e7feivKHz74U5auqxuOjKD/p9uIaFstZlG+aYZZfw7tQYduSt25Vq0rbt7yBG/RHUb7tZc9yeZb191VVvSZrW3rr6PLDPn84yp7DrFtG+aqqx08eRfnRufNxDYsuG/ssumxOMx5cjPJVVYPwmzib5fOyYTinOT35a1xDF06TX79xI8r/4b2sv66quthk78PsKJtTVVUdDc9F+Uez0yjftnlvl84H0rlAVVW3zNro6TJvY3s72Tfx3s0/RPnf/MOvonxVVfWyvmpV+X2cz7+J8uPR01F+Vfm4pbrsGusZtjRRfDAaR/m797PnWJWPg89dzOaFVVVXL2Xv05/vfhrXcPn881F+p5+NW9799L0oX1U1OcvGf6+tYb3k9CTrLw+Osv76ePYkyldVHTS7UX7cZm18VVXtHUTxbg0Ts8Ui62tG/Wz8tjvK27e9vex92tvN7+ODRw+j/PmDwyjf5EOG2t/P3sdvH96Na3j60jPZBRZZG92tsjFwVdVglM0tj0/zb2Iyzdak03xV1ew0u8ZwlD3LfpuN3aqqumU4js1LqC8W0w8AACAASURBVFqF88tw/BcuH1ZV1XIVrvmc5m3LP76Wze3+5b9+F9fw0+ez8wC3P70X5W/9+fMoX1X1zLVsLH/7br52dn4/26e5+02273h2J1+DPDi8FOX7vbxx6aVtyxo2etK1r23YJ0qvsJa1il52H+fh+t3yST52+j//8zdR/t/+41/jGgb9bBx8lp4b67K+sqpqOQ/3efr5Png3yMbB80U2p6qqGgyz8ym9LlvrWCyzc0JVVb3wu27bfI8lX8/N2pZrTz8X/v2q6SybV507/0Jcw9Vr2XnOr7++H9dw6/M/Rvnf/Pp/R/n/99t/ifJVVe0gm5Qswr2uqqq33vrw/7Nzr82SVFUagFdmXc69T98bsLu5iiAaaKgIOH6ZHz4xEY4RzBiho4GKgCBg3+lu+tzrVFXmfHDmD/BmWDURz/N9Va9TuXPvtdfe1VH8aJK9E2nvrqrqrR/cjuL39l6Kczg6yda7vb1svX785M9RfFXV44fZ/vSVl7KziaqqB/fuRfGnR1/GObz5RjZPnx5n81vTZ+dtVVWzWbZm72yHd4ur6uQ0vOcT1h2b4bllVdWTx9mznE7yOvg8PL89PDyMc9jdzeqv8Shb687CsVRVNd3MzrvSGraqqm2zZzkK+8HzAWqGzfDe2RAm4+y++9ks6+uPwudYVTWZZPPTYoB7tbth3TGEk5Nsf7q1lY3HUTg3VVVt72S9hq7L38t0TJ7Nsjv/m1v5O9Gm89sAv3dM72k/+ya7Y11VNQ7nt1F44NV12Vioyt/Ledj/q6qahWM6/R6bAc430rPTuJdbFZ+RpKVTM8Dd4PyOc17/Tafh7/TmQ/RiszHZhHe22jZ/lrNZth8Yon5rw/GQ1vLj8RD/RUF4z3uAQ7/07LIdYF82xG/rAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/pnaVScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqV50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurXXUCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvdtUJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+2lUnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6aledAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq111AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr3bVCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvtpVJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mpXnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66tddQIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK921QkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL7aVScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqV50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurXXUCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyv8aoTqKpaLLp69Oj0W8e/9+4bcQ7PvnkSxc9n3z7//7O1tRXFb2xuRvFdH4VXVVXTNVkOYXxV1XjSRvFvfO/1OIc7d+5F8fP5LIqfTCZRfFXV4fF5FP+Xjz6LcxiNshze/tE7UfxyeRTFV1WNmo0ovu/zZ7k9HUXxy73dKP7xk6dRfFXV8XE2xz73wvU4h402+x7bLouvqlosson6yl72PXzx4E4UX1X1xotXo/jN8Y04h8Xsyyh+Mv1OlkCfL7hd30XxTb7cVt+H70S2XFdVVfpn9DXP4pv8vY4LsCYbC1VV6YgchfPjjavXwgyqnj5+FMUfnpzEOWxuZLX81nQ7iu+7fGs3W4Zzy+gszuHu/U+j+KvXXolzaEbZd7lcZm/Ve+/8SxRfVfVf//3b+DNSJ8vwveqzhaKLZ7eqNlww+1rEOfSV7Yk2xnkdfGn7OIq//fP9KL4boFkxHmX7qqbZiXM4X2bxdx9ltfhigL7Vy7eej+KfPDuIc2jGYQ2avVL1wrV8P3Lv7w+j+OOnX8c5PHq2F8Vfv5DPLd0iqxv6sNfRjvINyTTs5d69ez/O4c6XX0Xxv3j/3Sj+wd2sB1pVNbqW1aCbG/kcvTXN+urz83Byqap2nK2XfZ+9Uxf2r0TxVVWz86z2mU7zPujVy9nf8fSbwyh+iPONnZ1sfrp++Vacw7IP/45xNha6ZV5Hf/5Jtre8eDGb46uqLu2HdfA861tVVT149CCKv3UzG09t3L2r6pvsnVgsB6hBm2kUP2qzc6JhjvOz9bavvHY6nWVr1c9+/OM4h08//jyKf/Xmi1H8Z59/EsVXVb3wYjaerl1+Ic7hqy++iOK/+9rtKP43v/s4iq+qOv1zVr/94p334xwOnmX9lvkir0HH4/DdTntnA5xVdV3Y0x5grUrbkH34Acsur52ODrL18tXX34xz+Pp+Vrc8uP84ir+0n58TTcMeZDqeq6q2ty9G8V/dye8DPP9cdt41nmb7/H6A+q9bhmfIA0xw7Sj8jCZrSI9GYUO7qrrT7DPOTvPe2e1b2fw0O/tNnMPfvsjupF66mPWDf/DD/F7tp5/8LYpvxvn+tgn3JGdnz6L4d999L4qvquq67L7UYoA+Qdp+29rK5qaHD7L1uqrqani/5PO/fhjncPlC9j08dyPvxZ6GdynHo6wnPmnzXu4yrH1OTvP6bTzOej6Hh1k/eTHP67+d3ax2Su98VVUdhmfAOzv5Oc8oPPdL75dMN7KxVFXxHnsjPLesqjo+yXoVfXgvdjrNv8dJOBaa0QD3vMP7d2mfYB7uZ6qqRhWexQ/QbzmbZb2vxTLf08wXWc9lEuYw3UjPFqoW4b3Y7e1sj19VNQovi5/Pw97XAL+RWy7CZznJ57eDZ9meZjwe4Kwp/C4X4RnwZvh7yaqqs1n2O73lAHNLuuYvw7uUywHOFvowh3aA9bYPzz7bcKnqw9/yVFX16flGeI7+v58SRaf1X1VVE74TaXz6HKryOTZ9p6ryM7c2XK8HGArxmO77fI4ehfPT1gBr1SxcqwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP7Z2lUnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6aledAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq111AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr3bVCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvtpVJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mpXnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66tddQIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK921QkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL7aVScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqV50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurXXUCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvdtUJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+2lUnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6aledAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq111AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr/GqE6iq2tnerJ/+5PVvHT876+McRu0kit+8MI1zODo+iuI3Fosovq9RFF9VNR5vRvGLxXmcw2KxjOKn0404h1s3b2Uf0LZR+OHhcfbvV9XDx8+i+Iv7F+IcptPsvXzy9Mso/uql70bxVVVHzz6P4je2rsc57G5m3+ONqy9H8csun1s+/etnUfy9r+/FObz3k59H8d0sm6Orqvo2W7Zv38ie5f2jv0XxVVWLeTY/jSobz1VV4+lzUfxi+TSKn0yuRvFVVV2frZd9P49z6ONn0cQ5VJP9HU1lNcMwpXT2PSy7/FkuwvGwtbWVJZCX8tX3XRQ/3cxq2KqqyTj7Hpp5OBaasyj+H58xyz6gz2rYqqrr19+K4s9m+Zo/nexH8U2XDepuFr5TVbUxzsbT0XE+tzw5fBLFX9gM6+ABlpl4emrzOrhN19vucZzDle3LWQp9VgfPF9netKpqHPZ8uj5f86fb2R551j2K4p8+fRjFV1XdupnVsTv7O3EOdx8+iOKvX8z+huVZWj9W/fRHb0fxf/zLR3EOiybbT2z2V+Iczus0ij88PojiT06yf7+qqh9l8/zXD7+Oc2iarP46Oc6+h+++/FoUX1X19Td3ovjjcI6vqhqfZ+/29kbeB53PszW7bS9F8U2Tb8zaCnsVy2xfV1U1HmfvxHye/Q3b+9lzqKra2szm2G6Wn7E00+y863SezS2PHw5RtzwfxXeLcH9cVafhWjUZ5ZuaK1ezWv7sLHuWOxt5/TcK91WzeXb2WlXVttmzGLXZPr8boN+S7nCb8Gyiqmq+zNbbjWW+Vl25cSOK3x5ndcetm9kZTVXVHz78OIr/5U/eiXPoFodR/NeP7kfx777/syi+quqD//x9FP/vv/63OId/+fm/RvHPDvL+3bJP36t0bhmggRfq4++gqgkbkWkp3jQDfI/hHLs5yfdENcnmhldfyvanH370xyi+qurdn2X3CRYn+Xt9Ps/W7Js3X4lzePAg613duPFqFH8+vxjFV1VN2myt6/rtOIc+rAHni6wOXi7z3tnuXra/nZ+fxDk0ffYsX335e3EOT5/8Nor/3e8+jOJffz17p6qqrlzO3qtHj/Kzqq3t7J3oK7sPOhrlPfE+PEMet/n95K7PehUffJDV0eNx/jdcvZLty95+45dxDvfvZPuy+3eyM7+qqivXrkXxaafhOLzrXlU1mmTPcjHP72J2aUs6rOVHA/Rbzs+yu0JteFe9qurChWw/kP52oqpqP7yv/uwgmx/Pw7OFqqrdvb0o/uQ0r512drMc5otwTxO/lFUnh1n9tx2O56qK7yuNxtncMMTvYJbhb5KaAeaWZTgexpO87jgN54aTs+ys6bmwn11V1YW9ry68l1tVdfBNdu9rZ3s3ip+H47mqajO8XzzE/ZStjeys6WyWn33mbchsbjg/z9fbCu/Y5D31vAYcjYY4N8wsw99stmvwN8TFfD491jLsE7QD/AAjPV8Y4JWoUVg3pL8hGWByi8+aFgOsVWkNuhHWTt0AtXwbPotmgDv7042slh6i7gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPj/pl11AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr3bVCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvtpVJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mpXnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA66tddQIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArK921QkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL7aVScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpqV50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOurXXUCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKyvdtUJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC+2lUnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD6aledAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADrq111AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsr3bVCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvtpVJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA+mpXnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA62u86gSqqpqmqelk81vHny7O4xw2Nr/9v19VNZ20cQ6TySSKPz09juJ3965H8VVVTRMOqb7Pc6hlFN9WnsN4mo2HL//+VRR/9drVKL6qanb4JIqfbF6Mc5ifZ8/y6HARxd+4mk+RGxtXovimfxrnsL+TjYeuzebHeX8UxVdVXb6WzU8bW/mzXCyy8dh3+dzS9ydR/Ch8llf2vhPFV1WdHt2L4ne28xy65TT8hGw8LZbPwn+/qiqrGarZiDMYj7N3e7HIxmNVVVPZetuHdUs7ymqvqqrlYiuK39raznNomij+8OAwih+1oyi+qurKxZej+PHoLM4h+xarlk2X/ftNVvdUVTV9ttZ1/Y04h2WdRvEHR9laWVW1t5fNDRuTrA6enedzy/ffeDOKn2dDoaqqJqPsezw/zcZ0k5de+YvdZ+/1P3JIew35F9F1YR0crtej0X4UX1XVddm+ajq9FuewOJ9H8S+/kK11L17P6+jzs2yOnmyGNWxVXb+U7Q1PT7IadrS7G8VX5fPT919/Nc7hdJ7VX2eLvFdRzeUofHGe9a12ttJ9YdXRaVZDLgZYJ27efiGK39/fi+KX4dxWVbW/l/WtzgaoncbjbDwul7M4h2rCMRnW8uPwbKKqqm2yuWWIWj49X3j+RrZedn3+PaY1ZHpEU1V1fPxlFP/4aXZmd/tWXrdMwlbDwUFW91RVHR5n68TubjZHV1VtBmev/5C9U+dd3m+ZjLO/YTzKe2cV9s66PhxPfd5HTdtv6fb4H5+R7Q1n8/w+wP7OhSj+o4//FMW/fPvFKL6q6ptnWS/2L19mf0NV1Uu334riR4efR/EnB3n998O3srXmqy/ydeLjL7JncfP523EOzSKrOxZhz6j6fHZpwhmqCef4qvyKSx82CvoB7tikluf5mv/Ga9+L4n/1qw+i+Fdfyvstv//DH6L4t97M+vpVVdNRdgbcLfPxdHE/61Xcu5vdl7p585UovqpqfpbVX00zwLljuLlL6+D4/l9VLeZZ32g0ynux8/Psfsp08lqcw5tvvh7F//mjz6L4O3ey76Cq6pe/eDeK//U3/xHncHCQ9Y3ef/+9KH52lvWjq6p2d56L4u/+/ZM4hw//lK1VW9vZvu7tt9+O4quq+mVWwx6d5L3cGzeys8u+8v3tsss+4/Qsi9/cyO+dxXX0APuJNlzvdnayuyFNHUTxVVVnJ9l7Od3I72x14Xs5meRndn24NxyNs+9hI6zDq6oOj7KezxDf4zys37ou7DOE/35V1XQ7q4PPB+hBboa/SZpsZ/dJ5+f5Wre5meUwOxvi7DQbT+0439PMZtl4uHQ5O4M+H+Cd2A7fiW45wCXCUPo9DNE7OwvH9HyAexXtKFur2jb/veMozKEJ70HOBngn0hwWszyHra2dKP7Zs6yG3A7XqaqqJuxpt21+XyosQeN7Gf0A93JH7RAnsJl1OF/owhzSc56NAfa3y2V23z39PfkQxuGeqOvzdSb+zeYA43mxyJ7lEOPp7HSA+3MAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/RO2qEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgfbWrTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9dWuOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1le76gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWF/tqhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH21q04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPXVrjoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZXu+oEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhf7aoTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB9tatOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID11a46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWV7vqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+h307XZakPu8E/GZmVZ21V3bUQjTCosHICJjwCMdownaEPffABfZNTHhi7JBCDkuWxtbYEmAhxE7T3TR99qrKzPnQ9gWYX4arPPE833913tz++wEAAAAAAAAAAAAAAGB7tZsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDt1W66AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2V7vpAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXrNNF1BVVWPVODTfOD6fzeMS2m6I8uv1Mq5hNuui/MHBQZTv12OUr8qvoW3auIahv4jyTWXXUFX10YcfRfmDw70ov7ebP8t2fRblv36wimsYq4/yr//gB1F+eZHdg6qqbrYT5cd19i5UVTV9dh/HJmtjP/ns4yhfVTUus7bhi/t34hqef+ZmlB/n2XOoqlqus/ZtvfrmfW1V1WyWf9ft3hNRfrnKa5i32X2c9FWrtgAAIABJREFUdeF33eT9TFX2LJssXlVV6z5rn8bmJK6hqexZVJNdQz9BGz1rszFk2kZXVR0dP4jys1k2Bt1bXI7yVVU1HEfx9fkiLqEJ5xPpMHgc8/Hf2GfTw6bLv+sHR19E+a/un8Y1fPrZl1H+1veeifI7s+eifFXVcJH1l92Q97d9m84Ns7/fVPZNVlXVGH7Xlc9va8x+Y4q2YRjXUb5pw7ZlgqWrrrsa5dfr+3ENs3Y/q+EkfJYTDABnXXYNzQTrTrtN1mdfhG3TJ3c/jfJVVU9ffSrK71Y+blkvs/HfEH7XVVU7s2z8duVSNre8dCl/li/eeiHK//73H8Y1HH/9VZQf1jeyAvq8v+3X2TvdVT4nGvrsPnbdY3EN8za7jn59HuXHIf+uhyHdI8n7qsNL16N8OnoLtyYe1bDIxuL3Hn4e17Azz9Y7/uBm1kYfn2R9RFXVusv6/NUE7dvQZN/V2Vn+Ql3auxTlm1k2fjs+/TrKV1Ut5tk1zLp87FSVfZfDmD3LYQzXQKuqwqF4PpKvGsK9qm42xTg4m9++8eprUf6vf/Z3Ub6q6rVbL0X5X7/3XlzD9cezsfTh4jtRfr3Ox9GLLluTbrq7cQ1n4VLq0Wm+j30lPGfTDFnr0KQLgDVF+5TXkC65bMM1pGYTrMWePcjW9v/sRz+K8j/+6U+ifFVV12Uzintf34truLyfrYO24T5RVdV8di3KHx4cRfmjh/nZkL3dbL2kqXxO04Qbh124f9tVthZcVXV2mp0V2t3J38exHo/y/TLv8w8Ps32//cPsDOLFcT5m+Jdfvxvl3/rhW3EN//Ov/neUf/edf4zyr77yp1G+quq9d38c5d/5zSdxDX/25z+M8jt72Tj66Chbh62qasP2qW2z8whVVR9+nF3H/t5uXMPuLOsn5rOsjR0m2IpfpWdaJ1isWF5k6+rpYP5imZ8hHIZs3alf5Tfy+Dx7IWbzvM8/P8/6uzYcyx/sZ2OvqqpZeHZtiv+/uDjP3qfj42yxY3c/P4t5El7D4cEE50HD9+niIj3fnLctY9jQt13+XV+ssn3HYcz/t+vK1WyOPYZrNsMEnd3xSfZdztu8bdnfy76r1SobMwz9BOdqw2cxn2B/YwjX37rwvFRV1RCuB4/hGcR+nf8vTjfLvsvFTj6Wv1hm+477+9mcKO1nqqq6sH1rJ3kfs/ehD9/ndoL9jXT8NkU/EZ8vnmB7YgjPZgzpOe8JztWmt3E+z8++rddZ27IO29h2gjFDE75QU4yD0xouzsN1hprmfQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/n3u379ft2/f/sb5t99+e8JqAAAAAAAAAAAAAAAAAAAAAP7zaTddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbq910AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr3bTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvdpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9mo3XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA26vddAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK920wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL3aTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPZqN10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANur3XQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyvdtMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC92k0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2ajddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbq910AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr3bTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvdpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9pptuoCqqrGq+uGb59tuHtdwdvZ1lJ91wQX8q7bbi/JN7UT52ewkyldVDevwB5r8PjazRZT/8ss7cQ2X97J3crfN/v7RvbvZD1TV9176bpT/3ad5DdeeeDrK3zs5j/KPX4viVVXVjdnDnO0exjVcnK+i/Hw2RvlhmX/Xi3n2XfertHGqGofsOrK7+Misy96ncTzNChibLF9VNWZDjyn6qrHPvqv0NjQTvA35o8hraCoroqnduIZ+6LMfaLP2seZdlq+qO18dRfmT48/jGp678XKUH8bsOQxD1l8/+o2D8Bey51BV1YR9fjtm79Nylc0Fqqpms4so383CQWxVXbr8RJT/7bu/i2uYtdm4o20vR/n18DDKV1XNuuybGMe8jV6v7kX52exqlG+avI0Oh3/VNPk3EXfZTT5+68OBRxv2E90E9zG9jeOYt7GrdVZFG96GIexnqqqaCvv8MetnHv1Idh2XDrL2sR+XUb6qqhnDuWWbz7Hn82zdaqgp2rfsOvoxG0PefP5WlK+qarrsm2iGCeaGq+w3jo+Oo/zhQT5m6Cr7rpsxXzvrx/tRvu3yZ5lObxeLrK+6e/f3WQFVtbv3TJQ/PMz2R6qqmsrm+eu6FOWXbfYuVVWtTrP2rQ3Xa6qqLl3KvqvVKnsOZ+f5mGEMR4BduA5bVXW4l32XQzohqaplH75PQ/Zd7s+zOX5V1bDO1mza7kpcQz9k6wT5tOws/YGqStvYKXY4wrWv8F2oqupmWTt/HO47vvLyS1G+quqzz7P14KeeyL/Lf/7NR1H+zdeyDdjlxWNRvqpqfZydB3j11h/ENfzV3/x9lD95+GVcw4/+219G+a/uP4jyzQT7t2kj27T5ekk67vj/wRDO8auqKlwDfHiczW9f+cPvR/mqqjuffxLlP/hdlq+qunkze6cfv/ZkXMPqPFs/u37l2Sj/8acfRPmqqvk8O+80m00wDh6zc4xV4drbOt+rms+vZzX02XddVTWffSvKD0PW11VVXZx9EeW//+prUf6XP/9ZlK+qunMvu4bLX2bj8Kqq//rHr0f5X/z8V1H+n/7vT6J8VdXDo+y801/8j7fiGtZ91j59/TCbj+x02f5vVdX+Ipsbvv9+3t/u72Vz7OOTCea3XXb+7vAwO9Nw7+5XUb6qqptl17C7O8WZhmwd8/Q0W7NpJ5iPtG2255c+h6qq3b3wjE1+G+J52WqdzU9PT/IzrfsH2br8yUl4NriqLl/N2obZTvY+npzl15Cuxa4mmN6uz8N1+fC8UzvBMsWwDjcux7yIvd1wTXuCfZ4xbKAullk/c/lK/o8sp8fZuKOZ4Fmen2f95WqZtdFtOG6qqlqF65jpNVRVzRdZf7uzk+WrqvqwbUjP/O9MMP6bh+cqTs/yPbv5Iusv+z67j+tw3FNV8UHGZoLOqmnDM63h2bchPeRT+XmArssH0ovwDGHb5O9TEw7gDnb3o3x6vqWqakz7ywnOeaf38Twcw165ks0lqqrGMTzz1U/wPqbt2wTPch228wAAAAAAAAAAAAAAAAAAAAAAAAAAAADAf7zbt2/Hv/H2229PUAkAAAAAAAAAAAAAAAAAAADAZrSbLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7dVuugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtle76QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F7tpgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHu1my4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgO3VbroAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALZXu+kCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhe7aYLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB7tZsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDt1W66AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2V7vpAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXu2mCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABge7WbLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7dVuugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtle76QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F6zTRfwSFNN233j9DDkFezu7kX5YX0W19AF96CqahzbLN9n96Cqqh2PovxQ87iGYVxE+csHB3ENH7zzj1H+yu5ulL/69BNRvqpqby97H15+5aW4hn6dvdP9uony61X+XS/H7Lv+xT/8Q1zDCy9mz+KgPY7yN298J8pXVX15736Uf+XlV+IaxmHMfqDJ3seqqlmbtU/r9SrKD0OWr6pq2mVYw35cQ9dlA4dmTJ9l/i5svoKqtsna6KbyccdQWfsUDr1qOZ5nP1BVwzxrW55/4Y24hjrPvu0mfBeqC9vXqjo7vRPl93cvxzWMYdvQ99l9bNsHUf6RK1F6vZ6ghC4bB7/5Rv5NtEM4J2l3ovjDo3/J/n5VHRw8G+XHIV8q6LrsfRrH0+zvN3k/0w9hX9eF7WNVjUOf/cAEqz5Dhe1TkzUOTZP3E2kb3VTWNlVVrftsHNzNs2sY+/xlSJ9lVfg+V1XTZNexvMjm+QeLrI2vqhrHbD4SLjNUVVXXZH3dfIL5bTo/jddsmqyfqqoalydR/g9v5Wtnq3AAlq6j9mF/XVXVhmOnJuynqqq6Jhs7PTz6fVzDlUvXovxymT2LK1fz9bu2Tdf2834idef++1F+OcFe1XPPPhPlz44exjWcHGf7PLMu7K+X2bipqmrdZ+3jpcN8n2hnkd2Hnb183HH33r0o/9T161kBq7yNHrqsbVkN2fv8yGGUTvu6dszXfNI5zTBOMC8L94DXfbYWXFU1W2RrgMuLrG25tp/PLT9YZuPg6+l3XVXPfetmlP/Fr34V5f/kjT+O8lVVy6+z/vLo/ldxDa/d+naUf/Awn5f9zU/+V5T/kx/+aZQ/f5i30enwK97yq6pKt5DDXbtxgjY6raHafN2pmYV7LEOWX3T5HvTiIFu0uTG7Edfw7nvvRfn9H+T3YafJxj7jMsvfePb5KF9V9dGn2X18+tlsjl9V1fdZn726+DDKz7v8GqouonTTZuPwqqq+z/r8ts33kPf3sv5uDBeE33j99ShfVfWr//P3Uf5372fvY1XVKy//UZS/8Uy2Hvzl3Xwd9LvfDfdvm/ybWIXrJbN5tm61aLN1iqqqO59m79PBXt6+jU22N7Czm6/5PHyYzZHTs+bzeX7Oe7XK3sfTdfYcqqoWi2yPZDbLxsHbcB8nEU4njo/zNZ8r18LzTkN2H9er/FztELbRi3k+L7tYZmch03ndtev5/u0q3F84uPxYXMPYZO/D/XvZ+HF3J38X0rNKTXrWqaqG8DeOjvK2ZRH+f1nbZf3MyUn+fyxnp9m87PAgX9Puwn3DPjxfvLOTX0PfZ89iGPP+er1Ov6sJ+qr0vFO4jpmvgladnWXPcmcn+66rKv7nhXk4Bm0mWE9Oxz5jP8HZkHAM2nXZcxgm+EfmPr4PE2xwjGkN+fvUh2ffTo6z93E+wTg6fRJtO8GznGXzy4uLbMxwdJTv+aVjhvScUFU+T28meJZ9P8HhMwAAAAAAAAAAAAAAAAAAAAAAAAAAAADgP53bt29H+bfffnuiSgAAAAAAAAAAAAAAAAAAAAD+/dpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9mo3XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA26vddAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK920wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL3aTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPZqN10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANur3XQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyvdtMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC92k0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2ajddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADbq910AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr3bTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvdpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9mo3XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA26vddAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK/Zpgv4N02QHWs9wd+fR/n5PLmCR75+eBTlrz92PcqP/SLKV1Wtl2dRvmv6uIZmmd3Hux++F9dw4/HHo3y3uxfl51efiPJVVV/c+SjKf/LhcVzDH73xX6L8qh+j/GyRN5E//dufRvnvfPuluIZ33vnnKP/mm29mBbT5fXzy6aei/Ni0cQ3L/jzK3/ni87iG5597IcqPYXc5jHlf145d/BuprGWoGif4hdQYPotmgm+i7YYo303wKpysLkf5j7/6OMo3q6xdqKp64VtPR/mxX8Y1dGEzvc5ehRr7vG3Z3TmI8t0sfyH79DrCpqGt3ewHJigif5JVaevUttm8rqqqDRuovj+N8vt7N6J8VdX52b0of7j/bFzDOIZzuzF7lus+n1umQ5/VkLfRq+Eiyi/Gx+IaludfZD+wyOans0V2D6qq2i57n/o+7OyqarbYifJjZTU0bdY2VVU1TXYfmy5fdzo6ztYazpfZ+3R6lt/HZ556Msr3wyquoWuyAWA3wXziJLyMdp59E7sTrIq3dRjlH3x1N67h8PBKlO8q+y6bJh8BrtYPovxsnvd1QzhuOb3I5/k1ZP3t1UvhGLLJ50RNm93H5Srv88/OT6L8tatXo/z5eT7+Oz/NrqFt8+/y/CJb71itskZ+GPOx1+OPZW3D2Vm211VVNVtk8/TlMr8Plw+y+3B+kbVN8y4b91RVNU02jm7HLF9VNYzhGmBYQxP2149k73S/ztbeqqpms6x9m3XZ3mtV1elp9k7vzbP1kvU6X0++9eKLUf7vfvnLuIbXb30/yj95PVsT/6d382u4dTPbf724/2Vcw8FeNsf+4MEncQ0vvnAryn/yRbYH/eS170b5qqpaZ2Offp2PQdPRV7zvOMXCfGrIxy21ztYa5uE6wVDZOaOqqv397EzD2fp+XMO3n3k+yv/s5z+La/jvb/0oyq/C9bv5BEchn3wyO5fx2acfxjU8861vR/m2ydaMKt9iqXHMnkU7wVrFOGZt7Djma7F9H15HeNBnMcv3Tm/e/F6U/+1v34lreP+3v47yr7z6gyh/78GPo3xV1a9/81mUf+ut/Dxos7wT5Xfa7Ezr3bv5GHbWZt/UbJG3Lesh+42dnXyt4rzL+ssxHL+t1/ma+O5uunaWr8XOwgNT50M2zx+GfL8tPmw0wZ7f8XG25nO+zNdLutPsWe7tZ+3besgHTw+OHkb5/f18/e5inY19mnnWPp6c5t/1wX52nnSxk+8NXDl8JcqP62zcc3qa/19VH46jpxjLr8JDqXuXsz2/qqrHnszm+cvwrNGDe/ka5O7BpSi/Wuff5XIVtpHh+3Rymn/Xw5B9Ezs7+dnePuxrJjjRUF04dlqGe8iHh9kZnaqq45Ns3BK+ClVVNYbnWuMzreFzqKrq0jPWE5wHSOeGy2V2H9o2H0cv9vajfLru9eg3smfRr/Jnmb6Ts1m6HpxvsgxhG53mq/I2+vAwGzOcn+fzuvRZTvH/QOn72MXv4wT/fwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPAfrN10AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr3bTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvdpNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9mo3XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA26vddAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK920wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP+PfTttsqu+7wT+O+cu3X17kxASEmAkwGA73gOGzEyVk0ql8iL8Av0O5lGqkplxPPGYxMasCZidIJCEWi31drdz5gF5Bf7eyr1V+Xyef2//zvbfGwAANle77gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztugsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO16y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztesuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADroZ7zAAAgAElEQVQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgcw3XXUBVVVNVTf+n59tmGdfQLcdRvhkEF/AfhqNRlH90ehzlt8YHUb6qqpomis/OHsYlPLr7ZZSf7GbPoaqqvX41yu9tT6L8H/759ShfVdWNr0f5xTD/JhZNF+UHg60o3w7zJvLGM9+K8l9//VVcw2OHV6J8V22Uf3icf9fT2TTK3/7idlzDcpm9j6NR1s9UVd2+/S9R/i9eeinK97Mo/h8/krUNTZv1Mysooary9m3duhVcQtdl38Siz/JVVWfHn0f5py89GeUH24MoX1X1x08/jPK3nrwZ11CL9OMO+8s+72/bJhu/LRfzuIblMqthPM7ep77fjvLf/Eb2XeYtdDYvrKpadvnc8KJ7FOW3htk4etCeRfmqqu1xNh/pu7yGCseQbZONnZYrGLgMx9k1vP7mu3ENF9NsHPzqKy/HNRwMwvepsmfRtNm8rqqqDweA5xcncQ27k8tRvg8HcH2dRvmqqmWXrRvNZnl/Oxhl/eXWIOsvz+b5NTx4lPUz+zv5NxHPq9qsfayq2plk79PRabZeMhxk7WtV1Sgcf+1OduMamiYdi2fvQtPlI8BBeynKz+b5utPZNOurtnd24hp2d7L5aR/O0ZvBIspXVS277D7ef3A3rmG8nbWRgybL74zy+e29e9l9GKyghvOLrI3swnnZkzeyOVVVVb/IapjsZHs0VVUXs+y7mqxgPXk4yNrps2nWvi0GeRs9arL5SFsrWC/pvo7yTTi/rcr7ma4/j/LjcZavqmr67Ltqhvm4o2n3ovzF+RdRfrh9LcpXVYWfdb38k5/GNbz/3vtR/ta3sjXtjz7J5lRVVZ/eyfYNn7z8WFzD8vRelP/Oi9kedFXVx59n96EP5wMHB3k/0XbZvKoJ50Tf/Eg4rwr/fL+Cfcs2bFyW87yGZhn+Rnhm6/Q8Xzt7dJK903fu5WuQLz73bJQ/OcvmplVVv//Dm1H+pR/+IMpfXOR70MNBtlaxt3cU13B+no1BJ9vZOLpb5uO/arK13KbJ1yArPHfWrWCvqemy+UDfZWvSZ9O8jT44zMaxly5lZzmrqh4cZe30F19k5zJefuWvo3xV1f/6+/8Z5X/9j6/FNfzlz74X5d99/Z0oP5vnbcuTN7L3cbidfxPpsOX8JB937E6ytYLZLGsfl5Wfy5iG++DDQX5mKz2TureXrTM0K9hvm4ZruelacFW+RzLayddBDy/vR/m0ZehX8D4u5tl6cj4Krtq9lO3fHp9lazaHj2dnKqqqLl3K1mwmzRNxDTXPnsYT17L++uNPfh/lqype62iH+Zr29SvZnGaync3rqqp+/+5bUf7e/WxuuL+b729cu3wY5dP9tqqqyU62fnfyKFsvGQzyvdM+bGW78H9QqqqW4bmxdP2vqmprO3sn07HP2Vk+n9jbzcZv03m+TpCeB02XtOcrOC8/Hmfn5dO9haqqwTA8cx8+hy6dGFa+l9+sYG8gXX9bxbysGWXXMQhrWMX/PsT3YQVzwy48I53+D8loFWeVzrN2frKbn/Np2+xZnpzk+zyTSdZXAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/Gdr110AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJurXXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyudt0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC52nUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmatddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACbq113AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrnbdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwudp1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5mrXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm6tddwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK523QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnadRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq110AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJurXXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyudt0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC5husuoKqqmqaadvyn5/t2BSXMs3zlNezsHET5r4/+Pco/PD6L8lVVH3zwXpT/3q1rcQ2Xb92M8odbT8U1nE4/ifL/+/+8FuV3969H+aqqvUn2PvzgR38R13B2MYvyF9PTKL8/2IvyVVW3nvxWlL+7lb1LVVWffHYS5e+99rso3/d9lK+qmmzvRPnDvcO4hqrsOkbDUVzB8fGDKP/o5GGU39/P7+N8tozyi0X2PldVNW32PjVNE+UHbZavSt/GqmYFNSyXXZhfxDVcObwV/sJ5lG6m+TU8e+2JKH9xeieuYXuc1TAYZO9T32fvUlVVdcFcoqq6Lm+j+/5elG+ax7O/v4L5SDqn6Sr/JqqbZvkVjDtGtRXlmz67hmXl30QfNvMr+Cqr77I+v9K2pcvfhcU0uxMv/fjP8xoW2Xe1iia2by6i/NHDrL/97KO3onxV1XSWfZdP38jmdVVVJyfZms31az+K8qfZY6iqqq5/FOXTMUNVVRs2cMNB1uefn2brDFVVVw6ydaemG8Q1hC10dStYUV6G7duVwxtR/uHR3ShfVbV9kI1Bm347rqEPx7HTRXYfJrv5Wu70PPuuZtNs/bCq6tL+5Sjfr2CbZTHLrqNrs05/Ps/6+6qqk9Osnxhv5fOy+Sy7jtkoe5Ztk7fRV65ejfKffvZZXMPOdtY+NWGf//A4W8Osqtreydb/tof5uGXYZHPs2Txv3/pB9k7uTPaj/NnFcZSvqhoOs36iC59DVdVglK2ddWF/W8369zeWy2wfvaqqb7Jn2dYkrmE8yNqG5eDrKN+3+VpFU+GcqPK+aryT9RMnJ9m7cOOJrK+sqnr3jx9lNVzL2seqqvNF9izvfPJFXMPX97N2+qWf/o8o/4ffZXvQVVU///nfRvmTB/fjGvoue5ZNPIbM25Zll80nmtEK2pbt7Dc++ODDKL+7m58NuXo1O6dz89m8z//HX/8qyv/k+9kaZFXVG2+/GeU//erLKP/MjaejfFVVH84t93evxDXcf5DtO967936Uf/JGtvZWVdWH5zm7FezzNOGaTdPmaz7LZTaGbNuwbcint3UxzdZ8XnjhhbiGt956O8p//En2HHb28rHXK6/8TZT/9a/+Lq7htdfeifKXdrL1u5s3n4vyVVVvvPFGlH/+xWfjGppsa6DOz9Ndmqqq7PzcYJidiRiPw5tQ+ZmEVZxJrXAcvLuXzQ0fHOdrZ+fTbB+8DdcPq6q2drL36fhRvh58/yi7l6Nx1r61g3wNchme5xys4LtchvvQVy9l++CXDp+M8lVVTWXPchXnpWqUPcv3P/jXKN80+Rh27zD7n6YbV/L/xfn4y8+j/HvvZWOGqqqD8D4cHGRj+e+9+HyUr6o6OT6K8ucn+d7ASXjO5iI88zUc5t/EYBDuIbcrONsbjlv29vK1ry6sYRqe7Rhv5X3dbJ690/PwrFNV/j6NR+E5ofB/9L6R/i9Nfjbk/DxbvxsOs/dpuYLz8uk3tQrpvxT1K1h4GoT/Z5fODZsVtNHx/8KsYHqb/sQqptiptL9M24WqqlE4r2rDNr6qarGCsxkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwH89v/zlL+Pf+MUvfrGCSgAAAAAAAAAAAAAAAAAAAID/itp1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5mrXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm6tddwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK523QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnadRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq110AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJurXXcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyudt0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC52nUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmatddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACbq113AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrnbdBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwudp1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5mrXXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm6tddwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK523QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLmG6y7gG201zfhPTjcruIy+uch+oBnENSzmfZR//PHHo/xXX92N8lVVfWX3YXp8Htdw6du3ovzRnffiGl5/47Mo3/dbUf6p565H+aqqnfFulJ/Pw2+qqtpB9m3fu38nyp+dHEf5qqrrVy5H+SeuPh/X8Oj84yh/dOcoyu9NsnfpG8so/fXR53EF15+4GuVHw+waqqoOD//0vrKqajLZifKLRX4Ny2XW1y2W07iGYWXvZDNosgKaMF9V3XKe5eeLuIYmHPu0TfY+VlW1/WlYwyTKz/qzKF9VNV1mv7EzeSquoV9k71NfXZSfz/P7WLUXpfusaaqqqvH4SvYD4fvU1Cj7+1XVDLaj/GKRj+X7PhtDDiobR1dVjdqsferCa6hwTlVVVU32Xa7gk6hln9XQ9tm4Y9Dm9zFda5ifzuIatkZZDYsV3IfP7nwY5d97L1treOxq1sZXVb34Qjav+vTDL+IaLh+E7VOXvU/7+9nctKrqztGXUX5vK58bDtvsm+jDFu7S/qUoX1V1sJs9i3aZ9/knF9k8f9Hn84nRMPsm+lnWvm2N8/ZxvgjHLYMVjN/C9ZLBMHun3/q316N8VdXlg/0o/9S1Z+IaFss2yneLfPTUDrLfOL14EOXPz/N52d5+uN5S+XrJ7CKbk5yfhfehyd6lqqq9vWzsc/lS3le14aM43M+u4Xyar/+dz7K1jq3xKuaW2Y2czvO12ArnE8s+e6fH43z97/jhvSg/mVyLa+gqG4sP26x9vJjejvJVVTvb2X1YxGsdVcsua2PbcC5QVTVss297Eq7FLpbZenZVVRPOB9oVrCE++/SNKP/6W29H+W/ffCHKV1U9fysbQ/7mX/4Y1/BXr/5ZlD9dwfjt+89m44bXX/9tlP/JT16N8lVVv/nN30f5l/7853EN0/NwXXyRraMORvkYtMKfmIdrwVVV//Zhdk7nymPZean9ncMoX1XVhffh6P7XcQ2vvPpKlH/ttX+Oa/jhd78f5X/39htR/uqVfE6U7SBXVZePgx+/kvW3Dz7K1mzefe+dKF9V9eMfvRTlL87ytiXd8WrCvaqqqsHgsSjfpePoQf4+9uH+xGyenXWqqrp169tR/o2338ryb7wf5auq9nayMeSffedWXMM7b2bXcf0wm1M9PM7WMKuqpuGaz852/k3UKGtbZtO8fRu02X2YhWPQR6crmN+G+9jLZX4fh4Oshtu3v4ry5+F6dlXVZDcbufQrODCVXke6f1tVNQrXc9Ozb8tlPmZotrMzW+P9bL+tqupwko1b9ocHWQErmFumW00n05O4hHc+yvrbvZ1sj+U7N78b5auqHoVnAP/ht/8vrqHvs4d5+eoTcQ2Tney7/EE4hr13mq8THB1l469BeB6hqmp7K5sPLLushnYF/+c3Hmfr6vMVnNlfXGTzsuVyBTUsst+Yz8P/fVjBuOUi3IdexVnznUk2fnvwIPsft2YF1zCfZe9Cu4JzFeNRNv5bht9lu4JzuX2Xjn1W8DDDZ9Gs4Fmm87J5+H8wbZtfQxf+j9wqzuyn0meZPseqqvE4G3s9WMG60zgctwxWcB9WMW4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD4z9SuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztugsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO16y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrrsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztesuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a67AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7XrLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztugsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHMN111AVVX1y+q60+AHxnkNzU4Ub9s2LmE8yPJ37tyJ8icn51kBVXXt2rUof3R6Edfwf//pV1H+4iJ/loNhF+X/289ejvLdIP8mHj5Mvsmqhw/z92k4yq7jcG83yp+ePoryVVW379yN8geX+7iGg8lWlP9qmr0LJ/08yldVdcvsN3728o/iGkbDwyjfLbLnUFXVDrI2cjY7ifJNkw8b+ppE+eEg66+rqppmGeXTPn8FQ4ZqKvuRRZ8X0YbjlnawiGtYzLP3YTo/jvLNIP8mxm3YtszvxzUM0xqyYU+1g73sB6pqucye5WDwWFxDVdZn9332PuUjhqpuOY3y2+Osja+qurgI72MTl1Bdk7VPy2XWNjVtPo6uJm3n8/atabKH0Yf56sOOqqoqvYYV9PmLysbB3TK/D3tbV6L8f38lWyfY3nk8yldV9X02t3z8x3kN83k2r1p22Vyg6fL5yMFuNsdO162qqh57LHsfB6NRlL9243qUr6qad1nbsjvJG5ed4UGUPz/Nx6Bdm7VvTdjpb4/zMeh8no0ZBsNsblpVtQgnmB9/+GGUv/nU01G+qmpvciPKz6ZfxzVUm419Hp5lbXxV1XR2FuUPDrM2emtrO8pXVTWVfZfTaTYfqarquuy7ms+z+chonPe3y0XWtlwJ+8qqqtu3v4jyO5NsTjTZzdvo6ewoynfLvI3uh9m4Y7ydr4Me3c/67MuXw/lEPDet2t/P3umTs3yf53A/XDdaZv3McLSf/f2qWvbZfKIN16OrqpomayMHg/xZzpfpdaTt/CrWKrK+qmnz9m3YZuOGV19+Kcr/029/H+Wrql7+4Y+j/NFRPid6892Po/x3n7sZ13D0Zdbnv/hcNpZ/cJzfx2uPZ/fh7oPsHlRVXT7I1o3my2z816QbdlX1MDwXceerD+Iabt38QfYDYfvYr6B9vHc3W/sajVewLt9mm3bP3XomruHzL/49yj/1RNa2vPnOv0b5qqqf/TTrJ+bn+TrBsMveh0uHl6P83XvZmlFVVVPZnKhqFtcQ79+uYAe2Cdunts3uY9+sYAzaZnOS44efxSVcuZy1Ty+++L0o/8mnH0X5qnx/4tbzWdtUVXX3bjY3fP/LrM+/tJefJ3jqmWz8dzLNzzHWMlsHXXR5+9a22fy0HWRt03AF6wSzWTYOPjjI9rqqqqbT7Fmcn/9/9u2uR67jPhP406e755VDDilStE3Tlm3JcaTYsYLECQJkscBe7VfQB/SXCILA2EB5E7JexbKSyJJl2XohJVIUyZnhzHT3yYXj7L2eRroD/H73T89/zqlTVaeqTvdMTcv1wySZz7u2cH7Rr8svlu3Bsb49zebdb6zKMzLjGg6H3L3z7a6GNZzz2R26vaZ25jRZw7zlo8+69/xf/rqft/zg1Ver/FH5XdQ/vvX/qnySnDzt3mlm8/5efuOFb1X5Ozdu1zVcphur/vpvf1LlJ+3B3CRXr3TjxO5hv4e8Ks9VTFbtedL+Oq7asW4N75Z7e929mE7753I1dtfhylE3zjwr525Jsl9ex+UaDmrPym8Prhx01/H0pDubkiSr8kKM6Z/L9nhxO4edTvvD6u03ScvyfEySLMqx5qA8G5Ik52fdmflV+T+05/9+q9y/Lc9bJclQns1Ylc/lOq7jqlwv2S37+CQ5LdvjZA1nZNozVwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAX9aPf/zjKv/aa6+tqRIAAAAAAAAAAAAAAAAAAADgv5th0wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL2GTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPYaNl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtr2HQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyvYdMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC9hk0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPTX4sMAACAASURBVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2GjZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADba9h0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr2HTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvYZNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9ho2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA22vYdAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK9h0wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL2GTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPYaNl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtr2HQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyv2aYLSJIxq6xWZ186P5kMfQ3jfpWfZFnXsFieV/lbt75W5cdMq3yS/Or9X1b5g72duobpcKXKH1378m3xd37vez+q8peXY5UfVlU8SXKwf1Dln56e1jU8Pfmiyu/Mui7uyuFhlU+Sx4+fVPlHDz+ta7jzta9W+QfHXVs4v7io8kny9W92/dtk1ffRF2dle5x21zFJLi8vq/w46dr0JP29bM1m/XVcjd11XJbj9eJyUeWTZD7fq/KzoZ8CjuXcZ7XsB6uz83tVfv/guMoPYz93mozdPHYydP9DkoxjN2avVt3/MEx3q3ySzOc3q/xYvIv8f+07ybxKT9I/U0P5L1yc9/3bbNqNVas1vJct083Fp7OnVX5cdn18kkwmk66GNbwbTmddDRm7Nr2O/6G9jpmW+STLct4yrKFveO7Kc1V+Wd7L1ennVT5JMpTzv+mtvoaxW+8Y041VF+f9MzEvn+sb19cwb5mU7al8Jt74x3+q8knyoz/7H1X+p2++UdfwjbvfrfLzWTdvSZLJ2LWndt4yLvtnYm/ezWPvPfxVXcNYvhveufP1Kr8/79bUk2S1eFzl17FO8OS0q2GY9+Pt1f1uTXu57ObBbT5JHj06qfLPzvr15Pm0e7YPrxxV+Wdn/bvl3k7XtyzL9cMkee65bv739KxrC8PQ99GH5f7G548e1TXcunW7yk/bwS7JwWHXt5yfd9dhf69rS0myTLlvOHR9fJKcPev2eXaGbryczrq+KUkWi26vaWcN4+20W27J5aJfLxkn3ZrNdOj66Em5/pckq1U371iO5Y1IMl58WOV3Ft2e3yu//3KVT5Kf/vxnXQ0v/V5dw3vluYqHD/uxarLq5g2nT7t9ww/vf1zlk+RHf/oXVf6d996ta1guuj23O7e7dad33nunyifJwy8eVPk/fPmP6hpWz7r91+W0e6f58JNPqnySDJOuj71x1M3dkuTxo+5Mw63nujlskrzzi/eq/B++/IMqP65hrHvjZ29X+W/e6ddB92bdftn9Tx9W+Vd+vx/r2tfT6dDPnVLuG45rOGuUct9xKK/DWPZNSbJcdGu5165159aS5OnJZ1X++Po3q/y773d9W5KcPOqey9989PO6hj/58z+u8n/1V/er/BfleJ8kN5/v3pEfPOnWrZLkyUn3bvnC3e58S5I8/LRbS93b7/qWoT0LkGS56n7j08+6OWySzOfdutPObrfmc3LataUk+byc/107vlbX8LR8JuZ7/TnG2bxbU756rXsvO7xyo8onyTTl2tdlv67eHn07uXxW5f/5X97qCkhy7WY3F//zV/+0ruGDT7vx8p/e6+Yd8zV8i3Pj+W6sur6GvuXu9e799I233qxrePSgm4Pu7nXP5d273Tpqkpw86fZIlmv4BqT9nmdVfiu4WsM6warcSx/Ls3NJ0h5jfPq0n3e0RRyW32btl/u/SbIsv10Y1vDtQ7vPc3banUlor0GSpDzz1Z4ZS5LZrOwbll3fMCvPpiT9cz0d+uuY8izlOr6LGsprOay6e3m56P+HaXnGZdo2hiTDtJzMl13DGobbLBbdeLuz28+DDw66fZrTNZx9u1jDuS8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID/SsOmCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgew2bLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7TVsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAttew6QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F7DpgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHsNmy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgO01bLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALbXsOkCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhew6YLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB7DZsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDtNWy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC217DpAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXsOmCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgew2bLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7TVsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAttds0wX81iyr8fhLp+fTs76EcVHFV+MaSijzl6vLKv/w4WdlBcmLL36ryl+7eqWu4ezkaZU/ODyoa1gul1X+9OxZlR9XVfy3vzEdqvzuzryu4fK8uw4X5+dVvr2PSbK7s1vlx7Gv4f6n96v8jRvXq/zu3k6VT5LlouvfHj3u+oUkuXb1WpX/7POP+hqudX3suDqp8pOdSZVPkmHo7uU6xtunTx5X+f39/Sp/sH9U5ZNkUXb00zXcy5PTiyo/TKd1DTt75bxh7GoYx/46Jt1vrNYw6Lc/sVf282dnXVtKkum07Ry6eU+STCblb0zKtrCGDnLStuk1PBJjurnPJP0zUd6KLBdXq/x06N9v29YwmfRz0FXbx66694np9EmVT5LlqhvzJ5P+nWgydMs2y9UXdQ2ZdG36smwLs73nq3ySzKddm74475+JcezGy2HStYXdnf6ZmAzdPHa+hrlTvXa26MaJxWW3fpgkb7350yp/8qR7r0uS6QvdlZxO9uoa6rs5Kf+H/f595Oz8tMrv7x/WNRwedGs2k0l3HRaLbu0uSRbL7rlax5r2zVs3qvxs1q99PTvv3ouelH3D2VnXnpNkd7e7DvOd/jru73ZrsYtFdx/ms36sOzvr7mW7bpUk06Gbxx4suz76ow8/rvJJ8p3vfKfKz8t1/SQ5PS3v5W5/L/f3ut+4WHT38vRiHX1L1x6vHXz5/effOS37yNW826vamfbryUO697rTs0/qGvYOblf5YejnoMvFoy6/7Paahknft6xW7dpX1x6TZHen26taLR5W+b15fx3vfO1Olf/4Xj9WXT/u5vI//7d/qWv44SsvVvmze90e9PXj/p3ogw/er/JXDvsa3nu3e89//xddDS98p7uPSXLzdtceLy77tYqh3Bt4+PDzKn/9uDsLkCT7e13/9OCzNbzf3uzWUu+VZ0uS5OWXv1fl33z7Z1X+D77b/f0kefioa0/v/fLXdQ03r3d9w4svfb/KT8d+f2MYy7Mh7d5rkpRnrtq1syQZx+69aizXQcc1nCcYhq6GxaJ/v93d6+7lctE913/yx39U5ZPk9ddfr/IffNT30Tt7N6v8n/3of1X511//6yqfJI+edO9lq6Ffv7tYdv3Th/f6/dvD8uzZFyfdmYT9vf6M9Tjp7uVi2Y9VY7r9idms62N31rAGOS/Paa/hKGauHJVrV+VYlyS7u12bvHqlWydYreGs0phy3tE/Evnki27N5t79bg3x1e/34+2yvBf/542/rWsYyzN8R9e7Ne2bt7p12CS5db3bO/3i6YO6hr/8yV9W+enQv0988xvdtTzc7/r587P+DOHuvOtbhjWcq53NuvNOF+V5gsP9ft7y+El35mod++Dlq+Ua9hZSH6xdLLp7uVjDt10XF91axaQ9XJxkKPun9l62fz9JJuVh8WW5B50ky1XXHqazrn88v+j32w4PuvWS84v++4u6Sa/huWzXrob229dp/15WW0MX3bbJ9mzJGv6Fun+alG0h6d+Rj67038Wv49kGAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPgyXnvttU2XAAAAAAAAAAAAAAAAAAAAAPw3NWy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC217DpAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXsOmCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgew2bLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA7TVsugAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAttew6QIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F7DpgsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHsNmy4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgO01bLoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALbXsOkCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhew6YLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB7DZsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDtNWy6AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC217DpAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXsOmCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABge802XUCSTCZj5vPFl8+v4d9YjcvuB8Z5XUOGoYovxvMq/+0XX6jySTLPpMovl1++Hfznb6xWVf7dd9+vazg+Pq7yBweHVf7Bw8+rfJIsxu467u3v1zUcHhxU+fuf3K/yFxcXVT5Jjo6uVvnd3b5veXJ60uWfPqnyd+5+rconycV51zfcvPl8XcNk6Maaw6tdW0iSMd2zPZ9eqfKrse+jn51/UeUvnvU1HB12ffRk7Mbry4uuf02SYXda5T9/0vWPSfL4yWmVPzjon4mr5b3MZTdvyaTMJ/X8L+W8J0mGaTfWXFw8q/LTsn9NkpTzlmHonqnf/kjbnrq2sCpfZ5JkmrI9Tsa6hjHdvZxkDfey7Odns3IOudrp8kmSroaxfLdMkknK/6PsY5fLve7vJ5lMurFuOnRzr/+ooowf1RVcLLr522Ls+ob79x5X+ST5yq1vVfl1jFXj2N3Ldtbx7Lzs45PszLu+ZTbtaxjTzVuGoWuPr776wyqfJPP5bpXfKfNJcnbyqMovL/saJtNy/jbp8v/27r9W+STZu9qtfd250a+XjGddmx53uvzFqp8zLJfdvbx63I9146pbazh70q29Jclk1s2d9va6uc/5efdelyRHV7p70b4LJMlHH/6myr9w9+tVfnXZr1udl3sknz78tK7h+tXnqvz+vFvXn07WsCb+tHsu9/b697LZtHs/Hdew5pPyWk5n3Vh3Oen7lpTvE8Oyn8u37eF8+bTKzyb93GvWLtlMbtQ1PDrt5qBHu1+ta5iWaz6rVbdOkHK8T5Jh0j2Xk3Y9OsnlRTfWTIdunFie92uQz13t2vSHZ117TpKrR93c6fnbd+oa3vrFB1X+zlduVvmPf9PN3ZJk97wbL79693Zdw//8i/9d5f/+H35S5Q8O+jXIzx/8uso/evigruGrt29V+YODro9dLS6rfJJk7Mbs68fX6xLu3btX5ctX9CTJUbkG+MrL363yH3/4SZVPkpe+9e0q/+Zbb9c13LrdvZ+Oq27OMF3Dnt9y2fUNw1CeBUj6hfU17Du26x1juQ9evlL9h/I6jP3cabko28Okm8O29yFJXnnl+1X+/775Zl3DRx/9qsq//NIrVf6HP/helU+Sn7/9TpU/utbPnfavdJ3LyUn5bplklbPuB8o2fXrWnSdNkv397rk+Pu7PbJ2ddWtXbd+wyjrO2HTXYTrr12JX7R7Ls36vafaku5fXrnXP5c6871vKpzpvf/CLuobj8ozzKy+9XOV/9q/9PPrR/W4Oun+1W7dKkue/3p1X/8pz3bvAxRrmLa//3d9U+ckavge6/ZVur+r4qL+Xk/JA5vJZt1d1ftrPGfZ2+/2FVnksNru73ZrP05N+L789x7ha9WP+UJ5PnqzhvHv7E6tl+Uwt+kPSY/lc75bnMpJkd7f8jXKvqj2jkyST8hzkOPT38vKyW8+dz7s95PaMTtJ/+7paw4cD03Itd7GGGsZy8Wp3p3un2Zn3+7eXF117vCjbc5LslX3LWpYQS6tyHjtrv4NJMp+X31Wt4V5Oy7NGAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/9WGTRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPYaNl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANtr2HQBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyvYdMFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC9hk0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD2GjZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADba9h0AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsr2HTBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwvYZNFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA9ho2XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA22vYdAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK9h0wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMC/s3OvPZKc53mAn6o+z3l2l8clKZMiLYoMY0W2YdhB/gh/IH9FgMCGEUVRokMokopiyjYpWqtd7nF2Znr6UJUPtOFPAQLeBXQnuq6vi7vn6eqq91wLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvdtcFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2l0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+anddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7q911AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr/GuC/hX7bdOdjWK/3rTbqJ8113GNSyXyyg/nU+jfLfZRvmqqkcXz6L88voqrmE8ym7r9Tq7F6qqnj/P7ofpdB7lR+P8mei3fZQ/OTqMa7i4eB7lp5NJlG+aJspXVa1X6yg/Hn37tnEoi8Uiyl88vYhrODk9i/KXl9m9VFU1D6/DbJq10VVV18vrKD+d3WR//yr7+1VVDx48iPJ//M67cQ2bVda+deHfX23yfuby4ZdR/vT0blzD+SsvRfmLy3zs1PTZb1ltmB9A32Xjr6by79CG3d1mcxzlx6P8Xuj77Et06YNdVZtN1sY+v8r6y5OTrK+sqtqGF6Lv8/lE02Q1NM0AY6fwscqfyvw6ps9ENbO4hmSOX1WVD8Xz5Y62zeY0m82TuIbx6FaUb8LfoaqqbbJx8HiUPRWrm/w6Xl/9PsqfHrwR15AuXfWVjSFH7QBrZ+FzuV7nbctkkrWRbTjwafr8merD9bebdbZ+WFU1GmXrTv1oFdfQtmE7vc1+i7ff+uPs71fV//xfn0X5i1m+VnF6fDvK3//611F+Mj2N8lVVB4vsM8ZttvZWVbVaZc/VbJ71lVVVDx8/jvLHJ9l1nL9wJ8pXVW23Yfu2ytuWxTxr3+5//XWUPzvJ5sdV+Tro0ydP4xqaJhu/bbvst3zttTejfFXVxeXDKN/Ms72FqqrFIrsfLsL9tqqq4+NsTXqzzO6FcZM9k1VVm1X2XI6nefvWVrg3EO7Z9dt8/LfusxrGk3wsfxzu344HWMttuqyGfhvmB1jzaZp0PTlfL+mb8ExCH67/pXOJqmrCGl5//btxDT/7+c+i/J//4IdxDX/3eTavevgk66v6Ud7fvvfB+1F+NMrbtx//5D9F+acX2f34xRe/jPJVVQ/uZ2PI115/Oa6habP7cTY7ivJff52tH1ZVTcdZ+zib5ffj0VE2N7y+yc92TEbZuGM+OYjyh0f5vuPqJtvze/mlF+IaPv40W7P5yz/PxsHryy+i/DdezeJ9vna2XWdj+ekkX6tIF9b7LhsHD7FPlI7E+wHO9lZl86Kuy+boN6vsrFNV1XjyVpR/9+38nM9nn2RnjU4W2fjt7t3vR/mqqvPzrM++vM7a+KqqxUG2h9xt8wMq6222b7iYZb9lera4qurkNBu/3bv327iGxTwbd8wX2fjtaoD78eo6ax9X67yvu7zK+uz0XqiqGk2z/vazX38c5d9+570oX1X1my+ye/qDt7P5cVXV/YtsLfavf/TXUf7ua69F+aqqN97JznacnuXn7w7m2T39d59ne9D3fvtVlK+qOjvN+rq7r+TrBOtVet4932MZh/PbdJ2gCf9+VX5e/fg4b6PTGUW4bVnj8H2iqnwfPJ3XVVWNp9n3GGIvvovHgOGZrfRmqKpRuAY5HuA9vS58b6AP9zfSs3NVVTc32TmdIeZE0/jdrPB9ogFePOjDzxjifcf0M4Z4R24Stm/p4hed4QAAIABJREFU/bQe4N2udH9jNMB7o9uwbejCvm6Arq5G4XmCNP/NZ4Tt/AD97Xi8R//dAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP+FdtcFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2l0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+anddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7q911AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3bXBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv9pdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/mp3XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+6vddQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K921wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/aXRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qd10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPur3XUBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvdtcFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2l0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+anddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7a7zrAqqq+mqqqzb4hGlcw9XVkyj/7OJeXMPR4UmUb7fZz9k0oyhfVbXZdlF+2zdxDc+fPIvy8/kir+HiMspvt32UPzw8iPJVVafh/fjo4cO4hvOz8+wDstuxnjzO2oWqqvE4e64uL6/iGk7Pst9ytVpF+eksb6O3222Un89ncQ3VZTdU0yT93DfG00mUf3TxdZS/c/5ClK+qOjp8O8rfLDdxDaM2u45Xy6dR/tHT+1G+quq1l96K8rMB+vxulT0Ti3He3/bhc1lN1t/2fZb/5w+J4kOM36rLnonp+CbK933296uqunAMOcAvWbN51t+lzdu2W2cfUFXTcTaG7Lr8Sm632YUYoLuNb4i0aWi6vK+rJpzq9/n4rWnCNjoczLdtfj/2YdsyasP5TFV1XTYfGKKNbSrrs29uHkX5V159McpXVc1Hx1G+6ZZxDdVnDdR6E7aPzQBzonAZcdQ8zkvoTqP4eJz9Dk1l8+Oqqj5aA61qaoD1u7CGx8+/jGs4PrgV5Sd91jb14Xymqurd774b5b/83d/HNaybbAw4np9F+ZvrbB22qupwkd0L23W2DltVNWqzZ2K5ysfit86z69Cl/USbr8s34XWcHORr2svr6yg/GoX9dbpOUVU3y2zccX6WPddVVc+fZ8/V8XG2Hr0N1ymqqk7CGu7dy/u6l1/6bpSfL/K1s68fPYjy58fZWLwdYO2sn2TzqvU276va/naWr3mUX67zvarRJJwTpesMVTVOjyV0+Vh8NM5q6MIzCekcv6qqbbL9sqbJ7seqqrDLj9cx2yHWxPtw/W2Avup7338nyv/3X/wiruG9d74X5X/xaTbPf/9PfhDlq6o22SNRn336cVzD1TIbS9+5la11DHGe4M/+9IMof3H5PK5hFf6YR2229nUnnJNVVf3T77JzY6+8ejeuYTY/jPLrPp9jd13YV62yNvrlF16K8lVVH3/2SZR/84034xqms6zP/unP/zbK/7v3/0OUr6rabrI+f7PN2seqqvEo66vayuaWVVVdH541CvfLmvBMRFW+l96Fc6KqfP91NMralun0layAqtqsszn6a69mY7eqqntfZec5/+Effx/lp7OjKF9V9cG/+Yso/zf/+T/GNayyY2M1O8j37NbX2T19vcza6CHGTo+fZOsdt29l6zVVVU+eZD/m6iZbq9ikE5qqWq+zz7i6zucTi/CePr+dr2lP59lawcn5y1H+4ipr46uqXriVjTt+8uMfxTVcr7L9ibvfyeY0t27n47/Dg6yvefrsIq7hf/w0W2sYNVkb/53X8zM2B7Ns7Ws+wPm9rrLr0IfzkaqqPlwI7cODjIuDbI7/z1VE6fUAfdUkfJdmE+6Dp/mqqrbNvsMoPKtUVXV1le2Dz2YDjEG34XMVTuzays80tKNwf2GAvc/Lq2wtdRWunU3H+dngo8OsfXo2QH87X2RrDTfL7JlK10CrqrrwHbl2iHM+8Ufkz0R6LdN3DbcD9BPTafZcpWeVhtCG5wG2Q5wNCd9DWa3z8d9ymb0XtR6ghrOz/KwQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPCH58MPP9x1CQAAAAAAAAAAAAAAAAAAAMAfsHbXBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv9pdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/mp3XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+6vddQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K921wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/aXRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qd10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPur3XUBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvdtcFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2l0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+anddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7q911AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3bXBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv9pdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/mp3XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+6vddQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K/xrguoqqp+W9vt028dn0xuxyVMJpMof/fVN+IamibLbzebsIA2y1fV6clxlH/6tItrWI2z73GzuolrOL91HuUfPXoU5dfrVZQfwsHBQfwZjx8/jvKj0SjMhw9lVa032f00m8/iGpY3WQ0Hh4sof3JyEuWrqm7C7/Ds4iKuYRHe088fL+MaJqOsr7p9dCfKN/00yldVrbdZfjwJ+7qqevDod1F+Nsv6uje/836Ur6raLLN2frNZxzX04bihr3zcUXEznX1A3/dpAdXE1zEfO1Vlbey2D79Dfhmrb7Pr0OddfjVt1mcfH55G+eUy72c27XWUb5u8nxiPsinqapWPg+ezeZTvttlN3bTZGPYbWQ192C5UVXV9Nm5p2/A7DNC2xP3EAG10H7axbZv3+WkjuZi+EOWfPfsiyldVzU6zOc16k3cU2z5rn1abLH9wkI1hq6r6sH3rK2sXqqq6PrunN9usn+kqb6ObyiZF6TWoqmr67DocTfP7qe3Ta5k9l+Nx/lyvbrL56flZ1jZVVY1m2br4OHwuu3E2bqqqWt/ci/LTaTaOrqpqR1l/Ow7766qqbZeNG5o2nJelmxOVr8Uub/I5zenJWZSfzrI5zVdffRXlq6puvZ59h2aA/vboKHuuLpfZfOLoIO/r2j6bo9++9VJcw+/u/TbKv/jSq3EN56cvR/lu+3VWQJutR39TRNY+DfFMTCbZPbkOF8UXB69F+aqqpxf/GOWPDvL7samwnW/ysfj9h9m4486t7LfYrPPFij6c5w8wbKlRm80nRpWNITebJ1G+qmo0vpV9QB+2j1U1n2R9/p/9xV/FNXzy859F+eOjoyj/6Se/ivJVVYtw/LYZYD15Ns36msVhln/1tT+K8lX5ftfR4WFcw/VNtj+x3jyP8uM2HzO8/ErWX663+f04CvdfD2fZc11V9fRp1k7fvpWtJ2+6fH/j++9+L8p//MtP4xre+967Uf7Jk+zc2oMnX0b5qqrbp9+J8tNmgL2qbTaGXG3ytYomHDul+W6QDbNwL36I8wDphn6aH+BYRtNm4+Bnl9l50qqqH/zwT6P8j3/04yj/+ee/ifJVVQfzbH/ir/7y38c1/Jef/DzKL2/yh2I2z+6n1XU27nh2mZ/F3Kyzdn4+z8+nTMKzIct1NkdfpWf+q+Kzc4dH+V7V2Xm4nnx5FddQTfY9+sp+i4NFPif64h+y/YXJNG9b7rySrSfPFtm6/HyWn5f/7LNPovzD3z+Mazg9zfqqu69ka5CLab6O+vjrB9kHrPNX1Lrw7Ntike9jj8bZPdmGZ/6b8BpUVa3Dvqrv84Hw1VV4JjU8S3kYrmFWVTyf6Lr8t0zfB3r27Flcw3ye9beLRfYuzvUyu5eqqg4P0xrydYI2fG9g1IYDwDRfVbNwLH7U5e8aXoVzklF4TmiI9nE8zvrLfoB+og8nFNvwPGlVVddnY/FR+N7BZJ7vDaTnpYY4x9htszMJm02W34Zjjqqqbps9V9Nx/ltu2uw6TMI9w6qq51fZfhcAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8P+mDz/8cNclAAAAAAAAAAAAAAAAAAAAAH8APvroo2+dffTo0f/x39pv/akAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/H+v3XUBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvdtcFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2l0XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+anddAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7q911AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3bXBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv9pdFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/mp3XQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+6vddQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K921wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/aXRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qd10AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPur3XUBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvdtcFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/xrsuoKqqmlGN2vNvHd+sH8UljEdtlF+tmriG0aiL8uvVdfb3x5MoX1U1n06j/HKS17BZLKL8zc1NXEPTZPfD4eFhlG/b7H6uyq/DarWKa1iFNaTX8fz2t2+X/kXfZc/1w8dP4hqms1mUH8fPZR/mq8azrIZmk9+PT549i/JHxydxDSeH2WeM++w6Xi8vo3xV1apfRvmHz/IaTm+9GOWXF1dRfnNzEeWrqtrK+pkh+olt+GjnLUNVhdehiYvIr2P6Hfo+b9+aWkf5rs/GXhWOm6oq/ynabVzCdpv1+bXJvsR8nvX3VVWX11lfNx3nY6dx+EwcDHAdunD8lrZwbTsK/37Vtt9kH9Dnz0SF4464pxiibUn7un6I3i69H9L7uarvsvap77O25fbZy1G+qmq72f1z2YT3w2yaPVPbAeZE02nY52/yNnrTZesEfR+OH5sB+pm0jW6ysVtVviB8PM3nt13Y51eTfYub5YPs71fVqM2ey/kkHzut1w+jfDu6leX7fE7Ujo+j/GaTrTNUVc3G2RriZBK2j1W1DNdcJuOwv06fyaoajbLn8voqXwc9OzuN8uM2+w4vvfhKlK+qevL4cZQ/Pb0b19A14RgyHDtdPs/atqqqw+lLUX42O4prOL+djf+6bT4vm4RrgH1zEOW7Jm+j2zZrY2dt9h2qqq7C9mkyzdqmrsvHf0eHd6L8zdWXcQ3HB1kbuR3gWMPiYB7ll8tsb2A+GWBOFM4ntn12nqCqahy2DanRJBu7VVWtu2w+MO6zfqaqatxk478v/v6f4hqacC01e6Kqjg7y3/L+g3tRvknn6FX1Jx+8H+X7Pht7PXv6NMpXVc0Os7HPpsvHLYtFOO5Yh+3bAPO6arPfcjLO+7p1eMZmEq51VFUtDrPf8v6T30f5zTK/H8+Ps/WSP/ruW3ENX3z1VZR/4+6rUf7Xv/k8yldVnbyX9RTTPvsdqqqacNzSjPN19XgjuwnPS1Xe13VpOz/Edlm4th/vdUXpb2z7rJ1/9CRrF6qqRnfejPLvv/delP/0k0+ifFXVr371yyj//r/9YVzD0fFZlN+u8+eymWbP5WadjSG7AZ6KF1/Ozu89f5afvzs4yPqJzSb7HYZ4gWMS7iFPp3kVk0m2Hrxa5/fTxdNsjr04yPqZhw+ydf2qqvOzbP/1zp38TMPhSbZ3+ehp9lz+9L/+tyhfVdU22XV4683X4xpmk3D8t83GoMurfE50GM7r1jf53sA4bt/y+e3NKuuzr66ytmk0yp/rdfg+z3SAd7vSM3zpWc4mPddbVctltt5yc5Pv86RHIWezdDW3qg3fuVyGbcMsfCeqqur+/Wxv4Ow8P+fTzoZ49+DbS991/OZDwn3wLp8TjcMx6Cg807AZYF632Waf0YbnhKqqmnDdqmnz+2kySeckWQ3pvK6qarvJ+5pUH/Z3XXgdhriO6fu3o+kA71+ENWw2edswxLt+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwLz766KP4Mz788MMBKmGI32JftbsuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID91e66AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD2V7vrAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX+2uCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgf7W7LgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPjf7NvZkh1ZdQbglXnmUyqVpJbUTUMDbYMNJsBTQDg8hC/sp9BD8Rh6EezwBDYewniizRCAW625xjNkpi9k+44L958d50TH991WrKyVmXtYe+88AAAAAAAAAAAAAAAAAAAAAAAAAAAAAHC82kMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDxag+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADHqz10AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcr/bQCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABwvNpDJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA8WoPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAx6s9dAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHK/20AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLzaQycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPFqD50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMdreugExrDfT+JrdN1FFH+yPhkhh00Uv9ncRPGLKPp/TPoo/PQ0f45VQxQ9mbRxBl2XPYfVeh3Fb26ytlBV1bbZc5iE8VVVs1tZe9jttlH8cjmP4quqVifZPbTTfHzb9VmfuLq+iuL3XfYeqqqqaaLwIXsEVVX18MH9KH4yncU5DOFz2PVZvxxG6Nf9Phsf33n4jTiHbpe16ZOzrF+/fvVRFF9VdffsQXaBLk6hqs/eZVUaX9VU1ieaeGzJ7yG9RtvkFVw/ZEuC6fw6it/sllF8VVUb3kO/y9pCVdV2/ySKX86zft2G/aGqar04jeL7PlvPvJHVPrtwnqmqGoZsvtvtsrXld//hB1F8VdXXfzObL2ezfKugr2y+bYZ0fBtjsktr8X2cQdNkNeQw5GNDN+yyCzRZn+rC9UxVVbXZu+ybfHzr99m7aMN7SOueqqouXNsNla8nptOsbui6bGwY+nx9O4R1Sw35XkXNsxx2fVb/VVXtw8fw4cufRfHrST7XPbj1MIrfd/lznDRZn9iFOTSVj49t81YUv99ldXhVVVOXUfxkmu3lVlUtF7ei+M02u4fZLJ8n+i4b5x8+eCfOYbPJavGuy57Dcp6tqaryffVtuO9VVTVfnEXx63nYnvufRPFVVX24Hmi6fJ6Ytdlz2O2fxjm0TfYum3aVxY+wJtrvsj4xnef1WxvWDS9fPYvi7711N4qvqhqGcD0xyc9vX18+j+KXqztxDutF9ixvNlndse3ze5iG54Zt5euJZ8+z8enB/ayO7rv8vG27zcaWfWXtuapqPs/exdX1eZzDy+dZ7TSfhWP0COeO65OsPbz/hS/GOVxevIriV4tsvl3O8/XIbJJdY99nz6CqagjPOK422Zy/3eX3cHp6O4rvtnnttAj3fGrI99UXbba3v9lkOXTtyyi+qmpxktXy8yb/zufpJJtv+3Bf/d133o3iq6r+/p/+NYr/vW/+QZzD9jxrT5NZ/i6H8IOldF2V/v8314gvEWuaLIn4FkY4Y1lMs/a4nufrsu//7V9G8X/0h3+cJTDN1yNvv/f5KP4nP8t4oFJwAAAgAElEQVT3k2+usv233/jqV+Ic/v2D/4jiz+5mdcur53nt9OTJiyj+wYN8jX11lZ2RTCbZPDGdZ2uBqqr797M96YvLfG1Z4bdv62X+HC4vs355/ipc163yddlNeA+vz7M1flXV+cUHUXwXrifeup99o11V9eB+du54HY7xVVXDLqw84rIjL94m4Xdjs/B3MFUVP4f9Pl/fduE10u+bx3iX02n2LsdYT6S3MZ1l+38vX7zOEqh8L3eUJVV4kfk8/9a867P1aR/+7mCMfj2bZe/y5jr/nd7paVa/NeG3mMMILXK3zb4VGkY4Q05r0EW4L7/fhd/UVtUu3A9O9/+qqtJjmnRfv6qqD79xnoXzxNV1/u1b3C9HeJfplD0Nf+84xrfq4c8dazPCc9yHc9UY8+1yNcov/AEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7VHj9+HF/j0aNHI2QCAJ+MMeY63vg0zPnH0B7SHD4N72EM6XM4hrbwy7SHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA49UeOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAjld76AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOF7toRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Hi1h04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOPVHjoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5Xe+gEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhe7aETAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tYdOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDj1R46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOV3voBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xu2hEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgeLWHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA49UeOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAjld76AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOF7toRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4HhND51AVVVTTbVN+7Hj57PTOIeXlx9F8fPZx8///wy7KLxtJlH8dJLFv9FH0ZdXV3kGfRfFz+fzOIfddp/F77O2MJ2O0LWHIQvvs/j/uUoUvVouo/j5PH+O83nYL5dncQ7nF9dR/GKR9Ynrm8sovqpqtVxF8We38+fYtNk4v91k/bqq6nr/OoqfzrL2+P1//Ocovqrq7M5bUfxv3D6Pcxi2Wd/uJtsofr1eRPFVVdtwnmmbw5eATTPGVbJ5Ik5hyOqeqqphyOqWdoT6Lb2N7T4bo292L7IEqmq9uB3FT9u8Xw7t3Si+H7L5uvZ5W2hqll2gexXnUJNszm5GGN/aNnsOz58/jeInI9Ty6dqwmrAtVFUzZHVL02RjS99nc+WbHMKZIlzjV1U14fjU9SPsVTTZXNWk7XGEpWUXXmS7zdpzVVUNWZtezddRfNvkD7LrwjbdZs+gqmoWrtO763B9OkK/bsPt2KYdoZAOL3GxyffvLp9m13j/vfej+OvLl1F8VdV2m61PhxHmqjbsV11Yg/aTfJ5pmqyGXC7uxDnUcBGFT0aYrLoumy9ns6wtXF89j+Krqk5WD6L4vs/2W6qqZtOsjt134Z54uqaqqvniVhT/+jxbj1RVzabZGrvCM5rF7LPZ/6+q3T4bWyZD9h6qqtIRcjbJ9hmqqvbhOn3ePozim7AtVFUtZtk9tO0IZwNhLX1yKyu+dmHNUVXVVHaWPp/nz/Fy/7MoPt47q6pJn62rJmF72o6wD9o02fjUVn4O3od72q/DWny5zMamqqpVWEO+ePGjOIezO1+N4u/fz8eGm6tsjfviVVZ3fOlL70XxVVXvPMjOHTfpPkFVXV9m69v1LPymIVwLVFXttlnlstvltXwbfqezWGZj/MuX+fnGdJLdw3qEb9+qsnfx/HX27VxV1b27n4niby2zMXoxz9vjZp8dnk6DbyD/11e++MUo/m9/8IMo/mtf+vUovqqqDfcxv/v9v4lz+L2vfTOK3+w3cQ7pbu6QHuaPcMbShG16CL9BfJNDFt+G33wtFvn3BP/yz9+N4p89zeu/09vZXPWd7/xZFL8+y/c6fvTzJ1H8w7N8ffv59z4XxV9f5+vb9eokin/yNFujtyOcDTx4eC+KvzrP9vWr0q/dq7pdds7Tdfl3Z32fretOTvL1RN9l+wQ3N/l8W302UbRDGj/CXBfOVdN4R7rqM2G/vHsvG+cvL/LvMvbX4Z74CB+1puVbetY1mebfEO732fi27fJz8PS3MF24rqvKn0PTht+GhGNTVdVkhDk7ziEc354+y/bVX77Ma4a3H6bn4HEK1Yf9ar7Ik9ht09+4ZePTPvyN3RtZv4q/J62qm01W+zThQr8foUFutzdR/Bi/XT09y87LLi6ys4ExfrM5nWRzfjfCWXylez4jjG/p76Jev87G+W6E376uVtm6qh2hPW3DMXof1k6X19m4UFU1hLXPdDJC7RSWTu1kjDE2P+MAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP5/7t27V48ePTp0GgAAAAAAAAAAAAAAAAD8P/hdGACftMePHx86BUbiXfJpMkYd/En1ifYTuSoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAnwrtoRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Hi1h04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOPVHjoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5Xe+gEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhe7aETAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tYdOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDj1R46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOV3voBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xu2hEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgeLWHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA49UeOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAjld76AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOF7toRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Hi1h04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOM1PXQCbwxV1X3s6LbNM3j48LNR/Pn5R3EOs9lpFD+dnUfx+/0uiq+q6vs+ip+M8DLbxSSK3+33cQ5d//Hbc1VVE/7/ZoQ+kUrv4c1FsqssV6sofhjhLjbbrD2tTpZxDotJNtQ/efY0ir//8K0ovqpqGIYoft9n8VVVw24bxV9eXMY5nF9kY+znPvdOFP/2wyy+qury8kV2gT57D29soui2yfrU0GTzfVXVvnsWxXfNrTiHSbuI4keZqsKxYaisT7Xh+FpV1Q/ZNW62eQ26WDyM4qdh4XEyQnuMDXn91zZZe0p7RR/Wn1X5PUyn+Tyx7y6i+KbN59umvR3Fv/vZX43if/jDP4viq6rW63Bsuc7Xhs0kqwFvtk+i+Nn0QRRfVTWZZH2ib7K16RvZu2jCNdUb8zCH7L/nlXxVG85Vq9W9OIePPvzPKP7k4Zej+G7I54l+Movix6hb/vrvfhLFv/PgfhT/5S98PoqvqhrCObvv8rplW6+i+PMR1tjnu+so/qd/lc2Xv/Nb34ziq6qGbVa3zOb52rDrsvXtfL6O4l++/jCKr6q6dZLt303afL7d99n+226XvYeqquUyW2PvwvJtOj3JLlBV+yGrxSeVtYWqqgrX2NPpyyh+1+V19LyyfrleZnNdVdXFxc+i+Dt3svlyu8nrlvn0LIrfbP8rzqEN1yRNm9XhVVXtkPXtfsjm66bN986GIXsOV9fP4xyWi2zObvbpXJWv65o2PL+d5DncPrkbxd9s8rOBdnoTxU/a7DlMmrxfP/0oO7N78PDtOIc7d7K9sycfZWvDtvL6b7nM+vXdt/L59qe/+CCKb8KzrqqqzSb7vuQ3v/5rUfwY69su/MZlPs/q8Kqq23eyvv3Ry6wGvXOWr9Fnk6xPTMI1VVXV9XW2xr53N9uPHrr8Ob66yPZbhtv56el6lrXpO7ezM8Oqqu0mm2+Xy3C+7D6TxVfV1XW2Hmjnn4tz2A1Zn/jW7/52FP+dP/+LKL6q6htf+VoU/+xZNj5WVX14le3L31u9H+dQ4TcJXbjvNMYZS3rQM5+PsTbM7mQ2zcbY730v7xPrVTZG/+mf/H6cwwc//kUU/28f/DyK377Mz/K/+mu/EsVfXmXja1XFfaIf0m9LqiaTrE2fnmVrmvXJCGdV22ydvwzPFqqqXoW1+K1VtpdbTXb2WlX10YusTa8WeQ6TsE90I9TiQ7p1Fe75jHE2sArP7O6+dSfOoQvX6TfXV1F8elZWVXV+ke11rNN+XVVdWLek7XGbHhpWXnttt/m+1T5sj2PUwdNptg/Zxd9V5HfRpD8qSttzVS2W2b7RNKx73n6Yf/M1nWVtYYz6L/2NXN/n9VvanFbrbJzfjHBOdHIr/TZkhOcY9u1d+JumYYT2uAzXt4t5fl52fZWdY89nWR287/LnmNbB83B8rara7bNvM25usr3gqnyq2e6ye+i6/PuUJvx2bR3+9rWqajLL9t8uLrNafrPNa9D1SfZ9yzDCXLcL+3Y3Qp/Yxd+XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhPH78+NApAJ+AR48eHToFRpK8y29/+9u/9G/tx74qAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJ967aETAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tYdOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDj1R46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOV3voBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xu2hEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgeLWHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA49UeOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAjld76AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOF7toRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Hi1h04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOPVHjoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5Xe+gEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhe7aETAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tYdOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDj1R46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACO1/TQCVRV9f2mrq9/9LHj5/P34xyG4VYUP59v4xz6/nkUv5jfieK7bhfFV1W1zT6K31cX57Dvsmt0++weqqpqyHJo2yaKb5osvqqqqfAawxDnUOFzWK1PovjNdhPFV1Xtw+ewvclzuHOajW8/+vGPo/gP+7xfv/Puu1H8UHl7vLi8jOLPTk/jHO7euRvF32z+K4r/wue/HMVXVbWTZRTfba/jHIbhRRbfraL4ps3Gpqqq2eytKP7yJmsLVVWLMIdJZW3hjXTOzsaGofrw/1ftu+weVuu34xy2u6sovgmH2Fkzzy5QVdtdNl9Opvm7bJo2i69JmEAYX3kN2XXZXFlV1dQiiu/7V3EOfWVru67L3sW3vvWtKL6q6vrqIoqfNtnasqpqt8+eYz9kz/Hq5sMovqpqvfpMFN80sziHJmyPTZv1qaqqGtI5O5yvh3yvIs1h6PI19r17X4zi9/vzKH66ymrYqqoPn2T9qplla9OqqvfezWqfp0+fRfHzyZei+KqqF7tsPfL8Kts/rKo6Wz2I4r9wO1/ffu8nv4jid2H5dnWd/f+qqtPZe1H8fp/PVdXcy3LYZTXsarmO4quqri6z8e30JB9bqsnGyL7J9yqurrM6djnP9oyms7xm2GyzvYbJNJ+rpmH9te3Povihyerwqqq+z57DdIQ19smtd6L4q82TKH69yMa2qqruJosfmnz/bjdk+y2LNmuPVVWTPruPvsK6Y4R90CHcJzi/+Xmcw6112CbDfYJ+hDO/arN1Vb/L12VN+FnCIh/e6mbz3+zcW48l11UH8FX7XLt7emY8nhk7jhMT5AuQoDggBQRCAvEt5gPOh+ANeAkg7iQBORdHjp14Yo/Hc+k+tzrFg4WEeEHyv5Q6oN/vfVWvU7VrX9be1VntarXM5j6rWT7WXZxne25Dl+/Z9X02GV8vs/H6yWc/j+Krqu7f/80ofphl8+iqqmPLaj77cN+yqurb38ruwyE8V5FX5auunmfzr3V4nqCqat9nmyRn4R7yZpetqaqqZutsvD0/y+vJrcvGmhfPsvtwfjbC+jY8X7IL+4WqqsUx62PX4fq4qmrosrd7t83W2McuPwq5WoZ9w5DX747hXP76abYe+YPf/04UX1X19//8/Sj+ra+/Eefwbz96P4r/ztv5s1yH7Wk4ZuNMuIVdVfk5xhGmTrXdZn3kX//lX0fx7777zSi+qurV+69H8Y8/zefB7/34gyj+3v1s7/T+vbzms9lkRZ95eG6tqmq7zcb8e3ez81ZVVR98lO0vfPU3skX2hx9k40xV1TE8K/7aV/PzUvuw3tGFa4GrsE5RVbU9ZPfxcBhhZXbI7uNikZ+rWC6zNr0+y/qG1WqMz3HS7wbyDNJj/+l3KMsR7uPNy5tR/PPn+XvZWlYPng/Zfdjt8rVl+k7N5vmz7Fp4FnOEifBikd2HuD2F8/AxpPOeqvzbrJduh/u36TdRVbVP66DHvD3euBF+FxXWW6qqDofsXi4WWf+4WOS13D781vD8PBtnqqo+e5ydG0u/fVgs8j66hROP58/zmvZFWM/dXWfjZRuj4DLP3okXV/l7PY/n4nkfuwr3J9IVzbDL98F34TWGEb6/3cY5ZH///CLfW0i/Y2nzMc7sh98AjzB3uhrhO2IAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+LIePnw4dQrA//DgwYOpU4D/VZs6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOV5s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABO13zqBKqqum5ey+WdLx0/DFdxDsNwEV5hGedQleXQ98fsz3ddFl9VbTbL4ochzmF3nbWHEVKo5XIRXiFMYowfEVou0ntQlTbp/W4bxa9X+Xv94sWzKL4t8xw+f/48in/rrbej+DbLh5rd4RDFf/zxoziHe3dejuJXi7M4h6rspZjPbkXx+83jKL6qqs3uR/GrefZeV1XV4svPOaqq+vA5DEP+G9qQvVdn8+weVFXt959F8cuzr8Q51NCi8K6y+LQtVFX98N9/mOXQ52P+73/3O1H8YdNnCbR8nGiz8L1M516VT6W7MIdRZn/hjziOMAedtaw9HY834xz6/edRfKtXovjLi7xv2YXtse83cQ6LRba+Xc6yudezZz+N4qvy9jgM+Rq7q2xddRyhdzgOWXtold2H1vK15eGYzb+6McaqVTbvePbsOop//NEvo/iqqlfuZfO3my9n/WNV1V/98C+i+FW4Pn2+fRrFV1Xt99n69mKe1jCrLtbZfdjssvZYVfXN33ojir/eZ8/ibH4viq+qmoVz0H6f9y2HffYsZsMS+LcAACAASURBVPPzKD4d76uqunCLYrvP6l5VVat1tkaez/I19qNf/XsUf/ZqNnc67PN5y2pxN8vhkNUZqqpq9lIU3rV1FN+GfC5/2O+yHLpwjV5Vs3l2HzbbbJ9oM2Q19aqqRVgHnQ3Zb6iqai1rD4d93p5Wy2wevJhn879Hn74XxVdVXd54PYp/9eXfiHN49vyjKP5i/VqYwSqMrzoesrXhYpnXCfo+mze0EdZl2+usf5l14b7j2Y0ovqrqvGXztw8//DDO4eZlVn9bLrNneeMyn8u//8FPoviLG9lzqKq6ezu7j8N5Nl5XVb14kZ2ruLxxGcUf5/lY18JrPHmarydu3crmHYewTrA9jFBPDuvBq0XeR88WWZveh/W/oWW1u6q8f9ztsrVAVdX1NhvrFnn3Vscum0sf9tm8Zb7M7+N8FvaxffZeV1XVkF3j2Gfv5XGT9y2//c47Ufxnn3wS5/D217P1xPf+6d/iHP70j78bxS+GbI9khK2q2vdZ3/LZx3ld/Qff/48o/vfe/d0ofjHPb+Tf/8M/RvFf/Vp+xmaxzOZvty6zgWI+z+cMy/As5RjnKlqXXaU/5lnsw/nbo0+yvYXjCHXQN9/6RhQ/H+G9TOu5j37xcfb3R5iDrsOz6iOkkB7fqxGOvtU2nEsvw73T+QhrokN4Rno2yx9mXn/L1gJ9eA+q8u9YVqu8Fpvex9k8+w3dCC92egZwjDOEy/BZjrHGbi3L4ewsW1sej/l4m15jFt6Dqqo7L2V76U+ePoniuy5/JxaL7D7Mw/e6quo4ZHvAFzfy/YknT7Jztdtt1s93I3zvmL4Tu12+vk33SFrL7sMwwrcPs1mWw+UyP2uU/ozzcI9lf8zb49VmH8WPMQdNx7rLcH+kqqrvs/5tGc47xlij92E9OJ3DVlWtz8K6fPgBb3/Mzyodw7bQhWfVq0b4tH6EuXjXncS/ewAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADg/6iHDx9OnQLw3zx48GDqFODXok2dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnaz51Al+YVdfd/tLRw/CrOINhWIdXWMU5dN0QxR+Hqyh+1nVRfFXVrM2i+GGW3YOqqv1uF8XP54s4h/kiu8YwHLP4YxZfVZU2h7Oz/J049GF7iO/jIfv7VXUe3ofPn30e53Bx8eX716qqxSL7Df0+f6/XqxtR/P37cQp1tsjGid113p7abBPFz+oiil8sXo7iq6qG4UUUf9ifxTm0yjq4ofZZAl3eFroh+w3rlvfR1V4KL5C1haqq/tiyCwzLLDz881VV33733Sj+b/7me3EO7/3kvSj+zTfejuL3130UX1XVzbI5aIXz8C8uMe28pRthLl+V/YahD59DVQ3hEvVsnT/LF9fh2nB4FoUf9ufZ36+8fxzakziHY9jHHvdZm744/1oUX1XV99l96Lq0zlA1dOHcZ8jWx1/IrtF12byjdXnfknaR83lePvv8OmtPT66eR/Gvf+3rUXxV1fqYvdf9i22cw7u/+04U//OffxjFP372aRRfVfXy7XtR/HGE17rfZTXEruVjVQ3Ze3XebkXxXeXrsn4I+7eWrdGrqhaLtEGE9ehDviiaz7Oaz7Or7L2uqlr0WQ4tXZtW1d272brq6fOPo/ibFyMUzw5ZTbzN7sQp7PqnUfxifjeKnw35e32o6yyHEXb9drusb7g4z57lfv9JFF9VVS1bY7cR9vxSQ/ssvsbxmO0NHPtsvDw/z+Y9VVXbqw+i+LPLN+McFotXovhNnz3L5Sytw1Z14Zi/H6FWUS2rqw9hWb6q6qWbWZs8DNme3aHPf8STz7O15eWNm3EOF+dZraK1bJG+P+Rz+fV5tr49bPL9jVVdRvHDCIP+JtyLf/48uw+rdb7nt9tn+wvzRdYWqqoO+2xd1sK9hcvL/L1+9iKrO7V5Xr9rXdamf/p+NmdYn+dj3RuvfzWKP5/lZ5WO4Tx4ux+hf1tlZwrm82yN/fmT/Azh7dvZs6wR9pCHYzZv6Crd68rCq6puhn3Dzw95IfTll7L16auvvhbn8M/f/6co/rvf+qMo/nqTnTOqqnr65FEU/9njfH3753/2J1H8fpvtT3zy6BdRfFXVo1+Fa8PzfG34jW98JYpfr7K+pU/Pgla+ZzfKuYrwEn1Yb6mqauF64GqTzaPXq3z+l54vnlV+1ugYrm/v3MvqyS+eZrXgqqoXz7N+frfPz5ofj9m7fXaWr2/T9jQP5y37Q17zOYTXWK3y/Yk+rLkc++y9vL7OzxNcXGR7funxv6qqzSb7Hat12D+OUDM6HtM+Nr+Rs/A86OGQjxOHQ7ZGTr9JSr/L+uIa2QL1OMK5ip+9/34Uvw7H6+Uyr//twvpfP8K3XYuwjtn3eQ7hEedan2Vj1WaTz52urrJrXF7m4+0s3CO5Cs8Q3r6d7R9XVe322Vg3m+XFs0M4bzkP2+PzTT7/u7rO2uOQLk6ragjXVccR6k7z+bT9236XP8tj2EGuz0Y4Ix2O+bt92B5HmEen89g+XI9UVR3Ca7TwOVSNM58HAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYBoPHz6cOgVgZA8ePJg6Bfg/oU2dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnq02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnaz51Al9oVbX88tHtbpzBUB+FV7gX59B16yh+6A9Z/LCL4quq+j67xuGQ/YaqqjabRfGzeRZfVbVeraL49Fnsd0MUX1XVZl0UHz6GqqparrJ34vHjp1H8an07iq+q2myzNr1cZPegqmq1zq7RuvBhzrO2VFX16eOfRPHH7jLOYX4zu49dy+/DMLTwCll77Pt82tCF7anNjnEOVVkfOeuy+zAc87bQhe/VMMJ9bGGb3u36OIef/SzrG95+6+0o/nDM7+PQL6L4P/juH8Y5bHfZvGPos/vQsltQVVV92JxmXf5eVpfPv6Z2DPunIZw/VlUdw/5p1+c5rM6zecNu83EUfwjWxv+lm2XX6OpmnMOh/zyKn89ejuKPwwhronYjih+GfH07VDrW5O9E68I22cJawwhry667iOI/+uV7eRLhD/n6K29E8f0I9Za+22fx/SbOYTnPnuVbb/5WFN/SJVlVtfC9HGO83e/Dufz+cZzD7ZtZP99X9jCOQ74eGY5pmx5hzO+yyfS+/ySKb7N8zjCbnUfx5+t8b6A/pPfhlTiHLtyqWS3vRPH73S+i+KqqRXs1ih+OeSfbwneihm0U3nX5b1iust/QH7PxuqpqNk/rBNm8J527VVUdwzpoHfNxYtayevI2rBlVVW03n0XxF2e3svhFPtZd9dlY88nTdP+36vatbN6y359F8Yf+WRRfVbUIx9sx+uguXBN1I9S0075hu8nid1fZOFNVdfdONuYf9vl5gC7cS7/aZPPo7eY6iq+qevmlrH/bb/NnudlnY3Z6HqGq6tbNrI/dhYX53Qi1isUiGy9n4f5GVdWzZ1k/ffdutqYZhvw33LrM2sKL67xv+cEPvx/Fv/56Vjt77bX8zNcvP/owy+GVfG05hHWnTz/Naz6tex7Fn51n64Fbt/Nn2R/Cmk96xqaqakjPCmVrgeUyr7ccwnOM7/zmm3EOf/e334viv/U734pz+NFPs/vwkw9/FMXfu53Ne6qq7tzK3stvfO3bcQ4ffPDjKP5HP34/iu+P+b7jO7/9zSi+G2GDomtZDXK7z+Z/Y+yxpCWb2Qh7LF14vuQ4xlmjsA45C9fY+RnGqn/9lx9E8ffvvRTncOdOVvO5DOfRT5+8iOKrqjbhGnu9zut3FzeyutONi/yM9HqdrQ1fe+UrUfzjJ4+i+Kqq66usPWw2ea2iP2S1ihb2jxcX+d7ALqy3jNBFx3a79FxGvr+RXiMdK6uqrq7Svfh8rFqF37G8eJGtj7vwrHtVfs57G44zVVV37mZj9j58r7e7/Dek36fdupl/k/TkSXYW8/w8G6+rqtZn2Ttx2Gfr4/0uryd/+smnUfz9e3m9ZLu9iuJv3cra0/6QjxPpeLkP15ZVVV3Yz+/CHPphhLFuE9bVRzifkpY7hhHOaadHCtI19jDGNyRhXX6Mb6kr/B3ps5zP8m8N0/5pjO/Bh0N2Hxbz/D7k3w0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPA/PXz4cOoU6sGDB1OnAAD/753CmA+cHnNx+PVoUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqUycAAAAAAAAAAAAAAAAAAAAAAP/Jvp0tWXJd5wFeuTPPUFVdPaEbA0EANCgFqSEUZoSfph+w30WWHXZQYVOkKIEiGgAx9dxVdaZMX7QUDuvKwp/2OUF93/3KWmdn7r3XHgoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhd7dgJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHC62rETAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB0tWMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDpGo6dwFtj1XTzg6Nbn/+Mrvsgit8dvo5zaGEOra2j+HHcRPFVVd20jeL3+32cw5B+D9MU55Barboofr28iHM4jNm7GMP4t0m0KLwfsvjnz59H8VVVF7duR/F938c51JiF78frKH46HLIEqure3R9H8d89y8fovoXvYoahZQzHp66yfjmF31JVVdeyfjnH2LLZXkXxZ+tsjO3bMoqvqvry68+j+K+ffhnn8Oc//4sofhjydvj0059E8ftD9i1MM9QM0yGb8/u2iHNYVVZDdpWN82PtoviqqmlK679sbKqqquxVVnXZ9zTN8BvGKfwRXdoIVZt9tp7Ybn/4uvJffPlVNkb+5V/+VRS/uX4WxVdV9d1lFN9NeQ266B9E8VOl7zLfJ2h91o77ff4u027VdTPsl4Rjwzacb7cz1KDX19l64P79+3EO6/5W9oBN1i+nNkMdPWbvcgzH+Kqqi/V7Ufw0hWuiXV63bA7Z+NYv8j2f9Vm2V7FY5O2w3WbP6LqwT0TRb41j+C77fE2ULkn64V4Uf6h872xoZ1H8enke57DbZWuaKRwf3z4ka4dFW2V//pCtC6uqpullFj9mtVdVVRfuuUzBOVVVVd9n76Gqqhuy+u3Vq/yc52wRrk/HrF/2YR1eVXWYXkTx6VlXVVVf2Zy9XGbzdVXVNDyN4sMjlmr7vJhfrbO56uX2n+Ictvs7Ufx6kb3Lm83vo/iqqqll/WqGY54awr2GscuT2O7eRPH9IhvnL5f5fsthl61pZjh1rJttNkY+e5XVDHdvhevryneNFmd5Dfr6Kjt/7bp8XdaHK6NDuB7ZzHA35Gyd1dFjeHZaVXX3zt0o/tmLrE/cucz7RDdmL3Mfjk1VVe88fBjFf/Txp1H8k9/9OoqvqmrhXu5hn891U7hfcud2vg/64mW2FzsM4fp2ys9Oq3udPyO0D/vl0Gc16G6XjU1VVYtFeI/xJl+X/eIX/ymK/9Wv/mecwwfvvx/Ff/mHr6L4/SarOaqqhvD89cWtvG755d9m66JPf/7TKH6xyMeWW5fZumw7w/nEGC7T0ztb+/hSRb63P8fZQHqHcL3O92LTH7K5ycaGfeV9Yh+eE718ma3xq6o+/PCjKL7rss2zruV3WtNuNc3QK6bw3ljYjG9zCA/MDuHdtdev8voxvRsyzHDXfAr331r4Izab/Hxjs8lqyDbDXcwWzhPpGns/w2ZumsNymZ+XXd1k38MQnrdVVV0dsvlyDDfPFot8gFytsnY4HPIaNP1HltZnY8vZIts/rKq6Ccen7TYf387Ps99xfZXfq12tsr7927//LIpfr/Mx+t2H2Z3Wm+v8bshqlf2OdHw7hHtOVVXjmPXL16/zWn69zNZV6fD2/cu8/kvX6On4WJWvB9I9zH9+SBQ+hf/kNs2wV5EuanYznJf14f9S90M2Nu22M/yGcHzbhWfYVVWHMaulFzPUoIfDDJfmAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+yDx+/PjYKQAA/x+Y84F/7dGjR8dOAfi/1I6dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnqx07AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOVzt2AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACcrnbsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABwutqxEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgdLVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA6WrHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA09WOnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAp6sdOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATlc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAnK527AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOF3t2AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLrasRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4HS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOlqx04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNM1HDuBtw61rxc/OHpRl3EGw2IRxX/x1Zs4h7Ozf4ziH9z/KIqfxttRfFXVfreP4s/O8k/y/Dx7l/v9Ic6hb9nvaPXTLIH2dRZfVW3aRvFTZfFvH9Ki8GXYr3e7myh+DstV1gZVVfvdqyi+q/Movm93o/iqqn7I+uWDBz+Oc9hvf/g8VVW17O/H91ZHoAAAIABJREFUOUxj9j1MU9aOY22i+Kqqrsv6ZdUU5zAMqyg+m+mqdl36hKonX3yVPaDlOZwts3bcXOU5dOEQOdWY/f0u79dD+C7GMfsNVVVT2q/CsalV9i1VVW0O30bxuzFfT5wPyyh+nPo4h1Tfuij+apPXf7/+zd+FT8h+Q1XVKqwhf/V32W949+GdKL6qqq+s/rt9/n6cQ4V9Ox3eFou8btnvw+8pXM+8fUYY3/LaaWy7KH4as3b88smXUXxV1ccfZ+uBoaU1bFUL9wn2Y/ZNHw7Ze6yq6qasHRZDPkYfxusovnXZfD302fq4qur1VVbLt7D2qqq6WGRzTWv5HuJu/zSKH/p3sgTCb6Gqqm/h2vKQtUFVVevvRfFdZe3QxnUUX1U17sM5O6xhq6qqC/eku3xd1rpwL3bK5vyuy/fv9mG/PjvP1xPjlL3L8ZD1qddv/hDFV1U9e53tQf72H5/EOfzHX/xZFD9Utgd5NuTf4yqcsw+HGeqWKTtf6KaLOIdll83ZN5tvovjVIt87O4RndncvPohz6KZsfDscHkbxiyE/36jxeRQ+DA/iFPb7bP9uG55BV1WdrbOxoQsX6a3Lx5bWZ+uBzz//PM7h1mXWjh9/8KMo/rvvsm+pqmq1DNf5U17/XayzWvrps2dxDpe3bkXxaQ16vsrXEy9eZOPb/XtZ/VdVNYV7+7fDKf/p9/na8s7trGa4czvf0x7DvdT//l//Oor/059+HMVXVd25k7XjF1/ktfz9e9l+yeGQ7yc/fJDVPjeb9P5dfu64CO8T7Hb5+nYxZOvbPjx23O/yPcj0zlUL996q8j3tH32Qryf2+2xv/sdh7fS7338WxVdV3Vpl7fjVk/B+S1X97K9+FsXv99l64vJ2Vje9la0HphnuhsRn6eGapp9hTdS3bHzqZjg7PQUt/B3jLnwXM3yPi0V2PnGzyfcJfvnL/xHFv/feu1H85WW+Hvn2m2yNvA7PsKuqFouw8JjhmCedb9P9ksM2P4sfhmx824RzXVV+5/71q+yu0iK8j1pVtV6fhU/IP8hduI85DFmf6sP9w6r8DuEwQw5jeNeowvvyVXHpU8tl9i5XYR1eVRWWTnV5O79Xu99ndUMf3su9us7uGVVVtbAhNzPcq01zSPcJqqpev8rOse/eyTZCzy/y/eR1eDawXOS1U7o+HcMlzWaGuuXN66softnyO1ubTfY7DuE9xnHKa4ZFeEbSzTDfTrtsvhxmWGOnT5jCdzHHLkE+RueD9CEcHNL96M0M95PTvY7FkNdOq/74ZwPdDPtnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACn5PHjx8dOAYD/h/4YxvlHjx4dO4U/Cn8M3wLwfzI+Av8W7dgJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHC62rETAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB0tWMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDpasdOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDT1Y6dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnqx07AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOVzt2AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACcrnbsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABwutqxEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgdLVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA6WrHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA09WOnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAp6sdOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATlc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAnK7h2AlUVVXXqtr5Dw7f7p7FKXzz7cso/t13349z+O7bb6L4q6uvo/jl4r0ovqqq9evwCW/iHA77MYpfDLfjHIY+e8bh8H0Wv8+7dhfGt9biHMbpEMWvVn0Uf7PdRfFVVcMiexeHPIUa+ssovuuyduwr65NVVV988Zso/vLOh3EOq+XdKH4ct3EO0xT2zG4Rxl9l8VVV3SoKb/HoVLVY/PCao6rqprKO+Z//23+J4quq1mG//OTDvE/sN/vsAdMU5zBVNtdsdlkOm+uvoviqqjuXH2QP6PIxdgq/6W4K5/w0vqqGRTZGv7j+Ns7hvD2M4qcpqxlmKL2qVdYn7tzL3sPbJLLx7WJ9Fqdw9zKr5T//6vdR/Icf5e24mB5kD5iy9XFVVQv7RPVZzXB19Xn296tqvUrX+TNsuYTT5fYQztdVtTm8yB4wZu3w6U/+JPv7VbXdZLV4N+TvcrPP3sVm/ypL4JDXXuvFvSh+mKEdd7tsTTKF64nW5+14eflxFP883P+rqqpDuH/XwrVlVQ1DNk+Mh9dZAjP8htaWUXw/3IlzOExZOwyV9es2ZevrqqrxkPXrQ7gufCt7l3Psgw4tW5cd9lkdPY7hPFNVi0VWR3/7zZM4h3v3f5I9YMra4fwsr+X78+x7/OxJds5UVfWbX/9DFP/pn/4oiu/36TlTVatsPVFdXreMtYni25h9C1VVXbifvFpm8/Wrq3zv7OLsnewBu7wd032nQ3g20HV5DToMt6L4620+tuwO2T7mepXXHUM45x+m7F3ux/zQ7/mzbK46u53PVRfn2Th9uMna8dZF9j1XVT1/lbXj/Rnacdpl+wT9DGvs56+y9cR7D8P9vxnOidpZNjYcDtl9hKp8b38ZvsvLy+wuQFXVFJ471pi/y/vhvvzqk2xdtlrm+wRvXmdjy507+bv8Nrx39v674bllVY1j1q+222xsmqYZ7vm0+1H8MrwnVFX1+k12F/LyVvYbagrHhaoap5vsAen9lqqqbVaDPrid79/97W+z+04/+zQ7Izm/yO9BXoX1Wy3y89vlKqvl0/hphrplt8va8TBDDtVl+wRdS+PzfdR8LzZvxy59xhx1cNgMXaXjfP4blstsbXl9PcM9xvB+8tPvn0bx+30+1y1X2TP6Ie+Xu302vq2nGeb8cHxLP+n1Kt/T7vvsXWy32X50VdWrcJ/g9u30fyfysWUcs/pvtQrPFqqq77P1QHqvYh/uOVVV9eFE06V9sqr68N5Y+i1UVdWUPSPt16tVvra83mTrspub/Hva77O+3bVsnlks8nlmv8v2Gs7P8/ONdLLKe2XVFN5DPAu/6bOzfL7dhe9yhuEt/p5WQ/ZND0N+dnq2zhri+nVey6/Du+JXV9n4+DqMr6oaw335LpxnqvKVXQvv/FdV/N+Gae3UtTnueWe/Yo59p4uLiyg+XQvMcX67j88W8jXRPpzr+iHvE1O4VwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwGl6/PhxFP/o0aOZMgH439Kx6Y/FKbTDKYzzp9AOwLxOYWwB/v1ox04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNPVjp0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKerHTsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE5XO3YCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJyuduwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhd7dgJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHC62rETAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB0tWMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDpasdOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDT1Y6dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnqx07AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABOVzt2AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACcrnbsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABwutqxEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgdLVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA6RqOnUBVVdf6Wp1d/uD4V9+/inO4ud5G8WfrVZzDxx/9SRT/1Zd/H8VfXDyN4quqVquL8An34xyGxSKK3+/z72m7/acovgu7Zj9kbfA2iV0U3lqew3aT5bAK++V6tYziq6q++frLKP78Iu8Tty+zfnk4ZH9/nLL4qqp3H34YxfeLHz7H/ItpalH8uM8bomvZy0h/Q1UfxldN400W39J5pqq6bM7f3Wyi+PWQ1ww/+eheFP/u/f8Q5zDus3fZ9+HgUlWHKZwv2zqKXy7nKKXHKHqGIbaqy35HnkP+hFVYdzw4exDn8Lurr6P4T29lc1116RhfNYaT9iEcH6uqbp1l/XI/5jk8e/M8e0CXjW8tHNuqqlbp+LTP56rD4XX2gC6rO1arsE9V1f5wFcW3cHytqniMPmzzdf7Q3Yni1+usXx/2ec1QXTa+7cP1cVVVTVmfuHX2QRS/uX4SxVdVxTPNlK+xW5fF933Wr/fjrSyBqurCdri1zvpkVdWiZW/z108+i3N4+PCdKP5Wy9pxnLI6/J+fkoXPkMN2G9bSfbYPulrk/Xoa70bxb67y8e3s7N3sAXOsb8es9hmnsG7p8/FtnK6j+Lv3Po5z2G6fRfHDkI2Pfcvr6GnMcvjkk/B7rqoX32d1y/3zrG65uf42iq+q6pbvhU/Izzdalz3jsM++56qqvmV7iNOU/YbVIhvj3yaRzZetz/ed0jOOccx+wzDkex1vrsK9irB+rKq6WGZrw9bndcfhkJ0NvHrzMoq/2eTv8uGDbL+jdeGiqqrehHtn/ZD1idUq+5aqqm6H52XPX7yIc7h/PzsDvh/ut1RVff9dtm+022X132LIz2+H4TyKby2fJ/a7rG+P4Rjbt3wPsuvDc/AZ1rd9mMOty2xN8/x5Xnvdu3s7it+F31JV1WKZrS1fXuX3pS7Os/Fptcr69es3eTtO/T6K74e8X56fZd/Ts+fZueX9d34cxVdVHQ7Z3Y60jn77jDdR/G6frw3//Oc/j+L/+m/+Jor/i5/9WRRfVfXt999H8VdX+Xz75LN/iOJ/9El2L/ebp/l523sPH0bx+6t8fGvhIcuQ1gwz9OvdPjuzu3snr0Gv3mR7sV8+zfe+wiuEterDe0Iz7LdcX2ftmNaPVVXLZbbXsNlk+wxdeIZdVXV+ltVO23BdV1U1hGd2mxnuGq1X2d58ul8yTfm7fPUqq8X3+6yGrapah3fu0z4xzHDu2Fp43naYYa7aZnNV2o5thrFlGe7lvnyRry2HcH07x53U8/Ae4zhmE/bVdXZHu6pqnGF8SqXHC9twv2SxyP/3oV9ktVOboW5Jv6dD+g9Blc8T6elEm+GO9Hp9FsXfzFC3pDfwpjFryRmmidrtsrrj9QzjWzdkdcMU1gwtXFNVVe33ad2R1y3pGfAcdXAduRbv8luxFQ7RNc1Qg77aZfugd9/Jzi2/+cM3UXxV1cVFds4zR9UT///rDPPtHPsdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/Pvw+PHjY6fATLxL4F979OjRsVMA+Ddpx04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgNPVjp0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKerHTsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE5XO3YCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJyuduwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+F/v2tizJcZ0HeFVWde/DnPYAMwAGIADCpEiJFB1iKBzWs+AB8Ry+8p3JCEISRVIEAQMYEDOc4z7v7qryBegHMP6yuu34vvtVvbq6KnPlymwAAAAAAAAAAAAAAAAAAPZX23UCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvtusEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhfbdcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2q4TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/tV0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+artOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID91XadAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7q+06AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD2V9t1AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr7brBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX8OuE6iqury8rE//+bffO/6Xf/e3cQ4X52dR/OtXL+Icjo/ei+IfPng3ij89+zqKr6rq+wdR/HY7xTmM4/P0CnEOfd9F8fN8J/z8Poqvyu/jzeY6zuHo6CiKf/zNN1H8xdU2iq+qev+Dv4niW7eKc6jKrtFlj3PN1bILVFXXrbMc5vBLVFVNc3iB/D60lo1P45SNDX3L3smqqq7LxvmLyy/jHA4OHkbxd2/fiuJ/+fd53TJ0WQ43l1d5DkP2TsyVj7FV2dgw9Nn4OLS8bpnn9Br5nN+1bEkwz9lvOYfjwncXycbHruXz7Q+P34nivzn7Noq/e3QSxVdVHXTZOD9tbuIc/v7HWe307Yuv4hyG48Mo/nf/+iyKv77YRPFVVXcOs7pjnA/iHKb5MopvffY7VOX3cQ5bJuOUz3VdZXP2wZDVPVVVNWdz/nSd3YdhyOe6qWXPw2Y+jXPou3vZBbbZfTxYvZV9flXN4+vwClkNW5X3O8b5dpZAy+voaZt9h6HlY3RVVn89fvI4zuD4flZ3nBzfjeKvb7J5qqqqC2vQ1ZD3CTbbbL5M5+vtlM7XVXNdRPGrw3yue/X68yj+/smP4xymKetdtS6bq242WQ1bVdX36VyT7dF8J+zfhWv0MZyvq/Jx/tGDbG+hqupHjz6K4jcX2fh4tM7rlm1Yt7Q+n2+7LrvGMNyPc5jG7L2a56zXsB7yXsU0vYziF9guqzntv3XZnH91/TT7/KoaVm9E8f28wP7GmF1jO+b7txc32TvRhevTN+/mdcs8Zj3xtkCv4tZxNtc8ffnnKH415DXoYXiN8y6rYauqXpxl9dvdo3B9W1UP38ieye34KktggX3wIZxr5ilf56drmmkK97pWWfx3sjp6nBbY5xmz8Wm1zp6n7ZTPMy9fZufG7tzK9+JXq6ynfXaR90HX4W8xdNl8e/deviZ6/iqrv+7fzmv5dbg27Lrsnbq8WqAn3rL+XYX7I0tcY5ryo7VdeBbyFz/7uyj+8TfZHnRV1aN3HkXxv/8ir52mW9l79aev/hTFDwvsnT64n63L4r5XVXXh+vQgHOPnRb5D1kd9+izvg3797EkUfzjkdfBNl9Uuc7g2bPE5yqrWsudxiT3kcZvex2yMby0/Y7M+yvZfjw7y53Ecs734cZPX4vMQ/hZDOufna6J0jD45yXuxm002NqR7JNub/JzP9XX2XrX0wHxVXV9n3yNN4dat4+wCVXV5ke0h32zy33J1kL2XfTjPVFW9fJXtNcW/5e28/9eF/Y4lWj7p+eJteCZ1nvN+cmtZ3XF9k8/5XVhLd+H5v6qqFtZfm5vs/2UHB/k7cXp6HsVfXub/kXv4IOvLX15lOTx/ke29VlVtw/Mt0wL/q7oI5/zNTTY+9n3eM1qF88Q27KlXxUeDF/iPXT5fplNVuq6rquoq+xKP3sr+D15VdRr+L/7ls2zP7/Aor0E34Xpiib+NHqyzHmC6Pq6q6haoYwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3fr44493nQLAf6i26wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t1wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/arhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH+1XScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qu04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vdp0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPur7ToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPZX23UCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvtusEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhfbdcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2q4TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/tV0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+artOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID91XadAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD72jTRAAAgAElEQVQAAAAAAAAAAAAAAAAAAAAAAAD7q+06AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD217DrBKqqVn1f77xx8r3jv3r8eZzDBx/+Ior/t3/973kO7x9G8athHcXfvfOzKL6qajudRvFzXcU5zPNlFN/VgziH1h9F8atV9ltut9nvUFU1jlkO6/VxnMPr138JrzBF0e//4L3w86tal73X1a3iHOZ5E+bQsvDs0/8qm67mcc5T6LLnaV5gyp3mPrzCdsfxVV14H9aHt+IcPv/qiyj+xfNnUfxbb+fzzEcf/qcovq8F3ok5myembfo8V/XDeRS/2WZz1RLjW2vZVeZwrvvrRXYa31X+LORPdH6FYcjm7M15Nl+/vnoVxVdVvfMwq2Gry9+Kqd1E8W+/89M4h1/9+r9F8R99+EEU39UYxVdV/EgvMraEo+R2G64Nu2xd+N01snmidfn41rqwDl7ivQzXE/OcPdObOf8OXZfVLUdDXsvPY/Y8zFN2H7twXVdV1bXbUfxm+zzOYRjuR/HzlP0O07RAHR32vtoqnK+rauqz7/GD97O5rqrq6uVFFH92kMUfr/N+y802y6Gb78Q5HKyzseHqKnsWzs9fRPFVVXfu3MsusMA8cf/eW1H8uMnrji6c86tlc13rD7LPr6p0fKs5r0G7sP6aw/VpV9l6pqpqntK6I5uvq6peXmS9s6P1u2EG2fNcVdWF15inJdZEaf22QOcp3F+Yp+yZnue8jm5DNj7dTNdxDvH+wpzFr1bvZJ9fVTVndcuwzmvQzSasW66/jXM4PHoYxedjS7hfV1Vdl82385CvDbdjNj7du/NGFP/8xcsovqrq5ORuFP/G/ew7VFU9e5Htg0/r/Hmahmy+61dZHb0J11RVVdMm7TXka8ODdXYe4Pw8O9sxrPLvMKyyOfvqKl8T9S2sxbtsvj0+yue6dA95vc7r4ONb2V76eoH7cHmevdtHR+FZo7DmqKo6Psxq0GcvnsQ5vPVmVrfcvfejKP6rr/8liq+qevdR2otd4Fhry57pKdzfqKoawp7P8WH2HbYLfIezs2yu+uGjfE3z+ePHUfzFJvsdbt3J7+MXX38WxX/0fvZeV1WdnWdnbG4dZ+PjepX3IL/+5sso/myBXm7fsrpjGvMe4hiuL3dde1VVzWE/eLvJ+3ersJbebLPfsu/zWn7cZM/CZszPg242Wf/tv/6Xf4pzuLrO5qo//vsfovg338j7BBcX2fp2DM8TVOXrouvr7FlIz95VVd06Ds8Xh73cqqq0/ErP2EzjAj3IcJ44OlqgVzFkPci+z89s1WXYOwv/23V2dhbFV1VdX2dz1WG4Pq6qWq2y3+LhW9n6+OYmr736lvXVlzhpNLTsvRr6Bc6NhWfPpnBvYZOXLXX/zfBsyLP87NvpVVhDhmci1gd5/+/0xesofl7gXO0UPhBjeAZwvUDdsg1rp9VB3k/ebrO6oS1wJnUOR8klzsWmhj7rOz1/lb1TVVXXm3C+C+9jC+vHqqoxPqeTn7HZhuuq9Tqvna6v8//WAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADw/59PPvkkvsbHH3+8QCbAkpZ4twH4v0PtBPB/pu06AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD2V9t1AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr7brBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23XCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv9quEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgf7VdJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/mq7TgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dV2nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+6vtOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9lfbdQIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K+26wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t1wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/arhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH+1XScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qu04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vdp0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPtr2HUCVVWr1arefvjge8f/+tPfxDlcXv8qin99uolzmOsmih83d7LPb2dRfFVVda+j8Nb6PIW6F8XP8604h364iuKf/uXPUfwffv+HKL6q6uc/+5so/vnzJ3EO7zx6N4q/dfvtKH47voziq6rm+TSKb91JnMM0TVF817osPguvqqp5XkXx05zdg6qq1sbwCgdxDvM8h1fYRtFdl81TVVWt1lH88e38nXj64t+i+JPb2Xz79MmzKL6q6vwsG1t+/KMP4xz6yu5Dq3zO39wcZzm0bL5eopTuwnei4nGhqsIxsqsWJpDGV81ddh/GOR3jq7ZX11H8R+/+MIr/8quvoviqqvPzbD1w+05eRz/+5tsofrV+HufwD//5n6L4aczGlu32Moqvqrq8zK5xtD6Mc+j6bIzejlndstnmdUtXR1F867IatqpqaNk8cbXAfbgas7EhXE5USy9QVcOc9Qm6Oa9b5krXJNl9yD+/Kq06+uF+nMM4nUfxQ5rDmI1tVfl3mOd8jP7si/8ZxT/5S97zuX94O4r/smW1z0/ezvpeVVX9ENY+86s4h3Gb3cf1Kpvr1utsvq6qmrbZNVYtfyfmyq4xL9Av6bpsXdR1Wc3QFriPNWd18BLL277P1unTlNVvXdxnqOrDZmrXLfBbrrL+2/U266uvh++/X/i/dWEtPs3ZGr+qqkt70uG4UFXVWtaTnqbsmc57RlVTeI1X5y/iHI4P7mbx66yP2tUCe9Bj9ixspzyHp6++ieLfuJ/t+VVVXV1m9dfxcbZvWXkLsm7GrPd1Mebv5e3j7LdoYzbXrRfoW22n7McYFtjfeHiSzXcvX+XjW7udrWm6cB+867L1SFXVPGd90H6B/t08Z8/0wWFWwy5RR4/b7J04WOX38dXr7KzR9XX4LPT5e70+yObb1+dZz6iq6k7YSx03+Tq/9WH9dpo9C/fv5+cJ5jmrfc7O8t8y7dncu5f1Cd599H4UX1X16vXTKP7e3ffiHCqca6Yxm+uqqsYxrKXHbKD/+U9/mn1+Vf3m00+zHP7253EO3z7N6uCWbRPV5SY/Vzu0bIx9fZr3k4+OsnfiZpM9z7/9/PdRfFVVFxY/w5DP+f0C50tSq7CHOKyy+zCO+T3o5nB9ukAhfHWV1ZDrIavl0/iqqin8LbpwD7qq6nCVrdM//9Mf4xzGsHd1eJB9h9ev8zH61nG2Rl+twjOIVfGBgIPwPm4XWI/0LRtb2gI97YMh+x4tHBsWWN5Whfexunx8m8MHsgvPk1ZV3bmT9fYvLrO9pq7Lf8zj4+w7rNcL7POM2V76HP4PZom6ZRiy3lf+/4+qbXiuIizlvxNufW434W8Rrqmqqk4vsufx+csF+gTh83D/TrZv2bd8jB7CumNcYB98msJ5IuyjXi9Qt6zW2X2cxvw8aPo8pL3gqnx/Yghrp/RZqqq6Cb/DAkek47ohPV+c/m+1qqoLex39Aj2f9KfYLDA2pGcIAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD2zccffxxf45NPPlkgEwAA/l+xRA0JwH+stusEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhfbdcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2q4TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/tV0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+artOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID91XadAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7q+06AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD2V9t1AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr7brBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23XCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv9quEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgf7VdJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/mq7TgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dV2nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+6vtOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9tew6wSqqs4vLup/fPqb7x3/3gfvxTk8+errKH51cBDncHk5RvFv3s1+zuvxKoqvqprqJoqf6yTPYT6O4o8OL+Ic/uWffxvFv3yR5fDo0YdRfFVV19ZR/JsPHsQ5bDa3o/iutSi+7+9E8VVV0zxH8V34TlVVzdWFF5ii8K5dZ59fVVWrKLp14T2oqorvY34fWpeN863vo/gvvnwcxVdVHd++F8WfDD+Ic3hwciuK78Ox5Z23fxjFV1WtV4dRfDdl8VVVm/FFFL/q34xzSJ/pec7munHcRPFVVUOX1X/dEuPbnD3T1WXzRM35d5inbRY/Z/FVVf0qm6vOLy+j+Hffz8fH7Zjdhy57Jb+7RpfVTn/84+dxDndPHkbxqz5bGw59NjZVVd1Mz6P4bZfn8OTJn6P4e3ez+Xpo+Xpk6LJxvi3wTszpGNuy+bqq6tZBVr+lz/S8zddE4zab66Ylptvwp4yFz3NV1TSF9zEb4v+aQ3aRFq6xh5Y/DKuDbHw7OzuPc3jzzftR/MmDu3EOd9dZ/+70+jSKvwrjq6rWh9l9mLu8nzymz3SX1bD9AjXDFNZ/45zPE12Xromy+/jdNdILhH35BcboCtfY1eXrslQLx/nWHcU5TOn6tvKio4Xvdltl79Swyh/I7TarfboF9qq2Ye9sHvO6Y+jDPZZVtj6+uHkSxVdVTdcvo/iTw+w7VFX1q3Bx12fP9DTm7/X5Zbbv2Ppwrqyqh2+8E8UPfT7fTqvsnRjH11F832drgaqqdbh3efY86xlVVR0dnEXxfct+y5OTfP/2ydNsfOru5Gui9ZDt+d26k/Vrqqpen2XropO72W8xh/3oqryW345ZX76qqqZsnyfdazo/y8+3HB9l4+OzF/nYkrZcukr3/LLfsapqfZDlcHqWja9VVdfX2dowXRNVVa1WWb/j6ir7Di8WmOtuHWdru4ODvG75w2e/j+L/8Zf/GMW3lh8pPbn3dhQ/z3lPe57C804L9L6ur7LzmEeH2Tt1eZHPdb/4xT9E8b/69a/iHH72k59G8b/77PMo/mrKez6rsN/xzZOv4hw++uAnUfxnj38Xxd+7n+1NVFVdnGbz5fVV/k6ks2VL+9FV1Q/healwfMy/QVUtcp4zc3iUvdubsAe53eZroiHt2SywiT2nZ6RbnsM2rIPTfvISmywHt7PznDebvHY6PMxyWIV91C7fLKspXKN36Rmdqhqn7Hkct9nztF3gbEobsjXNzSYf39LXqu/zNc31TfZb3ruX9e+WOBv86nXW0765yXM4DNfIXXgArwv/e1FVdXqa1ZBd5YcI+/C8/NVl/l/BMdyvOjrMaq+zBfqgB+Fctx3zOT/9f9l1OMbO4VxZVbUNa8jNAvNEOjYM4TzRL7AqCo9LLXDOKN8DXuSsUfg9xniPJi+eVuF/SLb/i507+ZXsTtMC/J4TcW/cHJzOtJ2ZHirLNnZXNV1DG9QUNKvegdggdk3+AbCAf4AVbHqJ2IEEolUrg1iyYI2aoVGppqaqustVbtXk8pBOp3POe28Mh0V5YQmLKvsNE2HpeaSU7Jv3O/lFnN/4/U7Esu+XbZNsm9NmC58HausE29hPtMuvk9N+vj067J8pBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4NP36quv7joFgE/F9evXd50CAJ9B464TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/jbtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID9Ne46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD217jrBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX+OuEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgf427TgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/TXuOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9te46wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F/jrhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH+Nu04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP017joBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPbXuOsEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhf464TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/jbtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID9Ne46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD217jrBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX/NdJ5Ak84N5nnzmqU8cf+PNt+scxsVBFX/v9t06hx++dquK/5uvDFX8ND1WxSdJ5s9U4bPDqU5hnN6v4v/7//hencPFC09W8S+8cLWKPzjo2nOS/PC1v6zif/9vfa3O4eGjm1X8NF2s4mezs1V8kkyr0y4+J3UOyVEX3nbL6WF5gWTI+Sp+HA/rHDabbowdpv5eDun69jB1N/Pai79VxSfJf/1vf1LF/+5X+nnipedfquLHjGX8NpRtYej7xKrsV6tVv3aaz7u1y2rdjY+rdd+vx9m6ij+YzeocNuuuVQ7Tqsyg79ezbojOOPY9c73p7uXhmTNV/J3796r4JPnRj16r4i9d7ObrJHn+2rNV/J379+scvv2d71Tx15795HvbJHn6creGTZLZwbkq/sGy25smyWbYVPFH5y5U8dPJsopPksOxa9Onm34dfLzs9rerdT9PzNZdvzo40+2Pp9UWSlebrj1Osz6HKd080c5UU/o+MZVlxNkW9mXzsd3fduuWdbluSpJh7BYuR4u+PT64060b3nznF3UOz1+7VsWfX3RtYTN140KSrFbdvZwdLOocNlN3L4eyZjRPP8+shm58Wm262luSDOnuxdCOTUmG6biK32za/Wk/Rk/l+zgr149Jspm6+XZW7g3HoW8L69Wd8gr9Hnt+WI5PY1e3+ta3v9X9+0lOTrux4fMvPFfn8PTVbq5brR7VOaSsO7114/tV/HoLldAXrv6VKn447ueJTVlXX667ue7Bg77WcfZMN87PtlBPzqprD8t1W4NMDg+6evLJyRtV/Dh29b8kGYfuGk8+cbnO4f797vz27NmudjalbwtPXHqiir9/v6/5zM51e7v5vO+Xi0XXnjarbnw8mvfzxLI8v7394Hadw6Lcp0/l2cLRmf6Zhps3u3rwwWG/Nzw+6fY0h4ddn5jK+T5JTk66dceQ8rAryemyW3csFv3Y0j6v1JZsHmzhnOjShe584vz57owmSS5f6erq9+5349vj569U8UmyLsfow3lXK0mS02U3Z0+5VOfQzrfr8pmE+ayvVRw/6Ma33/3ql+sc/vwH3f705RderuJ/+LO+Jl5OddlC6Sx3H71bxb/4Qref+PGP3qnik+TcuW6umrcPlyTJ1F1jnPXr4Fn5rNB61e+rWvUzzv3yLVO58FiU5zzHxw+q+CRZLbs3YnHQnzsuDrt7uSpruUly6WK3fmvX8m2fTJK7d7pnKY/K586SZLXsxob797q1+KL8LE+SzIbuGosz/fntYtG1h3IZXdezk2Rx1LWnaeyfTzk97eolZXNOkqxWXQ53bnfPfJ052/frS5cer+JP20VskqNF169uvV+Oj0f9Hv3B/a5NH8z78W1x2NUAl/10m/m8G6DulXX19RbWf8d3u/XXNPT7iaFcN0zlc2ePHvWNYVau5Yd5fzOXp91Avyr3RPMt9Ou07WkLfWIYuv1pu6dK+pcxG8s+tQd1+fZZpSTpX0Z5gS2UW4by+ZJttMfNurvGwcEWPru6hb4NAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAf5dVXX63ir1+/vqVMYD+0fQLg02C+BeCzatx1AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3HXCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv8ZdJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/hp3nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+2vcdQIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K9x1wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/GXScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP4ad50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPtr3HUCAAAAAAAAAAAAAI3aRxMAACAASURBVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvcdcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/xl0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+GnedAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7a9x1AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3HXCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv8ZdJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/prvOoEkWa9WufvOe584/rHHz9c5nD/XXeN3vvDFOofvfuvbVfw3vvvjKv6rX32pik+S+fpKFX/r3V/UOXzvBz+v4q8997k6h4P5WMWfnJ5W8Xfu3q3ik+TK1XNV/GZzWOcwjheq+PW6ex/X6+4+Jsk4zroLDHUKGcdNFT9N3VTx7nv3q/gkufh4dy/n86fqHMZhUcVPZXySrDdvdRcYujF6c1q25yS//zf+dhV/6/036hzeeftmFf/S8918eTTrx8f1elXFj7P+Xg7l+DSM/fuwWi/LHLr4w8XFKj5JNptPvgZOkvWmH98ydOP0enOmip8fPqzik2Q2lmP0uu8T7Zz9jW/+ryr+8cf69vjc089U8T/5WbcOT5Jr116s4l94/lqdw4Xz3Xx7737Xpx6c9PcyUze2nDm6Wqdw9mrXr779Z9+p4r/48stVfJK8d++XVfzJ8rjOYb3p1sFXr3y+zuHBvW6cvv3+a1X8lWe+UMUnybBZdxeYyvgkUzlRbMYuftW/hJwuH1XxZw77+t38YKriV6tuf7yFtzHD0I2Pw2Ffzl0s7lTxL5bzdZKcO/NYFT+1/TrdnipJhlmXw7CFos986Op3q9X7Vfwwe7KK/5Wu/jYO/d5ymrqxJenm6yTJ0L0PQw6q+M2mX7eM41EVv1r388RU7rGnsl/PyvgkGeddm57Nu7aQJJty7fOn//NPq/htnPmdOdfNl3du36pzuHql21e19egkefvNv6jiHzvf1Z0uPnG5ik+SVXleNlu0Y3xyfHpSxd+40Y1NVy5366YkWRyWZ37rfnxbb7pa7MGsfx+mdHuaxWHXJ+7eL894klx6vKt3rJf9md3589357enyXhU/Lbv2nCSHB93a5+ion29Xq65PzOd9TfvMUTfXrMrx8WTdj9GrVbe3Wxz2+4njR13tbFOOj3/5+k+r+CR57tlnq/jNpr+X5893Z03LZbdmuPlud36cJFeuduu/w0XfHmezbh28XPb1kocPu/n27JmzVXxZRk2SPHjQvYbHL/bnPGeOuvluSrd2eu/9ft1y8WJXN1qt9+Cx1qmv+WzaGmDZqIdZN18nyclxV08+WXZjfJJ85cuvVPE3btyo4q9c7NbASfL2za7WMDvsam9Jsjzt1sHzTTdGX36iHx8fPOpew1DWYZNkVq7F1/X5Rn9GcjBv1wzdGjZJnrh0qYq/d6/bWya/+uxCo10HLw77+t+sbNKLg75PHB50fWKxhbPPTfkM4Wm5v92suzPoJBnH7l4cHvTv44MHXd3o3NluT7ONsaX9aFTbFpJkXY4NR+e6vcBp+UxEkpwuu2vMD7s1Q5LMDrq5br2F9rRYdOdVB+Vz2idbeA3T1I0t63W/yX74sJtvl8uuT92515/5HR+XZ1Wzfm85P1PWcoe+fndy0o2Rx+V8Pd/COXiGbp7YbGEtv1l211iVdfV2nkmSBw+7mvjhYX8vT0+79nS2fB82W5hv1+Uasl0/Jv3ngfoLJO0HMIaydjZu4/m9Wdeml+XeNOmfQ2zfx/TTTN2c2me0k/5zdptNPzZspv4aAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwaXj11Vfra1y/fn0LmQDAp8M8BQCf3LjrBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX+OuEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgf427TgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/TXuOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9tf4635hGIY/HobhxjAM3//Qz/7FMAy/HIbhux/8+Xsf+rt/NgzD68MwvDYMw9/5tBIHAAAAAAAAAAAAAAAAAAAAAAAAYD/5HjsAAAAAAAAAAAAAAAAAAAAAAAAAPg7fYwcAAAAAAAAAAAAAAAAAAACw/8bf4He+nuTvfsTP/9U0Ta988Oe/JMkwDL+T5A+TfOmDmH89DMNsW8kCAAAAAAAAAAAAAAAAAAAAAAAA8Jnw9fgeOwAAAAAAAAAAAAAAAAAAAAAAAAB+c1+P77EDAAAAAAAAAAAAAAAAAAAA2Gvjr/uFaZr+JMmt3/B6fz/Jf5ym6WSapp8keT3J14r8AAAAAAAAAAAAAAAAAAAAAAAAAPiM8T12AAAAAAAAAAAAAAAAAAAAAAAAAHwcvscOAAAAAAAAAAAAAAAAAAAAYP+NRew/HYbhfw/D8MfDMFz64GfPJfnFh37njQ9+9n8ZhuEfDcPwzWEYvnn79u0iDQAAAAAAAAAAAAAAAAAAAAAAAAA+I7b2PXbvvvvup50rAAAAAAAAAAAAAAAAAAAAAAAAALvne+wAAAAAAAAAAAAAAAAAAAAA9sT4CeP+TZKXkryS5K0k//KDnw8f8bvTR11gmqZ/O03T703T9HsXL178hGkAAAAAAAAAAAAAAAAAAAAAAAAA8Bmx1e+xu3z58qeTJQAAAAAAAAAAAAAAAAAAAAAAAAD7wvfYAQAAAAAAAAAAAAAAAAAAAOyR8ZMETdP0zjRN62maNkn+XZKvffBXbyS59qFf/VySN7sUAQAAAAAAAAAAAAAAAAAAAAAAAPis8z12AAAAAAAAAAAAAAAAAAAAAAAAAHwcvscOAAAAAAAAAAAAAAAAAAAAYL+MnyRoGIZnPvS//yDJ9z/47/+c5A+HYVgMw/Bikt9K8o0uRQAAAAAAAAAAAAAAAAAAAAAAAAA+63yPHQAAAAAAAAAAAAAAAAAAAAAAAAAfh++xAwAAAAAAAAAAAAAAAAAAANgv81/3C8Mw/Ickf5DkqWEY3kjyz5P8wTAMrySZkvw0yT9OkmmafjAMw39K8udJVkn+yTRN608ndQAAAAAAAAAAAAAAAAAAAAAAAAD2ke+xAwAAAAAAAAAAAAAAAAAAAAAAAODj8D12AAAAAAAAAAAAAAAAAAAAAPtv/ut+YZqmf/gRP/73/4/f/6Mkf9QkBQAAAAAAAAAAAAAAAAAAAAAAAMBnl++xAwAAAAAAAAAAAAAAAAAAAAAAAODj8D12AAAAAAAAAAAAAAAAAAAAAPtv3HUCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvcdcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/5rtOIEmOFot84eXnP/kF1n0O3/v+D6r4q088Vefw9LOXq/hbt+5V8T/92btVfJIsH/yoir/w5OfqHK4993QVf3gwq3NYbzZV/Hu33qriv/yVL1fxSXJ08HgVf3LyqM4hw6K8wIMqerM5KP/9ZD7rrjFNXVtKkvX6tIofx+7fv3TpUneBJAfzoyp+s3lY5zCbnS9zGOockqtV9Gp9u4o/nHfzVJIczs5W8XeGskEmufeoG5+OznVtIY+mLj7JZtP261WdQ9Ldi9nsTJ1BO74dzLs5f7Pux5Zx7Obb45M7dQ5HRxeq+OX6VhV/7043XyfJ+XNPVPEHQ98ep3nXt89dKOeZqR9b3n2/u5ezLayjb73/ZhX/xMV+3fHM1WtV/GOPH1fxD0+6+CR58kL3GsZl356W624d+8UvfamK/8nrP67ik+Tll16s4u+/eb/O4cqVbn975qhbRyfJ0djty07Hi1X8Gzd/VsUnyWy1rOJffPalOofl0JXg1puu+DXOzlXxSXIwdO/j8fEv6xzmw3NV/JTuNRwe9XWCv3itq0E+dqncjyR5+lJRh01ysOn2lkm/Rx7LmtE09Xv0g1nXL7eRQ70EHLt19HLdr+Vn5TwzGw7rHKZyfNtsuvgkOTjs5uz1qqyXTP26JVM31xwt+lrF6elj3QXKQuhmG7Xcsl+fnvb7iT/77neq+AsXujrDX/vrX6nik+S9935exb/2wy4+SVKeL5w86s/sLj/RzflHi26PfXqvr1ttDrv58uadft1yWJ7zfP5at7c8fvh2FZ8kq66MmrYWnCTjrNxbnt6oc5gNXZs+WHTj/NGiX8u/997rVfyTF7s6Q5Ks1l17GIaTLn7snolIkmlTrkHHfi1/9/b7VfxU1gmSZD7r7uU46+rBb7/zThWfJFcud2eX47p/Hx8+6PZF63W3n3jqya72liTLcg25WJTr8CTLk25suHuvGxvmB33N5+bNm1X8U5ev1DksV937ePt2v3ZaHHRj7NNXnqniLz/Vv49tv9ws+/OyRVnPPVl3+/yjs32/fnTc5fDY2a4tJMls1t3L09P+eYApXXtYl3PV/Uf9a5jPurXP2UVfv3vr56918Te7/elf/e3+Wcx1eVZ1487dOodrn+ueO5sedZvL1aO+bnV00D3bcX/Z10FX666OOW3h2Y5F2a+OH3bPzh3M+o8ePCrX0fOxn28zdvei3ZeNQ7+3HFK+hi3UtKdNl8M49u1ps+n6Zfu5gXHRP3c2DOX7WMYnydFhdy/acslq2bfHo6NuP7KNc56+TXfxb7/TfQYlSR4dd+1pM/Tv429/saurn079+e3pcfc67j3s9uhnzvZjy2rZzVWrVT9XLU+7e9GeLbS1kiQZ513dqO8Rybu33qvip/T3ctPO+YfdGnbawtqpPYwft7AObj+bdboq+3VZh036dexq1T8bMis/A7Iq9+jTFj7HnLJfbmFrmdNl9z4MW/hs11CfubX7un6UPi7b02E5Pv5K9z4O7Ri7hTG6bdNt7W0bSdTvY5JxG/UOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP/Prl+/vusUAIAdGnedAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7a9x1AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3HXCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv8ZdJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/hp3nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+2vcdQIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K9x1wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/GXScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP4ad50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPtr3HUCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvcdcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/h317a5bjvM4DvLrnsI8ANgCCGyAgkpBEWRYpMYloKb7IRezKn+AP5M/IVVQVh7FLcWySVkiJBAgSJM77vGemu3OhqlSu+XbVTJznuV8za7q/w/oOAwAAAAAAAAAAAAAAm6tddwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK523QkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnadScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq150AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJurXXcCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyu6boTqKrquq5eHh0H8UOeQ2WfcXr+Ks7h7r2fR/GPvv3PUfzOfC+Kr6qabO1H8U+ePolzODy8HcVfXJ7FORydZO3hN7/5D1F8v7qM4quqLi8WUfx02sU5DOkQ1RxE4ZPpSfb9VbVaZfGTSd4v57M2in/+4vMofnv7MIqvqhqG7DdMJ1txDl3fR/HDkPeJqkkU3TS7Ufxilc91s+lOFL+zfSXO4fBmFn9+9sNrlqqq3Z3sGVRVzfobUfzF2fdxDjVkY/TWPGuPVVU1ycaGvs/qv6HN+mRVVVrGznfmcQ5nF1mbnk2zHPZ28jF6Eo6PfZfVPVVVl+FH/Pyd96L4J8//kCVQVS9eZnPd+++8GeewNc0G6c8++zTO4a37b2Uf0GVj0+3rd7Lvr6pweVvNdr7GXlyeR/HPnnwXxf/iZ38RxVdVTZpsrvvp/XfiHL5++HUUfzzJxviqqp2wdll2WR28N8vnuus3s/Hp6NW3cQ57e9l81/evZfFD3q+rmih6Ms32jKqqFl22Tp+HdceTJ4+j+Kqq58+eZvEvs/iqqqvbV6P4/a18S7mZHEXxXZ/9hq4JN2yq6vMvvoriD65m67qqqju3sj2XLiv/qq28lk9Hp6Hy/ZZ4jGyy+q+qatVltVPfZ2P0bPZ6FF9V1YX7Rl03wnFVWL8N/TL7/jbsVFW1v5eNb7/73X+Jczi4ej2K39rajuL/7r9+HMVXVb33/gdR/Acf5Ouy05Ns/21v926cQ7e4iOKXfbbZ0U3yMbpJzwaGbHysqrqyk/WJ6rP3MJ3kY/T5edYer10Pn0Hle2fV5PvqQ5Ml0Yd7PrM2n+vSNfrRCHca9nezc5pJZev8k9P8/HY6n0XxW9Msvqpqfy87Izk+yZ/DjRtZ3z49y+5VTGd5n3j6LBvfdrbyfacrV7L9jhcvXkTxN27ka8vLcJC+uMjv2JyHn7G3n41Ny0W+T9BOsjbd5GVLLS+zNc39t/8yzuHg+rUo/sGXf4rid3ez9UhV1RCuTyezfL9kOWT7BLt72V2joc/Pwb9+lO2d7V/JnkFV1eIyuz835Mv8GoZsfFsssjH66m52j7Kqqmmy+fLy8lGcwxdfZec0//Fv/zaK//i//0MUX1X1s5/8JIrv+3yN/fBRdjf35z/7cRQ/PzqN4quqjp6HZwsj7Cc382yMHOPI7vwi3GuYhne+tkdYo4fnjulvqKpahZd7u1VWe63S/eiq2grbY3pOVFU1hHe2ViP8BySds7e3s/ptscz6ZFVVW9m+02KE57hYZnVHG56XXb8RXuytqpPTrPZahfdbqqqu7Gdroq8eZLXTzm7+HJs2aws3bmT3W6qqPvksuwv5o3t5HRxeL47HlrOz/E5repZ+dJzXb+nwtOyy+XorfA9V+X9IutUI/6tKH+QINWiTbl6FZ37pnf+qqiacq/oRiqe0jl0usxpyGGFBMgn39i/CM+yqqrbN3mVT2buchHvBVVWVnmOPsJ88Df+zmY6PVSO0yfTK1wgb82l7HKVfpjmE39+P0BbSRt20I3SKsF+mbaFqnLMiAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYVB999FEU/+GHH46UCeTtKW3P/OthbAIAqGrXnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm6tddwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK523QkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnadScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq150AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJurXXcCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyudt0JAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC52nUnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmatedAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACbq113AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrnbdCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwudp1JwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5mrXnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm6tddwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK523QkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLmm606gqmqxWNaDh49+cPyb996Kc3j3F7+M4v/pk8/iHH705nEU/+t/81dR/Mcf/0MUX1U1mUyi+NnWLM7h0TdfRfE/fidvTz+6fz+Kf/Uy+w1Xdn4SxVdVbc2bKH6xfBzn0LRZe5pMrkbxXZc9gz97meXQXxkhh0UU/dprb2bfvlhG8VVVwxBOV0PWlqqq+u4yim+a7D1UVQ21HcW37V4Uf3H5dRRfVTWZZuP81f2DOIeD/ZtR/NnyPIr/7vnTKL6q6uz4KIq/ezvr11VV/aqP4tsa4hyGpo3iu77Lvj+se6qqlkP2HD7/wydxDm+9ldU+s9qP4ifNPIqvqhq6bIxtm6wtVFVN+qw9NovsNxwe/EUUX1X1xutZ7dMts3Ghqqrts/n28PB2nEO12Vy1u7UVxQ9neQ3abK2i+KPz53EOVdnvePvuG1F83+XzzGqVPccxdlzuvH4nij/rTuMcjs9fRfHhEF13bt3NPqCqmnC+bbfvxTks22yMfLH44ftmVVWnry6i+Kqqt27/OIrv2mx8rKq6vHwSxfcX2fr06rVsTVVVtR3OE5fLbK6sqppvZ+PbMORz1XKVzbft9CyKf/x9vm/14igbH589zeKrqu68fiv7gHBN1YzQr2vI+uVQ4XxdVU2TtunsOf5Zun8Wvoshrxma8DmMsRfbtOm7yObroc/n28VlNj6+++4v4hw+/STba5hMr0XxTTPCfssiHOcn2V5HVdXuzmEUP3QncQ6TcJy/WGRz1UW4p15VdW33RhR/cz/fJ1guv4/ih2mYQzhXVlVNw33MR18/iHO4dfvt7APanTiHarKz+L7Pzmjm4Z5TVdVkO3uX3z77Ls7hym72HKbhmd3W9m4UX1V1epmNT5NJXrfMZ9nG0XSa16DPX2bn2Ofn2brs+DhfE23Nsva0PcvqlqqqZbgvfvVqlsP5eV7LD322d3ZwkN3LqKraWWRnReFPqP29fGzph6xfnp7ltdPWPFsbbm1dj3Po+myMfHWczdfzfLqtg71sX345wvr22atsTXN4M9vTnnb5Acf1669F8X/88tM4hzduZ+cLW/P8fsrpaTZfXtnL1paVH4PXpLI7Lp/88xdxDtN5Nuendcv7774fxVdVffNNtq56+838TuuDhw+j+Ofhc2wn+diyHa5v8xPk9CZm1WyEORLOmQAAIABJREFUyapbZp27C89OT8+yu3NVVcOQ1dHXro5xrzYzm2Xv8uI8308ewhq060aYKML93HRNVVW1WGZtep5tddQbb4TzdVX14aLm+DhfG6afkJ4TnZ7lfWJ7JzvPPxuhX/7977MzlmvXsjr65bffRPFVVbffyNYTX3z5eZzD9l7WMU8v8331nXD/7uAg3PP5Jr+/1y2zfnm5yMfommbzxHSW7XX0lZ87NtO0js3vNAzhXci+z9/lJDyLb8O6ZQhr2KqqSbgm6Vf5/4HS+yVpzTAPa9iq/F7tNPw/UVVVE56Dp31qhKtz1a3CuSq+61SVdqv8vlVVO0nHhuz7x/gNaXscY7OiDcfoLhxb0jV+Vf4u2vQ9VMVXANsR2lP6LgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxvbRRx+tOwX4PzahPX744YfrToENMUZb2IQ2/a+BfgkAsH7tuhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO1604AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztetOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7XrTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztuhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO1604AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc03UnUFW1s7NT77/3/g+O//RfPotzuFwtovit+TzO4cuvvs5y2LkSxf+73/w6iq+q+vQf/zmKX3aXcQ7v/eqdKH5r6zDOYdJk7en5cfYctrdeRvFVVZN2L4qfhvFVVUM1WXx/FiaQfX9VVdNci+L74bs4h7Z9I4rv+i7MYAjjq9r2PExhFueQ/oymJiOkkI0tfZflsLd7I4qvqlossgfZNHl7GtosftZm5dP+1n6WQFUtTrJ5YjLJ65bql1F4V32eQzhPTNqsT6zi8bHq1fMnUfzFUZ7Dzjxr031lORxdHEXxVVWzSdaxd6Z5n5hNTqP4pr8axfcjtMdumfXr1TIfo8NuXQfXsudYVdUP2dgwmWU/op+soviqqm+/fRjFz6Z5HXzz5mtRfBfWDGNow8fQ9+uf63ab3TiD3e3sM5obWZ/65uW3UXxV1VabrQf2Ztl+S1XV5Vk2T2xPd6L49nq+Hnl89iCKv76Tryeu7d2K4h8/eRTF37qdra+rqn79wW+j+G41xpyf9aumPYhzmG9l8WfnL6L4w1s/zRKoqtdu3oviXz3P2mNVVddldXDfZ/sMTRO+yKoa0nX+GCVDOOc3TbjRUFVNWIM2TTY2DENetzRNONeEz+DP0vOF8D202V5wVVXXZWvk3Z3rcQ7/9tcfRPHhdkudnjzOPqCqdudZ3TFKKT9k/TJ9jlVVy+4iip9OsnF+b5IfQ1+cv4rid7bzGrTCddXlIlsLzGfbUXxV1c5OVkdPZtmeUVVVv8r2OyZtXndUn73LdpadO666bF1XVbUM9+9eu57PE0+eZXvah7dej+LbEWqvtskKwFdH+Z727nbWpvu0iK2q1XK9d2TO2vxdDuGkfXoWnkFX1fl59hlp3XHtan4vI95Xb0Y4dwz79mKRteduhAJwZyebZ7a283f54GF2NnBwMx/f/v53v4/i09HtjcOs7qmqCreTq+nyzYo7t96O4o8vj6P4y9WzKL6qajbJnsPd2+/GObx8lt0pvXUzr9/2925G8UO4VzGEZ/lVVV8/DNfp+ZRft+9me7HfPM72xJ989zSKr6qab2eDy/Jhvi578TJ7l2/99G+i+KuH+Vn+F6/+KYo/P83rv+397N5Xv8z7ZRPfq81qn27I57qdrWxNdHmR3zUfwt8xDdeW0xH2ztLqaTrCfam+z3LohvyOTJveAQz3rV4dnUTxVVU3br6dxY9wJ/XVqz9G8UP4X5zXX8/2jKqqHj78Mop//jJvj7/6ZfZ/nAdffhHFd2cj1PJDtq9+eZ6dTVRV7V7J2vSz77M1UVXV4Z2sln91ktUd3SQ/KLoI645mNsJhVThfTtL5Mr0AWFVHx1l72t3L93ya8Dx/MsK+elp3pLVX/ibzHNI9zKqqoc9ySOueYYT/yKU5jNEc23CMXHXZGnsY4bJSE56RxO15hM+Yj/Bf6lWX1V/pbxjjXabnjpMRzssWy+w5tuF8uQzXVFVVW+GF0jHeZdqeLkd4DmO0BwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP7f8OGHH647BQAAGEW77gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztuhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO1604AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztetOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7XrTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztuhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO1604AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM01XXcCVVUXlxf1h8//5QfH37x+Lc7h7v03o/jf/+P/iHO4/9ZPovhPPvssiv/3v/1tFF9VdeXa1Si+W3VxDo+/fxnFv/2jnTiHWu1H4W+88U4U/6cvfx/FV1Xdf/OXUXy/2opzqGaRhdd5Ft/kQ+QQDrOTyb04h6qzKHroJuH3z8L4qkl7HMV3q/Q3jKGNP2HaLqP4oR+i+H6Vv8u2shyGLHyUz2j6rD1tN3lbuHeY1S3LRT7fDuHv6IY+zqENc2jCFNLvr6q6c3g3it+d5/PtVpvVLY9fPYviv3n0KIqvqhpWqyj+zr3X4xzuvZ71y9XpSRTfTPIxelhltdeQDy3VzLJafOizubKqqqlsnD85y+qWF0dPo/iqqoODK1H89jRvT/0ym3Dn4fjW9dm4UFXVh3PV0OdzXYXtcTVC8dSE8e15lsPdnXxNtGguo/iH330Z59B0WQ5v3/vLKH7o0jdZtbzMBvrLxas4h6/Os/lydydbow99vk/QLbP5dlIjjC3D9Sh82szjFPpwbTjfOojiL86+i+Krqna3b0fx+4e/iHPoutMofhguovi2yWuGVNPm41s627Uj5JDvv2W1zxh1y6RN67cx3mU2xlZtZ+HDGEduN7LwPuvXVVVdl62rulU2xm9PX4viq6omaRk8xr7VJGvTJ+E+QVXV1k62dzVrs/PXocvXZe0sO+dZdum4UNVOsjV224TnG33+G4Y+awuTSb531vfZ+e18ku/FdkNWuyxXu9n3V1a7VVXN59lvaMJzoqqq3d3sOZxcZv16OsI+6CSs/16+zNe37c1szp/PR1iXrbI5/+XLrF/v7WRtqarq/DzrVy+eZ7+hquraQXZH5vbhYRS/sxPWj1XVDNk5UdfnhwN7e1m/evL0+yj+5CSvvWazbD3RjjDXvX3/fhT/4MEf4hzms+x3/Oq996P4IT0ArqqTi6w9bk2z+rGqalhkY+S1ebbPcDnk7XF7Jxsfj48fxzncDfff+i5vT10X1uLTbD3xv/70ZRRfVXV6nJ1v3HsruxNRVfX0VbbfcXqU9esrB3tRfFXV4jyrg8/Cs4Wqqr/+6/8UxS/CtlAjzHVHp1n9l65nqqq6ZVb7dCPsxU7D8/whvMfYjLCVe7nI2tN8mu/Fpj+jacO9t1m+rhvCizqTSZ5Duh6YjDA27O9nffsgXNft7eXzRNdl64nJJByjq2p7O3uO5yfZXfX/9ncfR/FVVTvzrD2dHOX7d//zyddR/I39bIz/m7/K7pZUVc0Ps7XlH7/K1uhVVbuzrF9deS27T1BV9fRZdi+2vZmdsTwJ997+nETWnsY4B0/vWS/Ts6YR7kttb4VnyF2+L58+xzHeZZ/+DyWtg8Paqyr/L80YhiF7F5PwjGQYYS+3Dd9F141w2Ty8P5e2x/QZVFW14cIqbEpVVdWEq6JV+P+NqhGeZfgchg24Y71c5s9xGq6R08ewvZX/pyndLxljvyVtD5M2/+9q+i4BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP5vH3300bpTAAAAAP4/0K47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7XrTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID/zb69NVtSlncAf/pdhz37NEcYBlAJGolG5CBioaWp5GvMB+Rj5CJWRUER8QCYEZXjDMwAM7P37NNaqzsX40Wqkiv+XbVWpX6/+3/vZ3f3e+x3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyutu4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhcbd0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC52roLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztXUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmausuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1dZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACbq627AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V1t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrrbuAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXG3dBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwudq6CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7V1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5pquu4Cqqp3t7Xr+ue995fzh0SKu4fatT6P8yz94Ka7h9V/9Oso/952vfg+rql77xS+jfFXVT3/ysyj/h7eze1BV1Va7Uf7u/TtxDZfP70f55bJF+Sce/8coX1V18+Y7Uf7a1e/ENXTduSi/WA5RvnWTKF9VVV32LKtWeQndLMoPQ3Yfq/owX7Xqs/+hurO4hhrS9yEfcocKn0W3DCsIn8PDIsJ8/j4NQzpvyNr1KsxXVQ1Ddh+GSt+FqqqsTQxD+i7kbaLrshr6Pu0fq/pl9iz3di/GNQyr7P/Y387mXqvTvI9eLk6j/P58J69hmfUti7Rr6O+GF6iaTR7J8rN83tJa1j8dD9k8vKqqLT6P8of3s2dx5dLlKF9VNWtbUb5b5c9yaFkfOwxhDWEfX1XVxWNdPk4M4XqgG2FN06VrmvBRDJP8fZz12Vz8mcfz9e29sy+i/Id3b0b5S/vno3xV1fZONuaf3Mv37yqcB9csaxMf3X0/+/tVdTXs50+OjuMa+lXWrp+8ks0ZqqreuXEjyt89uBflFydZvqrqO9/O5pB9n+17VVW1sI9uLathqGwe/lA43o7xiSOcd6yWJ3EJXYXzt/A+9PVZlK+qqvB9St/nqqphldUQTyG7/F2YTLP9t7v37sc1LM+OovyVS49F+TYdY+8sm3e0EbqWvs/6lt3dvbiG5Vm2xl627F1Iv01UVU0m2fu0Wub7JekUdD7ZjvKr9LtAVa1W2Zg9HaGPbuE3v5uffhjX8OjVJ6N8C9eWXfqtq6pOjrNn2YX7NQ+vkb0PR8fZmmZnO/8fzs6y+zif5c/y4H62Jrl4Pl/nHx4eRvmd7WwO++DBQZSvqhqGbKy7du1CXMOVR7KzGX26p92NcewrHOzGmMsP2Rp7vpXdx61F/u304PBBlN/dze/j4VFWw/5+Pgf91tPfivLpWNUqm3tVVc1aNv/qh3xtmC5K0u/ohyf5ns9idSvK7+/ke5Dp9434W1VVzWdZ/3LjRrYnfXySf4ufhmP++x98FNdw8cKVKL+9k7WJ04N8bfn1bzwV5f/hG/m3qoPDbMxfLLP547t/fDvKV1VN5tnacraVvc9VVX14xqWN8Q053KxI13V9eM6oKj+7drbI14ZbW/MofxSuLc9t5WvLc+F5pyHcw6yqWi6ya/TLvIbFLNsP3t3N9iAr/MZTlZ+qrcq+5VdVzWZZH/vb97LfHTxyPv92+vL3s/VI7eVroo/f+H2U37+czXs+vpWde6uquvHGe1H+sa/lv2OZtOwb8nSE81JPPvpElD9q2dpwhOPJ1VbhWfMRzt/14b7TdB7+DmaMc97pNUa4j6n81xdVFc4h09Eu/fZaVbUK28R8ls0fq6oWi2ze0oW/v2jxc8zF51GrKl1WxWuifoTfyIXv42SafxtI78NqhHaZri9b2Mem+aq8Xc1G+O64HOGdTLQR/n762650/lhV1eLfPuTzjvQ3SQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/9P169fja7z66qsjVAKbYYw2AQAAwP/W1l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJurrbsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXW3cBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyutu4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhcbd0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC52roLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztXUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmausuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1dZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACbq627AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V1t3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABsrrbuAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXG3dBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwudq6CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7V1FwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA5pquu4CqqmEYarU4+8r549PP4hqmky7Knx4cxzU899yzUf6tt34X5b/3T9+N8lVVf/3LO1H++R/8LK7h5z//9yh/+GAS13Dp+fB96LMaWpivqrp86Ykof7b8PK5hNrsW5YeaZwV0Wb9QVdVado1hWOQ1dFtRflVfvX9+aAjzVX2fPctJO4xrGCq7j0Pl7bJL72WXvU/D0LK/X1XVhe1yWMUlDMMyy9csyncj3MdV+D9U5fexC5/lMMKzTA1D1qa6boQ2EfYNwyrvY7uW1bA3347yP3zxxShfVTXtsvdpMmTtuqrquD+J8md1FOW3ppeifFVV12fzljYdYXk59FH8s7vvxyU8sX8hyl+7ms1hj07ytWXat7Q2Rv+W9U99OE4MI2x3DBXeh7BvelhEOOZ3+Ry0texe9uF6YrEaY02U/Q9np/mz3J3vR/m9iztR/u6DL6J8VdWf73wS5S9eyseqCxf3ovybv/5NlH/22e9F+aqqB4f3ovykZWNlVdXb72Tj5ekim7dUVfVd1r99eS+7j1cuZG2qqmo2D/uGEfZ8hj7bq2jtXPj3v4zyVVXVZeuJLuzjq6r6PnsW/fI0rmHSsjV2uovZTa6EV6g6OL4d5Xe28nGiDVnbHoasf+vrQZSvqlqGe/uzeb6+3Zpk72NbZW/kakj3o6senB5E+ePjfD/5yuXsG8vqLB8nZi2bOy2HbH3aTfLxdrnKnkV9qUQiAAAgAElEQVTX5W2iX4bjRPh9Y5iMsCfesnbVhd+Zqqq6yuYdu3tZvqrqwWk2hzwXjpfTEfYgjxZZu2zzfM/nbJHN5SfhHuLtz7I5R1XVxfMXo/zubjaHraq6czv7P45G2L9L55CL4IxPVdX2dt63PHEtW6fPZnnfsuyzd3q2lX6ryvcJWvoJOtw/rKpa9dmzmE2z/nEyzeaPVVWLZdYm7t+/H9eQnnE5Pcvn4qtl9k7u7Wf7qPvnHo/yVVXnwnns0TI/x7gMv/MsTrM2MTuXjzN729mzGMJ5T1VVv8re6dk0n7999GF2lnII19j9kJ99S23t5OPtwWF2DnFrnrXrZ7//QpSvqtqdZ/ehO833CQ7u3Yzy7954N8rPt/J3IT1/d/gg71smaRfZjXCWMjxXMYn31cc4dxaeJ8inwXV4lO0HT8KzwfN4VVaVruwWZ+kZxKo+nP91caOq6vrsGouTbC4+O5f3b22S7TV89slHcQ2v/+atKH/x4iNR/uVXvhnlq6q++HP2W5rL156Ma3jyRz+I8m+/9maU/+63898Dvfdp9i5M5+E58apahB39hzfzPcStC1m7XJxl3ze2Zvl9rEV4/i48Y/3wIlk8HWf6MSYN4X5LN8JvktInMcazTP+PIb2Pk/wc5Cw8L9+PcB/nYR+ZPsshXEs8FJ41D59DVVXfZ/1beka6G+Fd6NM2NUINq/Bsbt/nNUxn2f5beh+Wq7xNdOFZ8TF+k5SONKuwTQ0jfLdMvyHXBsxbxhjzx7gGAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMCYrl+/HuVfffXVkSoBAAAANlVbdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK627gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2Fxt3QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnaugsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO1dRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq6y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3V1l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJurrbsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXW3cBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyutu4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhcbd0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC52roLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztXUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmausuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1dZdAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACba7ruAqqqTk5P6t0bN75y/tFHr8U1XLz4RJQf+i/iGrp+EuVfeO65KP/bN/8Y5auqzparKH/l2l/iGl58/qUo//bvfxfX8MZv347y//qzn0T5B192Ub6qatFfifJD3Y5rqO5BFJ/OdsMC+jBftVweRfmtrUsj1HAY5Yf4PuT3sasW5YeaxzUMYQ1dLUeoIdN12X3o+7xvae04yg9D/iy7ll2jC9/pYTiN8lVVW1vZ/7Bc5lPA5TKb+8wm+3ENQ82ifN8vsgK6Mfq3sG8YoYZhyOZvQ5/1j9Wy51hV9aDPrnH/6K9xDefn2Zh9vsvmXken4ftcVcM065+mIywvu0n4PuVNoto0q6EfsvtwbnY+yldVLRZZH90m+Rw07Z+6dNqRTpzGuEj8T1R1le0TVF5CrYZ0vEzjed8y9Nmz7MLHUFW1XGZ9bAvb1Pb88ShfVfWNaztR/v5Rtj6uqrp161aU/+a3vhnl57N83nJylL0Ls1n+Qv7bv7wS5V/75a/iGqZbW1H+0t5elD9//lyUr6pqXfY+DEM+WA2V9dFdl817WrjP8PeLRPFln+0zVFV14WDVWvY+VlUtVp9F+fks6+fbCPOWvfmFKD9pI7SJLlvfLldZDf0qXM9UVZtmc5/tcM+oqursLLuPR+Ge+MHhvShfVXX+QtYudy4/E9dwdnYzys9GWJe1adiuVuEeZJ/P/ypcE3UjrA2n82z+tlycRfkxxtvF6f0of7zIx9vze9k7vbOb7Z1VVR2fZP/HIvzeVpP8We7tZ/vqn3+ezTmqqnb2s++vtz/PviFPJvmaaBG2y+3tEZ7l7naUv3+Qj5d7O9m6qIXf27a3s3vwsIZsH3Tovx7XcP/gw+wCLdsPvvrI1ezvV9WwCr99VjZ/rKp40N4N+8e79/MzX7v7WZu4efNOXMNsnvWR+dmQqt3dbJw4PT6J8jtb4XhdVeF2Sc238u/gN29l5+cuX34qyp8b4axSVfYsDo4/jyu4euVilP/gb+/FNTw4ydrlg7Ps7FzaJquqhlnWz9//PF9PXNjP5g0/fOmnUf7+Yd4/noXrqj+991Zcw807n0b5vQtZ/zbCp/x4nd+PsC/fD9le6jDGB9xQ32ftuhvhY/wwZN9YuhHOS50L91K3wu+Gp2d5/zgss3Nnx8f5/t2F/Wwvdj7L19htmj2L9/72fpTfPZ/NOaqqbobfwefT7Ft+VdU3nsq+pX/8UTaH/eXP832rV378QpS/8372HKqqutvZmua9D7I9n7/e/nOUr6q68sTTUb4P9xmqqu6E5ypqhP27F57O2sTvbrwb5SeT/LxUH54NrvC8VVVVhfOv1tKznFH879cIz0HmJcTnECfhfazKz9+1cA45xhmb9GzIOA8zvQ9jrKwy8bMYoV3Owj7ybJmdt9o6l587OzoMf+c3wnjbWrZvNUnP/NcIzSrsH7vw3NrDEsJ9ghEGq3SsSt+FMc7Lp33LdJbPnRaLrG8YYx68PUL/AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/19dv3593SUAAADwf2jrLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdXWXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAm6utuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANldbdwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAbK627gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2Fxt3QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLnaugsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO1dRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwOZq6y4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3V1l0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJurrbsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXW3cBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGyutu4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhcbd0FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC52roLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztXUXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDmmq67gKqq+XxeX/v6U189383iGvr+iyh/tlzFNWyF+WHZovz3X3w5rKDq9Tdei/L/9e4HcQ0vPXspyn/tqWtxDXe/PIryb7z5epR//plXonxV1fLkbpSfbV2Oa/jyy/ej/PkLX71fqapqLe9bhqGL8svlp3ENrWVtYrU6DSvow3xV17L+rYZzcQ1VaT+/HKGG7J0chjSfj3VdZf3jEI+WVdPJPMqv+uMo3w9Zvqrqgw//FuUvXcz6haqq2exCeIWDuIausv9jGIbs73dZvqqqq/AaYfdYVTX0YQ192L+Fz6Gqqi2zdnVxejWuYTbJxppFn80Ztnbz/vGN32Rz0K7LX8gLV7I55NYs6+Orqj7+9JMo/+RjT0f5bpXPnaYtu499ONZVVbVJOJeO1/n5vKXCPnqEYaKGbpJeYYQiwndyyPqGSfouVdWqPwtriEuoVbhnk7aJfprPvd7+w5+yGsJ3oarqn599Jsp/+smtKH9wkN/HJ68+FuVXJ9n7XFX14N6dKP/jH+V7iP/xi/+M8v/Nvp31aHJe9wE/Ve/W3dM9W88MV5OULMGSGFEhJTEJE8gXCZAY+QbzAfkNHMBODMMbFCkyzIiyIUY0JcoWSXE2cqZ7ut+lqnLB5C5X/JdRL5zf7/5Un7fqWc6z9OHhcRS/26R7HVVDl9VvQzq+VlXVNopu4uOBvPZK9436/jLOYNZmtfwIs23NZidRfBfuNcx2+WQ3D/ffNrtsP7qqqm+z9jQLJ/2D+ZUovqpq12V1bDPCfDs02diwrqw9Xrl6PYqvqpq3h1F8M8KedlXWHjbbB3EGbRPudzThPmqXnb1WVS1m2Zzf9vm37IfwvKu9F4U3Tb7n8/T8LIr/5JOsfqyq+tY3s7mutvna8GB+FMWfX4b9Mj3rqqp5WINev5bu61ddrLNx/uaNbF//wb18fHx0lv2G1bO34hxWy7D+OsrrjrbJ1hPPPpPNM316tlBVF0+z9cBqmY9vBwdXo/h33/3bKP65Z29H8VVVm024qmlG2IvNhrfabrMc7tx5MUugqu7dz+63nFzNx+gHj7K64+VX8vdwtMpq8esnWZ96cn4exVdVLQ+y9e2TBx/HOTx/52tRfNdlY3y3+ccovqqqb7PxaXWUtaWqqp/8dTbGXj3I59tt+C2G8H7LZoR7Pu1l9hteeTm7v1dV9dUXvh7FD+H5azPkY8sv3s/OWC4v8hyu38jmmnXYnpv43LMqvpIwwvW9fKdhjB3lrHjq+3APcoS7IUOfrfPbNj/nSe9sDeG+0/EI67qnT7O7mAeHI9yrbcP2OMLFiotNdn66G7Lx6Rcf5P/70IVnA4d56VS3TrOH/MEf/Ico/s//6L9E8VVV7/7o76L4b7z2WpzDn/3wJ1H8neB/qqqqbt7K7iNUVXXhfdL3HmX70VVV12fZ2PL73/l2nEMf3ms9nGd7++fbrPaqquq77DfMwjH+i2eENWBYd4ywLV9d+r+C+WuM647tNi+E2/BlzsJv2Y1w17xpso8Rho8ifQt78BNqjCzS5jAPx6btOr+/t1hka6LNGP06HWPHuFg7xhI5MEa/Tt9jN8L+Xfr/QIv0W44x14UfI11TVeV1S3rvrKpqvc73OwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9sndu3fjZ7z99tsjZAIAAAD8U2mnTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dVOnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+6udOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9lc7dQIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K926gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F/t1AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/aqRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH+1UycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3VTp0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPurnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPZXO3UCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvduoEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhf7dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2qkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/zadOoKqqadparg6/dPwwbOIcHj9+HMUvF8s4h13djOLnbfYeNuuPo/iqqjfeeD2Kf+fHP45z+Jt334ni33jzB3EOH33yF1H8rZNno/jffPpBFF9Vdft21h532y7O4fj4NIq//+DXUfzt09+N4quq5rM2im+afJgehm38jMwYvyF9Qh/nkJuN8IzsRTTNLopv2yaKr6oahqMovmku8xz68D2G36FtVlF8VdX1a7ej+Pf+13txDq99+19H8btuEefQzrLap2mzMXq7eRrFV1Vtu2y+PDjI+lRV1Tz8FMMQjg199h2qqto27Ffpb6iqarP5bggnu8vN1PN91cmVk/gZZ4+yddnvfOulOIfV7OUovu8eRvHtLH+PVVmbnlW+vk1zqCFdT8QFZP6MJh9bmvRnjJBD+i37PqvFu11Ww1ZVteG67OJpPucfXzmO4odwSXPtytXsASMkcTS/Eqfw6w9+EcW/9uobUfzmYh3FV1Vtt9l7nM3z9cQQ9qsnZw/iHL733e9H8fcefhrFXzvJa9Chwj2fWf4tt7vPovj1ZdYWrl65HsVXVf3wR9l+8Pwgr1u++/r3ovhuPUbdkS3Mdn02X3fNCOuJdB+0z/tEO2T7b32X/Yau8rplNst+w8XFWZ5DeN519Sib8/s+b4/b7UUUv2jzvdz5LHuPu8r3fC532Rp71t6I4lcjrG/PzrOzy/ky+w1VVctFVssfLLIcnm7uR/FVVXeeezGKPz19Ic5ht87Gp/nyy98l+L/6ytZ2R0fZt7x//14UX1X17DPh+e0uP7ObhxvKQ2V7PifH+fj4ZMja42effx7ncHyUjS03sqbwxTOuZX17u8tqp1kdRPFVVUNla6Kzs0/iHF58MbvTcO0kew9//eMfRfFVVW+9ld2RefjoUZzDIhxb5rP0jCa/T3ByfCuKX67P4xxOT78WxT98mNcd7UlWSy+Owz2bEbbEZ+Ha7vTGq3kSffgt+nBNtHgm+/tV1bTZfPn4cb6+Tc9PD4/zOw2z8KBn2D3JEtjmneLb3872clervH5rwnniF+9ndykvL8a4G5KNj7eu5+c8Tx5n/XI7z37Ddpfv+fRd1qcODvIadLPOzoqaEc5v5+HeVXp+W01eO6WnNOn9v6qqTZd9y36WrW+HEe60zuZhHZy2harqw3uxTbiPWlV1ucm+xa8/yfZs/vO//49RfFVexv7hn/xRnMO/e/OtKP787OdR/Hff/E4UX1X1+f2shlxcy9Z1VVXrJmvTX38+u/v26YP8LP+Ti2w98c1n8vXESy9ke9qXl/ld8wefhWfxTTbb7cK6p6pqHt6R7sL7zVVV1Wa/o++zHMb434dZuO9UI3zL1CxsC1X5bcw+3H8bo45OJ9wxckjviqf/WNWNUP+14Z2GEbplNeFDmrCGDYemqsrHp8N0bKqqrsvaw3qE+TZep08/xNYQ/59f3inifpnWDCN0inh8HEP6b1Fhn6oaZ5wGAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIB9dffu3alTAAAA4J9AO3UCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvduoEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhf7dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2qkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/tVMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+aqdOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID91U6dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7q506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD2Vzt1AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX+3UCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv9qpEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgf7VTJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/mqnTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dVOnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+6udOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9td86gSqqppmqNls+6XjH1+cxzksD69E8ccHV+McLs4/i+JXh9ej+FmXxVdVbS4fRvHfeeNfxTn89G9+EsV/+MufxTm8+fq/jeL/6q/+WxS/Wp1E8VVVN0+zZ8zaoziHGrIcjo6eRvGbza+j+Kqq1fzFKL4ZYZgehs3EOYzwG6oLHxDGV1U1s/ABaXxV1S6KHoYvP9dWVbXNMor/Iolsvm0qm2eqqvqhTZ+QRe/yPrFcZmPs669/L85h6BdRfB+2haqqtrmM4oewX88XaVuqms+z9rDr8/Ht7CysQRfHUfzhIq9bmniMzg3DOorfdI+j+OVBXstXk7Xpy8us9qqq2uyytd2s8joQEmsAACAASURBVPZUu2xsmc+ytWHX5+vbJpyz29lBnMPQp3VLNt82NUTx/yeLCaPH0VQTP6MNx4YwvIYh/w27XdYeDw/z9e1mk9Xiszab684+z8a2qqrvvPpGlsP5b+Icrl//WhTfb7L21K2z71hVVW24HpjnNehslrXpbpfVLVVV/TbL4fpxth6Ztbei+KqqLqzfqlZxDk/XF1H80Sqr5TebrAauqvr6N74axa/7fMbdbLO9s1k/Qr9cZOP8LsxhHbfnvP5btPm+0yJcGw5NNra0bb5G326zfjVfjnDs14Xt8TLLYX6Q9+vZInuPTZPXoLMmW1fNFvk8se1+G8W32bKs2j5/j4dHz0bxF7ts36uqapnuY4ZDw6y9lj2gqu49/DSKv3nyQpzDcp69x12fryea2XNRfLfL5tvTmzei+Kqqy3W2b7RY5O1pucjm7K7LxuiT4/xs4enTsyi+afI5f7nK2tPR0ctxDtuwDq5wvuz6fK9ivjiM4ocRdvB+9cv3o/iXnjuN4j+5n7/H9z/8IIq/fetOnEM7ZDXoYh6eE4X70VVVdZiN8/PZCHcawuXpM3eeiVP4+JOs7tjssjH65rVXoviqqrbP2sPQfRTnMA/PaRazm1H8dnMviq+qOjvL5vxfffhxnMOtW+F6Ijz/rap6/CRbk1y9ms11b77+gyi+qmr3JNyrmGf7LVVVf/nDH0Xxv/PC81H8wSqv5Q+32fnClf5JnMOQnjVt0/ky3ydI9776Ee7YtG32O5ohr0HTHekhfA9j7J01bbaf3I1Qvw3h+UIT3hvbbrN3UFXxpYSmzc83VrNsnH/0WX5H5vTG7Sh+dT1sC1H0F/7rX/4win/+NNv3qqq69/BRFH/75rei+D/+4z+M4quq5uHH+OmH2Xqmqmp+NasbPl9la4F/DOvwqqrv/+4rUfz1q/n/VaXnt3//m3xd9tlZdhey2WXz7WKE+bbrwvlyhLolXQ/swjq6Rrh3ltdO+Xyb1qDtGO0p3C/pw/jFIl9b9mGbHqN26sOxoQ1zGOM35O1pjPYY3u0N+3Xf5WvL9H9IxqhB0285Rr9Mx5b0N6T3o0cxwhidrg27sE13o+y3hN9ijPcYGkaonWaz6f8vCgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABg39y9ezeKf/vtt0fK5P9v6XcAAADgn6926gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F/t1AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/aqRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH+1UycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3VTp0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPurnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPZXO3UCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvduoEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhf7dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2qkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/tVMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+aqdOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID91U6dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7q506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD213zqBKqqtttdffzxp186/vqNm3EOJ1euR/HDtotzmM2zz7EbNlF807RRfFXVrD2M4hfz/D1+49Xfi+Lf+/n7cQ5HVz+M4t/4/u9H8T97539E8VVV77zzd1H86298N86h2yyi+Cur21H8bvcPUXxVVdc/jeLb5kqcQ1N9/IzEMOT9upohC2/z8W0YsvfYNHEKNWSvoaqy99A0l2kC1bTZXNVtj+Mc5svzKH6zmUXxi/kuiq+qqmYVhV+uH8cpHB5k7WkY8k4Rl19D1qZXB9k8U1XVdY+i+Mvz+3EOVw6ei+KbSr9lPk90w0X2gCHrU1VVTR+ODW22HunWD6L4qqp/+dq/iOLv3cvb453br2YPGKHu6Pqwbkgn7CGrgauq0pKh70aYq8LaKf7zeeFUTZuNbyOkEH/LZpi+7mjDvYZ+hH7dpsX4CN8y33NJx5bwz1e8LKtr156Pc/j0wcMo/tH9j6L4b34z3+u4OM/qltUIe2c1HGTx/Wmcwqa7F8XPl7ei+GFYRvFVVW24D7rd5GP0teOXo/g27Nhdl68tT45fyuJHGOCaytaG5+vfxjkcL7NvWU2217Fo86Oipsn61XKZr8sq3AfdbtZR/DqMr6qaz7IxerHI1xNdk73H3S7rU32ft8e2sj3E3S7br6mqmrU3svgRjnDnzbUofjtktdf8ID+/nYd1y6rP+2W3O4vi28VRFN+Ea7KqqtU8y6HbZWddVVVtONf0u6z2qqrq+6wWnzVZe5yH8VVVT9fh+UbYnquqDpbZt1zOs7nqt/fy2uv0NFvTrFbZGF+V1+Jt8yTOYT7LxobNNjvz24ywp310mH2Lmze+Gudw/94vo/iLdfYeT+9cjeKrqj766Mvf16qqeuXl/D2ePc7mmuUqW4+k76Cq6sNf/X0U/5WvPBPncHJyEsU/eJD3y3mbjW83wr2O6rI+VVXVddkYu5jn+067XbanveuyNv3gYV7/ffzbrPY6PMrmqaqqdbi2217m+04vvfCVKP7lr2T3ILs+309+sslq0J//95/GOXztq9l7XG+2UfzFZb62vHIla9O/+Sg/iz85yuqGw3U2NlyMsEYf+vD+3myMO9LZGN2ts/ZYVbVcZeuq5WG2Pr04z9cjV46zOzKfn+dzVRceIW826Z39/O7ccpHVHYtVfhfz0cPPo/iXXsjOiaqqnl5kdUfzODvv+os/+dMovqrq2Weye4ircE1UVfXBe38bxd/+Nz+I4k+uZeuZqqqnZ9nYMMYZy9OLbGz4+GfvRvH/6a23oviqqvPzrP67CPtkVdX//IfsfziW2/wsvu2z9UB6RTq+61RVNcL/T6Ti+i2svfpR7hBmd4NHuLJVFd7THiOH9P9xwk9Z213erw8Os7Om9Tpf07The4zvxY7TICNjjG9dOraEdznHGF7Te7Vj3E9Zhfd0mvBuSdUIV+7DRt2P0CnSNj0bYa+iD+/sp/GzWTZXfpFDWHuNsA+atobVcoSzgW6E+8EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPD/cPfu3alTAAAA4J+pduoEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhf7dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/2qkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/tVMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+aqdOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID91U6dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7q506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD2Vzt1AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX+3UCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv9qpEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD43+zcSbMc15Uf8JOZNbz3MJIAQYIEKAqcRKpF9iBKLcsdjm6Ht170wgt8QHyD9sbRET2YVoRsS7JadEgkWwAJkMRAzG+uqkwvEFp1eIN/hqvc8fvtT75TOdx77rkXAAAAYHO1604AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBzTdadQFXVZDKp8+cvPH98M4tzWB0N2QX6VZxD13ZR/HJ1nP397kQUX1U1nWTXePzoTpzDmRcvRvHnXj0b5/Db330Zxf/ph9l9fOvNN6P4qqq7dx9E8b/+5JdxDn/y/T+P4lcH2Xc5m70axVdVHRxn7/R8hO+yKhsjh2ERxTeVj49N04TxbZzDEP+O/D5UZfehhvA+NH0WXxXPl20b3oOqGoatKL5r72bxzfPXPH9wtMye5e3bX8U5PHrw6yj+h3/2l3EOh0fbUXxfWe10dHQ7iq+qWvXZd7WzfSnOoQ2XBENlv2GMeWKogyi+H7I6vKpq0mff5aSZRvF9vRDFV1Wtjh9G8a++9FKcw1DZGL3qn8Q5VJvlUGHdktZuVZWvT5sxvsu0bgkTGKP+S3OILzDCNZrlCDmEtdMkG2P71QasJyp/n9L5rk9fhSz82TXC93G1yua6qqppOETff5Q9h5//4mdZAlX1px9+FMUfHmb9mqqq6SR7Fk2b1eFVVW2dzHIIx/nFIh9b2rB+m3ZP4xyaZfg7JuFzaEfoyy9uRfHT7lyeQ7gm6uZ5Dl9983kU/9L5rI85bfMeZLrZtFzmfafdw0dR/KTL6pZpl2+5teF+Vz9C+dcP4djSZv2W9M9XVTXhfWybfJ9o2WfjfNfk8+1kyOaqgz4rvp7u5r2zM1vZnt92l811VVW7i+x3dLOdKL6peRRfVbUzOxXFLxaP4xwmW9l3NZnk3+UwZD3EJl3mr/J54sROdh8e7d2Pc5hPs/kyXWOfP5f3IB89yWqG7e0zcQ5Nn82XDx9+Fudw/tyVKH7os3dhax4u8qtqudyN4iddvqY5/9KLUfz132fP8juvZHNlVdXRzW+i+I//6z/GOfz03/5FFP+zn2fnU968nN/HPtzHfvFCvof8xfV/juJ3tvL+3WsX34vil0fZXtVqhPN783k21wzhGF9VdefuzSh+/yBbY7dhX7+qarp9GMUfjbDHsjrMrvHB+z+Mc5jNs3kirSC//DLrvVVV7e1mdfRrr+VnGvb2svdpscwaJuleV1XV3n52Hy+9/p04h08/y+qO7791OYr/xee/ieKrqrbnWR+zHWH7Np1r5iO8TwePszXNXthEbMJzQs+EDyM8b19VNZ1m64FFeBva+GxJVRf2tHcf78U5TMJ9x2W611VVX3+T9e8+ePudKP7BV/lZzG7IasjrN27EOax20/fhKIr+0Y9/Ev79qr/5z38Txb//vffjHL795l4U/2cffhDFP3man5178DjrB38TxldVzY6zb6IJx8eqqkmb9TGXq2yuG+O8fDOkc3Z+H4cwh/RsSB/fg6o2fJ9WqxFqp/TMVnrwrPJjsU1Y/zXhN1lVdXiYrS3bEXIYwmeRH2nN34X0jR5GOBCQfldpHd2OsB7pw3chPf/3LIf1jtFV+fuQn1Vf/zcRHw6ufGxIx7e091ZVNZ1kndB+GOPfGmZPc4z7kM4TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwPpcu3Zt3SlshKtXr647BYB/YYyxKR3njY8AAAD8a9auOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztuhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO1604AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztetOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7XrTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztuhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO1604AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM01WXcCVVVN09V8eur541ddnMPT/VtR/HzrxTiHpskex3TI4o+Pv43iq6qa9mwUf+r0+TiH23duRvF/8sYP4hz+4eHHUfz/+NUnUfzlV16L4quqmmY/ij939lKcw817n0fxl196J4ofhnxsmU2zd7pf3c1zmGXfZdtOo/jlcojiq6qG+BJNnENVG8b3eQrhzxiGZRS/WJ7IEqiq6fRpFN/mL0M14bOcbZ2L4p/uPoniq6q2trLv+srrV+IcDl/Jxvmne3ndMZm+EsU3zUEUf3i4iuKrqra3n78GrqrqunRsqqphEYUvjvfSBML4qqFeiuK3trLxsapqCIf5YZXnkGrb7Si+T29CVQ3DcZhD/k2kVUPTHEbxi+UI33W41J9MRniWYe0zhGNDOt8/u8YYNWSmbbMcjrIhvqqqmjYb57s+7FX0+fi4tbUVxXfTbE1UVbU8yL6JaZOtT4dmhDq6CceGEYa3ly9k/Y7fz76K4k9t70TxVVWPHj6I4s/sZPN1VdUwHGUXaPJvYhiya3z++Y0o/s0rb0bxVVU1ZGN0U/n7NPTZmqRfZe/C0OTvYz9k67Ldw4dxDrNZtp5oV1mvo6rqtZfTHmI23zYjrC2XYS3/5MntOIdpsM9UVdU1syi+aeZRfFXVcnU/ip90Wd+q6tmeXaJts9prHFnd0o6wFujCcX53Nx/fTp7KeohbW1k/+PG3j6L4qqrlJLsPxyN8l90s60GuVtl96Np8YddUVnvN5vmc//XtL6P4iy+/G+fQhWND02a9/eUq32MZ+myM3plnc2VV1ZMnj6P4M6ez+zDCNlF14d7nwf7v4xx2tl+N4k+OcK7izr3sXMX589l32adr06rqh6xv1Yf7I1VV83n2LF++mPWT79+7E8VXVf3xB+9F8b/65W/jHG7euB7FX7qQ1T2ff5H9/aqqN16/GMV/9r8/jXO4+EpWt+zMx1jTZN92O8lq8a7Jx8e+z9b5X9/Jv8t7D7Ia8uTJ01H84VHe6+iXWd3Stfmk/+M//6so/igboquqah4ukT/+b/8ziv/++29lCVTVdJLVTm2b9536sA5O97H7foyzb9k1dnfTcxlVr1/Kzvn87kZWP57aORPFV1X1x1n91i/zGrQJ38fDw+xcblXVsMgGqHTv8/TZrKdeVXXn26zns72T77FMwuPBzTLbx16t8nMZq6wtX1vTvJc73cpqyNsj1E4vnMnWA/efZD2f7kxWe1VVvfNeti575wd/FOeQnpjaC/fBmy7vy5+4lK3R9x/mPe333sr2oe+E38S9x1nvrqrqyX5Wd7R9Pr5Nwr3LPjxvVVU1hN/EpAnPfB2Hg3xVTcM5Pz2PUFXVdtmEe3SU1W+zabb/W1XVh3P2cpn3ICfhfRxDel69C9eGqxHGlvQS/RgbFPEl0guMcSZ2A3KI/11V2CcY4V1ILzGf5ef3FotwfBrhUXZddt4p7fkMI/R8mnB8W67G+DdJ2dourTumk/y/KGjD2im/i3ndMMazXI1QfwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACs07Vr16L4q1evjpQJwLiMTwAAAPB/1647AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7XrTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztuhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO1604AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztetOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc03WnUBVVQ19DcvD5w9fzuIU+dX4tAAAIABJREFUZvPzUfzB8lGcw3Y3j+KnTXYfuumLUXxVVV9H4RVOxTlceOFcFH/r/o04hx+8/34U//NffhLF377zdRRfVfUf/t2/j+L/9h/+S5xDN92O4i+cy77LZsjHlmm3E8Uv+z7O4fDgdhQ/m12M4tumi+Krqob4Ck18hTGyiDMY2iy+smfRds8/V/9B32dzXdtk96Cqqg3vQzXZ2PT1nd9lf7+qTm8/ieIvvvRanMNs9kIUv3t4P85hWGbj26Q7EcXv7GQ1R1VVhd913y/jFBbHu1H8cpnVf/N5Xv9NJtl3vVrm821Vdo0mjW/GmOuy8W0YjuMMhn4VxXdtXr81Ye2yt/dNFD+bvhLFV1X1ffYb+mER51BNWDs12TcxjPFJVFh7jVA+DqvsIpPZyTiHuw+vZzlMtqL4zz/N/n5V1cmdbM6fbWe/oarq7StvR/GrRThPdPkLOVQ2Rj988DDO4d5nD6L41y6/HMXfupm/j2+c+E4U34bzdVXVavU0ip90eUt5NstqwLff/l4Uf3SYvUtVVRX2jSZdPkY3la3ThyF9F85E8VVVk+3sPhzvP45zGPqsh7jV5WvDdhWuSfqsbjlcHGR/v6qeHGZr9LMnL8U51CL7tttwyywtgauqJl3Wb+n7bI1fVdV2We3TtFn/ryrvdQxDdo12yHvaTR+uT5us9qqq2j/Kxvn5PKujL7yQf9cHB1n9NT+R90GbVbr3mQ4O+Rhd/TQKXw15/XfufFaLV92Nc2iGs1H8ss/2/PrK+vpVVUN/OoqfNukYXbU1z+7D3mH2Tu9s5b/h9Mlsrrt3L3+WXZvtkUwn2btQVdV1Wd1w86tfRPGXX/8oiq/K907TPmpV1arP3oczZy9H8YvFZ1F8VdWTh9n7ePJMNi5UVV2/lc35V97K+i0n83ZL3b99K4p/790P4xyWx2FfPd/mqbRttGqyMfrh/S+yBKrq3r1sbbl7mNaPVSdOZeP8YWUP83ixH8VXVb313T+K4l+/kJ1Vqqpa9tmzOE77NVX1yX//NIp/9503ovi9vb0ovqrqxIlsnD84yM8apT2XNtxLX67yNfp8nq3Lxth43NkJ1zTT8HxzeCaiqmoS7lVN5/l5ggf3szXNxfPZ2rSq6nA/62n/8V/8xziH1CrsW3388c/iHGbhOcS+z77L7e28jl7cy2r5J03e89kOz+y/9+67cQ6PH2brsitvX4niP735ZRRfVbVYZPPldJo/y0/++fMo/vhxtmf3dRhfVfWTD3+YXWCEs0a7+1m/5cZXN6P4RXo+uvLze9XlN/J4yOqGLhyjq6qWYf0V/oSajPBdp89yjDq4DZ/FbJrVb8MoB/iya3Rt/m8f0mv0I/ybpCF8ln24X5b+/ar8nHU/wvvUpNcIh9gxjpqn31XT5kmkvyMfG8b4Ddk1DkboQaZGeJQ1jHHQJvn7I1yj67L6a4zj7rv7WT93NsnqjvQeVOV1xzT8DVVVq3C+HOPf80wnYQ8RAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAeG7Xrl1bdwrUv47ncPXq1XWnAAAAAAD/T7XrTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztuhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHO1604AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgM3VrjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADZXu+4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhc7boTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztetOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgc7XrTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAzdWuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANle77gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2FztuhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHNN1p3AM01VTZ87emiWcQaTtoniT01PxzkcHRxF8cOsDTPI7kFVVdvMo/jjo6dxDqdPnojibz14HOewM1lE8VfeuxzF3/j19Si+qur6l7+J4n/00Y/jHH75q3+K4n/1v34bxf/033wUxVdVHT1ZRfGz6SzOYW+RfZdVe1F0122Hf7/q6DiLH4Z8nmjDeaJp0jG6qm2yHPrhMIpvKr+PVdkYverzHFZp3XCUfdfvvvVh9ver6unugyj+aMh+Q1XV8vhJFD/tujiHrt2K4psmK4Xbpo/iq6qadojiHz24G+dw5szZKH46PRdmkNd/y9VuFN9WOldWDXEtnb0LTZPFj3GN1fJUnEM3yZ7lMOTfZR/WDfPZpfDvZ+NrVVU12fhYI9Qty1VWd6z6rADsuufvMfzBpMvmiabL72MfvtOrRf5NvHLutSh+Ms+exe3b96L4qqppk9UdR/v7cQ7LZdbzmTbZfUzfpaqqYcjmiS++uBHnkK6Rz7+YjdGXLvwkiq+qWi2y+9iOMEbXMpsnVv1BnELbZ/XXENfy+TwRG6FX0YQ1aNNl39RimY+Pq6NsfNrqduIcasi+q77Nt1mGNvsmDhc3o/jbd7P4qqpLl9+O4lfHI+zzTE5G8UOl82XYxKyqqmyMHirvt6xWWd+oG7L7MIww1w3hdz1UVrtVVbyuOnXqfJzC4VG2xu7Tfkv+OtbOyax+29vP+qhVVTvbWU+7DfbAq6r6VbbnWFXVD1n91rX5XlUX7yGPUIM2j7L4sO5owv2RZ8K5ZoQxdmcne5bXr2d1x9arF6P4qqp2kg1QF16+EOdw/8H9KP7smXz/9eyLL0bx129+Gf79vOdz9kz2XfXH+RmZdMILl7c1mebvwvb8TBR/4lR2nqCqanjju1H83tNsjD91MltLVFW9fOF7UfzRUfYbqqq6tKcd7lVVVW3tZO/kP/0mO+fz5Gm+73j2bLZ3OhzmOSwWWQ24NcnWt+9/kJ+XOnkim2f6Lh+jb31xJ4rf28uf5ZXvZmua/f1sfXo6nCuf5RCeNRqhBp2E7dxJk61p5pWfsTk4DJ9leCa2qupUeI2z29l5gKPjvJ/ct9nacBWevauqmmxl/bs7j/La6cL5fE2ybt08e5/6Nh9bFtNscEk7NpNb34RXqPror/9TFP/x3/9dnMPyKJsnfvv7/Lz7w91sbGjOZOuBW1/leyzf3svWyMMy32N5tMj6TmdmWc/oL3/00yi+qur+g6wffHic7/PcfJA9yybsMwzLEc60htNlerbkWRJZ+Gr9KdRyFX6XY7Stwlp8jGc5mWS9iiHsVYzxG5rwoxjjnE/6XXYjnGNchnvI6X2Mb0Lln9UY55PzNXL6TuffRPpvQBbp+FhVXThfLpfh+xz+27KqqmbIrjGf5fu36Xe5GuFZpuN0+kaPMN3W4VHW80n7+lVVs3B9m54vbsao/9JzkCP0CfpwrpuGdU9VPr4BAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/6+uXbu27hQAAAAAAHhO7boTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGBztetOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDN1a47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2V7vuBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXO26EwAAAAAAAAAAAADg/7BvZ8uSXNd5gP/MqjpDD0B3YxJAzAMhARRlkmHJImn7PfiAeANHOIIO68I2JEaIAE3S4gTQAAgSBBpDN3o659SQuqAj5Gv8Ga5S+PvuV52VO3fuYe19AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADte47wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFzjvhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4HCN+04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMM17jsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7XuO8EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhc474TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOBwjftOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDDNe47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAO17jvBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4XOO+EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgcC33nUCSTNOU3Xb9leOHcapz2G6631hsV3UOR6vTKn693XYJTH07rpbHVfywuF/ncO+8a4cXHv9ancPn9z+q4p89fayKP3vloopPkl/86r0q/m+vXq9zeOXVF6v4D977QxX/jz/+URWfJN957ftV/MX6bp3D6emjVfztW+9W8deuPVHFJ8k4nnTxQ51CdlP3IzMMsRmHRRU/5KyM7x9iTPcM27Gc65Ls0o2Ri6Gb8y8e9MuvxaLL4R/e+sc6hxefe6qKf/R6N9clyWK8VMWPZX/abvv5drf76mvgJLl0qRsfk2SaunYchm5sWSwuV/FJslt/WcUPc0wU7UA/tDmMZXyScq5bLPu1/DR1Y+RQt2MylK9yN3RjSzvfJ/2cPYz9XDWWfXJXPsN2e17FJ8l63Y1vpyfd+Joki2XXjjMsnep6x7Tu3uWy/yTSlo02u37OP73U1Uu298qxZY6GLNegc7h/0e2Rjxfd+La+s6nik2Qqp+xpOcPmcjiqwndTX6sYyjm/LWuPY/dNJkmKenaSDFPfn4aha4epnK8fnN+s4pPkysm1Kn7c9XuiTbl+2439u/zi9odV/NFx16effvpbVXySbMv+sFxeqXPI1PWHabpXJtCNC0kyjF07DGXdKkl1XvenHLq1U1unSJLdrqzllrWOP/1IN8ZOM5w7Hh91Y8PFutxXjf0zXKy/6H5g6Osld+92a5+rl7s+vdtV4f/nNx5U8atl/y6nbfcurlx6qM7hy3ufVPGnR1er+GmGdcs2n1fxc9R8NhfdOP/8M89U8Z/c7Negf/bkk1X8boYP88aNR6r4i4u+9vXgTjfnX5T3Mn7+s7er+CT57vf+fRW/WHT74yS52HTt8NZPujsJzz7V3QVIkkurct2S/m7I+YNujN6tu33ZjWtPV/FJst3cqeJ3M8wTSdcOwwx7mt/85v0q/ux+t2558YVXqvgk+eCP71Tx49C347KsG/3b7/yHKv7sTr8nOlp0+7L/+t/erHP4xqtdf1gtuvVfkuzKcu7DD3d1ggcP+vON5aI8X5jh/HZZ1kE3m+6b2m77Z3jkelcHzQx3tm7f6fa3Lz3/bBX/k5//zyo+SY6XZV9o71gnabdVq+OH6xw+vtXtBz7+u7+r4q893D/DvbPyfknZF5JkXa7lV+XQcGuGO9Y/+fv/UcW/8NJLdQ6bsh2ffv75Oocf/vduX3Xzw+6M5pnXXqvik+TrD3X94T+9+Q91Dt987oUq/sa1bq67detWFZ8kN291dwhvn3X7kSTZbrs5e9x165bFOMMdwnL9Nk197WxIl8Mc90HbGuBqVc5VM1wNae+0npx0/9+WJJuLfo9cmeFq8NjuaWbYE83yjyilo3L91T9C3wbtLyzH/v7dtiwUtP1xjnliO5X3GGcYo7fl3q7/rvt2bFuhnSuTvh23M5yXLcr+MJWDS1u7S5JFWTvbzrB22pXljtUh1P/K+/Ln5Rl20o/zwwxjQ1vHBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgK/ijTfe2HcKAAAAAAD8KzbuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADte47wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFzjvhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4HCN+04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMM17jsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7XuO8EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhc474TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOBwjftOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDDNe47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAO17jvBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4XOO+EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgcI37TgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAwzXuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADte47wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFzjvhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4HCN+04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMO13HcCSTIMQ8bV6ivHb9bbOofNclfFr4axz2G7ruKn7hEyrMofSLLeXFTxy6PjOoe7D+5V8ae7/rO4fvRoFf/h+o9V/HOPPV3FJ8nnH3Q5/Pjtn9c5fO8/freK//3RVMVfHh+r4pPkky/er+Jv3HiuzmF9cbeKf+jan1XxN29+XMUnyaOPPVnF73ZHdQ5TO8jOoOvRyTBereLPzz8qM0iGLKr45VH3DEmyXFyu4s/Xt6v4If2a4dPPPqni/+bb365zODp+pIr/+JN36hwunw5V/FR+VItFv2Y4OT6p4oeh+6aSZEg3vu123Rp2GL76PuBfdO9it+v3E1O6/jiW73I39c/Q9oUMXRv8SfcupxnaIdlU0f13OcO6pXwV6123r0v67jCO5Xc9de8x6ce3bbnHT5KhnGvasSnp18Hbiy7+9Ve/WcUnya9+88sq/qmv9XvsXdkld+26Zer7Y7bdnP3tb/1lncLdu19U8euLbu21WJ1V8UmyG7oxdjv0a9CjVfcbi2Vfv/viVrevOjnp9obHR/18Oyy7dtxs+v40lf1hSPceHj7t6jVJst6U+4lVWy1JMnXv4rNyj54k49iNsVdOnugSaDfISbZTNzZstl0NM0mOjq9X8cPu8Sr+7MGHVXySrFbdd7lcdnNdkixXp1X8nbs3q/jT477+t1qeV/G7qW/Hdnxbrfqaz8VFee5YbuxufvFZFZ8kQ7lHv37tWp3DrfvdueMwdu146bhfe52Wa587d+7UOVy52o3RF+t+rjpeded+m0035y/Gcr5OkulSFb5Z369TOD7q1i2bTfdN3LjRt+O6vl/S11sWi26cH2aoxY7lHZcXXuzOsT/97NMqPkl+9tO3q/hnnnq+zuGTm+9V8V9/+fUqfpq69WOSbIeufjftPq9zOD3u5uyj8vx3TD/XLRfd+Lgb+pp2W5N+593f1jm049uirFt98Pv+DHosz6q+9tSzdQ7PP/tKFb/ddd/12bbvjz9+860q/lt/+Vqdw3rdPcflq1fqHHbb8oyljG/3I0l/V2mcYd3Srn3GsVv3zHFnrO0LMyxBsxi7MXpTPsPU3kdIcr4p1/IznCGP5dnA+UVXt0qSRXHfPkleeqGbZz743QdVfJKk3I+cnvZ3jR6cPajiL13q6qjH3RY/SbIuR+mPPvpDncOfv9btaf7pl91ZfpI8dKV7F68+363f/stP/1cVnyTvXO72NN97/S/qHDbrbj9xUca/d7M7W0iSqVz/pazrJ8mqXX8tuvhhjqPTOn7/67/dDGef7XNM5UWfoVzDJsnQPsMM7dg+x65ci89xpXVXfhXDHO1Yrp3mqCdvy3fR1qPnuNPQ7k/bekvS98mp7I+zfNcH8C73nUI/Qvdz1VDP2KlrDXOMsfVTtDWjA6hbDe3l4MwxtnQ2mznON7qaz9VL/Sb7vNzTbGf4n6TdDHMNAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//9544039p0C8H+Z45v8wQ9+MEMmAAAAAPD/xrjvBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4XOO+EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgcI37TgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAwzXuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADte47wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFzjvhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4HCN+04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMM17jsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7XuO8EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhc474TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOBwjftOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABoIJkuAAAgAElEQVQAAAAAAAAAAIDDNe47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAO17jvBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4XOO+EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgcI37TgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAw7XcdwJJMmXIdhq+cvywOK5z+OTLj6r4p68+Uuew222r+MV4UsXfW39RxSfJ1aNHq/hp2NQ5HB0vqvjz9a06h+XweBV/bdu142//96+q+CT5xne+UcW//ebbdQ7/9LNfVPF/9VffquJ/+MP/XMUnyZ27D1fxD12/WucwLK5X8evNuoq/fq1rgyQ5e9B9l8ujJ+schuGrz1N/MtU5TOnmiaQbH1dHT5d/P1mv36vih/TfxLQ9quIXY9eOH31ys4pPkqeeeKaKX2y7Z0iS3eZOFX/jka/VOXz4wTtV/DNPd+24vui/6/W6+43FsKpzGMYuh6lcw253fTsmXTv042vSjrHJWEUPM6yjp6n8jakbX5NkGNp27N/lMO3KH+ieYUjfjtOia4f19kGdw/biooo/u3evir902u2Pk+ToqHwX7fIxyTR1Y+RYr2GTdh07TN34tjnv54lXX/6LKn5KOS4kGdt5YlnOE1P3TSbJtpwmhqFvxyvH3X5gu71dxW9yWsUnydm2G9/unfXv8uEr16r45dDPt4uuS/drn6GvJ2933UOsy76QJMtFN7YcpatpT+ddzShJVifdfHvv4m6dw3LVHZM8+ugrdQ679ZfdD6zPq/CyKyVJliddDfL+2e/qHDbbcu0zdf3p+Kivg+52Xb1l2vX7iW25tzs+faiK36x/X8UnyTB1ZyzDoq9Bjotu3bFe369zOC73NB/d/KSKX7f76yTH5aLhyy/6s8+Hr9+o4j+/3X3X7XyfJNOmW78ty7PXJLl/0c11pzOMsdvzbs4fh24/sNt2fSFJhrGbbzP1NZ/797t17NFRtwZt125JMu26tdOuH94ylYWjo1U/5x+vurr6etO14+lJf77x+GPdvYw//uH9OodXXv5m9wPFXakkuXO/XzPcvNONT0888kKdw+a8+7AWi25sWox9nWAoy5jn55/VObz7btenL18p55kkn9/uzsJPr3Tj29G6X7e8/uevV/GLVX8+MZZ3AN//oNtX3b/Xjy2vfv25Kv78rJtnkiRDWb8r19FJkvKcpwzPHMdEUzlXteueOQxlXxjH/hl2cywiS4vyrGlTHhQtjmYoQpb1vyF9TXscu3XsUK7Dk+SsrM1/8WV3F3NYlYc8Sc7Pu/Ou1ao/Q16M7TdRnuXP8B8cm0X3TZxe7pN457fd/b2XXni5zuHXH3TnC3//7gdV/PVlv5/465e7drhzpzxnSjKU38Sv3/1NFb+cYc2wK39j2R5iJ9mUc357V71cus1ijhTG8lc2M9xJHctvoo0/BO29taRvh125L2v3AkkyledduxnasT0qmqM/btbdfmCcYYxtte2w3fZ1gvqbKOeZqS1iJlmUd6TnyGEsx/ld+V0vDqBOsCn/fyNJpnrdUqdQF7/acb5dAyf9Pe1pjv+l2fMacI47DatFtz+92PT/S9M2427b1//mWDcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwr8sbb7yx7xQAAAAAAKAy7jsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7XuO8EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhc474TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOBwjftOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDDNe47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAO17jvBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4XOO+EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgcI37TgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAwzXuOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADte47wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFzjvhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4HCN+04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMM17jsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7XuO8EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhc474TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOBwLfedQJJkSKbF8JXDp/OLOoUnrl2v4jfnZ3UO03ipil+ka4dxO1bxSfL7m7+r4p975mt1DuPmpPuBTd+ftusHVfzlK9eq+N1nVXiS5PzT+1X8a//m1TqHn7z1ThV/+utfV/F/+/1/V8UnyU/f/kUV/9ZbP69z+Ju//m4Vf+9sU8WfnnTja5IsVx9X8Rfrrj8nSYaj/jdqUxU9lPGLcp5KksXx81X8xfp2nUPS9entrls+Pfn4M1V8kkzToorfDF18kmwv7lTxU/kekuTZZ16r4ofpbhW/Ws7Qjt1nme2uX7ck5dopZTtM6/Lv9zkMQ78tmqZd+Qvtu/zq+6l/cVxFj0Ofw2533v3ADM0wZVX+QPlhT2UbJBkX3TMsx9M6h3tn96r4dqoaljP0x/K7Hqd+jz0uuvFp2vVz1ZRyfBu7b2Ka+nX4tp1w2zaYQTu0ZIa5rh3mx7Hvj/Wcn20VX38PSS4ddzWf09P+m9hddIWjxdA9Q5KcXio79aLbT9z6si+ejWM3zp8cP9LnMHQ1yG26esnyct8fb9/5tIrftuvHJEO6Pj3suveQJIuhrdl049N6088TJyfdGcnq+Mk6hzsPuhrilZMuh8XY79GndN/VNMxQJyjrTuNQroMXV7r4JOvyu1zNsLk8WnT7qvubrm6VJGebboy8aM/LZqgTnFztatJHM9TvxrF7jmtXL1fxn3/Wr1sefuihKv7yafcMSXL3TldPvpj6s4GTVTe+TMMTVfznt35bxSfJww+VNZ+j/l1++mn3LhfLbmxaznBetxi7mvj5eT9Gn7TjUzlfJ8lU7rGvXr5RxV++dLWKT5KhPN944fl+f7vdlvuyci2+HPrz22ef7Nrh/v0Z9mWLsuZT1iC3u65mlCS/+8Mvq/iPP+5q6kny9NPdOfQX5R49SYbyDHjzoBvnv//d/p7Pg/Nuj3163H+Xb/7oR1X8Ky++XMUvZljLT2VRe5phX9b+wrRrC/P9tmix6PbYMzxCsuu+iRm6U20okyhLwbM4gGZsr63N8gzLo25PtN2UdwGSpKzltmfQSbJYda156/6XVfzFeX/PZ1Wedw3LfoDblfe8h/JdTjMMLuttt469NMMdwrY/rtd9f3r28ceq+OfK/cgca6f1uqvFPpihHd//40dV/FTuq4YZ7hMM7Xc1w2S1LPtTvQadY/1X9ulhhobclvuJOdag7R2X+l3OcQ+ybMc57oO2PzGUZzRtfJJk1/3GohwXkmRXvss5al//zL69LUlyVWcAXrmzqrp7jtIcZGlGIBAE2GHChO1w2PiB5018YbAD4wgCY4wOjAcxw0ijOXZXV2WmLwQvoD8jMsHfd7+qV2bu3HvttbO78Aw4vYYx3JtWzdGrmEH4LLa7rI4+XM7wTUM8t8ywyQ4nl36T7Q3n2NelZ9DTHGtd+H1y+l5X5eMpzaGbYW5pm+w+zrFOpHVDOsfOMBRqHLKzhRb2UavmqGPzGzFH/QUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPCn4sGDB0unAAAAAAAAzKAtnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA69WWTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9WpLJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAerWlEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgvdrSCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXm3pBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYr7Z0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsV1s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWqy2dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADr1ZZOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID1aksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB6taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC92tIJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBebekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFivtnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKxXWzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZrs3QCVVWXl5f1ycPffO34773/zRlyOETxm+3VOIfXw5Mo/qx/J4q/dXItiq+qerZ/EcV/8eXTOIfru9tR/La/Euewadl4utwfo/jvvv/dKL6q6qf/9e9R/D/8zY/iHD748GUU/+ThF1H81Zv5O/HO++9mP3CRjYWqqv/82Y+j+L/74T9H8RevzqP4qqqufyuK7/vncQ7TdCOKH6ddnENNUxZeQxQ/Dtk7+YdfiaIvD3kOJ2d3o/jNGM4NQ/5eb06z+MvDqziHqssoetfn78TFm99F8Zt2M4rfnuTXMITjYZqymuMraR2bbSnGKRtLVVVdZfVba32cQ/pOTOF9mCqcGKqq67Lf6MIauKpqGtK6IX8vuy77jXHaR/HTOMM7MW2z+DG/jzdvZPXbMaw7Ls7zGvTGtetRfN+1OIe+Zc/iMOY5VFhDdl0WX5VfwzRmNWhVVodXVY1hHVxTF4V3M7QA+5bdh+wK/iB8FFPLsphmGAs1ZnVHG/McpiHrnYW3saqqhvA3nr9+FsW/fv06S6Cq3vuLrOfTzVEHT9l42o8XUfxHj34dxVdVfeP+d6L4bct7uRfnH0fxU3c/zqHfZfVbjdlL1Vr2TlVV7S+z2qnb5Puy9JzmcMz6DF3Lek5VVeN0FsX33Qz9uymr3/pwbqqW9+UPY3bW1I957bTtsvnp6tXsnaqqevT0YZhDNh7359k6U5XXkOcXeQ7XNtl42F+8ieLPwudQVfU6zGGbrlNVdeX0JIo/HvLaqbpsX3Y8ZjXkWzfDM8OqujjP1qppl69Vb7+d/cblIevZTGM2lqqqxrDXcHqa16DDkM1PrZthnx/2QVt4H1uX139dl62XQ9yPrqrK5obWsjPobRhfVbV/lfW05+j5bM+yMf38efZtyGe/zebXqvyc5t333otzePS7rP6boaVdd+9m568/+H72rdH5RX5WdQhbuf/xr/8W5/Dhtz6M4p89z76RuX4t35cdh/D7lhlasakxPluo6vtsveu69GxghhsZ5rAK4SW0GSbIKR3Ua3gpQschPTPMx/SQv9a13abzW34f+hZ+DxDOTSdX8j7BEO7zxxney2M4z6c7mtbya9gfs+/OXjzP+8nXTrPe1U9/+fM4h7/9/l9H8fuLbG847vJvbH77+HEU//R1/ixbl81vmz7b182xTmzC+S1er6tqCs/z4/pvhtotvQ/jDPcx3U9sZzh37MK1ZkjX/DWUfzOMp3RMprV4P8M17MOaYY5vjdL9aTqeq/L97TGsW+aondLf6GfYHo/henc8ZL2vOb6XT8fjPNNbuscOzwxnqFu24Rn0cYb/SZrCd2KOjlG6ToQlQ1w/zmGOGjR9Ful73c/xvzgL1wxV+bfmc+TwZ9GLBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/mQ8ePBg6RQAAAAAAIA/A23pBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYr7Z0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACsV1s6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWqy2dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADr1ZZOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID1aksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB6taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC92tIJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBebekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFivtnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKxXWzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANarLZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOvVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPVqSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHq1pRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYL02SydQVbXp+7pz69bXjv/fx4/iHO6/+43sB45DnMNJfxbFj7WP4veXUXhVVb1/+4Mo/sWLT+McDuPNKH7T+jiHGrPxMLUxij9MXRRfVfX3f/mDKP7Xj38b5/DDe38Vxf/L859E8b/673xu+eA7d6P4jz/7TZzDvbv3ovhHn/08in/n7vej+Kqq/UX2Tp1sb8c5PPn8oyj+zt1vxjn0/fUofr9/FcUfhxdRfFVV3y6i+NOTd+Ic2pQteJvdMYofwzWiquqLzx9H8a2f4hyuXcvmluH4PM6h9dl6d77PxnQXvpNVVa1aFD+1kziHYXoTxXe1zeKn/Bo2m2x+G8arcQ4VvlZdt4viW8uL+WHIatDWz7G9zMZTVXYNVVVTZfN8vM3OS/kaji+j+NZdiXOYWja/bcMczqfzKL6q6uLidRR/7Uq2VlZVHYewfjvma9Vmm71XUzpBTlmvo6pqCvfIXZeN56r8PnRhfF79VQ1Teh/yOrib0gU3C5/yZaaqC+9Dlz/NKVyz91O6VlYNhy+j+LNNNr/duvd2FF9VNRyz/e0wzLDeVpbDbpPV4vfeCXvqVbXts17sMOTrxHZ3P8vh8EWcQ9W7UfQY1j5jzdATD+e3bprhjKVl+4n9IZwfu6x2q6ratmtRfDdk50xVVa1fwR47tGvZHNtmOCeaWjamD4dDnMOdt7Ne6ssX2Xp9986dKL6q4tpnP0MlfDxkPZc+3B9fOctrhvPz8Ax5n9UcVVWn17PrmLqv/y3BHz19lp373bmd7fNnOBqofpPNsVM3Rw8x21j1YU97GD6P4quqtrvs3LBv+Xpbh/B7ghnmt6kL93bhHD2G/eivfiPr36X7uqqq3S5b78Ypu4Y2Q99qd5qN6TbD0cAvfvmLKP6LZ9lZ17172XcdVVW///xJFH94no2FqqrTXTbHfud7H8Y5vHUj22On/bunz7Iatqrq948/i+K//a3s27mqqnHM5sjbt7Le15s3eb+l9dn81LoZDszS35gjh9Acvf0/C+mNSM8G5qi9wvONdF6oqprCMT2EOWw2ed1y/SyrW873+Xv96lW21szRi93uwgIsPDu9fjP7Rruq6ounWV/9eMzPqnbbrJ/cwp7PMOZzS7pUzbHOvLrI9lX9Lv1OqOqTRw+j+A/uZ+ddP//k4yi+qupwzHo2ZzN8bJS2rtIh3YXvVNU6aqe0jk2vYY57MIZ1S/pZR1VV2u64vMz7oLvsc874rZxlTxS+V2kNW1V1DHuAU/ihziHsw1bla/4sdUs4IIchvw/5nmQFe+xwTF/OcH672aS1fBY+x1OI17o5PsAL70P6vXu6l6jK16rT0/z/L/b7rAeY9v+q8m9zu/CsapjhAHe7ycbDcYb1dpd+fxfO8XOULZvwGrqWJxE/ijkm2Vk+UgYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP4/ePDgwdIpAAAAAAAAVFVVWzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANarLZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOvVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPVqSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHq1pRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYL3a0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsF5t6QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWK+2dAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArFdbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1qstnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA69WWTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9WpLJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABoOp2cAACAASURBVADAerWlEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgvdrSCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXm3pBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYr7Z0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACs12bpBKqq+r6vm9evfe345y+/iHP48uWrKP7myWmcw7Y/ieIvD9k1tHGK4quq+mMfxd+8+s04hzeH51H8tt2Ic6hji8I3NWZ/f8z+flXVfnM1ir//1lmcw6+efxbF719eRvG33/r689IfPXr4JIrfbbN5oarq/fvfiOI/+fTjKP7mrS+j+Kqqk9PsWRz3+Ttx48Z7Ufz+8vdxDmen2XUcjlkO05iPx+02u4/d1MU5bMKfOFxm6+2zF8+yBKrqxo2bUfxulz/L4+FlFN9avk70fVa7PH+VvROnJ/l93HRhDRnWj1VVw5TN05su21K0yt/rYcjGU9dl7/VXP5I9yy6Nr9dRfFXVOB6zH5iuxDm0tovix/FNnEOF26LWwvvQbbP4qro8ZDXoyS7f305dVre0PruPV8+GKL6q6uw0exZdXcQ5HC6zeX67fRHnME5Z3VHjIYvvsn3dV7K1apphj51OLuErVVPl1zDNUIvnSWT9kr7L+lY15b2zMbyGbhP2jKpqCuvofbgnqqra9dej+D58p8ZDvk60cM1+ff4ozuHsyv3sB8bsvb6yzWq3qqrhmOUwQ0u7+pb9yGaT34fLy6x+2/Z3ovh0namqGitb88ch3I9U1SZcqzbXsvv49MVvoviqqrfPslq8H/Jjv+OQnQ1MLduftsp7Rts+6ycP0z7OYX88j+L7Pt8bdkP2cl89zfZlwzG/j+OY1T7bTVj/zZDDSdhDnIZ8sbt2Nau9njzJ1qmqqu02m9+m6fM4h6s33orizy+y+e10k/dyd9tsfrscs3P0qqrxmI3J3SacW7q8B3m+z84Grp1mZ11VVX1lNeQh7bdU1dSy32jhHnsNtfz2JB9Pw5it+VXZ/DhWvr+tltUMnz58GKfw8mV2Hz/8dvat0aePP4riq6o2fVh3jPmz/Md/+lEUf/kmr0F34W348U9+FsXfuh32s6vq1tu3oviT3Qz9kiGrQS/Os1p8u13+k9Jxhl5s67I+QRheVfGxY03hfUjjZzFDCvl1hGMh/OtV+d4yja+ao/5Kx2O+1h322fnryQzfYl7usvVyrDl6FdmzuNhn68TmJO/59H1WB+/P8z7BJuwbHQ9ZT3uYYVPUNuGaHe4FqqouwzO3Ft7HqqpnQ/at0MuP/ieKn6F9V5s+e5aHGcZTWvtMYQ3bZhiP8Zo/w6Kffgs5xPVfFF5VVV14cDhH7ZTO0efheKya4TrSZzlLIZ09yzn2ZZuWvpfZWJjCfnZV1RCeY29m2GMPxyyHbVozVF67pHv0Ofa3x3Bf1YfrdVVey8dr1QyLXfosj4cZzjfC+K7Lathphj162k9O93VV88wNqS4dk+E6k76TVVX7Q/aN83aG784O4VqV1uKzdCDTeX6OOjisANsMH+ANM5wVAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAfxoePHiwdAoAAAAAAACzaEsnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB6taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC92tIJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBebekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFivtnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKxXWzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANarLZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOvVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPVqSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHq1pRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYL3a0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsF5t6QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWK+2dAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwf+zbW48l13Uf8FW76pzunubceB+bpCQbEeJLFFOSZQcwED3ks87HiAFbiS+AAScyI0aiZZIWDUlDzr1v55yqysMkQd4C8F9AHdu/3/uqXqdq195rr10NAAAAAAAAAAAAAAAAHK+2dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHK+2dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHK9h7QSqqqZ5rt3N/mvHv//2B3EOn3724yj+7P1/G+fQjS2K7/t7UfzF9a+i+Kqq89feieIPhzHOYbu5HcWP47M4h75lz2KcDlF8181RfFVVeomp6+McPv/pz8MrZD/iyydPwr9f9c6bb0Xxmz6bF6qq/vEXn0Txr7+RvdcfffT3UXxV1fe++2EUP9/s4hyG4TSKv95n8VVVX3zxj1H8gwfvRfHTeBLFV1W1LhvTXcvmx6qqlxcvo/inzx5H8W+9/UYUX1U1z9l6OU1fv+76f7KIorsuX/N34bt9/+79KP7506dRfFXVm2+8HcXPc77edt15FD8esvWy9a9H8VWVFy4LbIu6Ln2vsndiHLP6s6qqtRdhDhdxDtVla81mk73XVVU3u19G8UN3K4o/HJ5H8VVV2+HdKH6e89qpwvkpfqv7TXiFqpqzumWuLk6htWNo24RPI6z/al5gjq58XxXnEN6HeU7firxPMIdrVZ+Ohaoawnfi6nATxbdNXnsNwzaKf/EiW6+rqlpldezZNqthq6qqm6Lwab6O4ve7bCxUVW2Gsyj+/PzNOIcxHNNzn9Ve0wJrXbq/7SobS6+SyOqGLqz/qqoOY1aDtj6r37rKa6duzMZD32f9mqqqcczey8NlNrfcOcl7PuOY7bHn+U6cQ9eyuaGbsz5oa3nPKO995XNLS3sNc96/a5XVLmM6Py5Qg2632bPY7fL7eHKSvRMvXmTnjl2X74nOsumxXr9/N87h6fPsPpyd5WvVxWVWB/fh2edhyPstZ2fZOfimz/YjVVWH8Bz7EM5vXcvHQptfi+J3h8s4h27OnkU/5Pfh2fPsvOv0JKuD07PXV7IaNG63VNXJNnsW4xTuj6f8R3zySfY9wZNn+XcVDx48iOKfvsi+dxqm/J06Pc3G9B9+9wdxDjf78Cx9gd7Xn/3oL6L4b3wQftOwwDtxdpY9y/0h/6bh+jrr+XRduEePov9vElF4C+MXSKG6BXpfqfxsYH1L/Ib0GumTXOIppO/lAq9EfCPiuaVfoP4Lv6U8Pc3PBlqX9d92h3yff3mV9TG3m2xPc32d91vGq6soPv0GsarqcJ3dx5Ow4TKF++uqqhqz/cQSc/R2k43p8Ce8Eu6rDmN2H1qfv9djmMMSG9wuvMYUPoe2wHcd6dQwLVG3LFI5fH3HUMMusSfqW/Ywz8K+flXVYZ+td5tNegadP8u077TEeE5zaOFYaC2/j33Yk57mfLHrT7J+8rjPz1/TuiHe17W8WzGHz2KJ93II64YW7oluwhq4Kn+v0udQVbXdZvP8IVyrFul1hPPjEM6PVVVDH559jvmaP07p/JSOx/xZbobsvZ7ie1DVp89ygfotlc6xaU+9quo83Ocv0stdv5wHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIB/FR4+fLh2CgAAAAAAAP9itLUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4tbUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB4DWsnUFXVuq5Ot18/lfHiJs7hm9/43Sj+k198HOfwO7/976L4w0UXxc/9/Si+qupqehHFn5++Fucw76Yofj/mObR+F8X3fR/F3zrPf8NHH/80ir++uohzuH1+O4p/fvE8ir9/+14UX1W12x+i+EePHsc5fP/D70TxP/3sH6L4P/7eH0fxVVV/9Td/meXw3Q/jHF5cZM/y/NbbcQ41XUXh+30WP4RzU1VV67L58dmLp3EOu12Ww7vvvpUlMI9ZfFVd3VxH8ZshqxlemaPow5j9hqqqoc9K2b7LxvTr9+9G8VVVu322XnbV4hy2Q/Ys25Ctl+OU1wzptqbrltgWZXPLNGVzQz9k61RV1WF/EsVP82WcwzBso/iuy8fT0LIadDw8iuL7Lq9B5zncj3RneQ7hOlFTtq8b+mwsVVXVHP6GymundH6al8ihsmdR4VrVtQXm6Cl9lml8VRfWHdMY5tDS51jVdeE15nw8znM4nsL68asXT6L4qqpffvGLKP7tt9+Mc3jwxvtRfNvne5qphfuJynIYw/11VdW2Zf23ecrXqr5l9Vffsvcynx0r3yPP+wWSyOaWeYF9fr95EMUfxmx+2ob7uqqqvst6Dfv9aZzD1L2M4k82t6L4Nm2i+KqqfZf1Gq7HvHd20t6J4rs5e5Zdl50zVVWNU7ZHzmvgqpbO811+9tl12fzWuuxZDpt8rdvtsjOSs9PzBXLI6oa7d+5E8fsFaq9Nn42Ffdi3qqrqwxwuLvK+09174bMIzxYur/O+VWvZfdy0/L2cwipw7LI5etvnfatuzq4xz/l624ZwflqgDj4/y+5D12W1T79AX34O+3dx+6+qWrjeXl0/i+J/9snPo/iqqrNb2f62H/Kzqi8f/zK7QFi+ffO938wuUFXvf/DtKD5siVdV1dOn2fz02acfxTl8+9/8dnyNxHjI65b9Llur+iHvg56eZmd2qWmBCTJsEyyiq/WTiDNYpAGXphCutwv8iHRMdmEObYGxlF5hmfEc3oeW5bA75N80XIXfpI5jvp+4E15iXqCHOB6y+3CYs73hXPkZSwu/Gxu7fG45WfmMJO2VVFVtN9l4ut7le8v0e6ea8vktLV3i7+8WqEHH8Ef0Yc+oKl9v0+eQ7vGrqtqcjadxXGBjFg7ptM/Qh+t1VVUXjqc5/kanago3yUtUTuk1xn02x7Yh752N4RzdLTGewjF9DK6us7plu1ngWYbnE0u8Fen8lPZs0v8ZqMrH47TI/JbdhykcC4usE2HTJz3rqqrah3NsWjvNC7xT6Xq5RP9uDPdlaZ+gKu+lpuNpibP4tG5pC8xv07jumj8vUUeHbp3m352ltdMx9HIBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOBfi4cPH66dAgAAAAAAAP9bWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI5XWzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI7XsHYCVVVXV5f147/7268d/90/+F6cw/VuH8W/+/qDOIfPPvs0in//vW9E8be3p1F8VdXuZori50MWX1U1z1n8sNnGOXRtzHI4uRXF//lf/nUUX1X1wYO3o/iry4s4h5eXX0Xx7775G1H80+fPo/iqqrFl8ed3bsc5/Pijn0Txv//hH0Txf/pf/zyKr6r6ow+zef7jn/8szuG93/z3Ufx4eBzncOvsXhT/1ePsnXr9/iaKr6p6/CTL4e7dO3EO+5Psd1xcvIjib52dRfFVVUOfTS77/S7Ooeu6KH7o8zL06ipba85Os/V2ruweVFVVFy4UdR2nMNdJfIVE3/Ia9Pomm2NPtvn8Nk3ZHN33Wd1xOORzSz9kY3qa8ve6q2xfNqbFV1XNFV6jy96proUbmqqqOX0W+X2sOoTx6d5wid+QXiNfJ+bK9pbpHF1VFS75cQrdnPcJasj2+Vc3+d5wO2TrXdf6LH5e4J0Ys4c5t/xZjt1NFL+7yeKf/Trf14377L2+ezerOaqqxnC9nVoWX1V1ff0yiu9a9l6fn92P4quqDofsnWjxBFvV2mtR/H78MorvWt63qsrmx6Hltfx+fBLF933+XtZ8GYWfbLIx/fLiiyi+qurWrXej+L7L+/JtymrQcczm6LFboG5p2ZrdKr+PNWdzdGvZnmi/vxvFV1UNQ9a/G8esZ1RVtdmEtVM4P1ZVPX+ezW+3b7+ZJRCO56qq1of9uyl/L09PwvX2kNWgC3Qg6zBmOZxs8vX29F5WNzx+lj/Lwz5cJw7ZOrFboC9/s8me5XCa7S2rqoaW9Z3S5bKLe05Vw0n2Zo1jNi9UVT19+sso/vZ5fl7W91lPue+z+zhP+d5yCOenboEe4q++ehTFf/75p1H8O+/k3yr9+stsP9DiHmbVfMhqyD/5kx9G8ZeXC3wbEvZB//a//V2cw+v3srnhGx+8H+dwcpLtSS4us7PPboEaND0HT+OXEf6GRTL4538fFzixqyn9kDHMIn0OrzLIcpgW2JdNU5bD0Gd18GHK17rNkNXR6T2oys9Izs6y9Xpe4D6ebrN1ZhPuZ6qqri6yteoQ7i2rqg4X2bM8PcvWy5uLqyi+qmq8zvbIJ/fO4xwOU3Yfzrrwve7z97oPv7/r+3yPnc7yh0PeL6k5XO/SuWGJz1PC9XJa4jPGML5vYZ8g/PtVVfvwnKeFv6Gqqg+/7ZiX+EYmtET9ltodsr7RED6Hqqqzk6z2ubrKzn9rge984hG9xIsZJpGOx3GJWj7sQS7xXnfh/w3MaeOqquYu/EYm3JctMSDTeX6JTsXafYL871dceCzx/xdxryL8+y18J6vy93qJuqUL72P6jU1V1T78f+4h7Le0BfrJ6Xu1TP0X/j9P2hNf4H9xdjfZ3nBeYH5Lr7HE3LDEmAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgGP38OHDtVMAAAAAAABgQW3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYOwUowAAIABJREFUAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Xm3tBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4XsPaCVRVtdbVrddOv3b8T/7h4ziHb733W1H8vVtvxDk8ffoiiv/qxaMo/o3b96P4qqrtHA6pwxznkGqtxdc4zIco/q9+9KMo/re++c0ovqrqsy++iOKHLn+W77z1G1H8r778dRTfb7dRfFXVeJii+EP1cQ5vvZvdxx//9/8Rxf/HH/6nKL6q6tOf/c8ovuu+/hrzf1ze/FMUf/f0bpzDOG2i+Dt3rqP4y8vHUXxV1ev37mQX6OIU6mq/i+IPh2yO399kf7+qqt9k6+1udxPnMIQ59H3+MLfbbI7c76+i+Nbn60Rr2fw0z9l7XVU1VzpHjlF0398K/37Vfpc9y5NtPh6HYR/FHw7Zc+jqWRT/6hpvRfF9W2CSrmx+Gqd8ze+6bG5p3Vn29yurH6vy37DEgptfId1PLDEes7VunvNnWeF4WOIutC7dI4e/YYH7uJuyazx6mvVbqqp+8Xm2n/jBD/5DFD9ky/UrUzYWpi5bK6uqrseLKP7J42y9/P1v/04UX1X1/Crr//3k45/EOfze7/1uFP+rR5/HObwZ7g1PN1kfs1tghhy67MXqugXW/LAX27XbUfxuyvsEQ70Txeeds6phyO7DYXoS57Dt34ziu+llFH9ykt2Dqqr99DyK37T8fGJo2T79+pDtLaeWL7jbLtsjDy3bj1RVzXO2VlVlv6Fb4GxhHE+i+GHI3qmqqsP4WhQ/TfkR7p07WQ7jlPUxu2mJ3ln2G4b+Ms5hF7Zzu3BuakNet9xcZ3N0m/Nafgj7RrfP8x7i42fZuz2F+9P9Ib+Pu33WDz47y+bHqqrtkPXf2iHs6y9wH+cuO+f56qu/j3O4c/tbUfxmk6/5+5tsTPct7fnk52XPn2fz26NHeS3/4iJba+7czergJ5dPo/iqqjncn56d5XXL97/zwyj+sMtqyLOz8Ay7qv7zn/6XKP4Pv/+dOIeXF9laNy/wydbVVXgOHebQ+vybr9aF9Vca/+oiC1xj3T/fhfdhidsYD+kF3ok5fLHS+EWGY2ia8huZXmEOz4mWOPG7CTeXz6/yb0PGfTZHn2yz79buvpb3IHfX2TnREJ97Vr28yJ7l/maJPXbYc7nIzsvevpXXTt86P4/iTw/ZWKiq+uvrrJ97Fca3TX7CEa8zC8zR6Wu1xKdG6fdKY7jSpM+hqqql31IukEN6hTGt5RcYDHEtv0D9N03Z3JCOp37I55YprJ2W+G+gdH5qQ77mX15n9VffL3GSncn3E+tvKPrwf7vGMesFV1Xtw/8buHUr7+UO4f81Xb3Mz8vS72zStS59DlV53bHE/xqmY7qrLH6JuWkc07UuTqHS1SZNYZEvg8NzxzYv8JV2+CyHBdaJ7ZD1GqZwQI1h7fbK+v8LnX6vPoVzy5R+VFEVNzKXqFu6cKHoWz7HHkP9BQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/z8PHz5cOwUAAAAAAACOSFs7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOV1s7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOV1s7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOV1s7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOV1s7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOV1s7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOV1s7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOV1s7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACOV1s7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+F/t2tizJdZ0HeOXOqjpjTwCIgZgagCMEiGaEwwJFSY+CB+wXUdhWOOQgGKRI0CAGogUQYwON7j5DVWWmLhC8lC/wp51lxffdrzyrclh7r733AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFxt6QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFxt6QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFxt6QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFxt6QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFxt6QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFxt6QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFxt6QQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOFyrpROoqjo6OqnX7771o+P/9c8fxTlcXV1E8adHZ3EOd+++EsX/+re/juJPXz+N4quqTtbHUfwwxSlUvz6K4r979Hmcw6effBXFP/PM01H8+5/cj+Krqm4cb6L40+PsOVRVffnwYRSfvk7DOIZXqOrXWZm9vLyKc/ju+++j+Bu3bkTx//Of/nsUX1XVwvt45zz7DVVV9z/+NIp/+ud34hy2l9sofr05j+K7KPoHF5eXUXzftziHvmXXWPfZ+zgMQxQ/h80mr9G73S6KH8d9nMPpaTbvuAzfx2mGeUuLv6z8WY5TNg+uyuaQ4+5J+Perzs+fyXIYs/paVbXfZ7+j77P3ueuy+KqqaUq/iT7OoSqbg65Wj+MMtrvsXq767Jvopvx9rMrmsdMcBS6eOGTv0yw/oQsvksZX5U3NDKYpe5+68F0YxvwmtHYdxT91O+vRq6o20zqK/9W7/xzF/+Ltv4niq6q6PpvHXodzr6qqrstqw6uvZGtvu23eo5+Ec9hnn3suzuHq4uso/pUX/irOYbfN1iq6LuwnumzO8cM1st5yCsfrH3LI+rIuHG83LV/r2O2+ieL7dV6j03lH353EGUxjOBcPx9txvJVdoKpan33Xw5CtBVdVTVM4l19n+zyPL76N4quqdtcPovjTk2z9r6pqGMLvqkvHy2zeVFXVVVajhyEfJ6bK7kPX5Ws+6b2cKpv/TZWNUz9cJKvR45Dfx/U6q0/DPsuhhXPgqqqjTbZHsr3O1+/64+x3XF/lc/Hzk2yc+PZhVufPz/I5Q7pvuNvn5wFqynI4Ds9VjEO+dvbZ/S+i+JdfejPOoXVZjR2HvMYeHWXjxHqT7Zd99OEnUXxV1RdffRfFn93I505PP531RQ8efRbFT7u8t3zt7s+i+JdffDnOYRfun3793aMo/tP7H0fxVVVvvfWfovgnF/na2XaX3ce+5ScCWniN9DxAN8NvmOdkBPFtTDcXZkhhDl34O9I9u0O4B3PUlnTfbxPOe97/OJs/VlX1U7ZXdRTOvaqqttssh5dfeD6Kv/oiWz+sqjo7znqa/VU+3m7CDdyjys9LnYRrLkddtk7w4gzfdXc3PHP/p/xZ9vezs+LDyc0sfpWv+Vzus/p2PMM573GbzUG78DxCVdVZuC5+EfZVU8uf5Tgsf86nC8/Vpkc75jizn96HTXhWfR7h/HGGg0a7IRurNuEZ66qqMT0rPsNEOO1vD+DIV41hFm2GGl3jsn3+Zj3DvmOYwzhDfdtdZ+vi6ftcldeX/S6rLbOcae3THj1/lun7cHqS9USPnuR7fvmjyN/H1Soba7bXWX88Q3WszXG2b7nb5ftlqz48pz3DeDtO4f9WhXPY/H95qlo495lmGCeuw55mE74Lc6zlxsVlhhzSGt3C93GuawAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP/JvXv3lk4BAAAAAACA/2Da0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLja0gkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcLhWSyfwF9PYfnTs888+F//9Dz/4MIp/9ZVX4xw27TiKf/2116P4937/hyi+qupv3/5lFL/uuziHX//mN1kO3TrO4Xq/j+IfPnkcxb/4k2ei+Kqqx0+eRPHfX1/FOdy4eSOKf/RwiOKHIYuvqurXmyh+c5LVhar8Wf70pZ9G8VcX2d+vqnrup1kOf/rkfpzD3/78v0Tx7777v+IcfvHLX0TxD759GMWvW16jry4vsxzW+dTl6Ogoiu832Xd9eZHXx6rsWZye5bVlu83Guhrz9ynNYbXqwwzS+KqufvwcuKqq9edxDmM9iuL3u0+j+KPNS1F8VdU0nUXxrWVzr6qqYchqbNdltam1kyi+qmocsnehKs+hteybGPZZja6q6rrsPrQu+y6ncYriq9JRoqpqnCGH7FmmyxVdl/+GqrQfyJ9Eeh+nyt+nacqukX7X47iL4n9wHUXfOLkdZ/De738XxZ/eyGrs1T7vyx49/C6Kv3F6K87huGXj5e56G8W3Lq1tVU8eZXOGk9O8tpyfvBDFT1d5bVmvsme5H7O+qrV8/W8K6/wcY9UUjlVd2NO0yp5jVdUUtvn7Ka9vfZ1G8Zs+i6+q2u+zOegUzkHXq3y8Hccsh2H4c5zDapP1httdVudPj7L17KqqR4+/iOLbWb52tkq/y102TnT5UBfXt2GGdavqsrlT388wVqVFNuwNpxnm8n24XpL3plVTWN9WfbruNMdaR9ZPHB3NsDdwHa47TfncqZ+yudPt82ycudpmvWlVvr8xR5F9cnURxY9hDrtt1tdVVb3x2ptZDrv8WabrmH3L+7Jhn/VVH32U7b8+epyvy7/++mtR/Kdffxzn8OWDr6L4dZ+NVW//zd9F8VVVqzHcn4gzqPrN//4oil+HPfbzLzwfxVdV9X02B93vZzif0mfzvyEvLdXCOp+uJ08zTOXDJfEZdgbydflZklhYN8OPmGOPZGnpb5jjDqTf9TDDlt0wZhc5Dl+n403eo9eY1flbZ/kaZDvPesPvH4X76C08Z1RVlxfZubPTboavYsjWO87D97mq6tUXX47iv/pzNve6fJJ/Eye/z9b2u5P8fTp/9CCKf3ya7SGfnuVnvi434dxrhrMhxyfZ+/DG3bt5DuG+4wefZvsTDx5layVVVWNYG9osE8BlJ5FthvPJXThvWa/y+rYP/4ekwrFqlv99CO9j3M9U3mPPoQv709Q4w5p42hDM0lGF7/QYnqWcY9+xhe/jNMP8bwjnoHOcd0rXbLpwTXuWbyI0zZBDC9eDr/fZuzBLbUvPOHd5jU/H2z68D6vwOVZV7cNnmdamqqohXKvoZrgPFe7f9gewEHod/v/sUfj/aVVVJ0fZNXa78DnMUFvS9eBD+CbmmAfvdvl6BwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAh+vevXtLpwAAAAAAAACza0snAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhWi2dwA+GavXoR0fv98dxBndffSOK/8P7v4tz+Nlbb0Xxm+qj+BdffD6Kr6r63R9+G8V///gizuH5p34SxX/+zedxDtttF8W//vJLUfwnn30axVdVjWF8a9n7WFV1dXEZxd86vxHFP/ju2yi+qmq33UbxXZe9S1VV1bJr/PGDD6L4n/91Vtuqqv7l9+9F8a+8ltX4qqp3f/ubKP7NN38W5/D+H7Nn8fyzz0bx19dDFF9Vdev2zSj+m2++iXM4Os7mDbvdLorv+vy7nmqK4h8/fhjnkNb57fYqzmGbPYo6OzsNM8i/iaGuo/hVreMc+ilrCcbuPIufsvG+qmqasvex6zZxDq1l79M0ZbVhzMpCVVUNU/Yb+v7H93R/sdufhDnkc9BVnUXx2+39KL5vz0TxVVWtP8ouMGVz2KqqcUprZPhSx3+/quuy92mc8g8z7QemKe3sqqYxu0YL5z5dn4911WW/YRrzb+Lv/+6XUfzFdTZefvXVV1F8VdUqrLGbVT7e7vf78ArZd5nXtqrjkztR/Nm6xTnsrtKeJpyIV1V1WV/WhfO/3S7/JjabF6P4acrv4ziG30Q4TkxdXh/Xq+yb2O7ztdxxyN6nqU9rU1V1YV8WPstxyNfl+5b1hv3mbpzD1w+ytbNnnvlplkDYX1dV3b79XBS/H7J1hqqqPtw67FoWP8cctqbsPnThOFVV1VW2P3G9zddB+9XtLD5c6+imsDetqt3+iyh+vc7WxH+Q9obZWkdXc6wnp/L1lvU6uw9Xl4/jHLpwKn12lo11Fa4zVFWtNllfNVXeT1yPWV/UWtbn37iRf9fX19k6Zt/nX9Vqlc0h0/XkqqqPPv5TFH95nfUDZzezXqCq6osH2bmIMfwNVVU3Tm5F8W//13+I4i/CHr+qqo6z7/If/9v/iFN49ZWXo/jNJpt37Pf5ms823Ljc7vLesl9lc/HW5+PEFM5d9uF69Bxzp9Uqvw+LC/cWZjipFOeQnomoyt+HOY5spR3uOlyXv04PVVTVjfOsN/zmy7y//eK7bI/k7TezcebqNOtnqqruXGfP4vZ5toddVXUVvg/vf/Z+FL/p8/WWozHsDdN99KpKq+R6hr2mevJdFP7Nh9l3Od3J10FP72Tz6LrK505vPPVUFD+9mNWWJ9f5uvwwZN91n2/fVr/JauTN8Mx/VdXl4ydR/HXYD3TpolNVtfASbYYctuG52NU6e6HmOGMzhddI78EcOaR7JHPcx1XYW45zHGQM5+Jz9DTxrwgv0GZoSLqwvx1meJ8q/SbCGznHtmPaHM5Ro4dwXf78Tvb/G1VVV5dZX5bWx3GYYw85fR/zHMJHWVNl8+AW/m9Z1Qxj3Qz/f5GekenCyVc3w31Mdw27OQpclz3L/Qx7LEfrbH/i+io7G5L+b1lV1clRdo0xPhNbtUt7w/T/L2YY69JrpGNlVdWQ9oYz1IaWNocAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPxfde/evaVTAAD+H3jnnXeWTgEAAAAA/r/Slk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAADGWc/rAAAgAElEQVQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMPVlk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMO1WjqBqqqa+hr3pz86/Kjr4xSGfswu0KY4h8sn30fxt06eiuJXT92J4quqVsfZK3Vrhhw+/OPHUfydm9l9rKo6uZPdh8+//jL7+6c//nv6i/2YvdP77S7OoXUty+H6Oop/6umno/iqqq++/jqKb6u8vq3X6yh+2mXP8v4n96P4qqo33/rrKP79Dz+Kc9iHZf5fP/sszuH05DiKH8fsWZ6f3Yziq6r2w0UUf3bjPM7hKqwN+/Cb2Kyyb7KqqoWl4fIqew5VVdPURfEt/RFVtQ2fxenZWRQ/1RDFV1XVmF1j6o7iFPqwJejqRhQ/jNkcuKqq607CK2ziHPpVNm+paRvGh/1MVbU+q0/boKf7i2l6FMUftTyHGsI5aPg+7acnUXxV1bqyOcMcNXocsnc6G2WqpmkfXqGqKvyuZzBVNgmdZqgNVeE1puw3tJbW+Pw+jPurOIfvHmT1rfXZeP3s089G8VVVrWU59F2+dtb12TWGMasNaXxV1Wq6HcXvrvL72Fo2j94Oy49VFfYjq/5W9verqqtw/jaDLhyrpnDtrQvjq6r2u6wf6Lt8PblfZzV6P+RjVdqTdOHkaRjytdx+yn7D1OU99vnN7Nu+uHgYxZ8e5+/jVFmf37V83tK1sLaENbqbYbytyt7pvsvX78Z9WGMrH6uudg+i+NNNVt9a+C5UVa36bD14qnzeUuF3WZWOEzOsQXZZT5T2AlVVq7DT33aXcQ5Hm3CsCt/ps9NsHbWq6stw3/Hmrawfqaq6eeOZKH4Kv4lxfBzF/5BE1o904ThTVbW9zuag7/3hgziH27ezZ/nt42zuNIXnEaqq6jKb+7z2yhtxCi+9dDeKn66yGn11lc//fvXur6L4n//nbC+/quoyfJZTuAa52+fj7arP1tWPj/I9vylsDscZ1pOncMzfDVk/MMdefLpD0aVNep5CdfkFYul3Occ40bX0TMMMN2LIfkcf7g08usznThdX4RmbGWrsNt5rynr0W+HcrarqhWd/EsXf/zw/d3Ydru3fPst6micPs36mqmp9nJ3z6fsZxtuWnbk67cP9kaqqIasNf/Vcdh+36xnu41V4nuB0hrWKVfY7/vzev0Tx/fNZXaiqqqPsWY6V9xOPL7Me+Z/+OetHqqr6cMge0/22cJz6QfYj5khhHa6djXP0+anwRsxxwma9yurTOGZZdDO8DOuwr7re5vvo8bmxOIM5vquwF5jh/F46D07Py88hfg7hN1WVP4tphhxWYW948TjfLxvCNZv0TOoM2451HP4vzhxnMachPMcYfhTDNMO+Y3gf+j4/azSE97HC/0Mewv//qJrhjPMMc690/3YdrolXVQ277F52YXHYb/PzKWOF9XGG9eR1+L+nQ/g+prWpqmqq7DfMMEzEc6f0zH9V1bCf48wUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/nnv37i2dAgD/jnfeeWfpFP5DMNZ5lwAAAABgCW3pBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4XG3pBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4XG3pBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIB/Y99OmiQ5yzuAP/lmVVf39CzaEFrQBshgYVbLDg4mfPDBN0c47JM+oD6DfXU4wGDAwmBhZCOB1hkNs2jU01tVZfpA8AX0z3BmEL/f/V/9VNab794AAAAAAAAAAAAAAAAAAACwXG3uAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYrjZ3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsV5u7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWq81dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADL1eYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDlanMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBytbkLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC52twFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBcbe4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFiuNncBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACxXm7sAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJarzV0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMu1mruAqqpxHGq3v/zM+XbQxTUM+22U//pXvxbXUONxFN8P96L8dteifFXVWOso//7778Y1PPnYE1H+4vJhXMO9k+zV6lcHUb61/J3oa4zyY593Lxdn51F+fe1alN/v9lG+quqRRx+L8vfv3olrGMLfYrPZRPl7d7O+qarqyrXrUf75574Q1/A/b/4yyh9d/3xcw2PXbkT5n7/58yj/6qtfj/JVVbsH2Xu9OcjGyqqqbX32OUdV1X6bzRn2+12Ur6q6Gr4T2232O1RVXW6z79H32Zyhqurx61kfOwzZWNe3wyhfVdWFn7Hd5ePE2Gd9S9eOonzrsvZcVbXd34/yq/5zcQ1Za6qqsZ+7gqox69/6GuISWp/18+e77DtUVe2GrH9b99l73cb8txx22fyr9dn8r6qqb49G+e3ugyg/xXs9DNnacKx8XVaV9Q1dl6/zW/gZrc/a9Hafz1se7k+z/Dbv324cXonym7A99RPsE3Rd1j/euZPPW67fyNb5LZx7tZpg72w4y2poU2znZn3LqmXtuapqHLJ1WRc+hyn6x3TInmDIry4ea8L9vzFf33ZhDd2Y79+NQ9YeusprqDGtIdNath9dVbXvwv5tzNfY6+5qlL9sN6P8RXjOVFW1Xmdz8W7Ixsqqqu1lNmb3Lauh69L1cVXXZftOu/3tuIZ+9WSUX3X5uqwbsnXZyclHUf7qcbZ3V1XVdWH/FO51/F62HugqGy/HKSYNof0+ryEdq46OH49rOL/8JMr3q7A9jfna8trV7DkcH+Vz+e0+m7ecX2R7uetN3hZWB9m85ePbH8c1/Pbd7F7E5598Jq7hk0/DPcQWnhOF521VVd/4zreyGsbsbklVVdpFvv3h+1H+/PRBVkBVfemll6L82dlFXMM+PLNbrcK9jjBfVXUY3qvY7vI1dmo9wT2feNRPz5CnOC5L51/dBGcDcQ3p3w/zVTWG7/Uw5HOnMZx/nZ/nez4Hm6xN93029/roLP8xj8MzlmvH+Z7PGHZPFxfZWPX80/mdr7d/+5sofz7k52WtC9+JXfYcrxznd0MeeyRbD9x67724hnu3s/ONO2f5Xcq/+vNsz+X03aw93f7od1G+qurFR7O7SnU1zFfVh+fZ2u7qo1mbvn85wRz0MGuP24t8D3KobI3dt/wO4diyZ7kPz5qm2L5rLRvz+/AZVFXtw/nXsM+eYxc+g6qqfpVNGtL5Y9UE89h0STXBOfjDs2z+d7DOzx3H+Bw7LiGuIY3vwneqqqrCzxgnWJel73YL19jjBO/Eqs/62GGfP8fVKhsvzy/y9cQqXN+mWxVTnCEPYedwuMnXt6cPT7IPCMf8Ke5L9eH/8O632Ry2qqrrw74hvOezn+BuyBD+T9GVCc78zsMxP7wa/PvPCO9jjuG++ndf/W6Ur6r64U/eiPK78C5nVdVmnfXRQ/j/s/0q71vSffUp7lUsYFu9xgnWRQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAf6xef/31uUsA+KP12muvzV0CE/FbAgAAAABzaHMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBytbkLAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC52twFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBcbe4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFiuNncBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACxXm7sAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJarzV0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMvV5i4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOVqcxcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHK1uQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLna3AUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsFxt7gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWK42dwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALFebuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlqvNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy9XmLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5VrNXUBV1TiOdbk9/8z5oW3jGtpwGOX7MF9VtRvvRfm26qL8pw8/+2/wB2+99U6Uf+m5L8Q1fHj7ZpTfHF2LaxiHiyjfdeGrOWZtoaqq9kMUX7U+LuFyv4/yF+dZm14fHUX5qqpuHKP84dGVuIbLy8so362y9rgK81VVn9zP+sfrj9yIa7hynLWH09OTuIYPPnw/yv/Ft1+N8j/4wfejfFXV9777l1H+9GH+HI8O11F+2GV9/DhBH31y8mmUPz7O+5bh5GGU32w2cQ0H64Mov9tlY103xVS6y9pj3z8Wl3CxvxPlD/oW5bvKfseqqlXLnsMw5H1LC3/LrrJ8VTZvqqoax12U7yp7p6qqDlbZXPzhadaeq6ouxrMof+Pg0Sjf7/P17X64n9XQ5Wuiy102TvR9NlYNQzZWVlW1FtYw5u/EWNl6onX5vKPvsn5+1Wc1pG2pqup4nT3HK2FbqKoa91kN63Bdtdvlez7jmK0t1wd5ezy9yNrD8eZqlF9N8E7txmw90SbY8qlw/tVVvuezT/vpeB49wXfYZe91Vf5jdmEfXWM2hxzDfFVVF66RuwlqqLBNd90ENYxZDa0L5wwtX5ft0/4tXhNV9V32HDebp6P8p+e3o3xV1WoV9tFD3r/19UiU32+zvdy+n2Bfvss+Y32Q7yfv9qdRvqv83HHdZ9/jomXnbdvwGVRVrVfZd2hTjBPhkJ3ut0wxZxjHcM4wwfyvwj66a/l+cltn66IHn96K8tevPR7lq6oOwzXN5Xm+79T12W+xXmVt4cH97D5CVdX5aba+fff9j+Iann46uxdx/2E23lZVnW+zffEnn3wmyn/1y9+M8lVV2/AcfILrAPWvP/xxlH/huWej/NUrT0T5qqpdeC8jXR1XVV1cZuPlcBH2bxPst6wP0r2KdLyuCq+nTCLdPmvhXscw5A8h/Yw2wXlZ/CAneTMzQ9gg03xV1aqF59gT9A03734S5b/4zJNRfjtBczw+yOZvn7uRnzs+9Vi2Njw9y85/3/nw3ShfVdVaej8l/zFXB9m+0xAeUOyCO+J/cHiUtceTrClUVdX3/vZvovyD8B5kVdX3//mfovw3w7vmL1zL7kRUVdXmOIq/+bO34hLuPpPNxVdH16P8Zkj3jKr2l+HZQp/XUF3Wt0wxh90NYR8b3ndfhXsdVVX78M7+dp//lulc/GCdrYkut/m+1bALn8MEE8D4enC4HpliJZDey92G+wxV+TK9m+C3nKA1ROl+gv/Fie9FTNBJ78M+Ot23Wvf5Pe+0j24T/N/AebimSe8gVlWdnWTnfpuj7Gwh/b+sqqp9uId4cpHdiaiq6sO9ivSd2KZjZVUdXc021tPvUJWfNV1ss7OFr3z95ShfVbUK19j/+ZOfxzWkXcMEW9r12PXsbu6tD7N7Ou/+9oMoX1X16re+EeV//It8fXt6lvVP63U2XqZriaqq3S7ro7uwf63K72LGdzmrJjmvAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+P/U5i4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOVqcxcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHK1uQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLna3AUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsFxt7gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWK42dwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALFebuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlqvNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy9XmLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5WpzFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAcrW5CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgudrcBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXG3uAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYrjZ3AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsV5u7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWazV3Ab+3rxoffub0anwsrqCts0cx1hDXMIzrKP/2b96L8qcnn/03+IPnn30myt+887u4hn6VPceLi/O4hsNNVsMwjFH+/OIsyldVHR4cRvlhzL5DVdXh0VGUP314EuV3Y/5eH4Xf4fBwE9fQWovyFxcXUf74MGtLVVX37t2P8kfHt+Ma/vSVV6L8j3/0o7iG5196Mcr/+xs/jfLf/sZ3onxV1c/e/O8o/8pXno9r2G2zfv7a9Wej/McfvxXlq6r6PnuvN4dX4hquXnsiyu92p3ENu3041nTZeD3F/G8c0zE7HycO+sej/Hb/cZTfbLL5Y1VV33VRvu3yZdE+/S3D8bpqH+arxsrmTq3l67J9OP/arK/GNRz2Wd/Q1zasoA/zVV3L5qCXwydxDRXWUJX9Dq3twr9fVXWZxcf8t1y1bKy73Kftseph+Blnd7O9hkceeSTKV1W1tD2tsnGmqmq3zfq3y23YHrt8jb5eZ/OOR8L1cVXV7bt3ovy4ydYCbZXPGbp9Nhe/e+/duIYb116M8gfrvI/d7bO5zzBkfUu3vxHlq6rGytrTOOR9S+uyPZt0rOq7dA5bNVbWP41dPg+uLh2zs3Gmqqr1n0b53RCu88P1cVVV3w6i/G5/N65h1T+afcCY9fOHqwnWRLtsH7Tv8rlTOmvoWtYehzGfw3bhns2wz/voLuwbhiEfb8cx61uOjp6L8sOY7TNUVdUYPoe4j69K34pw2yp/KasqPbJbH+TjxDBm85bd/kFcw+4ym78dH30lK2DIz8GHyp5j3/LfsqvsvXxwP9t3+vU72Z2IqqprN7Ixe73Jz1hOLrI+etyFa4GqeuHZL0X5F196OcpvL/MzlpPT7Dn89I034hr+5MtfjPK7fbamubjM50778H5K6ycYb+MBM5O3xqqLbdY/ruJzoqo+/Iz0bklV1RjfFQrP/MI99aqqcUyfwwQ1hO9l+Bgnce04uyt0cpLfJ1iF/dPNO9kavarq5knWz7/8XPYdNhPcy1gdZ2cDV47ye2Pv3bwZ5R+EdynHCd6ps8vsnGdzkO29VVWdP8zaw0F4L7efYI3+znvZ/ZTjG/mP+W8/+Jco34f3Eaqqvv0P/xjlf/Uf2Tz45G6+Rt8cZH3L83/393ENn7z9v1G+C+/2drt8Lp9OZFcH+dnn2LLP2IdroqqqccgeRDoPTu/8T2G3y/eT0+fQwnPD1ibYlw/XllP8ksPM7bGb5FtkJvktw0XNFEuiMbzHmK7rLod8nBjDOeh6PcV+cuZwk4232wn2ztK9jtUEd41aOOjH984q/9+FLt0zmuDFHvbZc1yt8jXNfpjgjktgPcFe7sVZtsZebfJ34uw0W98+8bns/2CeuvZ0lK+q2myz5/DsX38hruGDO+9E+bd/9cu4hhqyc56Xv5T9b9dHt25F+aqq6zeyezpffv6puIa74fnrvXvhOr+f4B5kui6b4P+Y07FmmKCP79sUd1wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJbp9ddfn7sEgEV67bXX5i4BAAAAAAAibe4CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFiuNncBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACxXm7sAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJarzV0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMvV5i4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOVqcxcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHK1uQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLna3AUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsFxt7gIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWK42dwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALFebuwAAAAAAAAAAABXK0F0AACAASURBVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlqvNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy9XmLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5WpzFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAcrW5CwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgudrcBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXKu5C6iq6rp1bdZPfuZ8PwxxDeOYfcbp7jyu4Y1f/FeUf/Gp56P87nIf5auqPrp9M8qPrYtrWHVZs171+WsRNqdqrY/yq1X+HS63l1F+vd7ENXRd1h6uXr8e5c9PT6N8VdX52VmUv3J8HNewXmftYb/L2sLlbhvlq6qOw+dw69atCWq4EuVf+bOvxTW8/etfR/nnXnohyt/9P/btbMmS6yoD8MqdeU5VdXW1hpaQrcHItoSNQG0ZCDA4IIjgLfoB+zmAIJhsgzCD8CDLkjVgqeVudVd3VZ0hkwvBFcGN/iTyEPF99+vUyp079157qPv3oviqqtOT61H8Z4/O4xxunGTv8t69D6L447ANqqrC4bGGIWuDqqrdPktiGLKxpapqCuNbW0fx43gVZlA1TuFvjNkzVFWth+MofrPL+tOjy7tRfFXV9aMnovihy9txP4brge4kzCCvGbrKatB797N5qqrq6ZsvRvFDl9egWStU7XZZ/dda1p+rqrp6Koq/3Hwa53C0XkXxXdei+JaFV1XVfszWA9OYftdVqyF7kHsPH8Y5fHp+P4p/5eVXovj95S6Kr6rax9sded1SYZ9erbPxbbPJ963GMav/dlf5vtNTTz4TxT98kPXn4Sz7+1VV2222rnryxpfiHC4evx/Fr/rn4xzGMa1dHkXRF9sPw79fde1aVrfsxvybmMJ26CpbC7S4cqqaWtYOu8rbsQ/3YqcpXZ1W7cJvYuqyGrSb8v3kPj1uGp6McxinrH7rpmxtuO6yb6qqauqyOnq/fxDnUPG6KquDpynrz1VVU5cd0kxjvqBIz3nyna+qLvyNoc9q8WnK9ypqyt5FV/m5Y4X9KX0PMxyDx3PVWHkSDy+yOnjdZ+NjVdXx+mYUP47Z+UTfsr9fVTWN2Xe5GvL67cG9X0XxH7z7iyj+tddej+Krqt56O7uX0Vb5PDGN2Xf5W7/9O3EO1/tsnO522Rj7/vvvRfFVVefn2d7Xq698Lc5hHw7U2032XW/3+Ri93Yc1Q+XfRB9u6I7he9ill3yqarPN1qfdKq9bZrhyNUMOYRLxM+T9MX2EdIyvqhrDPpm2whx7HZdX2V2hD+/n5xtTOMYeHeW1U+2yttyHBxyvvfRsFF9VtQ7P/H72Yb4Xe//BZ1F8F77K/Qzz7Xqd7ZdsZ9gHHVbZ3td+m31T4TWjqsrvxa5Pno5zOD3O2mEzw/g2hnPNC6+G57cznG+k9dtml58hp7dap3hsmOFSQ7pvFZ5hV+V1yxx1xxj+Rrp/t8svJNRqyObbOf5vIN2STu/8p+d1VTP0hXQxUFVdmEPrs3ZI68eq/LvsZxhb0rXhPMvj7F2kNWg6V1bl/SFe41fVLpyzW3yHMO+Pm212z3s3wzfRhZs+Q/j/RFX5fcy0huzD8bGq4sEh3QuuqhrTGjLdt5qh9pr67DceX+b/f3HrtVtR/Aunz0Xxl4/z+6QXLWuH1T6/L//Cza9m8X/0cpzDh+9+L4q/fzfbMzpb5d/E2z/65yj+1u/8YZzDvfD/ub/+cnYP8mfvZvdRq6oqXBPNMr6F8XPsIc7xf+0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP8X7ty5s3QKAAfr9u3bS6cAAAAAAACLaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhaksnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDhGpZOoKqq66pW6+4Lx0/ti8f+t//45JMo/oMPPopzeOXLL0fxP//4wyj+5NpJFF9V1fV9FD90Lc6hDesofnu1iXOorBlq6vbZnw/fQ1XVVNl3dbW5jHNYHx1H8W3KnmFYr6L4qqr9Zhv/RmrcZ/3p7PpZFH///v0ovqqqwnH+aH0Up/D2T9+O4r/5zW/EObzw/AtR/OXFRRT/y48/juKrqt74zdej+H/99x/HOfzG17Nv+/Iqa8dnn3ktiq+qqu7TKHycpjyFsPyapmtxDuljjPurOIdUF5bj+ymfZ7Zj1pDrVTZPPL58EMVXVT26yH7j2vp6nEM/PBvFX15l65Hj43xNtB/HKP7G2XNxDucPPoviV6sbcQ4trBvS73oa87Gpq+wZjsPvuqpqrKwGvBpPo/huk6+Jhj4bG7o8hbp/nrXj2WnWjlVVN59+Ooq/CtfYY7eL4quq9rtsTbS5yufbs9OsP437rB3GLhvjq6ruPXoYxb/9k2xNVVX1rVu/FcVfP83mqs0mX9/+ww/eiuJv3crXEzduPBPFbzeP4xz6lo1P/SqLb7v8m5imbG3YVb7v1IXrqtafR/HbXb6f3MI9n6Hl7bjZZ+P81PI19jqsQffbbF99rHyuG8N32c/wLvfb7GygKqxb8q5Q6bFd6/J2rLD+GlZZDttNNk9VVbWWratm2DqrKewQ+So/f45pTA+7ZlgUVfYQ45StBaqqupaNsVN4VjVHZ+jDGwHnDz6IcxiGbK9h6G/GOYzToyyHVXZuWVN+NWM1ZHXsL977UZzD3V9la8MvvfhSFP/OO/8SxVdVXT8K69iW107feuNPo/hxl+ewOsrm7L/6m7+P4r/28q9H8VVVZ2fZ2nC7zfedLsN9o6vwPsH6KK2Bq4YhvKcz5Wvs6rIx8miVxa9neIY+rBlWM9zzSdfY0yxnyGEO4VnVHNJWGPd5O4bdqa5fz8bHq6v8rGo1ZH367lVey68us7trXzl7Ms6hH7K91HHM2mEfxldVvfnTd7McZljTrNO1XZjEHFs++/ScZ4Z3uQnH+S5sidOTfD85fRljuBdcVXV1lY0tq+O8fnv//fei+C9/ObuDeHWZnY9UVQ3rrB3uPrwb5zANWQ25Dc+g07t3VVWrsP7b7fI10RgWLq3P/2+gD9/lEG6edTOcsQzhM/RH+XoiXSNvwrshc+zLp+04xzeRPkYLv6l0bVpV8QC1D/9voaqqm+WUJJPepRzC8S1dX3+eQzY27LYz7EGG54ZT+FWlbVBVtQ6fYY5Jfxu+iyFco1dVXW2yvYJ1uB+d7ntVVU1juDbs8slqWIffZbi2rMr33sZwfHxihjutzz2V3dnfXGbPsJ9hPzntTpvtDP/72mXrslb5HuLzv/67Ufz9z/42ir+8yM49q6rOTrLv+h//7i/iHN74gz+J4n/45vej+OMb+f9vpNe0ZymDw/i0lq/Kx1gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP/NnTt3lk4B4CDdvn176RQAAAAAAOD/vbZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrrZ0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcrmHpBKqquq6q78cvHP/Wz9+Oc1jXURT/1NlTcQ4Xq4sofrVaR/G7zS6Kr6o6Oj6J4i8fZ21QVTXtLqP44/AZPs9hH8WP4xf/Hqqq1uusP1dVHR1lw8P5+aM4h81l9i6HVfYMq2EVxVdVbfbZM5w/eBDncHJ6GsXv9ll/PD7Jv6mry3RsmOIc1uusP/z4xz+Jc3j1la9H8TdOz6L4D6dPoviqqu+/9W9R/Hdefz3P4ft/HcV/97t/FsWfP/w4iq+qGvdZ3dH3+bvsumyMHcfrcQ7TlI2xaXxrWe31uT7MIRujq6pan42R2202Pl67NkMd/Sjr02P4Hqqq+nocxbcuew+Pzn8VxVdVnV57Oorf1bU4h7OzFsW3ltfB4z7r012Xraum8SqKr6pqXRbfd/n4Nq6z/nT/wftR/K+dvRTFV1WN220Uv502cQ5Hp8dR/DCFnaGq6iJrhzZkOZxvHkbxVVUnR1kdfDLDnL8P11VDn81V/Sqf6x4/zOa637717TiHoyF8Fy3rz9PwZPb3q+o7f3grim91I85hH24B9i3fq6hsyq/9Phtb5qgZpinbq+jTCbuqWljHbvdZ/TZVvv83Tdm7mPYz1H+VjdHvf/RunMMLv/ZCFH/cZ+1wtcvG+Kqq7TarY68fPRHn0IX9qbrzKHw/5XuQ6XfdKq9bdrus/tqNWQ59y8+quimro6fKzng+/5HsN7rK54muCyfcMYyfYb+lKqzfwjG+qqqbsn3QaczaYQz3nKqqpi4bo8+uvxjnMO6yd9FVNkZXVVXLzsuGPhufdtt8/+5HP8rqjq5l42NV1dkT2X7ug8e/jOL7Pn+G55/L9q1e/MprcQ77q2zf6CL8pqqq/vzv/zGK//pXs/23y6tsjK+qOj7K5stxhvptFZ4hV5/Nt9dnOIu/3KT7mHndktbSQ7jGXq/ytWXXhe0wQ388BPvwvlPaCtMM7Zj+xrTP1xN9n40t9z/L9u9+8Wm+//fGq1+J4ndhX6qqWnfZb9x8Kt+reO7Zm1H8v779syj+0TY/q9rtst84GvIryqvwN7a7rJaPx/jKZ8t1n7fjNjwc6FpWt3z2cIYzv/BebAtrr6rP77snNlM+vn18no3Td3+cvYvwektVVfXhd32VHnZVVRd+Vy3cQ+xmuNOajk+7OeqW8F228By8qmof3tmfWvYuxvAuQFXVNrxrtD7K90umcLbab7P3kK4lqqpaOFfFg3xVrcKxJd2rmGZoxy6cL+dY3qZvopvhLH4c07Ely2GGG19xn16t8v+lSdfYaTtsw/t/c2TRzfBdDuF8u9vn7TCEd8/S8Sldj1TNUTvlNWiF57fp2Wc/5O04hpe+vvut34tzeHCenRv2fbivPsc8E64NW3gfoapqu83+lyb9f6Kqqj5cD7x267tR/HtvvxnFV1Xd//TTKP6lLz0T5/DD7/1VFP/i174Zxf/8F+9F8VVV3VH2Xbb0fkzl80S8Hql5zjgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgMNz586dpVMAOEi3b99eOgUAAAAAAGAGbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcbekEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADhcw9IJVFU9fHxZf/lP//6F41988ok4hwfnD6P4i81lnMPrr3wj+4Gr/4jCHz6+yv5+Ve2nMYo/OjmJc5i2uyh+HPdxDqv1Koq/evQ4i7/aRPFz6Lr8N/o++5FpzPpj1/KHWB8fR/G73TbO4fLiIoq/EY6xc/SF/T77Lq+u8nZch9/1VFl/rKq6d++zKP7F55+P4o+OjqL4qqrh9FoU/4N/ejPO4dvf/k4U//03/yaKf/21P4riq6q2mwdR/FR57dTVp1H8OOX9aRqz77JVODZMWc1RVdXVOoof1nk7PjjPasgbZ89G8fttviS5dv3pKP7Rxf08h/5mFD+ss/40xzyz3WU1w2qV98cPf/lxFP/RR7+Kc3jjjdej+GHVR/HjNqsfq6qmaYrid1O+nuj3WTucDll/+uQym6eqqp5p2Tyz7lucQ1tlOVxezPAu+yyH/ZTVsMdDXresWtafuj6fq6Z99i7GKVsTDWEbVFV96eZLUfzdj9+Jc+ifynIYhqz2auH4WlXV9dne1273KM6hdadR/DTmc9Vul43TU8vGhlne5ZTNdTVk42NV1XZ3PYrvw7lqGrNv6r9+JYoeZ6hbWpfV0mfXnopz2G6zWrybsvXtasif4fzee1H82VE2NlVVTeFG5LD6chS/vczaoKqq77N2SPtzVVUL9yqqwn398K9/Lm+HVNeyMXacoSHStWHfsnbsZ3ib+7A/1ZStZ6qqashq8XHMxuhxG9YcVTWEtVNX+Tl4a+fhL2R7b1VV/ZD16U/uZvtW7733bhRfVXVychbFXzzOa9DWsn3MPtxv+Y1XvxnFV1VdP30mit/t88PPj+7ejeI/u5/db6mq+s1vvBzFP36cjQ2ty/fO0jPkoc/H2PRuyHaXPcM2bIOqqstNNlddO873nc5Osr2GdJmf9qXPc5inkk20OS5nhLqwHdL43QzvMq3l10f5fslFeO/rPLx3di+/YhMv7k7DOrqq6oWbWR08zbCmeeunWQ14fpXV0dtdfqfhJLwrNM3wXW724btYfnisFu/F5nsdJ+E9xs02+y7TM8eqOfYJ4hSqS/e+wjvWVVXDkJ1dpve8VzO8yzGc84cur+W34XybnrGMM3zX6S+kdU9VPs7PsaZJ15fp0DDMUP/twnXZZpOfl63W2XOktdMctVda+8yxrovbIRyj52jHtHRahfNUVdUYtsMcy+PVkM13Q1r/RdGfS5thjrkq/a7SmmHcz3B2Gs6XaXxV1W4fru3m6FDhb/RDVr/tZxij49/IX2WN4Xl+W2VjbDfDeuSPf+/3o/jLzRx7sWEtHo4Nc9zZj+9LzXGhIJbnkM414y7rC1/56htRfFXV0fFPovif/+yHcQ5P3szOPt95J7vbuz7N73xdhudlrc1QB6d7DXOsJw7grAkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+J/u3LmzdAoAB+n27dtLpwAAAAAAAByAtnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAByutnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAByutnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAByutnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAByutnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAByutnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAByutnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAByutnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAkk7gpgAAIABJREFUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAByutnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAByutnQCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAByutnQCAAAAAAAAAAAAAAAAAAAAAAAAAMB/sm9nvZYV1x3A1659hntvj9CAuxlC7OAhODg2yCRYsuQo36I/YH+MzFKiJCIiIchTwJjGNO3uppu+45l2HvBjnvhvaR9Fv9/7OnedfWpXrVpVFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9lebOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9lebOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9lebOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9lebOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9tds6gSqqg4X83r9lZe+dvwn9z6Lc2hH2aP4/uvfi3MY1pso/tWXb0bxH929F8VXVT16chrFtyFOoZazeRR/enoW5zActCj+8NJRFL9eraL4qqrtdhvFD7tdnMN8kf2W52fnUXxbr6P4qqohHNOz+SLOYXWRPYcnT55E8bNZvtTMl8sofqguzuFilY2Hvs/Gc1XV55//Psuhy+am559/Poqvqvrwow+j+Js3s7WuqurLL7MxfeOZLIeHX/wiiq+qunrl1Sh+t3ka57DZHETxi8VxnEPXsjHZVTZJP378aRRfVXXt2jei+PU6XyfmyytR/NPjL6L4ywf5e72t7DnsumxeqKo6Oc/Gw9Hy5Sh+scxqt6qqvmX7kZ9/8H6cw+PTrG75sx+8Gedwvv4yir9y+GwU31pW91RVbXcXYXy+n6htNsd2Laudnql8P7LtsvmxqxH2E+Ge5PTiJM5heXQYxR/Ms/W6jbC/HbbZfmA3Qq8i1XVZEpvzvNcxn2Xr7a2b345zOD5/FMX3Q/Yd+sr2VFVVXWV19MWQ1y3zLnsOQ152VD+/HsWfbbKxsAzHc1VVG7LxsN7ka/6usnl+MbucJTDGd+iy+m+9zdfbtGt0/VJW/1VVna+yfVW1bDzO+7xmuHnj65/xVFWtsu1IVVUN4Ty92WR1R+uz+rGq6uLikyh+Mc/2llVV1WX1X4X9lnFKr3A/0OX95Ap7sWM9iUTfsufQjVE07LLnuN3m9du6slr61x/+Mop//ds/jOKrqrr0fKPl5zxdy/qg56sHcQ6ffno3in/4ODsH38XzQlUXll/nx/ke+9JBtk68887Povjz07z+Wx5mfae//6d/j3N47VvZmv3Si3lf/TQ8S5+F+6pleBegqmoXHsbvRrjTkFYNq/CeUN/nc8u1y9n9lD7cj1Tl90vSyqmNUf+lRshhGLLn2I1wr6ILa8j0bkcboY4+PMgW3Pd//XGcw3qW9RC/dzPrvd0N7xlVVZ2cZr2GN76Z729PzrJa/r1f/SrOoWvhvmibvddHi7x/t9mETZv08lzla006N43xHVrXR/EX6+z8t6pqvc72A32f7Q1bGF9VtQt/yi4v/6oP16rVCHdSW3h4uQhr8YtVfu6YluJjdM6Wy2xPs77I3qlhhBJ0aNncsg89yN0m7yF2s+xhbsL3shthT5TuLtcX+TqxDfen6Tw/dPlY2Oyyz2gj7ImGtFcRxncj7C3T+m8e/i9PVf4cu3h+rOr7LIdt2usYoQZNR0P6Harynkv6HWZ9PhbS12qUY8fwM8b4f57tNpsbNuvw/9PGqJ3S+FFyyN6rtJ/8s7ffjuKrqvqTrO44G/JeRevCMT19GTxCCvkn7OKLsSNssiubGzZhCqtVvk5cv5H1Mb9zcDXO4T/eezeK/9Gb2dzw/s8/iOKrKr5jM8Z6O0b9BQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACM786dO1OnALCXbt++PXUKAAAAAAAAVVXVpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP3Vpk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP01mzqBqqqL1ar+5+NPvnb88tIyzuHs+CSKf/jgcZzDc9evRvGbzTaKv3nzZhRfVXXv/gdR/LUr2TOoqqqhi8L7+TxOoRuGKH7YZfHLZf5O7MLxNOtbnMN2s4niDw4Oovihst+hqmoTfofT81Wcw2KxiOI36+w7HB4eRfFVVRfnZ9kHdPl4TD9iqF2cw27I3svP738exb9w84Uovqrqtdf+OIr/9LP7cQ6Pn3wRxb/13e9H8T//n19G8VVVi8PTKH62W8c5zOd9FL/dZnNLVdWsXUTx4XJdh5eeyz6gqk7Osvnt8pVLcQ7DKqudvjzNfst+ltXhVVXLRfYcrhxei3P44lH2W+5m51F8X9k7WVW16LOa4bSysVRV9VfvvBXF338a1gxV9dGnn0Xxr72S1T6X5/l7vdtldUfr8rrl8TbbIz87ez5LYMjWiKqqbbjOrIcR6r9Vth/ou3xumA1ZIbzbhAvuCN+h4r1dXre0cI7shqyF1+VTdO3CPU0Lv0NV1bJdieI324dR/PwwnJuqanWR/RjzLu+dLeZZ3bGpfJ8/hJvsRZ89h5OTvJd7+VL4HML+X1VV37I+5vFJtj8+WBxG8VVV2232XreWfYeqqs32chQ/C2v5qqrL86w3/+TJx1H8/OqzUXxV1TZrW9WwCz+gqroufK/CuqdV3oOczbP96VD5nqirtK8e1j0j1C1pz2eEFOIk8tFU8RdZhVua2Sw/bzu/eBTFD0N+xjJfvBjF33g2nOO/+G0UX1V14+orUfxuhPrv/OJuFP/e+7+Ic5gtsu9xdCmrGdarrK9fVXX8OKtjv/vay3EOL770RhR/vsr22N0y36P/3T+8G8X/+Q++G+fwZdjHPL/I57e+z3ouXZfVb7t0wf4qiSi8tXzFTb/FfJb9Dv0I36FrafUzwm+ZFi5hCmOMx/QxDmO8E+mWaIQ7Da1lY7qFD/Jsk5+Dp2cs2xF2FN06Wyf69kwUf7DJe2eXjrJe6t179+Ic7j56EMV3XV53DOG9sXSOXq3y87LFMuwTjNHzCePX62xuWIZ3EKuqNuEdmfR3qMrv6aT3IMdo+rSwht2N0JffhWfAs1l2L6Oq6jy8S7kI70iPcAxeXfhm9yPcT07rr/Q+6XyE3tkqrH36eX5+m953H2Nu2G6zHGbhY+jDGriq6vwsuz93eJCf2aWGsI7uRhgLfZ/9mLsR7rSm+4l5OCBX6Xo9gnStHOMzhvD/ib76jGxuiZ/DKG2C7EM26QFwVS3DMZ0+hmGMwiWsW8bonI3Rx0wtFtn/qF2E9yBrD/4X5+BSfrf3+Ivs7tpf/PjtLIFtXv+lva+4HV1j9FLDvcAoFwrSD5l+XtiHs4GwTVBthB8zXfOfuZH/n97hUXaX8ugoOwdP14iqqk16hjzG3BLGjzE1jDEmAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGDf3LlzZ+oUAEZ3+/btqVMAAAAAAADYG23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX23qBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX7OpE6iq6lrVwWH3teN321Wcw2K2iOLv/e5+nMPVo0vZB8y+/jOsqprP8+HwyksvRvGPHj2Oc+j7eRR/cHgU53B+chrF77bbLIFZ/lsuF9lzPD29iHOYzbP3crvdRPG7IQqvqqquy97LxSJ7BlVVrc/GQ9+1KH53kY+Fa+F7uQ7HQlXVSZcNiN0mzyF9L5fLZRR/fnYcxVdVLRfZO3HrxVtxDgfZY6x//s93o/i//sufZglU1d/+499E8T/9yY/jHH7z0UdR/OFhNh6rqi5dyuan5fxaFL9oec0wmz+N4jfr/L3sttn89txzL0fxT88eRvFVVS3cDswqnBiq6tlr34jiV5uzKH6zy9+p03X2Tr3xne/GOfzy/r0ofnOa7w2/88qrUfxylo2n3Qh1y2objqfK4quqnls8H8Vvd1nNMLRsPFdVVXcehf/ufj6/fetmNscOI2xqdrtdFL9ZZ/H9CPvbqnRvmL+XaQuuC+PHeCV24XOsTdjrqKp+6LP4xbNR/MMv70bxVVXXL70Sxbd19gyqqlYXB1H8dshq2KqqLqylu8ri+/4kiq/Kew19y2vQvsv6Ro9Psv1E32djqapqPsvWid0m7KlXVd+y33IY8ufQKusnX70c1l6bfKFoXTY/tS4bC1VVXbpWDdlzaH0+R/dd1qtYr/MatOuy/WUXjoWqfCwMQ1YHZ7uRP3xGWICldXhV1bDL6q/5YbbOfHGc7fGrqmqbPcdrl/8oTuH4OKsB+8rOSG48m9WPVVV9uMd+8PiTOIdf/DrrJ/eLfL29fut6FP/o3oMo/jA846mqeuPPXo/irx5kPcyqqj48L/vd77Pn+LtPP4viq6q+//prUfzFRd4nmId3O4ZhhNopPANO1/zdCN+hhd+hjdAwSeuO+Syso8f4DmkPcYTiKXyM8e+w2+bjsVr4XucZxJ8yRj85HpPhHZuP87ZVvdZndfTpKj+rujoPz8HDuuPN73wriq+q+q9f/SqKv6jsjKaqqnXr7APCPVXVCDvccH6bhetMVdVmnT3HcLn+6jPCD5nNs3diPcJ73cLfYjPCvbM+PMfuh3TRz9eZcDsyQtcpv1PahzVDVdXBMtsjb1bh+UZ4H7Wq4vmttXx+a+Fv0cJznovz/F5tWnvNRvgt15WtlyO01UfY32ZjYYz9xFF4R3qT/t9BVXXh5i7uy4/wXvfhgNqMsTMLF4p1WHuN0icI34l0LFTl+9PwaklVVe3C75GfVY1yWhVFH4R1dNUI513pcBqj4RKXwSP0QcN3ez3CfmK1zvZF6Xrbwp56VX6n4cGTJ3EOf/0XfxnFX63s/PZklU+Qu3SPPsL0tg3nlnhqCMdzVX6+Mcp6G3/GCPv8+FmGY2GEu8GtZfuqk5N8b/jWW9nccvfT7E7E6Wney+3C/2vPx1JVl47pEeqO7QjvNgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACM6c6dO1OnAPB/un379tQpAAAAAAAA8Adt6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F9t6gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F+zqROoqhqGqvX268dvN0HwH7Q+iz9YLOIcPvzwoyj+2699M4ofNpsovqrq1q2bUfzp6Xmcw+nJWRQ/n3dxDsuDwyj+7Pw4iu+rRfFVVdWy5zBb5NPLar2K4heLZZbANp9bNun8NMJP2VWWw60bN6L433762yi+qur7b/xpFP/eu+/FOczm2Zg+2+XjabfbRfHXnrkWxT+4/3kUX1X19OmXUfyb3/tRnMOj84dR/I/e/GEU/0/v/msUX1X1zts/ieLf++D9OIfNxUUU//Q3d+Mc3vrx61H8o6f3o/grl65H8VVVNcyj8NU6qxmqqoYwfrbJxsLlxaUwg6rP7t2L4l+89WKcQ9eyRbsN2TrTKlsjvhJ+xpDX0VfmV6P4q7fy8VTrrIbcdNk7ce84r51euJbty44qn98uVtlzGObZ/vQ8/PtVVYddNkO+/MKtOIfdLtsTVR3EOVSl/Y6s9toNWQ1bVdUqm5/CltEfrKPozZCN6dksHwtdWLdcrH4f57BYPBvF9132HLp19gyqqo6fZM/h2pXn4hxql81vwy7v+QxDNs/P59n8eNheiOKrqrbbB1H8EL7XVVXVZT3IF154KYo/Psm/QwvX2xFaZ7HdkM3xVVVDfFSTrXWtT3eGVdtdNh66Lt9P9JXO01n/brfLz1iqyyqP1ue103bzOIrvZ1k/eQzpeBrCuamqahe+l9sRtvm7bfY9tmdZLX/QZ7VbVVU3z97rhw8/iHM4Onomiv/G838SZpCvM58/+iSK/80nn8U5LI6yumU+z3dmX95/EsUvZ1nl8fbbP4viq6pWF2Edvcyrp3/5t3ej+D96KevF/sk3X47iq6pmfdiL7cY4Q07HdF47pR+xCc/S57MRriulNeQINWj8EWHZMYR7/DEM06dQQ5rEGK9UOBj68I5OVVULczg9z/f5Dx98EcVfu5zVDG2R1wyrVdZ3euX6UZzD1SuXo/jNNqsZ/vvXP4/iq6rqIHuOu4v8LmYL99j9CGvVNtzcbcNewzDC+e0QL1Yj5DBkz7GFZ/l9WD9W5Xe+hhEWq7xuyHKI71FW3g/ejlC4xH2nEXJIx0Naw45R/7U++zW3I9ztXW+y9/LoMFvz133eT07rls0otfz0+7JwOI3wXuYPMl2r0rWyapxzmsQwwh3r8/D/DsbYHM7Cf0pK7yCO8TtOOxK+kq4TY0jnhq4L3+uwfvwqh/SsKs9hF9agLezLz/q8T7AL69ghPK+rys8uhxHuF3dh7yrcolc/y3/L4/D/9N75Uf5/LH14z2eT7uvGuNMQrlXxYKiqFo7HdI4fo4weo35L7cPeMBXnMELtlN4NGUbIYRM+iFf/+NUo/uO7+f8+pMaondK+UQvrv7E+AwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID/P+7cuTN1CgD/p9u3b0+dAgAAAAAAAHukTZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPurTZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPurTZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPurTZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPurTZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPurTZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/8u+vTXLcV33AV+9e2bOwR0gQYLgxaRsiZQihRSlmHRcecnXwAfEd8hTymXFSuQkTiSatCRexUtAgQAIAji3me7OA+1UpZIn/buqp1i/3/vqs2b3vqy9dx8AAAAAAAAAAACA/dWWTgAL5ktHAAAgAElEQVQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dWWTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dWWTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dWWTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dWWTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dWWTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dWWTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dWWTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dWWTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/dWWTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/bVaOoGqqq5r1R+c+5Pj15suzuHs9DiK3213cQ7TOEbxH330SRT/6g9fi+Krqo6ePIniX3zh+TiHD97/KIofdkOcQ7/KhtbhpYtR/MXWR/FVVUcn2Zg43W3jHLrKxvZx+BvW600UX1W13qyj+JOToziHVTjV//HBl1H8X7/9ZhRfVXW2PY3iX3/9J3EO//hPv4vi1zOMy1pnz7h7949R/I1nb0bxVVWvvfKDKP7Og/fjHG5cfDGK/3243l6+fj2Kr6r64ONsrXvumXy9/eLLP0Txb7390ziHbvNnUfzJo3ej+CdffhbFV1W9+OyrUXx/Pk6h7ty7G8XfvHA5ih9Psxq4qurG9Wej+Cen+Xp7bn0YxbcpW69bnUXxVVXjmNXBrWtxDpfXV6P43fAozuF4zPrD9sFJFP/cpWei+KqqfsxqhmHIa/mpy+q3B0ffRPHbIT8nuHT+ShQ/QzPW2NKxne9ppmnKMjh4Koo/PbsfxVdV9e1SFh/uTauqhso6xFDZmOpmOAKchmxuOT7O90RfP/40ir95PduPXLtwI4qvqhrq6yj+LDw/rKqqKXvGHP1pN2Rnqa3L6pZpehjFV1X1LTu/G3b5/FZTVn/tdtn8tlnn9V8X/oauZetUVdU0Zf2pqxnuBqaD8AlZO7Z1fiZ+ts3qln7K65Z0fpoq7U8zFIBhf+rCvWVVVd9n9ds0Po7iu26GvtBlY2qaYVxXl72Lrp/hrqqFa/6U7dH7KW/H3S7b51++8lKcw2F4Lt+NWf33/kf5GeTXj7KzjuQe/190q6wd59iX3XjhWhT//ZffiOJPT/J1oq2yteo//u3fxTn89Cf/Koo/Os764xz7kW1Yt7SW18Gbg2y9G4d8bziE+8shzGEzw3c+6fcEc0jPztISNN8RVXXd8u04hv0xvd+YpSFb1o7dDHcsZ9tsrfnmKPvGpqrq3i6bp18Kv5f67YcfR/FVVeub2RngC8/lZ4h3730VxX/88E4U36/zuuXscTaw1jPkMG6zHIbw7Kyq8rkh/dZojjk+XavStbKq4uU2PP+bZpij03aYY71O2zH9HmCO7wn6PhsTY7hWzmGGIRHXwXPsaXLhb+jzveGqz9rh+Dj7NqR1+d1pFz5jjj1VS8flHoyJdI4eZxjY3R5sDtM7knSt6sIxWVXVDeGaP0dDhsMqXfLn2eKn+9sZ6pb4XexB7RTuBaY5zr3C3zDHu+zDdqjwbmGGTwjzc6cZvvOJS+k59mVd9oxdev63y9vxlR98L4p/7mL2vXxV1TePsj59Gn6T0I35/W1r2f1Ga3ktP6bfvoX9eQr/flVeQ35X7gZy6W+Y4dvgsDvMsuaHz3jn3fei+DnOfPJOPcP+Nt3TzDCmvhvjEgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIB/cfv27aVTAL6Dbt26tXQKAAAAAAAA8H9pSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5qSycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP5aLZ3A/zEMf3psl/+MdZ89YzuexTm0MIezs20U/9Uf70bxVVXXrl2N4nfDLs7htVe/H8W/+9v34hy22+xd3Di8FsV/cf+LKL6q6s++93IUf/+938c5nL90MYpvbYripy6Yl/7ZGPbpcZfPLTdfuhnFP/P001H80ZPjKL6qqto6Cl+tW5zCv/vLt6L4//B3fxPnsNpmffLHr74SxZ+/cD2Kr6p6dDZG8dfWL8U5PNw+ieKffuapKP7dd96J4quqrr/6gyj+8ePHcQ7TLhtXmwtZO1ZVffLhr6L4e/ePovjv/8XzUXxV1fFwJ4pf93kOly5eiOIfPHwYxV+5lK0zVVUHfdYfnzx4EOdwOmZr/vnDZ6L4rnVRfFVVm7L58fT0UpzDen0SxZ9VVv9VVR2fZjk8deVKFL+qvG4Zpqw/7sZsP1NVdRR2yevnsnY82+Z19NEu6wvnVps4h2k8F8Xvxnx+W/XZmj0O4bicsjaoqjo7uxfFH6zztarrsnYIt7e1G06zB1RV1x1G8U89lZ11VFV9+tk3Ufy9+59E8Vev3Ijiq6qmKZsbWuVnZ9OU7S1XfV53dJU9o+uyvWXaBlX5b2gtq8OrqsYxW6umyvpjN8P1Qt8/iuJ324M4hxaeO/UtX/PPtvezHFZZ7TTmQ6LalL6LbFxXVe2mbJ/fh3c00zTDlduUzo/5nijdVnXh3FIztONUffaALoyvqtPt51H8ur8c59B356P49KxhSPcCVXV4PrsnivtCVU1Ttq/69W8+iOLHGc46rlzN2nHYzlGDZr/jjZ+9HufQjdmYSLv0V/fzu/jPPs+e8aPwHr2qarvL+sNmk9UMfZvh7GwM644uzyEe2vm2rLrwdxweZHV0+ve/tQcNGc5v6fxYXf4b0hzaDPcTfXjPM03ZuG4znHVcuZLdkfz+48/iHK6Fd35PjrNzhqqq3ZTNDetVth946VJeR18I2/GDD9+Pc3i8zfa3Xfq9VPId5z9bb8J1YoY5egrvy+Y4q6gpm9/SbxBX6+w9zGOGdSKsAdO1bpzhuCU+E5+hHdNnjGEd3c1Qt6T9KV1nqqq6sD8OM3wj3c3wTcHStuFZQ7rOVFWNQ9anx7SWn2Fct5adfc0xLsdd1o6bg/ye5/Qs+z4kbYU2w1nFLFNkKD0vmcLLpj7cS1Tl7TjPeptp4Y9I/x+pKl/zh3h+rPi8JT8zymvI3S4bE+t1/i534Xqb9oWq/E0chPeGu/B/7KqqWvptSHjuVVU1hHPsHGv+EO6R0/3pqs/v/F57JrsjGWf4JvXgINxPhP+/UV2+3k7hmJhjT5QuuOmZdnyu/+1TZnhGJr2nmacdMmkK4wyHPuHxX3UzzG+bTZbEva++iuIPDvN9XbpU7WY4007PCdpqhu9T4icAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMJfbt28vnQLwHXTr1q2lUwAAAAAAAIDZtaUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/taUTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/rZZOoKpqGIZ6/PjRnxx/sDqMczg82ETxfdfiHKYui1+tst9w58s/ZglU1dnpaRT/wgsvxjmk77KbhjiHH77851H8bz/9IIr/+c/fjOKrqlqXdcjNj/Ix8f4HWTus1uso/vLhuSi+quruw3tR/Ftv/SzOYTWMUfz2bJv9/ZaNyW+f0UfxbTfFOTwJH/Hcs9fiHG4+dSOKP9eyPr3b5u14sMn645en9+McPv/DF1H8s9ezd/nSiy9F8VVVF/psjr3T8rXuzdezteY//eqXcQ6v3LwZxb/5r9+I4nd1HMVXVX1x55Mo/vpTT+IcDtaXo/hHj7Ix1Z3cieKrqs5tLkbx1y49H+fw5PjLKH7sHkfxu935KL6qqsKpYZiy31BV1VW2txu6fIs7jLsofhyzhpwqr6NPhmxfdrTL57dnDrJxOY7Zu7ywyuuWL0++ieLPb/JxOQ5Zf1j3eQ1a6Xo3Zfuyw/VB9veralxdj+KHIV9v131WB09j1heG4SyKr6pabbK9XXpmVFX14vOvRPH3Hvw+ig9fQ1VVdWO21rUub8fT7UkUP8PRWVWfzfNdehY7Zet9VVUXLjWtZWtlVdVuyM6dVn02R7cum9uqqsYhWy+7Lq9b0rVqmvKzr351JYofpodRfBe+h6qqvrJnjNNRnMNY2Ry5allfGIcZrtymbFx1lY/LLt2TdNlaN4Z7sqqqccjmhq7P19u+fyaKX2VH4lVVNe6ycTVOWRKrzYUo/lvZ/cTdu5/HGXz80WdR/OFhNrdcfzpbI6qq7n2Vnav3LbzErqq//rf/Poo/O833NJuDrE///d//QxT/8sv5Pfhrr74SxZ+eZmOqqmq7zebp1SpbL6dwrayq6sJ78DS+Kv82pKZ8g9p12eauD/d105Sf31X8KvIc0p+Rx8+wLxuzJNbrvHBZh3PDdpvNb+tVtl5XVR0fZ+ctX5zmBy4tvKfZrPM9Tfckq6W3Z9maf2OG2ukf3v3HKH4T1n9VVX0L7wbCg6v1QX4uf3Sa1QxnwwzrRPi9VIsX7Ko+/LYjbYU2xzet8Zqdv8suHBMzVE7xE8Yx64/jDLVTH9axaQpdl9cMXfou5hgTYe0UdoWqyuuvccjqjmGGH7FZZ+fqYzjHV1V+0RMPihnGdZ/1hfi+raqGcE8yy7tMX0W4zsRn6pV/sz+kH31V1SrsT22VtcM4w3qbL5d5Dum5UVp7pXN8VcU3TXOc+aTr7RznJekcO4Xz21n4/xtVVS2to2dYJ9I9UXo3sA6/ifhW+D3pDN+ntLA/np3ld5/tIDs3OjnJzs7+6ud/FcVXVR09CvvTJt/TDGP4LsJx2fX59y1T+o30MMeYSOu3sI6Ooud5xhx3VXtxXxZvy7IHDDOcQaY1w3qdr7e/+i//NYq/dvVqFP/oSf6NdRdu7Oboj+m7TO/Bq6p2M9TzAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAN8Vt2/fXjoFgP/HrVu3lk4BAAAAAAAA9k5bOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9ldbOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9tdq6QSqqg4PN/Xaay//yfG/+91neRJnYxR+bpM35dluF8UPUxfF96uDKL6q6v7XD6P4V/78lTiHT/7wYRS/bodxDv/r3p0o/vUf/yiK352cRfFVVQebrB2uXX4qzuHNNy5G8e+9+14UvxtPo/iqqr/82ZtR/HC6jXOYximK71o2v63DvlRVdf7ipSj+3v2v4xze+cXfRPGXr16Oc+jX2Tx9VllfOD3L++NH//S7KP5sl4/L1157NYr/4vOs7rh0OevPVVX37z+I4l+4+Vycwy9+/d+j+Lff+DdxDr/+MOtPL7+Y1X+Pj7IxVVX10vM/iOJPjj6Kc+i656P4p69k/Wk7PIriq6qmIat9htbiHA4Osrrl+ORxFH/pwvkovqpq2mbt0Pp8zf9v7/wmin/7xz+Jc9idz9py6rJ93W7K5qaqqnPrrD8erPo4hy+OjqL4Gxez37AL+3NV1fmDK1H8neO8bnn+MOuPrc/f5Xa3iZ+RydfbacrGZXV5DtVl/Wm1yvY0wzavQbuwHdsqfA9VNUzZ2L569S+i+Idf/yGKr6q6cinLYdg9iXOolp0hdut8bmltneXQZTkcb/P1tp0bovg+PG+pquqnbGwPu+wsd7W+HsVXVU3hPN91eQ06VvYupy5f84cxO3NpfdafhhnOW9Z9VjN03bk4h2HI2nEYTqL4rvLfUNkUPYtpCmufsHZqfV4z9H12TrAdsv1IVVUfzi015nd2qy5bb8fK2vHk+F4UX1X1P37zbhR/eHghzuFceE5w5Vr2Lr+6+1UUX1X1zPWsZvjRD9+Oczg7zc4JxsrHxN/+4pdR/M9/9tMo/ig8K/n2Gdlatd3ldXAfnjWM4TrTd/li2fpsb9nNsWCHy21aR1dVjekdcnpeMkczhr9hGPMx0aV9ctnwb58RPmQY8nacxqzuODjM1on/+Wn2jU9V1cuXs5phldbhVbVehWdnh/ke+3sv3ojiHz7M7g3f/zS/O10fZGvd6Wl+fpfecIzh/Dat8zuWdIIahnBPVVUVrxN5CpXWHeFZ7jDm7ZjOTgebvJbfpd/Vhn1hhtIrrkHbDHXwFN9DZw2Rzk1VFd9vpPXjHPoZvk9Jx0QLczjY5PfHaY8OP5evqqrWsjV/CM//djMsNJt1dv53fJKdM1RVnT8XfmMzQx2czpHDkI2pKexLVbN8FRE/Ie2R6XnJHH0hPevow/W6Kj+zSVuhzdGbwnaco24Zwke0OU5M0n1VWHuFZc+3z4j74xzfbIVnkOlvmKEGTd/lDEOipi7LoQ/POqry+ela+P9AF8Lzv6qq3Tar3+bY0qTS/jjLlijMId+bVtwhu3BDMc7wG+KaYY53Ga91c6wTYXz491fhnqqqanOYfbP1y1/+5ziHt958PYr/+NNPo/hHRzN80xovmDMsuOEj5hkTy59dAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMzh9u3bS6cA8P9169atpVMAAAAAAACA75y2dAIAAAAAAAAAAAAAAAAAAAAAAADA/2bf3nrkOK47gJ+unpnd5V2iJErUlZIsQzZiwbckBoIEyEM+BD8gP0fy4ItixzYQRDGc6BJJlEWFEkWRXO7uzHTngXnMk/4ddMP4/d7P7JmeqlOnqnoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgudrcCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXG3uBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYrjZ3AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsV5s7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWq82dAAAAAAAAAAAAAAAAAAAAAAAAAI2GjfgAACAASURBVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADL1eZOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDlanMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBytbkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC52twJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBcbe4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFiuNncCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACxXmzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJarzZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMvV5k4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOVqcycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHKt5k6gqmocx9ptd986vrU8h/VB9ijGYR/n0K+6KP7xo2//DKuqWp8Ph9Wqj+J/8+vfxTnUfojC3/jOtTiFq0+/FsWfnZxE8QdtE8VXVQ1nYxTf93kOzz11KYo/fOd7YQbZnKyq2p5uo/hxl9eW1fowim+r7Lc8PLoYxVdV/eE/PojiP//TZ3EOzz6XfY9Xrr8V57Drsvr21cOvo/jbn96O4quqHj96FMW/8frrcQ5V2XN84cXrUfznd+5E8VVVV597Lor/4P0P4xy+e+NGFP/7996Lc3jh6tNR/N1vvojizx1eiOKrqsaz0yj+YPVinMN++1UU3/dPRfHrTbbeV1Xth3tRfGtZH11VNVS23h4dZTnstll9rapadQdRfDdB7/Ti889E8e9PUGNvvJDV2N3+OIofKt/gbtbPRvETTIm6vM764C9PH0Txl1Z5jX54ktWWo3Ed5/BluM+/fDGr0U9k36OrbE8zhr1bVVVr2VlFq/NxDg8e/HcUfxTuq1arsyi+qmocs71ha/lvuRvCGjlm4/HihXxODbu7Ufyqy/fYXZedO53ssviqqoN1Ni/7IYs/Op/3oNt9OK/yKVFdZc9hs856r3HM9jNVVS08xxzrKM6hKuvf9vU4zmA/Zr1THz7H07P7UXxV1RBeL6Q97BPZnBiGrL71fbYvrKqq7Fi+pjjTjo3ZlxjGbG9aVdW6rDas+wk2RWHvtN9mtamqqmvZWcHx42yx+ujjfI/+ykuvRPGf383vBvb7bEzfvZudy7/5+ttRfFXV9Wezs9wpfHk3G4937mb3RFVV3/3ud6L4h+H9xjjkDeDpWVafjk/z+nbuMN0bpucl+VrXh+cEY7jWTfEZU+QwDOFndPk9diqdVlM8x77PxmTXhWM6/wrVhR+yDt8TqqrarLMNxe0vsvOWZy9cjuKrqjZheTt9lH2HqqrxwpUo/tKV/Lzkg08+ieK/vp89h3Pn8nP509Nsn9/6/J4nLU/b4D3Mqqq+y+d112e/xZiuU1XVhy+VtgnqW9y7hI9hHPMetF9lNXrY5z1DC9fLrmXxEwzHSsfCbpedH1ZVhY8h7lt2E7wHWWF96tPeq6paWFuGCXrQVbinGcL33dN1pqoq/SniPrqqTk6yO4512MO2CWr0dpvVhqPD/Ew73VelNb6q6iBsxk/j9+Xz/m8fjocJSks8r8Ywfpjg7CztIbvwf3meJBGGp2dGU1xCx/M676OH8KdI1+uqqmGXrXfpbzlFbUnn1QQlOv4/u3ydmKC2hDV6iv93HLqwuPT5c3j4MOud/vbHP43i9yf5u2/p5m7Y5z9mN8Hczkxwv5F+xgTFJa2xaX2c4m5hCfK7qimyyMZDuuZvNvn/vv7zu+9G8d+58Wqcwzf3s/e+9mkvPsWZeNr/xRlMMabnv0MGAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAqKq6devW3CkA/L+4efPm3CkAAAAAAAAA/4c2dwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALFebOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlqvNnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy9XmTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA5WpzJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAcrW5EwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgudrcCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXG3uBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABYrjZ3AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsV5s7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWq82dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADL1eZOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDlanMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBytbkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC52twJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBcq7kTqKpqXauD1UHwCfsJshii6P24izN48M1JFP/0lXNR/FPPnI/iq6o+/uReFN+qxTl87wdvRfEH6zyH0+PHUXxXXRTfVvl3GPosh8NL+Xj61W9+FcVvd8dR/F98/50ovqpqHPoofr1JauP/5tBlv+X6XPZb/uPP/ymKr6oadtso/ic/+lGcw27cZB+wydeqD99/P4o/Pj2N4l97+aUovqrq/FG2Vr333r/FObz2+o0ovu+zGnv16tNRfFXVZ7dvR/HPXHsuzuGTTz+J4l98/dU4h8PtGMV/+P5HUfwP3nk7iq+q2m6zHrTGrMZXVXX9UZbCmK23w7iO4quqqjuMwvf7bJ2pqmrZkl+ty+rj6fbrLIGqaptsnWh1Kc7h5effjOLvP/g4zmEcszq/7p+P4vf7L6P4qqr99kH2AUM2r6uqjg6yuX1ynOVw7/h+FF9V9fzVN6L4rjuLc/jo0w+zHMLxXFV16fyV8BOy9brGML6q9kP4GeGeqqrqwsXsOZ6FvfyY7meqqu+zxe7sLN8TffPwiyj+ypWwDx7yPXrXZWeIXcuf46bPxsNmlfVeVVW3b38axV99JttXHazzObEasznx+Dhcr6vq6DD8LcIedBwmOIMcw/pWeS/ftWzNXoVnuVVVY3jWcHyW9U6HR/k5wW6b3Q1sd1l8VdUqrG9py1DheH7yGVltGSe49hvje5osvuvy/i/+hCnOKobwnmfI58SD4+ze8YOPs97r6rPXo/iqqrv3shzGMTx7q6pW2Trxd3/zD1H8aXp+WFX7cFr/9je/j3N4/tqzUfz169fiHCpcs09Oszl1cpK/T9DCfdnhZoL6FjrdZv3bPrx7rarahM9hiJuGqiGsT8M+rw1DeObSd1lxaS3fT3Rd+Bzzx1hp55EefaX3llVV63U2rz66k59pH66yHFp4fjdu8rOO7VnWv/30rZfjHFp4WfXvf/wgzuF4zM6u0jG9n6A+pu+u7cI77Kqq6rLf8uAoew7b03xvuWrZvDwXvqtUVbXfZf3XFOMplh87xYYhm9dn2/y+7OAgO5tP74mm6L1aWN/6CXqnCU5MIn34PmpVxc3TBK/Y1Bg2kd0E947pc+jCXn6K0rQPa8sU46mFa9UY/g5p7/ZE9h2GCTZF6d5uisq036f3p+E6MclzDMfjBOvEJnxf/fhxdlc1TnDekj6F7dkU7xCG5yVhjd6FPXBVfgd9/Dg7R62qWoXnoFPUlnXYg54+zv6faJLakvYdE9zZpT/GEH7AfoLnuDnI9shjeFZSVbUL+479g3xe/vWPfxrFj/twrQvvXquqxnhMT3CPHY7J+BtMsClK71/T/5d8kkO4Nwz3I1Ns69K9YTqWqqq6tHuaYJlI9xND2DP85399FMVXVb35WvZ/UVOs+buwl74fvrO/2+c9aNr/7cJ5/UQ2L7sJ9vlT3J8CAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmVu3bs2dAsCfrZs3b86dAgAAAAAAAPD/oM2dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADL1eZOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDlanMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBytbkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC52twJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBcbe4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFiuNncCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACxXmzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJarzZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMvV5k4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOVqcycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHK1uRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLna3AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsFxt7gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWK42dwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALNdq7gSqqlZ9X09fvvKt4194+Vqcw3Y7RPGfffJZnMObr12O4l+99nYUv19fiuKrqvr1H6L4D/54O87h3t0voviXrr8S59CF8W2VTc31ahNmULU5zD7j3Xd/Geew3T6O4o+OWhR/tttH8VVVh5tsXvXrPs7h0fGDKP63v/hFFN+fy8fjz975SfYBj8Y4h7Y+i+J/969ZfayqunT5YhR/cZONp3OHB1F8VVW/z36LV1/Oa/Rnn/0pir9x49Uo/uT0JIqvqlpv1lH8/ftfxzkcnDuK4h9+nedw52G2TvzwnR9G8b/+l19F8VVVf/WTn0Xxp2fbOIdxn9WG3XA3TCALr6qq7jAKH4bTPIV2HMWPQ9Z3bHfZfKiqWq2z/cimsrpQVbV9lH2Pi5uX4hzGcDyMY9Z7rVq+Lxv32f52HPPfssasB7y8CdeZ9aMovqrqYB/uJ/p0Z1i1Psie43a/i3NoLSvU4xDGT7BOtC77Lbs2xfFZVuf7PluvxzHrH598SPYcDw7PxykcDdm+LK2PB6v8O4yVrTPdmPctQzgehm1+VvHcteej+G8efRnF96us76mqavuszq9X2Zyqqtrts95p1cLaMEFt2Q9hH93lC8U63JT0Xf4ctkM2Hu7dz57jwSrvnZ669HQUP+7z+tYqq9NjhfVtvJ/FV1VVdv42Re9UXXzDkf35lvewQ7bk16rPcxgrO/u6c/tenMNXJ1nvdO7Ct7+7raq6f5bPid0uqw1XnzoX5/DO9/8+it8fZ+d3fXgWXFX181/+Oop/+63sTLyqagh78fDorKqqtuF42m7D/W24N62q6sOzhnV4B12V35+enmXxmz5f7MZz6VlFnsN+F86JMVzsKj+zSVun1udzoo3ZnBgm2E8MYeOx22dzYrfL+5a0/fv8q/zO7+q5rA++9lS2z//8zqdRfFXVy2+8HMU/fJDvy/742SdR/MFhvuC28P27MXzjKq2vVVV9uKepMZ+X/Sp7Do+PsyJ9eJDfbwxD9hzSc/2qqnQ0pEtlVV5j4x16y59jF36JzcEE56DheteF4ym9o6mq6lr2HPNZWTWGPWTag04xr+NefIJ5PabnyRPMy31YoNLakM6pqgn62DyFeEymc2qK55jah/uRqqourFBTPIb03CmtselYqKrqw3/p2U9Q4Hbhe4h9l62XbT3B2Vk4oLb7/F3Mw022vz3dZjmsJlhntmEOh+sJ7pDDNb9f5f1betmU5jBM8M5Xv8p+izG9cKuqsZu3Rk+xzqTv/R8c5OfyY3gO+pc/+HGcw/l1dhc/bLPvkD6DqqourJHpXqAq39OkGUxxv5GaIoP0e3TpOjPB/UZ63tJN8STDOj/FPr8PK/35w2y9PTl+GMVXVXUXsv9jmeL+9s7d7P95TrbZuyXnD7NnUFU1hC8ETFGj43fNJzjBS2sDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUHXr1q25UwD4s3Tz5s25UwAAAAAAAAAWqs2dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADL1eZOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDlanMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBytbkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC52twJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBcbe4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFiuNncCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACxXmzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJarzZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMvV5k4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOVqcycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHK1uRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLna3AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsFxt7gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWK42dwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/8PO3fzadp93Af+utfc555775uvr99iOEzuO81IX8oKVtkEMGJVJmTCJBBVC6qQDkJgg/gJGDJggITEoEh4ggQQDJqiitGlJmsRpYzmOG+fdsWP72vf6Xt+Xc87eezHwRURQiOPvCnu7/Xykqs65+1nn2Wv9Xp7fb62zAAAAAAAAAAAAAAAAAAAA2F3jthMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHctt51Akly/eTNf+dNn33P8xx7/YJ3Da6/+pIr/q594tM7h7NnuexxlVcW/eenVKj5Jbt04quI/9yufq3P40h/8QRX/8IOP1Tks9hdV/Onzp6r4n7x5uYpPkh8+90wVv1mv6xw++9lPV/Gn9rrrcNw15yTJ2VNDFf/8D79X5/DSSz+u4h999P4q/oE7+vHxxrXuWq6nN+ocvv5M1yceeuSROod7736wij++8XYV//Jr/Xl86N57qviLZ0/XObx5da+Kv/TGpSr+4FQ3xifJwcFBFX+46PpUkpza777HlctX6hzuuuvOKv6LX/5yFf+rTz1VxSfJV7/5zSr+009+tM7hxpXjKn5YdP36ZNXNU0kyjCdV/GLZ9akkuXmra9OHp85V8WdOP1TFJ8k0XaviV+urdQ7D2F2LKX0Nutl09ds4TGUCZXySadpU8ePYF8JHx4dV/P5+NzbtzbAeefXaD6r4y9ffqnO4764Hqvgzh33ttLrVjbEZuq2nuk8lmdL1iSHlOUiy2XTnYRi7a7kYrlfxSbJZn6nix6mfb08fXqziVyfdfsk0dmuJJNmU4/wwzbCd2011WQz9GNsmcWqva49DOS4kybo9xlBeiCRjOcYeH3f7BMsZ+sRi0dXBRyev1zlMq/NV/OFBV7ckyTJjFX/hTPcdzpzqx+jNSTln910im3TXYhq6/ZJN+tprsej69d5iv85hU67t1qtb3e8/6eb7JDk81Y3RJ0ev1Tm88PwPq/jD83fVOZw91/Xtaze6fdCTVV8zfOyJT1bxd198uM7hpPwab77d1aDf+W7XlpLkiY9052Exw5w/lHs2M5RO2ZS19KlyW32zmaEG3XQ1w83jfn27XHbn8Ux5IpfL/v7Gat1dizmuZdumx6FrC+8cpAsfygJumuE89vp9p025F3vmdHe/7evffbmKT5ILe9152JujX666Wv6Oc90+wZMz3IP+3ve7+11vrvr9u2G/65cn7V5wksXYDS7T1LXHsYyfI4c5xreTk+5atM8THJ/0ex37B936dLXq22PKa7kYZ9i/K48xln1qjrqlPcYcdUt7HmbZeNq2GRZF9RBZ5tCOr0myaeeJORaXbXuao0+05Vd5HlebGe4TladxmqGWH9oxurxH094zfOcY3RjdrvGTZF0/m9GvJ2bZOGr0l7I2x3xb1+LtdZijlm+fL5nhWva1U3cehxn6w3G5HlmW65EkWZYTxWqW/buuXy0X3b76eoYadrMun0+ZYU2UqW3T3a+v66YkQ7kvf3zUP4v5+EeeqOLPnu3vv7Z9ot5rmGNN1MbPMVdtPYe/AOvjJEO9T9Cdx1nubrR7kLOkUJ6HGZrTupxrvvzFP6riH3/sw1V8kqxW3d9zX36r//uL19/q/o6lXRvOch+8bI9tfJK6X86xNN2N+6cAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwPU8//fS2UwAAAAAAAAAA4Oc0bjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHbXuO0EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhd47YTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3jdtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAy8zJhgAAIABJREFUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDdNf6sDwzD8PAwDP91GIbnh2F4bhiGf3j75xeHYfgvwzB8+/b/v/P2z4dhGP7FMAwvDsPwjWEYPv2L/hIAAAAAAAAAAAAAAAAAAAAAAAAA7A7vsQMAAAAAAAAAAAAAAAAAAAAAAADg3fIOOwAAAAAAAAAAAAAAAAAAAID3h/FdfGaV5B9P0/TxJJ9L8tvDMHwiyT9J8rvTND2e5Hdv/+8k+fUkj9/+v99K8i9nzxoAAAAAAAAAAAAAAAAAAAAAAACAXeY9dgAAAAAAAAAAAAAAAAAAAAAAAAC8W95hBwAAAAAAAAAAAAAAAAAAAPA+MP6sD0zT9Mo0Tc/c/u9rSZ5P8mCS30jyO7c/9jtJ/vbt//6NJP9meseXklwYhuGB2TMHAAAAAAAAAAAAAAAAAAAAAAAAYCd5jx0AAAAAAAAAAAAAAAAAAAAAAAAA75Z32AEAAAAAAAAAAAAAAAAAAAC8P4w/z4eHYfhQkk8l+XKS+6ZpeiV552UTSe69/bEHk/zop8Jeuv2z//1YvzUMw1eHYfjqlctXfv7MAQAAAAAAAAAAAAAAAAAAAAAAANh5v6j32L3++uu/yLQBAAAAAAAAAAAAAAAAAAAAAAAA2II532F3+3jeYwcAAAAAAAAAAAAAAAAAAAAwk/HdfnAYhrNJ/n2SfzRN09X/10f/nJ9N/8cPpulfTdP02WmaPnvhzgvvNg0AAAAAAAAAAAAAAAAAAAAAAAAA3id+ke+xu+eee+ZKEwAAAAAAAAAAAAAAAAAAAAAAAIAdMPc77BLvsQMAAAAAAAAAAAAAAAAAAACY0/huPjQMw17eeYnEv52m6T/c/vGrwzA8cPvfH0jy2u2fv5Tk4Z8KfyjJy/OkCwAAAAAAAAAAAAAAAAAAAAAAAMD7gffYAQAAAAAAAAAAAAAAAAAAAAAAAPBueYcdAAAAAAAAAAAAAAAAAAAAwO4bf9YHhmEYkvzrJM9P0/TPf+qf/lOS37z937+Z5D/+1M//3vCOzyV5a5qmV2bMGQAAAAAAAAAAAAAAAAAAAAAAAIAd5j12AAAAAAAAAAAAAAAAAAAAAAAAALxb3mEHAAAAAAAAAAAAAAAAAAAA8P6wfBef+bUkfzfJs8Mw/Mntn/3TJP8syb8bhuEfJPlhkr9z+9/+c5K/leTFJDeS/P1ZMwYAAAAAAAAAAAAAAAAAAAAAAABg13mPHQAAAAAAAAAAAAAAAAAAAAAAAADvlnfYAQAAAAAAAAAAAAAAAAAAALwPLH/WB6Zp+mKS4f/yz3/zz/n8lOS3y7wAAAAAAAAAAAAAAAAAAAAAAAAAeJ/yHjsAAAAAAAAAAAAAAAAAAAAAAAAA3i3vsAMAAAAAAAAAAAAAAAAAAAB4fxi3nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAu2vcdgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K7lthNIkkxTsjl5z+GLxX6dwuOPfrKK39ya6hwWe933+MGPf1DFX33jrSo+SS5cPFfFn9y8Vefw1FO/UsVPWdQ57J86XcW/8N3nq/grl9+u4pNkcXpVxT/10c/UOUzrrl+tbq6r+LPnL1TxSfL7f/yHVfzxjZt1Dk99prsW65Oxit/kqIpPkktvvVLF/+TS5TqHjz35ZHeA1Xuf5/6n5Wavij9zcEcVf7Xsk0ly5e1rVfxDZ7vxNUk++NCDVfyPXn65ij9/4c4qPkmmDFX8MHT9OkmuXL5Sxd918WKdw+uvv17Ff+RjH6niX/jOd6r4JLmvPA8vvdq1xyS57+zDVfxq2lTx4/LuKj5J1utuvhynGeq//YMqfprOVvHLZV9HT5suh/X6ap1DcqqM7+q/d3TtYRi6OjpTP99ObZvuppkkyWLR1V9tezy3f1cVnyQvn1yq4k9fOF/nMHZDbIZV3yeWZXuYxm7rab0p+1SSYehO5KbYs/pfOXTnYbHo4lerM1V8kgxDt7ZbrfrxrS1jl3vdOn819Xtnmcp9zE2/D7ooB5dxnGG+nbqLebjXzROb6XoVnySbdOPTohwfk2Scun2Co+OuTR+c6X5/kqw33T7mqf176xyGqVtPbFYzXMuxm3DPH5TXYtMXgIv2EDPcrTqp5+xyH3Q6LH9/knVZAE597bRIt77dG7v9u7fffq2KT5Jrb3Zr5B//uM/hnvvur+Jfvf5mncN060YVv7fs1uhPfeqvV/FJMpb1396ir0G/8rVvVPF3nO/unT764Yeq+CRZjO0+QX8ej46Oq/jlXl937C278zCWDXJoG3SSq9e7uuVohnXZYuyOsdwr1wKn+jXRrbI9zrB1Vh9jHPoshvoYXVuYynsLyTz9qnV80tWgdVuY4d7p+ma3t3/hsB+jT+91Y/T+QVfDfuWbz1XxSXLhrm7/7cK1vj3fPOrq4BkeB8hYbuBt1u2aZo57LN0x5hij26XhptwTH8v96KSfbxeLvk8MZXvo58pkKnPYbLr4dduYkgz1fskc/bI+QhXd3qNJknV5z64dm5KkbdLjsjsP7dI0SYb6eYAZ+nV5LeboE+t1dx7a8W01wz3odk98jmu52XRj5JQufpa1ZXkt2/VM0u87TXOciLpbtc9izlBIl9p9qyTZbMq+3U40M4yP7THmqP/asaXerZnhPJ4q19hzdOt1WQcvZriWq3K+bdfYswyP5XlcLvoCrp5vy/Xtuvz9SbI66Z6Xevxjj9U5fPjuB6r4Gzf6Nc2mvA/d/u3DHHs+/Tg/w3pihjb5fjfHfNteirY1zVH9lUN0f/83ff23nuFSPv/NZ6v4X/r4E1X8SbmHmSSXLnfPy1+60T3XkSSbsl+1S/STGfYg+33UOoX6+eRhhlq8XpcBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAlj399NPbTgEAAAAAAAAAgP/Pxm0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDuGredAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7a9x2AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsrnHbCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwu8ZtJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA7hq3nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAu2vcdgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K5x2wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLvGbScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO4at50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALtr3HYCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyucdsJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC7xm0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDuGredAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7a9x2AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsrnHbCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwu5bbTiBJTp8+k8/8lc++5/jNalXnsBm6+IM7z9Y5/NF//1IVf/70QRV/cHhSxSfJPRfvr+KnjHUOm2lTxe+d6tvTV772xSr+4h3defzAB++o4pPkwpknq/iTW911SJL9U/tdDtOtKv73/tvvVfFJstjfq+J/7XOfr3PI0boKv7k3VfFff/H5Kj5JNkc3qvhPfeLjdQ7X1117urnp+8TVo0tV/NmDbmz48Nl+rvv2pdeq+KtnztQ5LMr4B+65p4p/8+23ywyS8+e7a3l8fFzncO7cuSr+5VdeqXM4dfp0FX/5ypUu/sa1Kj5JHn3kkSr+2ee+Vedw75P3dQdYdfXbcjjsfn+S5XC9ij867mvQ/f27q/iTk5eq+MWivI5JhrE7D9PqrjqHxeKtKv7kpG9Ph4fdTLHZdOdxM0PNsDzXrQ2f+cYLdQ6PfvDRKv70Xtevp1UXnyR3n3uwir9x3M0zSXLr5s0qfrE4VeewP3b9arV6o4ofFuer+CSZpnb7q1ubJsly2V3LzaatYvu5bko3tiyWfR08pVwPTOV5XHdr/CRZrbu2sLfX5zCO5Vy37vYJkmS96fYhF2OXw/qkX9/ul2163U/5mdId5PB0N9et15er+CSZylsUY7mvnyTTVI6RwwwXcyjHpzL+ZNPviS/L6fJmWfckyd5eN1dNUze27O91+7BJsl53x1jPMLgsll39dXz8kyr+m996sYpPktNnur2zcxf79e3RcVcHr4+O6hwu3tHtnX38k3+jil+t+++Qsl///h/+cZ3CRz/yoSr+6Kirezabvvaaynun49RPuItFN1cNM8z5m3Kcb1MYZ/gS+8vuPJ7tulSSZFEWYItFWXuV1zFJluU+aP0d0u8BzrGH2NYdZ89088zRDHPdwUFXhH7nhy/XOVy50d1DfvLRh6v4M8u+lh8X3brsE49197qS5K1r3Rr7mee+UcUvD/p+ff1Kt0Ye2wfXkmTo+vVihrlqTDdOL/a6uW6vrDmSZL3qzuPRqn/+rp3upnTfYYZpJoeH3f2J4xnmibGcsxflPmqSLMoxdlW2x826nycOT3XX8qT8Dkk/Po3l2HB80p/HvortnZTPWR/ud7XX8a2+X7f3SIYZ5rp1OUjO0RbGck3Tfod2fE367zDHGrvdcqlrpxnKv3Zdd/qwf8bm6LitfWaoQee4WdT8/lnGlnK+nGEPcW/Z1S0nJ30d3FqWc/7+Xv9syM1b3f2u+vm9Kvq2dp6YY4Arv8kc52FT9su2Bl3P8Ddy7dgwzXDfsX2mob0Oc7SFJ3/pl6v4D1y4t0+ifE5nuejPxKrMob1H097LnyOHOVrUHGuSMoP6CHNcizqHel3WfYd+RZTsl7XXZoZrear826xnn/lqncOjDz9Uxbc16OVrV6v4JHmjPcYMa+y9cl99U875MzxOUO+JzzG+DmUOy7JfJ8nRDHupAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8F49/fTT204BgF+gL3zhC9tOAQAAAAAAAPgLatx2AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsrnHbCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwu8ZtJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA7hq3nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAu2vcdgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K5x2wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLvGbScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO4at50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALtr3HYCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyucdsJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC7xm0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDuGredAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7a9x2AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsrnHbCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwu8ZtJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA7lpuO4EkySaZjof3HH56/0ydwpXj61X81/70T+oc1utVFX/Pg/dX8RfP3lvFJ8nJjZtV/PLgjjqH67euVvEvfP1bdQ7H03tvz0lyeOdYxZ8/uFjFJ8leblXxZ8/dWefwg5dfquJf/M6LVfzDD/V94gP3PVrF37h5o85hPZ1U8c8//0IVf9+DD1TxSXKwd3cV//ZRfx4Xy/0q/p79C3UOb117tYofDjZV/K3NVMUnySP3P1jF/+jST+ocHrh4vorfK3//3n7XlpLktddeq+LvvuuuOoejtjmM3VyXJNdvdH37jgtdvzx3tq9bvvbsc1X8U7/8ZJ3DV77+TBX/+V/9fBV/61o/Rm+mru7YX75d57C36Oq/TPdU4cdHb3S/P8ly2dWQe3vlOUiyWnVjwzRdqnNYr7u5arMpv0O62i1JxpvdIP3XHv90ncPRpmsPN45er+KHqZ9vzwzHVfypsa0aktXprn4bhkWdwzR1OSwW3Ri92nRr/CQZhsMqfjEe1DmsVt21WIzdGn0cZ9gCHLo2fXTU98sMb1Xhh/vdXLe/7NYSSXL55ptV/FRehyQZ98q91KkfW9arbowdl908s1f2qSTJpjyPfelUH2Qcj6r49eZ0FZ8kw9TVTsPU71VMKdv0DNdyKveTy1sLybIfW169/OMq/tzps3UO+8tuzr91q+wTq+7+SJIMQ1d3LNsxPsnRrW7f6dt/9mdV/CMfeqyKT5JL5R7iauruGSbJW1e7vYbHH3uizuH+e7r7E+XQlLdvrLsDJPn+975RxX/08e4cJMmtW2UtPnRz3Xrdz3VJdy0WM+zljou2huzPw3rTrW/HGc5D6/BUN0+cOpijPXWmsn5r45NkuezXNK22PW3K9pwk63V3jJtHXe30+uVujZ8kV6+X9xdmaE/rcr7cK9vj5sblLoEkH//QI1X889//fp3D0dVub3+v7Nab1Rx9qptv9w76Pcjl0O0BTjPUHUPZJ8Zykd32qSRZHXfj26ZepCdjuU5va/k59jo2m+48jIsZatCU8+0cfSLd+HJy1N033Fv09wZWJ10OwwwNal3O2Sersj3OcI+lrf/mWI/s73dzzeqkO497e/19ok1533I59vPEOJZ7uWXNkCSLco29KfvEcrkLfWKGsWXVXYt1+Szl0BZOSU7K77CYYZ5o19hznIf2CG2/nGaY69p1fjsuJMmqni/bfdB+fGzP481bMzxDWNbyQ7ufXM6VSb+POkefyFCOseVaIOnrjkVZdwwzzHXt2DANfb9sNwoW5Z88Lg76++B3Xeie7d1c6/vlUD6bu9l0ex1J6ts0szwiU2q3g+e4wzJH7fN+/v3JbrSFujHM8HdVw1Cub8s1fpK8Wv5N0hOP9c92HJV/DzSU65FXr16r4pNkWe/t9/PESblnM5Zrw8UsY0t3jFnGt3JsaNdUyTxrOwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP7yevrpp7edAgAAAAAAAAAAfwmN204AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgN01bjsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHbXuO0EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhd47YTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3jdtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDdNW47AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB217jtBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXeO2EwAAAAAAAAAAAAAAAID/wb6dNdtxVXcAX91nuPfqap48SBYmNhAgEBwwcyg+hz6gPkUeSEERIIRMjMZYMpaNbHmQJd3xnO7OgyvPqfK/q7pD/X7vq+863b33XnvtvgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB8tVMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB8tVMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB8tVMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB8tVMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB8tVMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB8tVMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB8tVMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB8LadOoKqqXba1d/Hsp46/e/ePcQ6b45Movt9u4xxe/frno/i2+/T3sKrq5LiP4quq9s5djOLv3vt1nMPjR9mzXO/uxDn87Ut/G8U3p8dR/P6wF8VXVTV7Z6L4n//3f8U5PP7ooyj+m994NYpvmk0U/8lFsnH1wcP34xRe+2M2R37+pc9G8TcuXIjiq6oO+yaK33SHcQ5nu90sh3UX53D+6rNR/N17d6P4F29+JoqvqurC9fLquWytq6p6dPA0ir+4n+Ww266i+KqqJ4+z3/Do0aM4h7Nnz0Xx165djXM4OsrWy36bzdFHRwdRfFXVzReycf2L//hVnMN3vp6tl7/4ZZbD17/6ShRfVXVwcBTFt+0izuHBu69F8VevvhzFr1bZmKyqGoZsju66bL2uqlq04RZ1mdfBw5DtJ5qmDRPI38dUH9awVVXLZbbe7S+ydeL4+J0ovqqqa/aj+LbJ1/xlk+1P+y5f82uZ7fOHIfvzTeXjuiobl12f1RxVVW2b5pDNj8OQ/4Zmkf2GM2fyfsvjx1n9ddRlNcP+XjjHV9XZcy9G8Q8/fD3Ooc5k+9Pd3bzuWIVjot+cRvHtCPuypsLaZ8jX2yFcs/s+ew5DOsmPYKgRcmiyZzmMcMzSNFkNuAjfhYOjB1F8VdXl81n9trdzOc7hyaO3ovhF+Cjb9np2gaqqytbsDz74c5zB3Xv3ovhnrt+M4t96J3uOVVUV7m+b9GWoqu+++oMofjHGPj+c3964+9sovunz+u+Zq1eyC4ywVu3tZHuS7XaEs6ZQu8jWmXQ/UxUvt9WPseTnl4j0fV7//TVIa8gxatA2fCFPNvm43llne5K93ezcsqqqbbK6Y3Oa3YfH2/xZnoTnjjttPjOswj1Jurf83I3no/iqql/9NvtO59qVrH9YVbXdy97p4/DMLmx7VVXVMlxvx1inzp/LashHHz+Oc0i/B1gts1p82+XfZaS103qE2qkL34g23NN03Qh9q3DNTs/yq6oW4fs0htPTbEzshmv+GLVTF4+rEWa4tJeaptBM3wftR+gnx+fYYXhf+W/own1V046qZkw8AAAgAElEQVRwH9P4MYZE+D4s0rpljB8R1tFjbLHTb4XSveUYc/Tueh1fI5XuacY5a0rPeUIj/Ib0Pmy3eR3c9+EZ8k74fcsIAzv9b579M9n/TlRVHR1n/ZZF2meYQe9sjPKvDxvC3ZD371bpWVH6KIYx9rdhCmM8yzC+67Ib+YOvfjvMoOrgIPw/lBG+IRzCObIf4buK9AppDTlGzZB+XzJGGZyfl02/P03v4yjVX3gj02/V2xH6BP1O1vPZdvn/Mb/zdvZtxvPPZf8HU1W1Ds/LHjx8GMWfjnCWvwzPmlYjHFA0aU86/QxyhAkyHVZjrBP9COcLqcUoPRcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+v7pz587UKQDwVyxdZ27fvj1SJgAAAAAAAMBfm3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr3bqBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYr+XUCVRVHRw8rX/95U8+dfxquRPnsLe/iuK/88qX4xz6kyyHnSb7+2cv7mcXqKof/fTH2QX6Ns7h1svPRfHXL1yPc6jTIQpv2mxoNjt9FF9V9c8/+lEUv9pbxzl8/7vfjeKPHh9G8au9RRRfVfXan34XxR9tNnEOX/ra30fxe4tsXB6P8BuqPReF7zXhBFlVH50+jOL3m6txDqd99k6eu3Qhin/z7bei+KqqF565EcXvr7K1sqrqcMiu8ejgIIpfrnej+KqqZ599Joq/+8YbcQ7nzp6N4nfW+bPs+2y9PTg4juL39vJneXj4JIq/9dLLcQ6vvXE3in/22uUo/r2Hr0XxVVVnz92K4ochr4MvXf5CFH94+H4Uv7eXPYeqqqE/Cq+Q1/KLdVgHN/m47PvTMIczYQb5/DhUl8UP2ziHvk/3JNm7sFpfC/9+VTc8juLbyueWZZOtt81qhLmheZpdoM96Nk2bjqmqYTiJ4rshqxmqqppwbPf9XhS/3X4UxVdVLcI6eox1YmcdvtPDX6Lwrns++/tVtemyXsW1K/n89vrrYf33XH4fzuxmc0MXrlVt5X2rYQh7DU22n/lEtt4OQ3YfmrDmqKpKWzZD5fdxiOenfH7rh6x/1nVZ3bK/l/UZqqoWYU/7/pv/Fudw4fz5KP7c/s0ovo/3VFVv/vnPUfx7D7M+Q1XV9evZPP948yiK79tsT1ZVdfVSVot/7Ss/iHPonoT7smXe0/7pz38Wxb/8Ny9G8cOQz9FtE55PHGV7gaqqc2ezPcl2mz3Lps3fhSZccEc4YqmqOeSQSd/pfoQxMYPbEN+HND59n6uqurCG3Ixw9rleZbXTw48+iHN4PzxL/+Jnstpp9TivW067bG946/ns3LKqqu+zNf/hh9mzfPvD7Ay7qurSxawH+egg249UVbxL39/Lemfp/rqqarEIvy8ZYZ04Pslqn5PTvBavLhsTy/A+5mcTVYtFNkePseanz3IZ9q2227zn04b3cdnm52Vt2KvYnObnZWm/ZIRXOhbXX6MU8+E1ujF6sZm0nZzGV1Wl28t0ZhijT5D2g7twnaqqWrRhP3iEMZHey0X4PegY+7Ih/OarH/IJMj6fCF/pLtzPVOU16BhjYrVM67cxeohh3ylcZ8aoQdtwbhljjl2FvYox6uBUeh9Pt9OPy7QAXIzwHNJn2c3gbGAZ1uFVVekxdPo5wBgjqm2y9ynto1ZVbbqsl/qP38rO7PrDEda68JuvkyHPocL1sl3M4HRhBmNiHudl0xpnXzYD8e/IHubOKv/u7PUH70bxeyN8s3XzRvZtSD/CfuKN+/ej+CfH2Xc6TbrHr3xcdWPsJ8LaKd0TzUG6F6iqGsJnkcZXjfM+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMI07d+5MnQIAAAAAAAAAAEyinToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnToBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOZrOXUC/6vp208d+9yN/fjvX770QhR/fDDEOSxXqyj+8fY0iv/dz/4liq+qqiG7D1/8u+w5VFUt20tRfL/t4xzOnzsTxd998CCK//W//j6Kr6p6+XPPR/E3r74c53B4fBLFn9Y2iv/VL38TxVdV9eGY+NJXvhjnsGjT+SlbKo42R+Hfr7pUmyj+ZJEvd4udC1H80xHuw/4ie5ZXz1/JEtjma92jw4+j+Ovnzsc5XFmfjeJ//d69KP7F69ej+Kqqocvmtxdu5uvt2/ffiuJvPH8jzmG9ysb2sLcTxT95kq1TVVVDffoauKrq40cfxTmc9Fntc/PCxSj+zTf/HMVXVZ09n/2GxSJ7DlVVbZu9T9tNVj9utwdRfFXVepX9hoODv8Q5VPNMFN422Z6qqqptd6P47faD8O9nNUdVVT9k82Pb5mOiqouihz7b31YtwviqtsnGRFP53rIfsvvQdPl9WCyy+3DaHUbxy1X+G7rwUTR99j5/cpG9KHy5Oo7iF8u8Bt1ssvmt7y7HOaxXaf2V1aCnp9l+pqqq2iYKf3qY7y13d7K17u4f34hzuHo9ex+effZaFN9vsz1VVdUy7DX0I6xVVesoehuO6/UyH9dNOCb6Pn+W6TUWi2xMVVX1XTa/rdfPRvFdl+8tHz96J4q/fi3vJ+8ss3F5cpT15d+6n++Jnh5lv2G1k9ctx5usfquT7H1+6bOfy/5+Vd18/vNR/GaT1/JH3ZMo/g//ma+3L332VhS/XGZrVTbDf2IVnp3u7GRrZVXVwWH2Tm+22fnG7gi/IX0WTZM/zfC4rJpR3qhUlsMQ9mGrKu40jHEXh8oe5ulpNibGqP/SPsEqPJuoqvr9vXtR/HKEHE7WWU86faH6vbyO3jt4HMWfO5t/a/S7116L4g/DreHOOt9bHjzN7mO6r6uqqrAnfXqa9VHP7GW9u6qqp0+z+m81wjcNfXreNcKjbMJn2YWT9BjzY/pVRN/n31UMQ/Ywtl14RpMWb1W1Ddf85TI/8zs4eJrlsBjj3DGbp09Os/3IGOfgq3W2Jzk+zs43qqoW4X2sJnun+yGv5dtwXNcY+7JwfmrTGXKMDcki7FXk01v8PegYe8MhfCf7PnsYy/A5VOVrzRhrVXyJMH6M7zLia4wwLrvwnR7lWYa/Y4wcUmn/bYwpNu6/hXNTO8LeMr1CO8J6m46J+F0I+/pVVW04JsZ4H9N91XaM9TbsxqZ1RzPC53vbcLHanGT7uqqqH37vh1H8dpP1g4dR6ugshzG+IUwNYf33ifCMZPrl9q9CulaN8RjSPU26n6mq2ltn37SehOvMOx99GMVXVe0M2dzShf2/qqp12PN58N57cQ6bLltruvD/qtbh99FVVYt0XzbCBDn1SfoYvY60jzpGDumzWIzQL7FgAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATOfOnTtTpwAwS7dv3546BQAAAAAAAABmrp06AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmq506AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADmazl1AlVVu7vL+vwXrnz6+MVzcQ7Hx30Uf/XSuTiH1+6+HsW///BRFL/cy1+HG89cjuJ3lpfiHNqujeL3zp+Nc/jJv/88in/8wYdR/Pe//Y0ovqpq2ZyJ4hf9SZzDw4fvRfH37t+P4m/eyueWy5cvRPEP7r8V53Drxs0ofqh1FN81+bvwztOPo/hrZy/GOaxW56P4j4/ejnNY9IdR/H7/TBR/7erVKL6q6q33snF5ss3mpqqqZe1G8V9+LpsbPu63UXxV1appovi2GeIcrlz69LVbVdXhQfY+V1VdvprlcHT0MIo/Psx/w3KZzbGr3Sy+quripaz2+a/f/yaK/9Yred3yy1/9LIp/9ZvfjXM4eHIQxZ85k9XBT5++EcVXVa0W2Vp3/ly2zlRVnW6ycTVUvk6ktc9ime2J+v5xFF9VNQzZsxynVZCud5souhlW4d+vWjQ7UXw35HXw0Jxm8V32G6qqVm12jZOjv0TxXRT9iTac39rlXpzDcbgfOLN7K4rvR9ijV1hHN5XXTv02fKfbbG5arLKeU1XVXx5kY+Lw+CjOYXOUzbHDJh+ZHzzMavHlOnsWVy7l+9vt5ji7QDvCehvuDReLrF/SD/m4Xi+yObbPt7fVd9m4arPHUFVVy+V+FN9tHkTxp9m0UFVVFy5+OYpfVna+UVV18CibY//4p3ej+GvP3Yjiq6oOj7OeeFfZWVdVVb/J6oZXvvpqFL9a5rX8qs3Wqj/dy3qYVVWHR9kc+cKtrP6rqtrdyWqn4+Nwrat8gjw5CfdEcQZVB0dZz2fTZ/dhJ3yOY+iH/E42I7wPcQ5h7TSEb9TQ53N0fBvDe1BVNYQF2GaTjesx6r/dsK9+/92s9qqq+t4/vBLF/9NPfhznsLqS7Um6bVZEXhnyveXll16K4v/9D7+LczhzNtvT7B5k68zQ5fcxrSGXzSLOYbvNfsfOKvymYYRex3qR1bHdGM+yT6+R977a8BLpOtOF71JV1XabjYkxetrpop/WXstFPq77dvraab3KxuVykffvTjbZerleZTlstvn3KaenWZ+gTSeGqtqGc2S6F6gR+i0Vrpej7CdC4bAeZY/epxuCEd7HIZ2jR9iXtW32PnXh3NCPsbcMew1pzVBVtQjXuzaM70cYFV2XzQ3tCAccad9ohLZTLH0fx+h65S2ffH5LZ+r0WY7RP9yGtdcqrB+r8vlpSHuYI8yP/ZDNLemY+sT06216jSb9TnuEOfrwNDvn+c43vhXnsAg/V9puwj36CN/Lp/uBdozz23RuGWO1CteacdaqTD6uR0hi4uJnjJ+QvtFjrBNd2Kv46DCbH++/m33XUVXVhr3cL3wm+z/Bqqp33n8/in90nH831oR1x95OdjbQh3uqqnxvOcbITEdVWkKOUYM2Ye2T1rBV+fy0GKHvNPU6AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMJU7d+5MnQLALN2+fXvqFAAAAAAAAADg/9ROnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VOnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwP+zbWZcd1XkG4K/qnNMt9SAQEprAkYyMwTFTjDGxL7yy8jP8A/UzEmctB2OCF2E2CMIgRgmNraG7zzlVvjC3uQhvZVV5ree5f6u/U8Pe395VDQAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVjl0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANM1H7uAqqqm2aj5/LEfnD+cb8Y1nDyanYrf/+kPcQ2zLqvhzLntKH/29BNRvqpq/0H2G9ZdG9cwP5rlX/nDf8Q1tPNFlP+X3/xrlD+4fy/KV1WtwvP45uW/xDV063WUf/TUI1H+zInjUb6qqvrsXjh58kxcwv2DZZTf2jyM8ttHdqN8VdW9u3ej/P31rbiGzdlDUf7csUfjGr64/V2U35llz1S/7qN8VdXZE9k9/fWdO3ENjx3N5ppmkY0N+zc+ifJVVbf2s+f63LnH4xoWi6z/euvNt+Ia7ty9H+XPnj0Z5Tc3N6J8VdWNazei/ImHs7GpqurOvWyMfeTU6Sj/9nt5z/CLF16K8q+++kpcw69e+nWUX+13Uf7Ikew6VFU182zOf3CQPZNVVZsbO1F+tcrmuqqqbr2K8u0sm2f6Ph9bumY/O8A662GrqqqZhQfI1pZdl9+Ps3nWx86bbD1SVXW4/CLKt01+P63WWf81X5yK8suDvJff2Qn3jcJ1XVXVkSNZD3nzzldRfmfrfJSvqlrMs56hKh+jD5fZsz0Pe9iNjXwPMj3Gnbt7cQ37Bw+i/NbR/Dwc3T4S5Q/3s98wi+epqm4WzlV9/ky0s6yHbNr0POTn8cpX2Rp5dztfE6W9dNOGvVdVHR5ejfKzWfZuYHN+LMpXVc26bHx68+18n6CdZb3PsRPZPsGNvew6VlUtl9mez85udi9UVf3ihd9E+eUyG5sWi/w90X++8qco/7OnfxrXsBXOdUO4fz/snebZXLexka9Hrl67GeXv72d7HVVVGxvZedgJe6d5uM9QVVVNk+XzVwPVD3GQsWsI402bX8u+z8bYdfjutapq/zB7rg677Dfs7+e911fXv43yv/3lr+Iausrm/NUA17IN379Wk93TG4v8c6X3L78f5be2w48iquowXKdvzMN11QDr23X4DvgwHBeqqo4e3Yry6Rjbd/k8df/gIMq3A8wT6z77He0Az2Xcd4T5Phybqqr6WVjDAPdTeBarabMjNAOcx2ad7lulZ6EqfCRqHfYtVVWLcF2V7t+1s/x+7NLz0Jh/NfYAACAASURBVAywFoiXNOH4mI5tVVVhL9+Ov6SqLnyo5uE3tX87RjY+LVfZtwBVVekIOcT6uAvnmiaer7N4VcWDdD9EDeEx0jX2EHNdF44t1Q0xvqX7LROYqyYgPQvrboB9ggHuycQQ0207y3qneHysqlnY/6XPdTpfV+V98BDP5CK8llUDjAvhOj29Fofh/39UVT158WKU39nM9muqqpb3sn2jKbxbSK/lIPPUEIPkyNIxth9gfBviGGNrwiZ2mPVtuMZu8z3I2XY2Pl396KMof/bhh6N8VcXzzIMB3pfdCt8TpfdjVT42tOE+5mw+xLps/LEl3c+dh2uBboi93HT/boAa2ib934V8XbYKvxsDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYy6VLl8YuAQAAAAAAAAAAGEk7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATNd87AKqqtpqamu+8YPzD5rDuIZX/vzfUf7wcBXX8PyzF6L80eZYlJ/lP6GOH2mj/Jc3r8U1vPb6X6L8Ty4+Ftdw7pF/iPLLw+ye3p/nF/PdP78R5R8+/lBcw7kLj0f51Xod5fuDB1H+bwf54WNbVdWRxVZcwqrJzkOt96P4cplPNSceOR3lv73+bVzD6c1ZlF8fNHEN57aPR/mv7mRj7LHdR6J8VdWH738c5dcH2f1YVbV3MjuPpx+9H+W/unI1yldVnTj5aJS/dfNOXMMnn2TX8uSp7DdUVd26vhflt4/ejPLNPB/fTp3MnqvVKu+Dd7eORPlvvs3u6XZzEeWrqq58eSXKP/WTp+IaPv/8gyh/4dy5KL+/zq5jVdV3N7+J8ltHNuMaNvrsGH1/N66h77Neup1l/V8f9o9VVV2TjY99l/ctsza8H8IS1v317ABVNeuPZgfos+tQVTWbZX3Lavl1XMN880yU3ww3Gzb6fG25OrgX5TcXeR+86neifNdm/dvh6rsoX1U1m+1G+cVG3jt1fXYt+76L8qtlH+WrqjY2svFxMUAPerdbRvnNre24hvPns96nW2fXIrwVqqpq3WX7oOsu33eatdl5mM+zHvLyxx9F+aqqh3ez8XF7J9sTr6qazbJ1frfOn8vNzeyZqPC5bvsB9gk+vBzljz9yNq7h9l72Ox6E+6B797J7qarqx+cvRPknz+fr29Uym2/D1xv1x1ffzg5QVc8+83SU37ubry3bNpsnFvNsP7qqanMzW1/u3c3u6a+v52PLapm939gcoAfd3srWhtvh3luft6DVpQcZoIiuCxuwJt+rSMUlDHAel6tsjX3vXjbGV1U9dCzrv768lu1BvvjiL6N8VdW/vfL78AgHcQ1tZWvD47t5H/zs09l8+c7770b5ja383cDR8BjdMr+Wm/Nszu+67LluBhgf+3U2Rh/ZzN8NpA6X2Xnc3x/guV6Ee/sDzBPrVbY2nA9wP3Xhz0j7lqYZoHlqsue6CfdrqqrSn9GH5zH93qqqah0eYz7L54n0sYr76MrXdstwfOsr/w1DrEli4fg0/moif66bAS5EE+5VLMNBvksniaparbONpzYc46sqvqHSMXqIY8za7Ee0A/QM6/QY6T5DVTxCrrtwrmvzfav0XhjgsZzEGJv2Hek9PcS6LL0j0/3oQYSnYYjz2Ibj2xB9T/pcpvN1uE3xfQ3ZeUzHx6qq+Szcb1nn/0uTzxPZXHX68ez/kaqqnjz7RJRP/6epqmq5zI7RzLI1VTNA/5c+11NYUw0xxqbHSOeqIdYT6cUYpIbwPM7i9XH+TMzDeWI2z/d8/vj661H+5z++kBUwwIdn6b7T3gDv/NJvKYcY4NKxIX4NPsDeWfpcD/E9aLqfuw6/xRxmnsnyQ+y3dOH7svkA67L5APcDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/9WlS5fGLgEAAAAAAAAAAPg71o5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y5dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADTNR+7gKqq/dV+fXD1gx+c315vxzUsD29F+RdfeCquoe1ORfnZbBnlF1v57fDmW29E+Vu378U1vPzyy1F+0cQl1IPD7Fpc2/82yl/54IsoX1X15JMXo/zO9tG4hlmf5Zv5Isp/t1plBVTVTrMf5Y+0m3ENiz47D1/vZ8/lic3seaiqWnXZg9mtw5upqt5+750o/9xzz8U19N1GlF8u11H+fy5fjvJVVc88nc2Xn376SVzD4f0HUf7OnVmUf+a5n0f5qqrlwWGUf/ett+Mann766Si/vb0T1/D4Y1n+tdf/K8r/9vlnsgKqan+e9V/vvpONTVVVbZ/d08t1Ns6v+2xsqqpqd7JjnDl1Jq7h62+zvuHuYRflu/5alK+qOnbs0Sjfd/fjGvbufR3lt7d+EtfQra9G+WWX9U7N4qEoX1X1ULcb5b9e5uuJh7afiPKzJuv/ZrPzUb6qarnKnqu2PRHX0HXZemK+kc+3t+9m52HrSLbX0VS+LqvK5rp1n/VeVVXzWbZGfmQ3a3xWy+tRvqqqmjaKr7Op7nvZHuB8fjfKr1dHonxVVVPZedzczPdbjh8/HuW3d/O92PU6G+fbcK+jz7cJqmmzazmbZ+NjVdXN2x9H+YMHN6L8xfPZurCqqumzvqW6m3ENfdh3tG1+QzVNNt/t7d2O8pcvvxflq6pOnc7mqhu38rmqDdfYB/ey8/j8sy9E+aqq3d1sjO7Csamq6sqV7Lnau5Odxx9fCDd8qur+vWz/b3Mj24etqlossvvx9p29uIY+7INv72Xr/HaA+3HnaHYtdna24hoW4djShPNMDfDeMp6qBuid+j77IX3lC4ouPMR8nj1TbZtfzHW4hzjfzMe3q3vZe+yNrayX3xrgodjt0j3p/P3tv7/2SpT/0QB72q++9VqUv3j+XJSfhd9UVFV9cz1b5zeLfJ2/v8r2jbrwm4St7SG+lwp/wwCbPk04T+w/yPq/ts3G+O8PkuUH2Kw4upX1PqtV/lx24Tjdh/l2gHmiCY+xTpuOytuv9LnsB/gNO+H3AA/u5e8dm3BPuw3zVfm1TNcT8XqkqlbrsHcaYD2RHmRjI+tBh3B4cBDlN8LvIP8mfP+aPhMDzHXpO+Qhnok+/B3tADWk7yf68JnqBriW8SEGOI/p+JTOM+t0fK2K941WA3wjnV6JebiPWpXvucT93wSu5RSkY+xikc91y2V2T3cD9MFdlw0u83B9mo5NVflc1Tb5GjvdD07nuqqq+4dZ/3Z891iU/8WF/DvIB/vpns8A41ubjfPxlRxkPZL2oPlzOUjvE0r74HSMTf/+9wfJjxFL953CeWae349N2L9dvZl9q1RV9Y8Xsu+Dl8tsfJzN8rnu488/i/L9AO8dl+F+cNpHV+Xr27T36voB3m+E34OuB3jHsgj3jdL9vy5+91pVEziPfXgeVgPcT9OYqwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgL83ly5dGrsEAP4Xv/vd78YuAQAAAAAAAAD+37VjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdM3HLqCqqrqmZvd/eCmf3bgSl3BidzvKb9XxuIZ1HUb57Z2NKP/7P/wxyldVraqN8r96+ddxDev9gyi/H1dQ9dWdq1H+6qdfRvmnnv9ZlK+qmvd9lF8ul3ENs3CI6pss//B8M8pXVd1YXY/ybZc9U1VV7Sr7HWd3Ho7yd5vsmayqunXtVpS/8tnncQ0/feapKH/rwc24ho/e+yLKzzfXUf6fnnk2yldV9Q+yue6pi0/ENfzprTej/PMXn4vyb7z+5yhfVVWr7Fr+80svxiU0fRPl580iruG7u99G+YsXn4zyr73zXpSvqnpo+0iU/+mTF+MaPv086ztqmfUMz//smezvV9Wnn38W5d949424hh+d/VGU/+DDD6P8L196KcpXVd26eS3KX716I67hzJnTUb6rb+Ia5vOs9zlcfhXl2yYbX6uq9uezKL+7ld3PVVXVZ33warWT/f22y/JVVU3WR6+7bF1YVbWxOBPWEJ7H+it797Zsx1WdAXj0XGvtk2QZLFmyLMuWbWGMQ6ACpkIKQiUXyUPoAfUSqUpVKiEGxxxCAIPBYMAnWbJknfc6dedC5DJVif9OegHfdz9aY3XPw5ije5equlm23/aVjYV5dzaKr6oaWnbS3w5ZDVtV1a3T2ukw+/dbfh+3/f0ovh/yNuSsZdfow7WljdA1OjrMnuXhURZfVbXts3P6dsh7PsOQ9Ttmla3RfZf/hm6erQ3Xb2Y1bFXVMjwbPnMhO99uj8fYb29H4a3LeuJVFXa0q9osOxNVVX34QdbzeeedrPd19qnzUXxV1c072Xlgucl7iEeLbL/91jf/PopfPbgXxVdV7e1lfYJ/fu31OIfLzz8Xxe+fOR3FdyOciVrLrrG/l78buHsnGw+f3HkY57AJ4x8/kdUd+/O8/js6yubEOtwrq6qG8H1ZVTYe8xmRz6uh8j2/C+dlv83vxLbPZsX6OKshj5f5Xnf+7Jko/q1b78Q5fO1yVkN+ePPtOIfUssvm9fd/9MM8iXV2njjzZP4O+bOnsl7sjZtZ/fcg/K6jqqrtZ/vEw+N0t6zahkvkIqw7Vpv8N3Rhv2WT3oSq6jfZNbpZ+BvGqBlm2bwMl6aqqtqssr1qMcveLVRVDWH1sg3vQ/rvV1W1sFPQD/l4SrUW7hMtHwvLsPaZjZBDdeG8DOOrqvo+G9TbMH6xGKEvHy7zY8yJ/FyWWS/zdwPzefaNzAid2LgPOgvXln6E59jieR2nUJtwXtYIw3mbjojwPozRq4j7JSM8zCF8GOl+u96M8I11WL+N8SzTtWGMb2TSen4WfmOTjqVHF0nnRJ5C/CzjOZGfb1s4J2bh2XIc2XhahT2nqqouPqDmc6Lvs3md9qOrqiocD3/15Vezf3+VP8s+XFuqy89lXbg2DENW94xxlkjPhmOs0dOeiB6JV4b0WYxxE+JXfiPUoBMvsf0Ih8vwFXK98c6v4hxeeeHZKH4T1h0ffJR/G7wM+yWzMf7WMIzvwp747y8ShbcWnuvCbxir8nNZGl+V75d7YQ9xucwXlyFcoEY534Znw1F6FWMs1AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwB+Uq1evTp0CAAAAAAAAAABApE2dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7q02dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7az51AlVVm/Wyrl17+1PHP33hXJzD8xf/Iorfr02cw28+vhHFf+dHv4zin3rqqSi+qupzz70Yxd9/cD/OobohCn/3xjtxCs898WwUf//McRZ/61YUX1X19NlsXq2Ol3EO6a94YpbF77UuzKDqZL8Xxd/cruMcntxvUfzD41UU/4t3Pv36/l8O9k5E8V979atxDouDwyj+Bz/4UZzDZ86fiuL/7OkXovh+m8/rTVh5/PzDd+McvvSFz0Xxv3zzzSj+xNHJKL6q6vLz2W9Yr/o4hzbLrnHtxntxDo+dzNbYU/02ir/+eLY2VVW98nw2L5dD9huqqi5cyGrAg/3sOVTlv6Ebsr3q8uWsdquqeu6pbF7euJWdBV5//btRfFXVpecuRPHPXXw+zmHYZhvFZrgX57CdZWeSxTyro5d9Xssv1mei+K6l87pq0x9F8et19hz2Fo9H8VVV81lWe223WR1eVbVeZmfDttiPczhx+JnsAuEaXX1+Jmpd9iyGyudE12Xny6Gy+zhUPh6rm76NOIS1TxrfahHFV1W1lvUQ2ywfjy0cj90I69vQZevTusvuwzDkz/IXP3stir/47OfjHM4cnY/iN5uwFm95Lb9YZM9iNkL/bhnut2+9+fM4h9ayNfbosazXsNzcieKrqpbLbK966aXsTFVVdeH801H8w1XW++r2H4viq6r+5V+/E8W//NLlOIfjsB/cZtk+cbCX73U1hH2r6/m57Pbxwyh+1vL99rGwZ3PyKOuJHx7m55HWshc9682DOIfKt5o/eNu0Zqiq1SargzfbPIeq7B1yC+uObZ9/T/DvP/tJFP/1V78Y55C6fy+7D7+4/R9xDs+evRTFP1h9HOfwt9/4m/gaqdXe9Sj+1KmzUfwyrL2qqt59/6Mofn2c7xNduDZs+qxuGWObylbHqhryLIZ0nU/PhiPUXkP4VlWuQgAAIABJREFULIc+fhLxXpVnUNWFvdh5+huG/Fek43F/hDPNahmeT8Nz2XyW987Sc1ltRxiRYR90E9awY+Qwm4W93Cj69znMs3PZfIT3E334bUc6r0dYWuLxlJ6Pqyoej+l46kfY69LfsFzm7x0P9g+i+O12hLUl7otnz2I7wqRI3522UVa4tO7I9rr0fd2jJMIcwpqhKl+f+hHGU7pP5J+u5c8yPVuO0U9Oa+kRVob4Cumm3Y/wK9L3r+mjHGNpSW9DusZXVR2E3+xvwzN6VdW5k9n71z78+7J+hN/Q9+GzGKMQDq+RDqcx9hkeSfeJLq69ovBH10gXuBH6oF240KdHgc1e/v3fW7/9IIp/6dLFOId7D7Le/kc3b0bxy80Y37Rm8el5pCqv37Yj9M66Fr6/Tc+WI9QtffgsNqv8Pra0iEx7ZyPUoOm7hfUq/Fa9qvb3sr748XH2DWJV1WI+/XfaAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/87Vq1enTgGA/8aVK1emTgEAAAAAAAAA/iS0qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHe1qRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHfNp06gqmp//6BeuPz5Tx3/9JMvxjls5l0U/8abP4xzuH7t4yj+i1/+UhT/xNGpKL6qanPvYRR/98HtOIc7m/tR/EsXX85z+ORWFP+FZ56K4t9+97dRfFXVr373uyj+3NnzcQ6nZtkSdes4G48n94+i+Kqq/dnJKP50Hcc5vP3hr6P4T65l8/Lc09l4rqq6eD5b51cPsjlZVfXW229G8c9cejLO4exRdo1+tYziV8Mqiq+qurPNcnjmdL5XLTfZ2nBwcBDFnz93MYqvqhr6dRifry3v3/goin/sicfjHGbzbJ0+XOxF8V99/HQUX1V1vMrqluqyGraqatFalkINUfyNG9ei+KqqZ89fiuIf378Q57AO78PqYTavDw6z8VxVdfLEiSh+s7wX59CG7Hd0i+w5VFV9cOODKP75089F8atl/hveG34TxV/YezrOoWvZfrlZZPt1ddmcqqrq+k0UP2/5vEyX+X7Ix1N1+1H4MKR7VfYcqqqqy86WrcvGc1VVDVkd3A/pmM5bgC28j1XbOIfqsmsMQzae+jqM4quq+nVWi8/6RZxD1SyKnle2LlRVrftsTjzY3oni796+HsVXVb300lei+NkItXy/yno2rWXzepjl47EP5+XDe3fjHH78459G8c88cynO4aOPP4zih3kfxXfrvG75yqtfjuIPF1kftaqq22R79p27WQ/xvXd/GcVXVb34wqUofnmc9+9qyMbTPFxbjo+zPaKq6uPb2fl00+d1y354H04c5vvtyRNZ7TKbZTVD3+fnke02q4PT31BV1cI9ewh7Rl3lNUNqb5GfJ+Z72TXu3X8Q57DZZuvbB9ezGnLIjxN1P3zPUzXGeSLz8bWbUfxqnfcJzj6drbFf+dzX4xwqXBvG6JfsLbJ3HOt1+C7+KK//7q/ej+LvbPL7uAj3mi7cL7sRzpatwvdEI2xV221Wxw5hr6NGqBmGbTaeuj7bp6qqupat88MI/eQ+PE+kGYxRO6X133adv59YzLMxOYT3YTvkZ6IhrL36TZ7DYjF97VPhvErf84wxryscT/PZCBvFGJtNYG8v752t0rVhlDU6vEYY34Xfpvz+KlH0wUHeb0l3q7RPUJXXb+mcCj+3r6q8Zui6McZTJq3exqjl8+opt03r4Jbfh3m456f75Rj77RCeDTdj1G/h74i/QdyBOTFKDumZqA9zGGF9TLfs1uVzYhX2bIZ5fh+++vKfR/HrVdbT3sTfW+Vryxg1aHrGTo0xr4dwXv+xSL8Vnzi8qqr6tG80xhk7fMdxcJi9bPr5e+9F8VVVF05lOWxGeM9zJ3xveG8TntFH+J4g3arGeBefnrFnLe+rp/27Puyrp/FVY9WxmbTXsA7nZRuh59PCOnZvhF5weh8W8xG+pRxhfQEAAAAAAAAAAAAAAAAAAAAAAADgD8PVq1cn/fdv3sz+PzkAAAAAAAAAAACAXTH1d5kAu+rKlStTpwAAAAAAAAAA/AlpUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO5qUycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO6aT51AVdV8sV/nznzuU8fvLR7EOXz72/8Wxa+qj3P4xjf/JrvAg3UUfvv4XvbvV9Vys4zi5/N8SF56/Nkofnn3OM5h3vai+C6cmhcvvhTFV1X99re/iuLX61Wcw3zWovjVMnuWv7t5LYqvqnrh0nNR/I33rsc53P7gVhR/+cvZeDo9fyKKr6o6XmXr/LVPPoxzePHZS1H84ewozmE7DFH8w+3DKP5On+91Ty4OovhhE6dQR0fnovjPPLaN4tfbbK+sqtpssrHwwx/+NM7hlVey9W2xzcdTt8j2y2X3WBT/5CKrvaqqrt+/HcUf7uX38WAv229v3cpqyPPnLkfxVVVdPR7F336Y77ff/4fvRfGnz2T75csvvxDFV1Xdf5DVDHvzbE5VVbXhkyh+25+Jc3jiVLa23H7wbhR/4uj5KL6qqt15O4pfL/INt3X7Ufz+LBtPy+O8lu8W2bycdYdxDkNlz6KrrG6pqmpdVnfUrIvC1+ssvqpq6LP72Fp4D6qq69I9O78PU9ts8tppGLJrtJadR1o3woGky2qvMUbC0GV9q6p8TmzCc/5mdTeKv3j+S1F8VdV6lfW+hlley6dPYtayETXG+vjG974fxXddPite/sIXo/j33sv6qFVV61XWs0n7Tn/5tb+O4quqVuuslt9f5L2z73z3jSj+3NmsZ/Tk6c9G8VVV83m2Rm83+fuN2Sw7E925m63xD1f5fnt/ma3RJw+z80xV1ZOfzXoVQ9gLfiRbI9Mc+hH6yX8M0vs4wlYX24zwLPshu8bRYVbLV1Xd2WTry9mzWd/p8oWLUXxV1T++9k9R/GuvfyfOYX/vRBR/92FWy//dt16N4h9J313me9V2m+23s9kszqHCb1wWi2ws/Ogn2Tc6VVX3wrpjry3iHDarrFexv8hyGPq8ZkjX6C48W1ZVdWENOptn/ZZhhA23S8dT+Byq8vpr3uXfbHVhDtswvoW9t6q81zCf52t0v816+9shjB9hbYln1RhrS8vGw3yR59Cn9zIMb+E9GCGFeJ+pqtpu0/dlmTGOZel3sYuwZqiqGsI1No1P3488ukb2NOI5Wfl+O0btNMLUjozRtkr37DbCfUxnd/oavQ/366qqbfj93Sj7RDivuhFW2bSc78NBvb+XvnvN6+Btn4+ndG7vwnhMR1P4ecuja4Q9m7SfPMabhbj+GyOH9P1E2K+pqvrgZva3B6efOBvF98v8N8zCzaofoV8y/VcRI4jvw/S/YYzvKtKfke4z3ZD/hnlYg+4t8j3/OLwPv/7w/Sj+VJfXDOlYuHv/fpzC7fvh37+G7wxn4d86VuU9xLT2qqrabrLx0I1QPB0vs7+tSmvIcd7Fh/XbCL2zVmO8N/z00jPVo2uE7zfGaJaE42GM/XYxwt/WAwAAAAAAAAAAAAAAAAAAAAAAAPD/4+rVq1OnAAAAAAAAAAAAADA531QC/N+5cuXK1CkAAAAAAAAAAPyPtakTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3takTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3takTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3takTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3takTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3takTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3takTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3takTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3takTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3takTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3takTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOA/2be3djuqKg3AY9U67EN2QiAJwUBAxIAaEeOxtbvtx4v+E/mB+Rfd/dAtIEgrKiLhIA0EgZDzYZ/WWlV9gX3XF/3wlVa1vu/9qD1WVc05xxyzNgAAAAAAAAAAwHg1QycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHg1QycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHg1QycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHg1QycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHjNhk6gqmq9XtXNuze+cPwr774R57C1sx3F//j8s3EO9/d2swuET3Nv9yC7QFX97rdvRvE//N534hx2D+5G8YvZZpxDs8oeRteuovjD9V4UX1U1nXZR/P379+Icdo7uZPHhuL567bMovqrqxVdei+IfPnE8zuGH378QxbcHiyh+eXAYxVdVzZss/ssnH49zaGZZEuv1Os5hd5WN7abJcnik2Yjiq6ra9TSKX8zncQ61zN7JVZfdx2u38rnlyM6RKP74qSy+qmovnOdPP/L1OIeuaaP4u/s3o/gX3nw7iq+qeuj0g1H8rAsnyKqaLbIcTj6UxW8vsvW+qurDP74bxb/+xuU4h+ee+2YUf/xYNi539/P6b5kNqVqvsjq8qmp7fiKKn3TLOIet+bEovtuYRPHLg7yOPnn0qSh+3V6Pc5iGG9SNSRa/nDwQxVdVLdvsnZ7O8vW2wtppvd6PU1gus17BYpHdh0ll96Cqat1mvyHdH38umxsmk/Q+ZH+/D7Me+i1V2TVWq4+i+GZ2Noqvquq69F3In2VX2Z6m7e7HOWyFc8POZlYzVA/zYxOOq2mTP8vJLNunp7XTm6//Ooqvqjr7WNazuXHrVpzD+x+k5wt5r+KxM6ej+Kefyvrqy728lp/NjkbxL7z4SpzDU099OYpP+3dduKeqqjo8THupPcwtk6zXsHuY3cdVm9deJ45m68zmZtYTr6paLLK5oW3zF2qVvtPho+jSC/ShhzI4/hnhBdoefkMfFWSqCevYK598HOdw4fz5KP7jG1fjHFKLzaz+O/fYk3EOb33yXhT/zz/5aRR/sLwdxVdVTZs7Wfw06x9+fpH0AvnZQOqtd7I6+vadfG+Z9o3Wy/z8dj7N1vzw2LGX9bZbZ3XHZJ7376oZtve1PMy/l5qH9V81+bg+ciT7RmbvXj4u01dyEu4H5ov8Pm4ssvV2sZHvJ27fzPodTfg+xe3oyuenXua38Brrdfb9XlVei8e3oYdeRbo/nfTQB52F60QX7mnacK2syqu31Sp/H3vY6KcJhPFVXTiq+uhUpHNLE/beqvL+Xb5g53eyDdf81TIfE/mvSM/84gTi92naQw26THuQcQZ5b38WfpN6EPf1qybxs8hfqOksW2/Tc+xevmgID2rSuamqjxpy6G9L8tpp0sPTTOu/VQ/12+XL70Txs80rUfyPL3wviq+qOgi/+aoeavnVwGdF6dlEVVWXHgL3cQ/S39FH4TGwuAauqmk4R3Y91KC3wm+95+FGf3sz/34vrb2u9vCdT3oOvpiG71MPYyrtNfQxv9U0GxP59y1V02n4z9DhHNvHt5ipPvqgcT84vQ093Me0hmzScV1V6b99tn18OBZ+XwwAAAAAAAAAAAAAAAAAAAAAAADA/82lS5eGTgEAAAAAAAAAAABgFHxXCfDnc/HixaFTAAAAAAAAAAD4i2mGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8ZoNnUBV1cH+fr3z9u+/cPz2g1txDt86dyGK37t1O85hPVlF8d1sEsU/svlwFF9VtfuV+1H8/v5+nMPOxnYUP5s0cQ6r5jCKv75cRvHHpvnQfuRU9j60bRfncOXKlSh+vpHNDauDgyi+qurJx5+I4h995Eycw8FBOK7W16LwxfyB7O9XVXXZuNzeOBqn8NGd7D7cXt+Lczh3NLuXh+vs708n+dwy29jIctiexzncvJGt2R+8814U/6UnHoniq6ru396L4r/y2FfjHHa2ptkFZmF8VX145eMo/pNP/hjFt222XldVHT+SjYnNRVb3VFV17ZEofvvoZhT/6i9ejOKrqg4Pstrrp//0gziH1Sp7H9ar7DdM2ii8qqpmXfY+boR1eFXVap3lsJhn82NV1Z07n0bxV+7eieKfPftoFF9VtVpntfikORbnsG7vRvHN9FQWP9+J4quqFtvHo/guXyZqUlmfoOmhfuu67H2Kt4Y9THCTcJ8f3oI/5ZD1bNIcwj//J9mz6ML4P10kMp1mc+xyme/r5vNFFN+uw41dVa3W2Z5oNj8R5zAJn2U6N03Sl6mq5tPsGsvDrO6pqprOsvX295ez/e3O8Wy9rqr64KM/RPFHj+b3sWmycfmdC8/GOaxW4bgKl/ybt/M+6B/evRzFP/HE2TiHRTjHrsIzmtUqn6O7cH7qelj054us/3bieFaL93G2MJ9ng2La5OdE6VrVhyaug8P3sZ9COosfQQppEn3cxza8xv5h1reqqtrcyObow2U2R1dV3Wyza7z1YXZu+fo770TxVVVH51ntc+xE1uuoqvrHU38Xxa/DR7kxP5ldoKqW4Svd9bDHnuZLTeylV8LefJPdiIOwp15VNQ33ZZMevqtYd+F3PmHtM5vm522zeVb/rdq8Dq5wXB2E33ZsbmZnXWPJYX83+zZk0kMdPAnrjrSGbfpohIa/YdVD7TSNF4qwHx3+9aqqVZv1g9OeelXVOiw8+mir5+cTYV++h/1E/ChQLpruAAAgAElEQVR62Oevw7eyCee3EUwt8bvQh7Sv34T1Y1W+v03Xmar0tKyf9yk944j3NH30W9IU+pikBz6AnfSwMUzPDdMxVZXPsX0YuhPbR93ShrXTtIe9YVxLh/Ft2jSqqkW4v+3jLD69j2np1Md6m55V9TEm0r3lfJKPiVMnsrPwZ849HcX/+0v5d7U/+dGPo/g7e/n/dlXaNxrBeVs6v3XVQ79lBFdI57cxnDum365tHcv7d1ff+l0U/+QTj0fxy/SApKr2Dnaj+MMe1vxZ+H8ofdQdQ+vC+rEq/8ZmNsvPWNJ9+n7Yl582ec2Qng3Mwxq2D/G3JT3ksA5r8X56uen3KX2sVQAAAAAAAAAAAAAAAAAAAAAAAAB//S5dujR0CgAAAAAAAAAAAACj4LtKgD+fixcvDp0CAAAAAAAAAMDflGboBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr2boBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYr9nQCVRVbe/s1IUf/fgLx1++/Gqcw/Xbt6L4VXc7zmEx2cri2yz+Tg+/4dETD0fxXdvEOazXWfxheoGqOpwcRPEn5osoftnD0O5W+1H8bDaJczh16lQU/8abb0fx5585F8VXVW3Pt6P4yXovzuHe7sdR/JH5iSh+Mc3mpqqqxbHsPv7+3TfjHD798KMo/u++dz7OYW+Vjat5k93HddtF8VVVR7ePRPGvvfXbOIfNSTZH7q2ycTnt7kbxVVUPP3gyil90O3EO25ubUfzPXnkpzqFtV1H8iceyMTFfHY/iq6q2pg9mOUzz2qmbHUbxz//b81H8AyePRfFVVc899w9R/HL3XpxD12VzdDfJ3udZD/XfxnQexS+XeR0938yuceveZ3EOzUY2vz1z7PEo/v2rWc1RVfWlk2ei+O4wn1tmi6yWX3XZfmQ6z3/Db3/3RhTfHmbza1XV+a9/I4qfNvncMJtm12jbdG5ow/iqabxe5nVwuk5UDf8bJpPsGk0fvYrJNItvs3HZNNlaWVW1t5ftBzY38n7LPNznV2XPoapqEo7trs3i23hMVXXhuNq9dyXO4d333oviT5w+G8Xf3r0ZxVdVTabZOtHDclt//6OfRPEH97Navqpq+0g2tl99LeuXnDmd1W5VVWfOZDXoxkbWE6+qunfvfhQ/nWbz26TJ55Z8yc7X/NUqG5dbGxtRfF4/Vq3C25DO8VVVq3W2Vk0m+ZpffVwj+fM9XKMLH0Xb5fuJdGyndXQ/dzJzuMrXuo1Fth84cTzvxb76n7+J4r92JjsHv3rjWhRfVfXdZ7+dXSCfYuNrTNMx0cNvmC+GH1ep1998Pb7G3nIZxTezcH7s4XyjptmznIbxVVXpUtM1YQ552RKvl+sevrGZzbOeyzw832jDGriqahrWDH3cx+0j2bcZq3Be6EVYAM6aHvpWYQ7rPt6nWdhLDX9DWodX5e90M8nXieUqe6f7OGNJzyfacG9Z8X6kahLuSfrYl3XhNSbh3ND18D526biMM8jnli6c39LnUFVV4bhu+qj/1tnTGMVupI8X6q/AJK3FU+FZV1XeQ+ylBxnWwen82IswhaaH+7gKa6d5Wj9WxUVgG77TTQ9nLKtl1sfs5X1M34cwh36mtrDn08NCk+7Te+g61c2bN6L4F176WRT//W9/N4qvqnrlV7+M4p+7cCHOod3PvgFM34Uu3VNVVRvuB9L4qvyd7mOPnU4v6XdCzSzfT6TfAzz/0stxDufPPRXF7+9m/8eysZ3/b9cn17PzrnSPX1XVhmvNNO4TROFVlZcMvfTOwn5w+m1xVdVynfbvsme5HsG+rA9pHdtHLZ5K3+k+5paRdG0AAAAAAAAAAAAAAAAAAAAAAAAARu/SpUtDpwAAAAAAAAAAAAAwCr6rBPjfXbx4cegUAAAAAAAAAAD4C2uGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8WqGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA8ZoNnUBVVbtua3ln9wvHP/zQ6TiHd69cjuK//cT5OIfDZh3FX717I4p/6MgDUXxVVXMwzS6wOY9zuLt/J4o/mN6Pczg1PZ5doJtk8W2bxVdVE+YwnS/iHO7cuBbFf+trX43iN6YPRvFVVev961H8zcrfx5M7j0bxbZM9y9nOdhRfVfXzl1+O4psmTqHOnn0oim/brTiHzVn2LFaVzQ2zrXxc/8cvXojiT+0ci3PYnWfr5flvnInit2aPRfFVVW2bvdTNIl8n/uWl7FnO1wdxDt987okovu2ORvHNJK+dtsLa5+NPPohzePutN6P4p859JYp/+HT2HKuq9nfvRvHdOouvquq6cFzONqL46Szf2nWTLopf7t2Lc7j28WdR/PEHszm6qmq+yMb2tMmexQM7eQ16596tLIftfH47PDyM4hcb2d7y/SvvRfFVVfPKxnUX1m5VVb967ZdR/HcvXIhzqC7c54cmfRTzI9B12RxblcbnujbMYbKMc2i7rIacdJtR/HL5aRT/uXBu6KEGrcrG9STcW1ZVTWfh2F5nObTxmKy69tnVKP79K1fiHB49m/W+Prv+X1H8cpmP61MnH47iz3/9+3EOu3vZ79g6ktXyVVX/+vzPovivPXMuil+vsrOJqqrpJOsnt+k6U1XNNJxbwt8wCeP7yKHp4Wwg1XZhDj3cxzFUkHn9l2vCe9mFNWgf9yB9n6Y97CcWi2yfv1ytovg/Xs3Oyqqqjmxma9Und7/4Of7/uH5/L4o//3je89nZys5p2jZbL5dj2N/2sMVfHmbPsgvvw+7+7Si+qupgfz+K/yjsYVZV3b+f7W/X4dzyubB+W2Xz/NbWkSi+qqqa7Desw71lVVWTjqtwuezWPay3YQ25WOR90FX4Tqd3oY9aPj0bmITvc1XV/XvZmt1H7VRh3yg8qqoHT+a9s8UsO7+9ey8/L9sL16q0FO+jlk/HVVp7VVU14Tvd9DAu0/5Z2pdP70Ef0r1pVdU6/I4xfafj85HKx0QPXad8cgjfpz56kGkPMa05qqqaSTiuemkZhe90Hymk0pe6l97bsP3g0w+diOKrqj69lu1P+zgvS59FH7V43AcNf0O6p6rqZ71M9fI+JIYf1v3sDSdZo6Btshtx8nj+3dn1W9k31n08yoPDrI7eXOTnt806qxu2p9mdePXl7BvtqqrnvvODKP6N3/w6zuHJp7NvGjY3s75Td5jXoOuw/9b1cHIZf3WW/n9a5fv0NIMjPfwfy4sv/TyK/+bT2XcZVfm5YRr/0Qf5/x2En8vXtId+S1zLh3+9j/pvHV5jIzzD/lx2J1Y93Ie0Bh16L1BVNQn7BMse+iXpt2vLsB/d9nDeli528bdKVTWbpuMqf5+G3pYBAAAAAAAAAAAAAAAAAAAAAAAAfxsuXbo0dAoAAAAAAAAAAAAAMd9EAvx5XLx4cegUAAAAAAAAAAD4f6gZOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxqsZOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxqsZOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxqsZOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxqsZOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxqsZOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxqsZOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxqsZOgEA/pt9e1u26yzPBPzNMTdro6WdJeGNbHDkHQ7OhoSCkOr0QVf1TeiiuAzdRA4CFcBFgakEiI3Bjo0xlmVbkiUtaa25GXP0gZLDrq7o/akxmzzP+Tv1rTH+8e8FAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwu7qxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgd3VjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA7urGLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3dWNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAu6sbuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdlc3dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K5u7AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F3d2AUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLtmYxdQVbXdruvBya0nznfzRVzDn197Lcr/5uPfxjVcu/pnUf7qwaUo30fpx1azdVbD8jiuYX++ifLnJ+fjGraTLsp3XZafR+nHZl32Kx/dfPJv+j/Nh+xdHpzbi/Kb/osoX1W1nU6i/DN7L+Q1TLI+8sHyYZR/+623onxV1Xqd9S1f/4uX4hoWdRjlZ10+Vs2m2bB9fHo3yt/79GaUr6rqummUn38ln7pc23slq2FyEOXPHeZt4YObt6P87xvMW/bn2czhtTdejGuYDmej/P6QtcfFYTbOVFW985ufRvk7d76Ma/i77347yp+eZjVsTu9H+aqqybCN8l34XVdVDeH8rSrLb/sh/Perjjfhu9jmK4qnrzwX5afTi3EN2224pllnc9ijvXw9cnfzSZRfrh/FNRwePB3lt/0yyl+4eBTlq6pu3fl9lO+2+Xc5dFn/du9+Nmeoqrp45kr4C9maaFLZeF1VNclKqKr8XW4re5fbbZafhvPwqqq0Sad7HVX5UNP32ZpoPs/23h7L3uUQ7pW0+I3ZNF/TpC9zszmJ8u+9/+9RvqpqcXAmyu8d5uvbT++8H+XTr/KNN7K1RFXVhaNsXTfZ5t/EyUk293n7nQ/iGv7mr/8yyn92O1uXDUM+1s2m2Vgz7bP+sapqsQh3xsPHkD/Fqi6cuGwbjLfp39GHk4auiydvVWGbHhq8zfSzavFdVotnGZiG5yNVVeESvabT/JvY9Nm85d6D7Izl9nG+Rj9+FP7GIt8HXS5Po/xmk4/5Nz/Pzv3uhXOGPjzrqqr6xx9+P8ofHeXv8sH98Dw/7N7yNX7VEJ6mz+b5XD7tnfoGY9U0vNMwDc8tl8v8m1gc7Gc/MGkw5ofT2M0qew7pPLyqqgvbQt9gLp+eIQ/pi2gw9ZqEHdRkyDu4Wfgcl6tVXMN8lrWn2SzrW26H431V1QvPX81+oMFcPl4PNDifSKUtetOgb5nPszF/Eo/YVUO4d7W3l83ftg2e4xCeT6R9fFX+TaT5SThW/kcVWQ0NnmN8ZpfuW1W+rlsssvOJTYN1WbomabHvFH6W8Z5Rix2n9Cmk7bGFdA762Z183jIJ977StUBV1Tpc00xnDdY04b54izVNKm3RTb6IeLwc/7tMn0Q676mq6tO7IUO2H337y+xORFVVn87/GvQts1k2lx8arLGXJ9me9gtXsjuAew2+qX97680o/2d//ldxDb97PztL/+q1a1H+7F5+N7hfZd/lth9/9tTk2LHL9mwO9rPv+sdv/iTKV1W99mr2f0hWy+xOa1XV8Ul23+nWnew+6LrF2cI2a9Mt7gOk+x3r9C5mg335ebjOXzc4O53Ef0f+LtMrBZOwPYVXAaqqahHuaW/6/F2u0nVZ2B67NiuSyGrVYl2X3jUCAAAAAAAAAAAAAAAAAAAAAAAA+H+7cePG2CUAAAAAAAAAAAAAjM6dSoA/nuvXr49dAgAAAAAAAAAA/w11YxcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO7qxi4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgN3VjV0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALurG7sAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHZXN3YBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyubuwCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhd3dgFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC7urELAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB3dWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDu6sYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDd1Y1dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7qxu7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB2Vzd2AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsrm7sAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXd3YBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwu2ZjF/DYpCb99InTTx2eiSt41G+j/J3jk7iGl+ZP/gyqqtab0yi/3Q5RvqqqJpMo3nXZM6iqmoTNeujyz6IL8/2mj/KHR0dhBVXff+snUf4vXr4a13D28GKU35x+mRUw3c/yVTWbZX/D/pm8hl9/8GGUXx7fi/Krk/tRvqrq6qvPRvlzs7NxDds++7Lni/xd/vLDX0b58+FzuPXFp1G+qmo+z8aaZy88HddQm+w5HB7Oo/yPfvLjKF9V1VU23j71VPY3VFU9e/mpKD8dLsQ1zPcOsnw49/rBD/4pyldVnTu/F+W/8+3/EdfwKJtC1rZbRfm333s3K6Cqvv7K17Mf6LNvqqpq1mW/kZZw8/7vsh+oqkvzrH/cO7gc1zAMiyjfbx/FNXx59w9R/vzFbN6ybNAenz93Jcp/cOduXMNym83FD/azddnhUTZOVVVNp1lbmE/TlWHVpMvmTpcvvxTXsH50O8pPJtl3PVS2Pn78I9l3NVS+XzIJ52+zcK9itV5H+aqq6Sx7l8cPv4hrmM82WX7xTFhB9u9XVXWTrG9I81VVw5B9V7NZto9aVfXuu9kc8O6dO1H+K89k43VV1b37n0f5cBu1qqpm22w98e1v/68ovzwNFxNVNQv3S9782c/jGp69ks1jn3k636v47IusTQ/hUHXuKD9jmYVzn02fj/ktzhciDb7rITyn6cK16WMtfuPJbfNhJu5jm4y34buczfL3sF5nD3M+D8/b0s6pqvb3s3fxxd38fCL9ru48eBDl3/jbb0b5qqr3387mXq9/NZ1H5+3hN+9/FNdwsj2O8pPKxplZ+E1VVfXrbLw8PcnXhnuLbA66Xmf7yZNJPm+Zz7O13WaTrw37kcfbqqpJl/Wx2yEbZ6YN5m6Pjh9G+b39/Px2dZq16b1FuHfWYLxNFxRd2JYel5DWkLWnIWzPVfmaZtjk73IarsvS+V9VVRdOxtPnuLeXjVNVVb//Q3g20KCGtDVsw1+YNOijVyfZvtFBgz66D/uWbYM+dhb28+ne/mza4C5m+F2vVtlYWVU1n2d3XNJ5S4v9lvxqbt4e+7CPTeePDWnVPUwAACAASURBVLZbarPJ1zSpeP7VZCkQ9m/hffkW878GTfpPoYRYegbdZD0RjhOTBp1Dk///EEjHyqqqbbgx3jfYWE+fYj7UtbiXEeZbvMvw70gfQ4uvYTrL5l7LZX6GvL8Xrgca9Avf+of/GeV/+sMfRPmLZ7L70VVVZ4/ORfl3/rXBWfzXrkX5zz+5GeVPz+d31c+fz/4/0KzBvtMQ9vOLWb7nswpreBReB7hw4Xz2A1W1WmXridMG69tb4X2nStdlDe5lxHOGFoNV+n9Xw/2SFn9Cn45VDeYt8b58gzvS6VnRarWM8i3Wt8uwhmmD/btteHYZXrGuIdxnqMrXhi3m8unHPW2wvu0bzBsAAAAAAAAAAAAAAAAAAAAAAACAP54bN26MXQIAAAAAAAAAAABAE+5FAuyu69evj10CAAAAAAAAAAD8l3VjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA7urGLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3dWNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAu6sbuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdlc3dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K5u7AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F3d2AUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLu6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHd1YxcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwO7qxi4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgN3VjV0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALurG7sAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHZXN3YBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyubuwCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhd3dgFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC7ZmMXUFXVTaZ1dHD+ifMnm2lew3Qb5V9/8aW4hs2jh1F+6LK/od8OUb6qatrNo/xkkjfJbrLIaphlf0NV1f6QPcvJ2cMo/6OfvBnlq6rm66w93b2fteeqqv29rIb57EqUn0zzvuXo7H6U/6cf/Siu4cyZrD1N5pMo/81vfTPKV1X1x32UHzZZvqrq8PyZKN/iu7x45myUP+7uRPlXX3kxyldVPRWM91VVm7Bvqqo6yF5l/eCffxzlu3k+3h6dz8aqq5cvxTXMpxei/N78XFzDrbufR/lf/OqXUf6Nb7wS5auqLp2/HOVXJ/fiGtab0yg/zLP528WvZON1VdWj5SrKn907imtYrh9E+bvL+1H+2TNXo3xV1TycB6/Wm7iGmiyjeL95FJdw4eLXonyXrmmyqVdVVd0bshqevfxMXMPP/uXnUb4fsvlbv83n8nuLbN7x8GHWnquq/vqvvhHl+3U2/6uqGoZwnd+l6/x1mK+KZ1/5FDT+todwn2E+z/+ILx/+IcofLi7GNSxm2Zpou83mDNVg32o7ZO+iC/f/Hv9G1p4++ui9uIZNuE6/fOXpKP/o5FaUr6pabbK5zzNX8nXZ66/+XZTfhnOno6Nsz6mq6vs/zNbYr7x0La7h0Uk2Zp8sszVVVdV8lvUvh4d7Uf78uXxNdP9Bth/c4HiiFuFzTMfbtI+vqpp02aQh/RseF5HF03c57bJ8VVX6GLYNGmQXzkInla9pqsJ99bBNp2NlVdXvbt6O8g/7cP5XVRcPsj42/S4//O0HUb6q6rnwfOPzL7L3UFX10c2bUf7gsMEZcvhpT8L+cdPn30Q3CTvJId94Su8UzOYHYQX5d9332XPo+3zMXyzG7Vuqqrpw3pHuBy+m+Xc9n2V3Q7YN9nwWi6yG9Jsatvk5eNy3NNB12dyn67K/YdPnzzHdhUzXAlVVffh3dJW3hfkivHMVzkGbvMuwPbU4L5vNs+e4XmXj5aTBOLO3l/WP0/A9VFVtwnfRNbhDeHpyktWQTkJned+yDceaedieq6qGsI/dpoN++h4aSNfoVS3Gicy0waZP+jfMwv3DqnwuPmkw3sb7mH2Wj/umBlrU0GI/N5P/DZPwOQwt9kHDMTvNV1X14bnjpMVFndA239SOa5iE72IaPsdNi/Vtg/aUy55D2hZarIm24d5+usavqtqENSym+Rz07p1sX/xbf/8PUf7dd96O8lVVk2W2HnnxXHbnv6rq4z98HOWfu/ZylN8s8/t7n97KzjeuPf98XMNymX0T0wZzp09vZ/cQb3/xWZS/+sxXonxVxQfZ94+P4xJOwznofniG3GLPJ56DNrjSkE59+vA9pM+gKl/TtKghXhO1OGRJ19jh/G/d4E5D2sfG+1aV76XOwvyywb2MIXwODY5YKj/nydcjkwZ9JAAAAAAAAAAAAAAAAAAAAAAAAPB/d+PGjbFLAAAAAAAAAAAAAIi5Ewnwx3P9+vWxSwAAAAAAAAAAgP8vdWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDu6sYuAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDd1Y1dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC7qxu7AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB2Vzd2AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsrm7sAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXd3YBQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwu7qxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgd3VjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA7urGLgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA3dWNXQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAu6sbuwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdlc3dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K5u7AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F3d2AUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsLu6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYHfNxi7gPw01PHF2Nsn//VllP3Lp8tNxDb/48N0o/8zZvSi/Nz+I8lVVm82Tv8eqqqHBu+yn0yh/pjZxDbfW2W989svfRPmh30b5qqqrL5yJ8nvzvHvZ3/tqlJ9Ouii/3KyjfFXVW2/9LMrPJn1cwwtfuxzlz+xfjPKrR1G8qqrmi6x/O94cxzW8/dbPsx8I+8eqqv2n51H+yvypKD+ZXYjyVVXDXta33L1zJ67h3979VZSfLbI+/vXXr0b5qqrN+ijK98NhXMPBmbNR/lfv/Etcw62bn0T5v//Od6L80Gd9U1XVdnM/yn/6KMtXVV2aZ3On2TRrT+fP5/Po93+dfdfPP30lruFkls19nj3K+uhuWET5qqrTVZbvpsu4hm2f9W9dl7Xnqqppl73L7TabQw7b/DlWn7WHfsj7t4tPZW3689ufR/nFPF9c/u03vxvlH3z5cVzDYpqu0/N12ST8rjZ9Nn+bt5iDDuG6apKvsSvY93qczvLTyX6Ur6o6e/BclO8m+Xc5VPYu0udYQ94WJuk6f5KvLd97/70ov1rlz6Hrsj2bew+yeXDX5c/x1Ze/EeWvPpd9U1VVm3X2Lu6dZPl//9W/RvmqqtdefjnK3z8+iWuYzrL2eHSUz51m4Tdx9ijbb/nks9tRvqrq0SrbL3n20vm4hm3YT0/Cc6K0b6uqqiHrn7YNpi1DWMMu/A3p3Gva4F3Own2C02W4SK+qRXhOs1xl69sPP/siyldVbbrsu1wv83Oek1VWw4vhvtOli9kZTVXVL975dZTfNJiDnj2bjVUPH+b7oF14bpj3Lfm+1TrsJKcNzuK322xNM/RZEZMG7TEd6sIpQ1VV9X32HPf28/3g7SarYTrL2nS6xn8s3CfY5u0p/Su24Xe9t5evR9bhvGPY5nOntIterbMxP10LVOX7qOtVfjaQ9g2bTX5fah3+xjQcrOL1TFVt076hwTiRPscdGOpqCPeD1w32YtO/ZNvgm5hOsw5uNs3WdUOLRXb4LuN9+RbS84kG5xvpvlU+ia2ahH1sOl632Dubhvstfbieqcq/y1WDPZ/5IrtD2A0N9jFD6f5bOo+uyueAkx3oH1s8h1TaQ7Z5l2E+7ubzcSLdt0rbY1W+p53udTQZJ8L/Q9Ji7rQNx+z0PaTPoCr/Lls8xz5cl20arCd++8H7Uf7SxUtR/rnnX4jyVVVffnk3yi9v3YxruHohO+P4+MMPovzLr74W5auqzp7Jzjf+8c034xr+93eze4x3GtwH6Pps7+rF57P/P5HulVRVffhJdp9z2ec1zMIxOx3z0zXVf1QRpVvMg7vwDLmr8ddE6btch3viVVWz8JxnF6R3UuctnkHYpFusidJ98U16Bt1gDtqH55Yt7ifH+8kN3mWTu2cAAAAAAAAAAAAAAAAAAAAAAACwo27cuDF2CfAn5/r160+c/d73vtewEgAAAAAAAAAAAP4r3KsE+ONI7tcCAAAAAAAAAACZbuwCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhd3dgFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/h317W7KjvO4Avrr33nPS6ICQkBABGwzEBtsx5sZJfJGbvIQeUA+RqlRiquIY7LgqlI3xARtjIxsDkpBmpJnZu3vngiIPoP9Hdcf5/e5Xz9rd32F9hwEAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPnqp04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPlaTp1AVVVXVcvqHjt+d5n/jP78fhT/72/9JM6h1g+i8GvfejGKPzk5jeKrqvZXB1H8GLSDL+ztZ9/y3Q/ei3M412dt8rNHd6P451++GsVXVV3cfzqK36m9OIeDvW0U/5v3sm95erKO4quqjjfHUfxr3/lOnEO3zt7j+CgbG65efjKKr6p6+52fR/HjOMQ5HG2OovhXvv1MnMPecCGK3+kPo/jlQTbGV1W986ufRfHrBnPVJhyenr1xLYpfhN+xqmqxPB/FH5zv4xz+7Y1/yXK4kM3XVVX/+P3vZQ94tIjC19397O9X1e07d6L4q+efiHPoV9m32A6bLIHxURZfVVeuXcoesJfXoNfCOnhR2XcYuvw91iKrW4YxG5uqqvo+G5+24yrO4fQ0qwHT39AvzkXxVVXbrPyrzXqMc7hy5ako/s9/+SiK312GY1NVdeH4tr+Tr8u2Q9a3hzH/ll2X9avlMpurtpXXf12XjfNpfFXVdpt9i224phk24cBQVYvKaqc8g6quz3KoysboLhzjq6rGTdamf/zTfA/y2ee+FsUfP/pznMPJo2yNvbOb1V5//71/juKrqsaH6b7RTpzDO796J4rf280WyE9dy9bHVVUP03V+PkTXInzI+Qb7JQ9PzqL4Dz/+LIq/eJj/hicvZnviQ4P9u73drF+ltVOL2issGapB2VLbcEGRxrcR7ok3+JZn4b58i/b06w8+jOIP9sLz10W+Rt+cPIziLyzT+rHquavZGcdOmMN/vf12FF9VFS7ratzkY/TZJmvTq3gtUJX2qmHIntBibbkI1yTDkH/LtABL985aFIDbbfYe+gbtMf0ZLe529H2WxHKRzRNNaob0GV0+3/bLcJANtzE3DcbodL9lscj7RNqehtOwLTTY89mss3XdapXvE4xj9h52Vnn9lq7tttvsW4wNxpYhfcYMxre47mixtgwfMmzzJOLXkE8T1XfT1m/DJj8vW4VzXYtdgj6uQcNzoii6zTP6Fps+6Vl8+vcb/IQu/JZ7O/md1kcPs72KZYO9ijFen4a1T4OOHZ/f5inEPyNd326arNHTNVFeB6ffssU+aDxPpPEN3uMQtqeuQa9YhWu7dYO6I9akX2XS/Y4uXB+3GCHj+3sNchi3WXsawv2/qorHyE+PwvvFQz62XL+R3V0bL1+Oc7j9u/ej+C78X8GDc/ldzHvhPe/vv/ZanMN//zz7X5plg/+5vBq2h806u2Pzxz/9KYqvqjpO6+g4g6pl+JB0vk33D6vys6oW+8lpHbxt8B5y0+/lbpvs2kybQ/otW5xVpWuiFns+6e9I78i0mGeGyuq3eK+jgRZn8csGfRsAAAAAAAAAAAAAAAAAAAAAAAC+LLdu3Zo6BZiVmzdvTp0CAAAAAAAAAAAAE3CnEuDL444uAAAAAAAAAAD839VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA89VPnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA87WcOoGqquqqxmX/2OHj/iJO4a3//FEUv7+7E+dw5/5ZFN9tsvewu3cxiv88id0o/NxhFl9V9dZb2bc8f3AQ57A+N0Txr33rm1F8N+bvsVtmw8POufw9/vBH2bfcXWX98sKTjz8ufeHbz72aPWAbp1CL3aw9rJZZ/A/f/HEUX1W1t5e1x9Pt/TiHv3vlq1F8NzwZ57CtMYpfXcj65RtvvBHFV1Xt72f9crG/jnPYGbL58uKF56P4vdX5KL6q6uOPP4rif/TmT+McXvr6N6L4K1dvxDmsz7Jvud1m7/H0bBPFV1VdfeJ6FL8Y8zp43Gbz3e3jbIxdnhxF8VVVT195OntAvxfn0G2Oo/hhuJP9/f4wiq+qWi6uRPHZLPWFrI6uvHyrGrsovItzyAvALnxGsDz/X4fhQ/72xeei+Pd++W4UX1U1nD2I4rct1mVduG3TZe35c1m/3KZNusGaqMLXsI1/RNVikfWJPhxcxrHBKB2+x77B2DKM2Xqg22bv4fizvG755a9/E8U/de2ZOIe797M6eJMvy+r61ctR/Kuv/EMU/+Dhoyi+qur8wX4U/8Z/vBnn8PKL2fr03mfZXHdychLFV1WdnWUN6vKlfE+7C8foDz++F+dwbj+rG544zNY0q1V+VDQM2RjbYLqts3W2Tk9z2IbzzFyktc92zOL7fKuj+rDwuHTpQpzDp3eyseEPf87m66qqw+vXoviTjz6J4vtzeQG4f5LNE6++9HKcw6d370bxv/vwdpbAIq9bTh9mHWsVzpVVVcMmG6MXDRYUy9Uqit/dy+bro6Ns/7CqquvDhVmDbYKum3ahPwzh/mFVLcPJJj2v+/wZ2e9YLBpMmNsW+0aPr2uwb7VI69gGNeheeL/kwb3sjGWRjgtVNWyy9tiiX276cJ5YZmP8JlxLVDUYYlssikJjuK6ryvv2OIb70VH055bhfakWfWIbtqi0OY3huq4qbwstLrXG77FrMOeH7zLtEy3m27j2aVBzhMe3tQrvEB4f52cDXVi/LZZ5/dflm19RmZgESwAAIABJREFU+NBiPRLGn55ld7SrqnbCu5jpuFCV12/pe0zHpqqqbdwg8jF6GdaQZ+usPa3CfYqqqvU6+xYNlhPVpw8J761VVaVbFUN4lj7GeyV5v1w2mCcenZ5mOYRzXYu6ZQxr8RY5LHfC9Wm4j5r+/0dV1ZieE8UZNFhPNHgPy3DfKd0T//R+/r8Pp5vsfOGZG/n9lOvPZXcAr4Tv8eThwyi+qur8+eze/4MH2b2Mqqqnr16N4tcN6uDdnWxd9cmn2R3po3Ceqsprnyb3AVochgfSO4xV+b7T0GAfNN3HTNfHLWqG9DLltsF90PTccQZb2jWG/bJvcVaVnmO36BNhe0gzWK/zC6XpmqbFnk9aQ3YN7jT8tdw9AwAAAAAAAAAAAAAAAAAAAAAAYH5u3bo1dQowKzdv3pw6BQAAAAAAAAAAACbiXiXAl8c9XQAAAAAAAAAA+P+rnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOarnzoBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOZrOXUCVVXDONZnxw8eO/7B7T/GOYz9Jor/yktPxzlcuXc+it9Z7Efxq92DKL6q6uj4bhT/3tu34xwWi50o/sq1/D0c7tyI4pdjH8XvLRdRfFXVUT2M4n/6kx/HOZwNJ1H8C1+/FsUfLK9G8VVViyEbZvtVPkx/dnQviv/D738WxT8aj6P4qqqvPf+NKH7VPRvnsNxmY+zhahXncH84iuJ/EvbLa09dieKrqj45/iSKv3HpiTiHZy49H8Xv7B1G8e/84q0ovqrq47/cieK/+/r34hx2V9l8uz05i3M4O/s0it9s11H8+YO8T4zr7D0OXVbDVlX98ZPfRvFXLlyK4ru9vF/3wxjFj5vTOIdxzHJYLHezv99iaRf+hqohTqHvsvhtZXV0VdU2TyLTpQ+o6rbZt+jiH1HVj1ntc3n/qSj+6usXo/iqqvX68fcpPpeN8VVV1Wdtugub8+ey9jCO2Vy1HfMfEb7GJu9xCOeq1LjN//4yHB/7dHytqnHMxrd33/15FH94mNU9VVXXr2d7iJ+dZmuqqqrxNOuXX3vhhTiHG9ezZ2xPs7bQok/84IdvRvFffe5v4hzuHz2K4rs+20PcabBvtb+f7bc8eJSt66qqVuFe6rPXn4xz2GyyNj2E4+Mw5LX8OGY1w3ab16BDuKZpUjqFurTwaPAjxvBbpGPsIjwfqapaLLNnvPOb9+Mcup29KH5zlo9vfZ+N0xcOszXN8Wn+G1546eUo/ncf/D7O4XiT/Y7TcA9yscnmyqqq3Z2sX67P8r3cnZ1wPzmcZ6ryMfbkJDu33NnJz4nGcM8nnSur8jk7zWHR5fPEWTjGLpYNJtwu+5aLLq/F1+m3WGRtetNgnlgsslo+rXuqqh4dZfcqxnDPqG/QJ1bhOfa2wRp7GxaywzprT3EdXlX9IvsWLdZE6a9o0ScW4WZsuo+6GfKz00W439HiW6btaQ5r9C48G+ga1H8VzhNderhQVVXhOXY6Xzf5DZkW80TaptPzieUyr7224bdoccqUHkOnrWkI90Cr8vsELWqnTbqXus3rjm1au4Qvcti0OHfM4hcN7khvwj2fPuzX6blAVdUirkHjFOI+0WKu6tLBIWzSfYP1xBB+jBb128Fetqf9KNw7azHfpmu7tPaqqhq77BnLcHxr8Ru28b2xGZz5NTj7PNuEa5q0PYZ7wVVVd46zue7he9nd4qqqF5/P7uyvw2/58d3s/9uqqr5y45kofr3Oz1jS+XIVntFU5eP8R/fCb9FgW36Rlgwt9nzCZ8TXCcK9kqqqdVjHttjyScfYtJZvUXvFz2hxwaXFgmBi+XtssHeWji0NOkVaA6bx6TlTVdUmrL3S+wgt9OFdzKr8PQAAAAAAAAAAAAAAAAAAAAAAADBPt27dmjoF+Ktz8+bNqVMAAAAAAAAAAABgAu5lAnx53NEFAAAAAAAAAAAS/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBf/dQJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBfy6kTqKoahk09uHf3seOPjh/EObz2za9E8Wdn+3EOly4+EcXv7J+P4m//6bdRfFXV8f3TKP7hyeO3gy+8+sqzUfy4zt5jVVVXZ1H8/sWLUfzv//BBFF9Vdf/u/Sh+GE7iHL772utR/Ljpo/jlMu/XB4dZDj/7xTtxDotuG8Vv+zGKf/3br0XxVVVddVl89gqqqurg8CCKf/+D9+McTh5mY8vZ5mEUf/ujO1F8VdWLL78cxT9/+Xqcw6PdrEH84Af/GsXvrqLwqqr6h+//UxR/fLyOcxjGoyi+77Kxpapqb+8wiu+6rF939T/s21m3HNV1B/Bd1d13koQmwCDJQhiwjeOAHceJl52VlYckH0IfUJ8iyVqxwxCMWTEY24xmBgFm0HRv3+6uzoOcvCRP/I9XlZPf733X3V1V55y9z6mbTy7DkI3LT1f5uLxw5kIUv7vI1rr1kL+PHx8fRvH37eZr/mL/RBR/tMrGxO3bn0TxVVUnDr6WXWCbP8vtNmxRu7zF7cI2eTN8Gf79TRRfVdV12WLTVYPFKp0iwwJutcnqx6qqofai+Du3P41zOH06G5fDtkEhHMtyaLHeTuE2dF32Ts5msyyBButtOi5ffe3VOIWbN7Ma9PLXr0Tx73/wdhRfVVVdVjsN23x+++EPs/2WWbcb55Au2a++k+193b6Z1Y9VVY88dCmKn8934hwOj7KxfeJEVgcfr9ZRfFXV8ijb6zixn9/Hs6ez/eA7d/J90H6WzQ19uM60WSvDi4S/oUUK4RZkGl5VVdv0YTR4lot5WHdss/52sZeP64O9rJa/cZz3ZQ9fPB/Ff/H5x3EOn//+ehT/8NkzUfy503lv+cprr2QXmGfza1XVep2td304rpvsE1Q2rmd9OC9U1XYIz6oaTHDps0wXzOVxVvdUVc3TmiHOoGozhPN8nzUD+/t5P/Ldx5+I4v/t6WfiHA5OZOcbq03e5/fhGzGEYyre66h8v6UL56aqqmGTjYm0lm9Rg6b7b032INMfktbyLdqR8H1K3+c/ZJHl0OiNSqRzw9CiKQqvsbOTr1VHy+z7u/Qbma5vUTWE71Pf4n0MNZjf0nl+Hq+XDcZE2tM0eJR92JMcr7JafD7P+9u0p4n3jKrih5GWTrN5fpaf1qCbcN+qKq//ZrPxP9tPb0Mf9nVVVV2XndOsVtn+390csjGRzvFDg/cx3evYNqj/5uHYbtFPdOFeRbpW9Q362/WQ7QHG+16VP4u0btmGz7GqarPJ7uPQYJ+gtuF+SXhG0zeo5dcNzoBT++E5z9EyP79N66+0r2rxLPvw+5Rlg7nlzfDbjvQ+Hq3zM5bX3nwjin/sG9+Iczg4yL53/+TT/DvGdz7Ozh3T2mcWno9U5Wt+k+278CLH4Z7R7m5et8zCuWXbYq0Kz9wWi6zPz6uWfJ2Zwmc+jbKIpOfYLeaWo6NsXKbft1RVrdK6Jd7/yyfItPZp0U+kPVF6jg4AAAAAAAAAAAAAAAAAAAAAAMB0Xbt2bewUYFKuXr06dgoAAAAAAAAAAAD8ifJdJsAfj+98AQAAAAAAAACAMfVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdM3HTqCqqu+q9ne7rxz/zctX4hyOj3ej+INuJ85h79TJKP6pZ5+O4s+ePhfFV1Ud79yO4r99+VtxDjvbU1F8vzPEORycvCeKf+q556P4obZRfFXVhUt7UfxjZ74X57A63kTxO9s+it/fy+Krqn72TDYuTx0cxDmcuj97lhcuPBLF98dR+N1rzGZR/Ml7TsQ5/OyZZ6P4M2dOxzl89Mm7Ufze/n4U/3c/+bsovqpqvs5Kj+u3P4hzeOGnL0XxV658PYq/9MADUXxV1Z3bt6L49WYZ57AZDqP4xSxbK6uqZn02N9Q2W/OXQ1b3VFWtu+xZPrB/b5zDMGTr3fEmW6+3XV637K6OoviP1/mY+OCVj6P442V2H0/tZb1EVdV6fT2KP3c2r1suX3o8il+vs7mpqmq1zsZlVVb8zBZnwr9fVfXV++uqqm1YR1dVDZW90304N3S1iOKrqmbzrI7e2b0R57DdZveh7/JnuRmy9bLvwvexwTpRDXrkOIMwhSF8DrOwp6qqevud30XxB/vZfk1V1ckTWV91/bOsn1gOqyi+quq+cL188s/+Ns5heZytVbu7+T7oT5/9eRT/8OVLUfzJsD+uqtqZZ/3tjVt53bK7l+1p3zrM3umuz+b4qqoz4Z7NwV7+Ph4dZf3AfJ7PsV24XqbS9b6qakgXu5HvwVRs07olfQ5VNZultXQW/8t3s/66qurJS/dF8bv5sK7FXrZOzId1nMN3Hnwwir8Z7kG+9P47UXxV1c4iPMre5PVbOq7m4R7m+jj/Det1Ns+3mKKHsLdbNFhvh3A/eLVJ34W8R1+Evd26wZhIn8Rslt3HJx5/NMyg6tPrWW/41z/Iz8Gf+vfse4CTp/IzltU66w0X4fzWNxgTXbgPmlfBVRXvnWX3oU0VPX4NmvZEaXyTHchwnenTc8+qGsIf0mQ/eZPdh/w+5r+hn2XXWK3y9bbJtvjYfz8tIhsUoekVugbzWzrDzML9txZrXfwkGjzLdL9kvpPtVbR4FdK6ZdZg0Q9bmtqEN2I33FOvqlqFOaTPoaoqXCaarFXpWpOuty0Wim1l52WLRYOBuQ3n2PB9nDV4F9IchrSArAbfA8QZ5Gfh6Vn8ZpPv5c7CyWU+y+fY9PuUtC9L15mqBj12g7OBNId0XA4N3sdN+D3ozk6D89tldn7bYr1Njd/R5ON6vsif5WG6T7DO3sd5g35kGT6Ll998K87hkUsXo/i3rn8U55BK18vFbvYtZ1XVJqyDm2zXhPP8bJ71t+t1vk506XrbYA9yN5yf4p6ogfG/aG2QQ4v9kpE/FRrCdaqqan8vm59a9GV5LR/WsA3u43qVzU9pT3X3GuFZfIM5thrMkQAAAAAAAAAAAAAAAAAAAAAAAPxP165dGzsFmJSrV6+OnQIAAAAAAAAAAAB/onyXCfC/840uAAAAAAAAAADw/10/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATNd87ASqqmbzeZ0+f+9Xjh/qVJxDvz+L4lfbIc7hVy+8EMXP+kUU3+1uoviqqgunz0bxfffV34P/Ns9e6/X2TpzCL174RRQ/rG9F8d/67mNRfFXVvDsdxa/XfZzD7qm9KP7Wlzej+NdffCOKr6o6c+pkFH/x8j1xDovKxuU2/Pu7Jw/CK1TdOlpH8S8+90ycw95uNsd+8slHcQ4XL2TP8uuXfpglkA/revXdl6P4X//2rTiHH//kiSh+1mXv9HLIx8R69V4UP6+dOIfqs3ViWyfyHLrbUfjtW9l93Nm7P4qvqtqd3xfFbxsMzKFbhVfoouhZl82vVVXnz1+K4p/++fNxDlcuZjmsNtlad3h4I4qvqjpz+nwU/9H1D+Ic7r0/q4OPl/l92N9Le5rsnZ6H/UxV1bBZRvGbSueFqu02W2uGLptbqvIeveuya+wcXI5zuHE7G1eLWb7m7+9kPck2bCi28buQrlRVDVKorsv2XOazbG745Uu/jOKrqs6ezdaJT3//cZzDwansPixvZ/Pjo1euRPFVVVceyq5xeHwc53C8zgbmL57Na6dvP/JwFL9cZvdhNsvr6C9uZv3Iasgnl+NV9k4/cDab4+d9/htms3Bffp3vaW822ZqfrnVVDdaa8ALbBj+ia7FgjpzDfJ7NDet11tdVVe3uZP3EMOR18M3bh1H8wV5Wg87vyfbUq6pW66ynWd7Je8vXXszqr8cfzc95nv9Nthe7d2I/ij+xn53xVFUd3snW21mDuanvs7khnWPTueluEmF4k3Uiix8anMUPQ1Y3LBZZ3bJcHkXxVVWz8D7223xMnDuf1ZDf/MaVKP6f/+lfoviqqge/lu3L37iZnUFXVf3oL78XxT/3fN7nnziVfWeTrreLRf4+pmckfYO92E3YY6dz9NBgjt4O2TUWO/ke5Drt7dL5scUeZHg2kNYcVVXbBj1Jqg/3CrouG5ebbYN9gvB9XDbYv9sNx1XfZ3VLF++q5zXkpkH9l46q9D5WVW3CM+D0Pu416Mv6cC+1D/f/qqqOj7JxtQ0X3G24f1iVP8sh/oKvagjnt/3d3Sh+G46HqqoK975m4XlbVdUmXG9b1G9p7dKF63XfNfhWKV0nGozLfLkLn0P656tqnp6xbPNxme5Jp/s1VVXb8Mwt7UdanI9z/aX6AAAgAElEQVSk12hxVnWwn+0H3znMzhY2Dc430vmpRV+Wjol0ju4a/IZFn/UjLcZEep4/hHsdVXl/u017mgbjOtViXz61DdeJFjsl6V1Iv4moqnrzg+wbwvk8/0477W8XYS2+XOX7LbO4jm2w5qfz/Gb8umWdrnXhd7lV+fw0C9fLIXwOVRW/Ti327+ID3PE/E6rNFMZEuE/QogZdLLJ5fnkUnmM3+A3x95wNnmW6f9diH7RFbwcAAAAAAAAAAAAAAAAAAAAAAPB/zbVr18ZOASbl6tWrY6cAAAAAAAAAAADASHxXCfDH4RtdAAAAAAAAAACAXD92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABM13zsBO7qartdfOXo2c4szuDt99+O4ofjbZzDpltn8bOjKP6eg1NRfFXV6b2Hovj9k1/9Pfgvb76dPctar+Ic7myzZ/HE9/48S2CZj4n5IrsP+yfOxDn85ne/jeK7dRfF317dieKrqhY72bjuh0txDjuVvQ+zg90o/q333o3iq6q++PxGFH97exjnsLl5M4p/7OFH4hzuP38xij+1k61V//r0U1F8VdVyWEbxf/+PP45zWB0NUXxX2Rz/5eH1KL6q6mCezbE7XV4CDn02Nyw3n8U5fPbZ51H8+bPnovidndNRfFXVsM7mp3XldctQ2ZjoK1tva9Nn8VV1eJjNLfeeOxnn8P5H70TxJ8+ciOLPP3BfFF9V9d6bv4viz507H+fw61deiuJP7Ofv02OPXIjit0NW/61XWXxV1bayMdF12VpXVbUJevyqqlmlzzKcm6pqm02PVTvpBapeD/vbRx66HOewG77TFdYd2y5/ln2XvU+zBjksj29F8c8/n82Pjzz67Si+qurDD9+L4oftJs5heZhd40d/9UQUv9dn63VV1Xa7F8W/++GbcQ53vsz2Ox66/PU4h82Q9aeLRTa3fPJlNiarqrpZttbtzfO65fTufhS/CuuOfifvLderrKfZrPO5pQvn+c2Qr/l9n+XQpbVPg7UuvUT8GxpYzLN91NXqOM5heZTV4kerfEy8fjubox8L92Ln8/xd+OJmtp/8F9/5TpzDBx9ne4Cf3vgwzuEffvw3UfyXt7O9t//41a+i+Kqq+Swbl9vKz2+3YXN4vMzmhvk8X2/TnmhosNal6236HO7mkMVv1tmzXDSo/7ZDNs8/+MDX4hwuP5jtAb7zxqtR/L1n828aPvk0O5+4ePGBOIe333g9iv/B95+Mc3jx5Zej+Nk864k2m/x8o+uzObIb8nGZVi7p7NY3qeWzayzDte5uEln4LKwZWvREFdYdm01ey6drdh/2RFVV23DPZ9uF8Q3qv77P5oa93Wz/r6pqswn3bLrsWaZ//w9JROHbbf4sK3yWXfgbqqoW4R5iF/6GFs9yPg/f6XBeqKpahfsl6VqX9lQtbBr0ROmvOLWXfSf05He/H2ZQ9cwLz0Xxh3fyc/C0T28xveU9dvb3W7yPad0yNMgh3XdK9/UbvArxFDs0eCG7+FmM39Okz3LW53V02pO06Ghu3cnOkGdp7RVF39XPshyOjrLvraqqdsN+YBvOj5sG32Wk8+MqPP+tajSuUukcG07SLcZEF9axTXrstG4J5+h5g3dptc76qhbPchHOb8fhb6iqGsLzibSObvK/D+G4TO9BVdU63ANMf0OLc8f0zG7RYL9lsw7np7AObrGdvIh7ywbn4GF8gy2fJmtNIq1hq6qOw2/XGqTQ4H8Pxv9mqw/X7BZvUjq/zRrMsS3OigAAAAAAAAAAAAAAAAAAAAAAAFq6du3a2CnApFy9enXsFAAAAAAAAAAAABiJ7yoB/nh8pwsAAAAAAAAAAPCnrx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx87AeA/2bezZjvK6wzAq3vvfUbpCAmEBhAi2IIgx2DAQ7lSlav8Cv1A/YyUcWwMGONgbGwzz2AQEpKOzrh3dy6IK7nW267uqjzP/dpap/sb1re+FgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAExXO3YCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAExXO3YCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzXfOwEqqrms3k9fOrUfce/+PprcQ6Pnb0QxX90+/04h9XxMop/5uoPovjNrfNRfFXV5loTxb/0m5fyHDa2ovhV3Y1z+P7l7Fn23XYW3+5F8VVVixM7UfwvXvplnMPOInsOs51sTj35/XNRfFXV2uzRKL6dZ3OqqmptI1vqX/zP7F1efjR7BlVVe0dfRvHNso1z+MkLP4/i1+brcQ4He7ej+Nd++4so/pFL+Zy48MhPovij/d04h26V/caNg+Mo/uGN+695/q6dZXtdV7M4h729G1kOXf4uH3zw4Si+77PnuOyysVBVtervRPFNuxHn0PRr8W9E//4s3+u6ZfYcL19+Ks7hj2/+Loq/t5vVb1evPh7FV1V98PaHUfxino+lvs/qt6effj7O4Wh/P/uB7igK7/t8bWnb7F00zZk8hybca7psLDRtvrbMZtnfsFzm7/LZ8Jw/G+Bd9stvo/j4XfRdFl9Vi8Uqir9951acw1/++kUUf+5idq764sYnUXxV1cFhtr6dO5fXwU8++bMo/uj4MEtgPT/Xvfzq61H85UsX4xxOX3wgil91+by8t5vtt7cPsn1icy1vi587czKKX636OIeuz35jFe634T9fVVVNZftEul9XVTVp2TDAcxjdAC8z/Ykmb99VE77Mo6Osfltbz89EhwfZfvvFja/jHP79uX+J4n/3xptRfF9Z7VZVdfaxS1H8m2/9Oc7h5z/NavmqrG81hHfffzuK75t8bVl12XiYtfk+EecQ9r4ODg6i+KqqxTyrfYY4Y+f7ZT6e0vGwtpb1Yu/czXqYVVVXn/peFJ+faKpeezX7NuP82bNR/Fb4LUBVVRvekXzx2d/iHHYeyM4TRwfZ3WlV1b/960+j+Bd/9XIUv1jbjOKrqtpwr0nPRFV5HZyeaZoBCul0mW/bPIc+PBv2YQ+xG6DXkZ5vuwH6oOl+2XX5frtYLKL44+PsTJSeC6sqfJPDtAnasG7pVlkN2w/QJ1hbZGfk/QHq4HR9Wq3yedlX9hvp2rJc5nvdPDxPnDyZ1T1VVQf3sn5yOqKHWB+7MIt+gBxm4Rp98272Xe2b7+b9lsOjbJ8YQt7uGKAXG+9W6b+f/w3tLFuj4+8RqqoN64Y+rCGH2G/TsZDuM1X5mWgtXJuqqpbHWW9/Yz3r+RwOUbekZ8MB7sva8EySjun03rOqqgvHQnqeqRpgbQj//bR2q6qaxf3gfDyme836Wv4uV2H9lZ4mxt3tvzNEzyfdb9MHMcR+OwvrlrRvVVV1nJ7tBngOaa9iFfYqukFmxfh7VSrNYBm+h6qK5+UQfdD0OaS1V9/l43GVjqdBzhPj/0Lam08fwxD9vyH2y1TaF18sshoyrYGrqrrwu4wheiVp2TJE3THEOR0AAAAAAAAAAAAAAAAAAAAAAOD/un79+tgpwKRcu3Zt7BQAAAAAAAAAAAAYie8qAf4xfKMLAAAAAAAAAABAVVU7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc7dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATNd87ASqqvb29uq1N9687/iNfhbncNh9HcU/ePqBOIfHLj4exa/XRhR/tLwbxVdVvfz6W1H8bN7EOZy9dDKKb5frcQ7bi4tR/GItew67e2tRfFXVb1/5fRS/7Po4h3NXHo7it5tsiVufn4riq6o2Zm0Uf/PwVpzDn976KIrfPLEZxb/z6TtRfFXV9mIriv/5j1+Ic5gttqP4Dz78Y5zDBx9k7/KHzzwdxW+uZ2tbVdVqbzf7gTabU1VVB91+FH9hK1sbVl02nququv44il929+IcVv1RFL+z/XieQx1G8e18L4r/5tbNKL6q6sTJrG5Za/I9v49r6WwsrFbZe6yqapozUXy+slQ1zTL7gX4RhR8dHGT/flWdP5+daT779JM4h+89dSmKPzzo4hyacI1t26wGbSqf111Yi3fLcDxXVdUqCw/3/G4V/vtV1XXhb3T5+bZtslq8a/Jzft9kZ+Smz97l8VFYP1bVu+9mdXTbZP2WqqoTO9lvfBvul/u7+T5x5YnsPHD50lNxDnWcPYe0V/HiS69E8VVV37uc7XUHB1ntVVV1dJztl02T93zWN7P97sJ2tj42TV4BLtPn2A6xT4S/EdYtXZ+PhfRvmA3QJ6j8VcT6tH7rwjp4gGfQh+NhHo7HqqrZLDvfbq5ndc8v//xeFF9V9dhO1oPcT+vwqvoi3GpOn8p6HY89+miWQFX99vevRfHPv3A1zqEq6wHe28/uLauq3nr74yh+dy+rIZv8+ja2sZnX8vd2s3NVU9kavb6R/w1dF07sAWqntG6Iz+hV1Yd17L3drJ/8yKXsLFBVdWYnu5/47L38zu7oIOudffPN7Sj+7Jn8u4zuIDtbbm3kC9zdu99E8RfPPRvn8OnH2Xh45gdXovjX/5CPx42tbI3sK3+Xq1W2zveVrU3NAJ99tW2YQ3o2rXyfSJ9jep6pqpq12XjqwrFUVdWGOQzRLzk+zvaJ9Fw3hLRmaMLxWJW/y67L7nmGeA+r8K5pPs/Xt7SN2czy9a0P74qGWJ9Sa4usl7u1dSLO4avuRvgL4bscYK9LtQPMy6Pw/rSZZfPy66+zGrgqb2Om+3VVVaXzcoDx1IRPogt7FYOsTGmfYIDvAZp59p1OukYP8Rz7PnuXs/D75qr8PDBEz2exlr7L8DkOcOeXnomWg3znE0rv/IY4C4QT6+g4f47p35GOx2aAXscsvLMb4v723n72nfcQ59t0nU+fwxBngXivCsdjVdUA7Y7QAN9lhPN6OcDaslxm+2U7wF6VntOPDtM9f/zz8TCydzHEu0xNYX1bhueBtA4eYjSm33kPIR1NQ9wNjN36GuRuINwn4m++qqobYM9ODFH/zedTeI5h7TTEvJ5AHxIAAAAAAAAAAAAAAAAAAAAAAJiW69evj50CTMq1a9fGTgEAAAAAAAAAAID74JtIgH8M39cCAAAAAAAAAAAwFe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXe3YCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXfOxE6iq6vquDo7v3Hf8pfPbcQ5b6ztR/JmTl+McZptrUfyHn30exe/v3v87+LtuPoviz587Geew6JdR/OaJi3EO8xPrUfz7730Qxe99ezeKr6pa2ziI4p/+wbNxDn3TRvFdly1xm9v52vL+h+9G8d/cyOfl8Wo3ij86PIziv//4P0XxVVUXLjwZxfeVrQtVVa+++uso/vBwL87huedfiOKbpo/i9w6+jOKrqto6juIXa2fjHLbXHs9+oM/mVM2yOVVVtb+/H8WvLfIScOdk9i76bhXn0IRze/f2zSh+cyPfJz748MMo/qkrT8U5VNNF4X3XhAlshvFVi3k2L/tlXoM+9/xPovhXf/d6Fv/Kb6L4qqrZLNsnHnv84TiHh049EcUvl1/HOXTNRhTfpPF9dqaqqmrbrJavcL+uqurjvyM7C2Sj+TtNeB7pK1tfv5Ou0fl+u7GZrdPvvvdaFH/z5lEUX1V18WJ2Jvn65qdxDtVm86o5zuq35557PoqvqtrZytb5VVoyVNUXN29E8V9/+VkU/73Ll6L4qqoTJ7K649atW3EOszZb35omf5lNZb/RzrJ9ZtbnO0Xfhs9hgM1q1WX7xCx8jn3471cNM55GN8B4Sh9DG87rNh3PVZUO6u2trTiDN95+L4q/8mh2N3DxytUovqrqq7ez2umJs+fjHG5/nPW0Hzp9Oop/5Y3sGVRVXX4i27M//1t+tjwOe6mffP5JnMPaWta76sP9Og2vys80+/fCXm5V9U22X66F++2DZxZRfFXVjTvZPpH2o6uq+i7bJxZr2T16VdXRUXa+3NjIzseffPhRFF9Vdelcts5vnDgV5/DohWw8ffVZdi77+Nusr19V1XTZ3cLD5/O7qp8990wU/9mHb8U53LmTrbHtbnbf9cMrj0TxVVV/euebKL5Z5H3QJq3Fw32mbfN7x67P1rfj47x/twjvLtN9ZpiTaZjDIOfjNIcBUgif5vFxNi/bWTYnq/Iz9gBtgur6sOcSPodwSlVVVRM+iPkAAzLtXKVrS1VVFz+HcDy2+d9wfJTNyyF62m04HtLzbTfAWJiF83KINbpbZu9ydZTV0Rtr2Te1VVWrVTaz0zk5hGaAXmy8T6QXFMNcxo8Z/p3wOaYpDDEc+3oPExAAACAASURBVPBHhtjrjlfZ2pDeW1blQ7JbZufjYSr57K/oBpiY6Zkkvf+dhXVPVdUqnNfz8P/BVFXN2vD+tU/Xx3xEpmvLEBtF2icY/4RdtUzXlgH+iLRvldcc+dqQjsdBWh3hdxFDvMvjsJZfX89r8WXYs0n3urRfUzVE/TbAt0bpmA73yyGe43KVrW/z8O60Kv+/MPF7GOA5pnXwEOfbLlzf0viqvHaJv5caonYKn8MQ398N1Ny/b+k3jFXjfztXVdWEZ+TD8HuEqqrFAGcSAAAAAAAAAAAAAAAAAAAAAABgONevXx87BZiUa9eujZ0CAAAAAAAAAAAA98E3kQD/OL6xBQAAAAAAAAAAgO+0YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1YycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHTNx06gqmo+b+vM6Z37jt/euBDnsJgvovjZ5lqcw29efTmK39jcjuKPZkdRfFXVUXczit/evhjncGJ+KorfOXEizuE/Xsne5fZaNp4evvRAFF9VdWb7n6P42XGcQh01qyj+xKlsTrz4619F8VVVD+zc/9pWVXWw/DbOYXmQze0fPftMFH9y83wUX1V1e/erKP71378R53Dh4exdvvDcv8Y53NvP3uWqO4zil6u9KL6qamv7dBTf9Ms4h2Z5EMUfdbei+D6sOaqqNjez3+iXbZzDahmWkW1edzRdlsPpnUei+OUApfTp07tR/O7dO3EOJ7a2ovimCcdjn8+J6jei8EWbry2Hh1ndcnCUrdHnzpyN4quqvrmd7bcXzj8Z59DtZc+h2pN5Dn02L7smW2O7ZfgMqqppsvNE02TrwneyOdE0fRjfRPH/8ytRdDvL99t5+Gcs1rP1sarqvff/FMUfHmTj8ZGL56L4qqrPv3wvip8t8p7PWpP1Gn76459H8YeH+dqyHj6Gl179bZzDIxez+u2hBx+K4ptmFsVXVd29m+0zbZuvLVXZGtt1WXxV1bzNnmXbZzn0bb5PtOme33dxDuFjqFWX5TDEfhv/RD4cq08f5AA5pM+hDcd0Gl+Vz4mb396Oczj15NUo/oO3s7pnd+2bKL6qatZnG+65hx6Mc/j2TvYu/vDun6P4nZ2sr19VdevG11H8nXv7cQ7LZXimma0PkEN2LkuXt0GOZaGuy3s+B8fZfvnIhWxeXnniuSi+qqo+fTMKf//drCdeVbW1nfVs9vbzeTlfZH3IdE49dOZMFF9V9c5f34/if/TM03EOtz79KIq/2X0cxR/tZWeqqqq0En/6+5fjHN7+U1Z3fP5Vfodci+xc9uCZ7JuEgwHO2FevZN8K/ddfPolz2NzO6uBZm+24qy6vGfo++7hjPs/vy7pVNjP7sHJpp3C+HaB2GqYvnknHQ5/2SwY4o6cNl/R8XFW1CnPoVlndMgt7d1VVfdh3msacGKBfEv5GPBYG6OWmdfDBQf5NQx/+Hemd3arPnkFVVZvWPgP0k9O+fHpHsgrHUlXVbJbl0KVrU1WtwvE4H2C/Hn2NHb/kGKTuSe8G0hqySe8mquLapxngm4ZZmsMA9xPpEpnel6Xra1XF82qIM02aRBPeYw8xFsJPjeLarSrfa9I7uymsj0OMxvRMsgrPRFV53dFP4Nu3dG1YrvK9Kp3b6btM32NVPq+HOJctwvuNIebEMu41ZPvEANtENeEKlZ8mqvLmVbq2hP98VS3m45/L0v8DfLTMeuLdKr+DPg7XhinsE/H3VlU1C3up8VMY4G84TtfYAXJIT3bpcBpiLKT9v8UQd1Xp2XCAM3Z6rgIAAAAAAAAAAAAAAAAAAAAAAP7X9evXx04BJuXatWtjpwAAAAAAAAAAAPD/km8aAabLN7YAAAAAAAAAAAAwnHbsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrnbsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrnbsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrnbsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrnbsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrnbsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrnbsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrnbsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+m307bdbsquoAvs55hntvz0knDRkMDWSeICEolFaplKV+hv6A/QGs8o2lKGBETDCIkIkkGJNAm6SH9HTvfabjC7DK1/nvqnOU3+/9Onc9++xx7XMBAAAAAACYrn7sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrn7sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrn7sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrn7sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrn7sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrn7sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrn7sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrn7sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrvnYCVRVLRYH9eCDz37+BwzbOIfVbBPF/+CVH8Y5VL+IwrenDrO/fyf7+1VVLzz7R1H83nIW53D35t0o/uV//XGcw2y9juLPnF9G8SdnZ6P4qqrdZojil3vZb6iqqm0fhf/4lR9F8YtF9verqq7e+DjLoc+n6T/9k2xcHh6fiuLf+8/Xo/iqqo8+fD+Kf/SrX4pzOHf2vij+9p1snamqGupqFL9Zd1H8iYN7o/iqqu3mRBQ/azC1fHrtoyj+4CCbG/Zn+biezfaj+GGer7dd7bIcdnk7DJX16fU2a4ehz8f16RPhmGgwKIYhfUb2Hprs5Xd3oviPr2frdVVVP8v60zdfeDGKX6+yNqiqevChbA95/foHcQ6n9y9E8bPZXpzDsDsTxR8e/jqKP9g/H8VXVdUQjssGurHnhq5FG2Rr/jAcxRnMF9l6+eab+V6867N1YrM9juJv3f0kiq+qms+y/vTlR74a5/DQQ49E8YfH2d6rm+d7hu+//E9R/CMP5+eyPpxbzpw7HcXfvJmvt8uw1pCeBaqqtkPWnzbbLL6qqu/Dmks4z3dZ2auqqnZD9pDtLk9is8vmty7cM7RYbYcwh12D88R8lvXHFu2wCNf8zSZrh2vXbkbxVVW7XTY33HMmq0FWVZ0Jp8irR9n+7dmHH8wSqKqqc1H0Bx9lda+qqivXs/3X8iC7a1qv8n10uNRVhfNrVVWXrlXVYLEKG2K5yGodLebo6rI5+vAw708PPZDtIS9cfDKK/9u//6sovqrqyadfiOK/9lx2P1JVde/5rN5x9dqNOIe33ng7it9sb0Xxx+uDKL6q6vkns/PpT/7tZ3EOzzz65Sj+wpcuRvG/fCOvdbx4MVuzX/3ey3EOd8N9x6OPZ3NLVdWVq9ma/8mn16P4+/v8rmrYy/bRTz/xQJzDG2/+Koqfnw5PFF1+35aeb7sG59u0pr0I9y3b8ExVVZVv3/J27PusHYewL1TlZ8N0H93ibiBth6Oj8Pu9qpovsnrufB5+g7jNx0Qf7uUbzCyV32M3qIOGOaTt0DVYb7vwXbaono09v/UN5pZ0XA0N+mNqltb1G9jE81P+LueLbI5N+3NV1TZcb9P1emgwS6ffE7Rox/gJDfZOqfS+rcX9RjeBHPJ5Pty3NFgnZuFdVYvemK538dzSYEzFT2jTIaPwXXjG7hrMj7NwTLTIobbjz7Hp/i2do9P1vir/DScO8pr28XH23VhcJ2jQleLzQIsxEf6QFnunU3vZ9+5HYV/YbPJv9hfhXr7J3il9StgfhwZzS6rFmr/eZP+zmYrnpqqaNZkbMundQIs6Qbr3GeL7ifFr4vPwf1CqWuzlsz3DrMFvGMIc8ppRPj+1aIf4u1oAAAAAAAAAAAAAAAAAAAAAAPh/5PLly2OnAJNy6dKlsVMAAAAAAAAAAAD4neSbRoDp8o0tAAAAAAAAAAAATEc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATNd87ASqqrq+am9/+NzxH3x4Jc5hdedOFD/0fZzDfRf2ovhlP4viv/jg41F8VVX2C6re/9X7cQ53bh9F8cPqbpzDS998NorfrRZZAutdFl9Vp06fjOLf/Y9fxjls1psoflXrKH4x76L4qqovXfhiFP/wg0/HOdT688+vVVU/ee37UfzRZhvFV1V98w++lT1gky93m91xFD/0V+McuuFEFL+/n/Xp7S5/l13djOJv3cnn6MXJrB32909F8f0mW6+rqrabbK27e5S34/4iG1eL7r44h36e9cnVJuuPVz/9JIqvqrpw4f7wCcs4h2HInjEM2XpdaXxV7R0cRPGbW3k73nMi27/tDdncsDc/E8VXVW132fy46fNz2bay/tCF7VhVtdtke6f9/Wz/t9ndiuKrqmazbI7uh/A8UlU1ZO3YVRifb+Wruqw/7Xb5/PbqKz+O4h94+CtxDh9/+qsofrGX1UuOj1dRfFXVs898LYo/u3cuziHs0vXptU+j+BvXrmUJVNXjjz4WxW82+ZhIjyQ3bmRz7P5+g71XWLJZr7NaR1XFk+R8lq+3LabpxDYck1VVQ2UvM6/eVQ1hS+52WUOk8VVVQzgoNg1e5sEya8e+y3Pow/uF3ZDNDZ/czu5Hqqpuh5P0F8/fE+fws7ffieIf+UJWq1jM8xrkW+++G8Xf2R3GOcznWX9cHWY53H9vvvfqd9nc0h3n6+3RUfaMrs9Xy3R22myyvXiLc9l2m+0hH3vyYpzDxfseiOL/+uW/i+Kff+rFKL6q6tyJrKY9X6Q3wFXDYdYj7z3I54ZvvfDNKP764WdR/HsfvhnFV1W98fbbUfyzTz4V5/CzN34Wxf/B738jiu+P87Xu/XeydlwfZ3eGVVXb8D7/syt5LTZdc9c3szP21RvZHU1V1YMns7vT9epGnMMzT34hin/7nf+K4vdPNqjlhvuOrsGin9Z8jo6ycdliL5/uvroG1ZL0bLluUL+rIcuhD+tOaRtUVW3Db5VOHGRzU1XVNrxjSb+3mrWo/4VdOmyC3+SQ3lU1qSFO4L4rtF5l59tdg2+NFotsvduFdYK+xYsIH9GF3wZXVQ1hPbfrsjl2NmtygRtFt7hjSftThe1Yldd84vW2wZjYbsO5ocFC0aV1+fA3pGPqt0+Jolust334O9J7ot88I5zfGuwhU+m72IR11Kp8D7gNzxPp3FSVn0/TvtRCvG9pcLZMR+V222JcZ/GzBuN6FZ6r9pbjr7fpm0jrLVVVy2W2l+/D9Xab7t2q4oNZi3eZ9ukW5/zjVXZvOJtnOcz7vA6a1r5avMsWd8CJFmtd/IgG+79NuNbM51l/arFl2MXfWDcQ/o5l2I5V+b5hF/an+GxaFXeIFvuWdHraht/ftfgNm3DNbvIuQ+laV5XX7wAAAAAAAAAAAAAAAAAAAAAAoJXLly+PnQJMyqVLl8ZOAQAAAAAAAAAA4HeSbxoBpss3tgAAAAAAAAAAAMD/1o+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1Y+dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADTNR87gaqqw7t366c//cnnjj99cCrO4Wi4HcUf7G3jHM4f3J/F798TxffLvDv88ys/jOJn/TLO4fT5Por/xqPPxzkcHWX9oe+yv3/23jPZA6rqu9/7hyh+bz9/l/1yF8XPtodR/OOPfz2Kr6o6dTIb19ev3YhzeOPnr0Tx8/1sTD311KNRfFXVZrOXxa/zdtxtP4vil/P74hyqX0ThQ2VjqpsdR/FVVbdvfBzFz/fydjx14lwU3+/uZAl04SRfVbPZQRR/+kS+Tgy7TRS/G/K907DN9m9Dl+Xw0EMXo/iqqmGXjev1JuyPVVW1iqK7PlsnhmEWxVdVHa+yZ5y/52Kcw6Ifovjt5iiKH/q8HXezbH46s30kzuHq8QdR/NkTZ+McZrMT2QPCuWUWjqmqqvUqO9vtLbN5oaqq67LzwDZbZmo+y8+3h4cfRvGvvfZ+nMPzzz8Xxb/9i9fjHLpw75LuQb/97b+I4quqbt/J5tjuYD/O4Xsv/yiKP39PVvO551yD+TGdn2bZvqeqaphl/Wm7zeI3m3wPm+6dZrN8nYjH9S5rx6p875LtvKoqP5blj9jFvyKW1iD7cP9YVXWcbjsanC0/vX4rin/g/vNxDu9dz2oud65dieJX63UUX1XVLbL919DgXT52Orsr2t/LapCvvf1WFF9VNdvL9tGLsM5QVbU6zurq81k2x2/WeV+ocK1aN1jzhyGsE4T7lqqqrsvexYlwTNy8lc2vVVXPfePpKH7vRFZHrar6m3/4XhT/+y99K4pfzvLzyHwezg0NatrpmGiwA4yfcfZUdi574mJ+B/3qq/8Yxf/0zbwdX3wuuz/97ne/H8V/56WvRfFVVe+9+14Uv1zk7Xg6rMtfufJJnMN9q2wPeOFCdg9+5frVKL6q6qP/zOrJ991/b5zDNqwbvfTiE1H8K/+a1/9OncnaYb3NzxPzeVbv2DvI6vrrVViQrqpNeK6ah2eqqqphCL+xabDmd2GxoQ9zOD7Kv2lYLMK9U7zvqeq22ZlkGfan1SYfE2k9eWiw/0trXw2GRPVd1g5pLXcT9qWqfC8/T8dUVW3jmnT2G3bh/FqV94Vdg3e5XGZ1p7Q/hZ9U/OYZDe5IUukdSTfPv+3Yd8hqnAAAIABJREFUW2bjaheO63TfU5X/hnWDHPpwodgN4X1bgz1D+oSuxYVZmkM4P1bl96fpPjodU62ekUr7ZHwH3WJMhM/oG3yzlfbH3ZDFp2eqqqpZeM9z9+7dOIdluE60uWNJv5fKzOd5nWAWfpdx9yi7M6yqunM3vXdMv7HJ915DvF7m89t6k+19WpxpFmGt4XiV1cSH9JBf+dwwNJhjF+HYXoc1m02Dmk86P7Wo+aR7yPRNpt//VbWpxabSvVOLd5k+I23GFt9i5v+e36IOmv2OeViraNEX0oHZYkSl+7/j4+xb9aoG33YAAAAAAAAAAAAAAAAAAAAAAMBvXb58eewUYFIuXbo0dgoAAAAAAAAAAAC/c3zPCDBtvrEFAAAAAAAAAAAAWurHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6erHTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6ZqPnUBV1TBUbdbbzx1/e3ErziFtiMcefSbOYb07iOJv9YdR/Fuv/TSKr6q6u9pE8U88+UCcw+nluSh+vZrFOZzYOxHF37xzO4p/9bXXoviqqtkyGxW3N3fjHB64994o/vGn/iiKH4ajKL6q6uNfvRvF//vPX49zePaFJ6P4k2eyMfXO629F8VVVFy+uo/hZn4/rveWFKH5YD3EOXb+K4rfDcRT/i3d+GcVXVT32WNYfa8jWyqqqfsjmp83mZhQ/n2VzW1XVdpOtt/2Q98ftLhtX/fzz7/3+x26Xxc9m2fy2yaam38rG5XbTYB+8yPYt1S2j8M2uy/5+VVW4Zm93+Zrfz+6J4meVtUM3hAOiquZdNjfcmV+Lc9irvSj+g/ffi3P46le/FsVvsym6ttv97AFVtQzPyLvdyTiHxSI7TwxD1pDvvfdKFF9Vtd2cjeJPn8vf5S9//YvsAeG4rqp65JEvRPFfufhcFL86ytbKqqp+ls2x3/3BP8Y5fPmRi1H8cpmtt7MuX2+PjrPzyHyen8vm87SCl+1BV5t8D7sM++MsboOqYZfNDbvK9x3dkLXlEO4huz4fE7NZH8Xvdnl/qvBdpu3QNZhb5n225nezfEzsnT0TxW+3+bs8/3vZenvrkw+j+NPLrD9XVd1cZ/cTe3t5zefXVz+K4m/fyfbRD589HcVXVV357EYUv6p8/9d3WX/owvXy9u07UXxVVReesfNWrBrCObLr83GZtsN6ndVR/+xPvhPFV1VdO/w4in/5B/8U5/D8S1+P4g/C+9/lIquV/EY4JhrUndKR1TU436Zn5D6c3052YR22qp5+7ltR/E9ez+slb76b1Sq+/e0/jOL/5d/ye/A//ss/j+LfaXAXf+3d7A757HIR53D1vz6N4k+ezvY+D5w+FcVXVX0cfGdUVXX9k7ym/cQz2d3nZzez/d9XvvxQFF9V9f4H16P4vf28P+7CwvouXKt2Q36+Tet3LeoE2/Dycj7L63dDeEbehfvoRYPa2W6b9acGZaeahw9Zb7O+0Dc4j4Rb0NqlHwNUg9pVeD6uqtqF++AhbYcG9btZWNNerbK7haqqZbr3CY8Tmwb9Ma3tdw2+8zleZXdui3n2HoYGv2Ed9qeuQdVnsQjboUEO6TF9Fs7z23SSr6rj8A64wfRWFe590nWmRQ0yvSdq8CpjLe6a0vuucPuXf8RYDebIBu2Y5pC+h13an6tBOzZYq1qsd4lNg9klPWPvH+TfS23DWmyLM018tgv7QosxUeF3GS3+/2Ie3uf3LQ7ZoW36jU2Dd5mekVuMiXX4vwupFtNr+u3aepX/40B+55aNifzbu/x7qU2D7+/6MId0D7r7f7BnaKHFu0xn+XTf0uI9pFvxFl0h/R3pOhPXMGsaZ+y0HZaL7J6oqs13iAAAAAAAAAAAAAAAAAAAAAAA/N93+fLlsVOASbl06dLYKQAAAAAAAAAAAPxO8k0jwHT5xhYAAAAAAAAAAACYmn7sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrn7sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrn7sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP9m386a7ajOMwB/3Xs4RyOSEMKYQSAMCQ62cWxjx3EFT6mk8hP0A3Wfi1y4ylWOhxDAsQ02HhJGGRCTJDSdce/dnQsqyb3ednUneZ77t8+3e1jrW6v7AAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tWMXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0zccu4FN9df36rtOnto/EFZx/5CtRfmuAM3n5/atR/vbNj6N8V4dRvqrqq1/98yjfr4/FNfTdTpRfHs1ruHLloyj/ybXsWu6vdqN8VdXhYXaMxx67ENfw6OlHo/x6mf39V3/1m+wAVXXn1vUo/63nsrGpqmp/fSrKb+3fjPJn7jsb5auq1qtskD1y9HRcQ199lO8WB3kNXRflm1pE+Sef/IsoX1X16u9ejvJffPoLcQ2rvRtRfj7/TFhBG+ar+lpF+VWfz/nzxX6U77t78hpm2djQtNlEcXiY3UtVVZv1XpTfPrIV17DKbqdaLLOxqZqwgKpqmuy5auvu1yL/XUNl17LC39D3Tfb3Py0iSi+aE3kFi2yueujB43EN68Nszu426XydzxOb9ckov9jK19gfX3s9yr/5xpUo/8ADD0b5qqqbux9E+cU87//acFHzha88E9ewtbwvyu932T197U44vlbVh++9G+Uf/uxDcQ1Hj2xH+U06trT52DKbzbIamnyu6rtsXVZhDW2b/4ZN+BtWe/nYMp9l98NsgPupmrCXbzZRvu/De6mqdveyPnaI0xgfIzwPfZf30Yuw//v4Rr4uW96XrfM/O8/vp8tvXY7y24vsmXrq8UejfFXVJty3euPy23ENu+E9ubWV3Y/vX8/e8VRVdeG6bJCVYXiQ2Tw7j5t1Prake7mzedb3VFX1Yd/Qhc9UVdU63PQ5eiTbV0/3o6uqfvfKK1H+m89+O66hmuxaLPuwj27zeSY9QjdA75T2X8PsfIVHicfH/FecOZnt+Xz9y1+La/j1y7+O8un49vmnvxjlq6p+8sLzUf47zz0X1/CrcD3xcbjXUVV1+nQ2zr//5lvZ37+Q77ec2872W04/+XRcw+VXfx/lP9jP3redOXt/lK+q+rMns73U1994J64h3CbIx/h4tqw6WGfP9XIefuBSVelk1czyuWq9Dvds1tm1aAfYcEn3MQfpncJLEfdeQ/SgE+j/0n3M/CwMMD6l+3cD/Ir0lh5iPznez+2zHnSIdwPrcJ7YbLLxtapqayv7vmRvP/uedNbm+y3pu6ohrmW3yfau1gNcy3Rdle7LDzHfpt+4DDFPHIbPZXoeBmgZqtI9yHB8rKpqw6sxyHwb/oy4bxngPfgmvBbNEDdU+DuaKfQM4R2VfoNYVTUP56r0fdsg80zag4bft1Tlz2U7wHM5yGQTGOKbhvRKDPJtSCidbwf5VqnPnqtugNluGfZv83n+D4+3d+5E+a1lth4Z4plYhe9OmwHWE+maJj0PQ5zH+Jv9Afad0mb64DD8X5oBxpb0PM4GqWH8ffX0COk9PcR3GelewxBty6bLe8DEEGNLG37TOkT/14bP5eFqgP/TWw7xrggAAAAAAAAAAAAAAAAAAAAAgMSlS5fGLgEm5eLFi2OXAAAAAAAAAAAAwF3yXSTAdPlOFwAAAAAAAAAAAPi/ph27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmqx27AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmaz52AVVVy+WyHn3k/F3nH7znXFxDu8jyP37xhbiGU8ePRfkPb16N8p9/4rEoX1XV7W1H+eXWJq7h+PH7ovyPn38+ruHMqVNR/vrtT6J83x9G+aqqZ77wdJS/Z/v+uIaD+U6U/7d/+XmUP3H8ZJSvqnr2G9+K8ut1H9cwX9+O8lf3svvxvlOno3xVVdu3Ub7p8rGln6+j/LtXLsc1bPaz/JOPPRXlV212HaqqHnzkgSh/eLCKazgyz/qGdZddiL5ZRvlPj3GQ5WfhzVRV6+5ElF80TVzDfJbl1+tsfJu3+Ri9deTeKN9Xfh4Xi+x33Lr9cZSfLbooX1W1tcie6+3FkbiGvrJ5ou/TuSq/F9Lpctbk80TThOexwoVdVc0qOxFtfB7y87jczsboa9f/I67hnXeyseH8+Uej/PWdD6J8VVXXZOPjZr0V1/DXf/WdKH9nN+sZqqq2F9k9+dLLv43yZ+7J9kqqqk6fztYk28u8f7tzZzfKHz2azVV9n/cts1nWfOUVVG26sG8Ix+hmgDXRLDzGYpFv58ZdwwAXsw/n2/g3DNC37O5lY+z2VrigqartZXaM9DQ0TX4/3ryT7f/1q6x/rKp64N6sd+pv3IhrmN3JjnE2nOtuDPAb3rzyTpQ/c++ZuIajh+H6djfbR+3yoaWW4XxbA+ydteFc06eDyyw/kf1hNjZswnmqqmrTZ31LM8vX+X2T1bCcZWuan/8mf3f6zW/8Q5Rf7eT7oF0XzjVtlu8G6OUrnLOHWE90XXaMZoD95DY9RngeNn0+Rm812TyxNT8e1/ClL38pyr/0yi+j/P7v8uf6W899N8r/809+FNfw7e9l49uL//SPcQ3dzq0of/xIuPf1SfaOpqrq4b/7fpR/7/dvxDX88ePsO52to9ne186N/Dwuw231+87l3wO8d+VKlF9uZeNb1+T9XxfuW20qf1+W7t8dHuZzVTpnt+He2RA9Q2qI3il9B9yH65H5AHtn8ZqoHWJNlOVXA+w7Lebh/tnIPWxVvh3cDLHOD6tIx4ZZ+nFKDfB+Y4BvCNOxYTHPmoYhxugmHB/jdWFVdetwfBviO59wbEkr6Dd53zIF6Tu7+KmcwDORjq+DGGLfKTxGeh7adF+/qmqTrUkG2UIc+QBDjNFNm12LTXgdqvL7Me2DF+k/RVVVF/YMmwHmiT7snZrZBL6rSI8wxHcZ6f04QC+/Xofrqnh8HH+AHGK2TZ+qvYP8G8Kt8Pu5zSa7F9J9r6GOkVqvx/1eaoh1WRc+l5vwHFRVLcJN7fT/WMLXnlU10PgUiu+HIfad0nfIYe80H2RcGP9apv1XG8756Z5T1TT29tM+eIh5ZjXAexoAAAAAAAAAAAAAAAAAAAAAgP/vLl26NHYJMCkXL14cuwQAAAAAAAAAAADugm8iAf50fGMLAAAAAAAAAAAAMLx27AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK527AIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK752AVUVc3m8zp56tRd53f6dVzDH37xcpSfdftxDefufzDKX3j8QpTvu/w8ztqtKL/qDuMann/xxSjfNn1cw/tXr0T57cUyyn/lmS9H+aqq5fJclH/v3dfiGv7wWnaMJ574XJQ/e/ZMlK+q2j+4FeVXBwdxDTc/uRrl+8V2lO9OnozyVVVNZWPs7m52DqqqVjubKH//meyZqqra39+J8h/deCvKHz+RPxPHt49F+Vk1cQ2bbpUdoMnux6btsr9fVW3XZjX0J+IamsrmqtkivA5V9eFH70b548eORPnl8r4oX1XV9dlz3WS3QlVVrTdZ/9WF/duxeT5PtBX+hk1+PzZN1gf3lV3Mvs/Hlr5Pb6i8j5632Zpks/4krqHps2e7CdenR7ZmUb6q6rU3X4ryt3fy++nsmbNR/oMPL0f5rst/wwOfuft9iqqqJ574elzDzt6dKL88lvVeVVU/+tlPo/z5hx6J8pusDa+qqntOZedhZyff85nNsme7abI+OM1XVTVtWEM+TVQX/o4+nKtmbd58tem16PMT2fXpeRxgTROehy48Dc0AN+TWdvYbthb5/TSfZcfowhP55vsfRPmqqlvrrBd/7Ew2X1dV/eHyzSj/5In8mXj4gfuj/JWPsmtx5my+LrvwxMNR/v13P4xrWB1m12J1mPXyzSyfb7vKmp8BpvzaHGZr7LzvyH9Eu1hE+f2DvP+bL7L+rx2g70iX6ZvwfqxN/hvSu6EboHdKH6y0bxliz6dpsyL6Ic5jaIga0jMZj04DDNL53ZA7eTRbYz914fEo/9rrb0f5qqpfvPLLKP+t574b1/DDH/4gyn//7/82ruG3P/1JlL/1wXtR/tHHsu9bqqp+/oMfR/kjp/N3n+fOZvvJV29m65HDO/nmWT/P3vnd/5l8dPrS038d5e/sZvfj+fNPRfmqqn994WdRvlvnc91hF35fMsSCIt2b77N7Ot3rqMrn/MUyW498WkT2O/J3yPl5bMP95Pk8P497e3tRvhngZXy6D7qJ33cN8EzEY8MANYT3U2qI945NuKZp5/n9mI6R83C/ZYj3G+nttD/At5jby6x3GmKFHT+V8V7F+PNEDTEuhL9jCvug6W8Y5N1n+B686wZY04Tj9HyW/TvNZoDfsAx7yG6ADyvS85g+EkPs5fbr7D3P1lbm7iKqAAAgAElEQVT2/V9V1V4416Tj4xDvFtLeJ+9hhxghh+iDs3OZfic0xHOdXss+/LakaoBvZCawHonHpyEawAnM+XEPGNbQDDAydOnFGGCuGvsbwPiZrPyWbsNvnary8a1tw++0h/hmf+R8VT5nDzG2zObhfBlei2aIeWKAPelUvD6dwPcAm7D3GeQb6fTbkEn0wQAAAAAAAAAAAAAAAAAAAAAA//tdunRp7BJgUi5evDh2CQAAAAAAAAAAANwF30QC/Gn4vhYAAAAAAAAAAABgmtqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutqxCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABguuZjF1BVtV6t69rHn9x1fn93N65hd38vyn/tL78Y19Cvmijf7G6i/JFTJ6N8VdXb770T5a9dvRbXcBDm9w/uxDU88si5KH/hwaei/JGmj/JVVS+89KMof3MvvRJVzz779ewAXfZMrVb72d+vqvUmG1uqmcU1PPzwk1H+2s2Po/yNW3+M8lVV1WXxY0ePxyWc3F5E+WaTP5dH7z0a5d/78P3s73frKF9VtWjC1qMLb4aqWneHUb4NH8tus5UdoKrmTXYeFvnQUqsu6zvW63y+PXZ8O8pvLU9E+U13I8pXVVWXXYzr1+++h/4vR48fi/Injp2K8osmG1+rqroum7O7Lpyvq6ppl9kB+uxemA+xsgt/w+3bV+MSVqvrUf7e04/ENbR91kPu72bj26u/fjXKV1U9/Pjno/y1T16Pa9gJ16dtk/UdzzzzjShfVXVsmfVeNUDvdGsnm/PffvXluIbPXXgiyvdh/7ZcZM9kVdXObrY+XS6HGGTTY4R7Rk1+HvNj5GuiIX5H9PcHOEbfh+chP41VbXaQPl+W1TpcT6RFzGf5oujE0Ww9srefrU2rqg5W2Xn87Ll7o/zhlY+ifFVV37dR/p5j4XxdVTc+zPa0V0fuj2v497feiPIPnc+u5WyRP9jzdhXlDw4GWJd12ZqmCUf6dC0xRA39EHNl2L/NZ1nf0zfZuFBVtd6Ev2ERrvGrahOuB2YD3E+zNrsW1w+yva/vffVvonxV1eE6G1tqgPupC/uOPsy34TPF/4h78XCMbdv8fkyXA80ANbSrbHx79N6sd3rtj1eifNV/snNnz5ZX1R3A19nn3Htu3x4BEboFJZSiGHFAk9IQB6IhVValkuf+A/s5efAhcSCGFOBUUgoBG1QcGhwKtOnh3numXx6Mb3nq7079fqWfz/s6vX7T3muvvW9XnYQ38oUf5v2Wzz75pSj+K1/7SpzDU3/1iSj+peez+u3q69ei+KqqdWXv9NFb1+Mczu2yF+rsmWwf+9bqVhRfVbUN9+zOn3kszmEe1qD3XvxQFL89ye/jQw9cjOJ/9OrP4hzSPb+49qq8f5fGp/3oqrwHOKQHXCq/D/Nwzu9QMtRqnb1Pce1Wef21Ceueqqp2kJ0P2YbzzBRsN2EvuKp24Tp/b5GdSWgtX6O3sNcwdOgnbzfZO93CNXaP7zrtnS2X+ZmttO/UY22Y/kY6X/Z4lrs0hw5nMdN1/v5+9l3vOozxadWRPoeqqqHy+TKV9jvWYR28DN+Fqqp1WDtNYR971qEXGwu/69tH+V5Vm4f3IRwaeowt6RuVrkf+kEH6VudfRXont9usDu4x36a/kO5vVOW19HYCdUuqx/i4i88a9ajFM/NwjN5s85ojPSs0gSE2Xguk67qq/FnMO5zZWoXr22W4/9rlCGP8WXeYJyYwtgzh378O4Y3sUbfE+7c9qvm0rx7O+fMOZxriXkecQY81cv4s9/acDwEAAAAAAAAAAAAAAAAAAAAAxnXlypWxU4BJuXz58tgpAAAAAAAAAAAAMAJnKgH+/zijCwAAAAAAAAAAAPCnqY2dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1cZOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDpamMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tbETAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC62tgJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBdbewEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJiuNnYCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAExXGzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKarjZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVxk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOlqYycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1sRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLra2AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMF1t7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK42dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATNdi7ASqqnbbbd24/rs7jl+eOohz+OhHPhHFn9xucQ5tMYviz999Jop/7jvPR/FVVYtF9krdXt35e/BHw3YTxX/sscfjHM5fuC+KXx3fiOKf//ZzUXxV1anD7Fk+8elPxjkcH98OfyH7pqp2YXzVfJhH8W3vdJzDapPlsL/Mcvj5T38exVdVfeDhD0Xxe/PDOIfZsI3ih1rHOdRmiMLPHmbPcn28iuKrqg5OZ2PLUNk9qKoa0qFhll1DixOoqln2G9sO93E3ZPNtPkZX7S0uRfGb3a0ofhjy+m8YsrHh7rsvxDmcnJxk8aubUXw4TVVV1WKWjfPzvbvjHDbb7H1q87NR/GI/n+t+/osXo/gzh/txDpfu+3AUv1ql9WPVyeq3UfyLr7wWxX/88c9E8VVVr7z8QhS/2eZ1y7DLxsgnPv25KH692oviq6rmy+yd/s73fxDncHiQ9Tvuu/ddcQ57LRuosyq6OlQtVfmMndcteR2bxc86XEP+MPIcWutwHYke/3x4H3dD/lXMwvVEm+c5hO27mrVsXXbmTF47rdfZfHnhXN7zee7Hv4riH7g/myd287yYPxyy9cjpw/xZXrw7Ww+89PqP4xzue/D+KP6dYH+lquqww328dStcY6dFQ1XVrEflcOd2Q95P3u6yMXrokEML93naPIvf7DrMdfEv5Dm0WVaFrjdp761qL3wWB/N0XdXhSeyywWHW8tVAuqhp4Zqqx6IoHRt2u3xsSWvQLs8ylF5DD+l6oMsVhO/kEI6PH3006x9WVf3ge9+N4ldhz6iq6uWrL0fxTz75D3EO33z636L4L33xC1H8s994OoqvqhpW2XzZoeyoxZmsf7dbZPPEYlhG8VVVD//Fo1H8+fP5XtVqnT3LZ579ehQ/7zDPfPZzX4ri33o7Py916yjbI1l0uA/z8J0ewg9zSGuvqqpwvu2xNsyLwPAaOgyQLe1B9jhWEf5I28uP1p4cH0fx83CNPgtrrx6Gef4wFy1bn2422cJuuczn28Vedg0nR1kftWr896HHXlW6Nuyxx5Ke2Ro65JBeRz7Oj78+nnfYn5jPw/dpG54n7dBnaOE30Rb5uLBN70OPvc8wPl4PdPgk9vfDeeK4wzwRxqdnInrMU2kfcy+svary+i3dG1iH6+uqfHxchHsTVVXb8FmmY1NVhzF25Piqqm14MKNH6ZT+RHpOaBWuBaqq5mGvIf2mqvJ3etuhV3FqP1sXbcM9vxaeE6rqsCZp+X1Mv6u0dtp2+Bu5eE2UZxCPkfF+W4e6pbUsh3mH9USP+TLOIRwbUmkPsyrfQ0574lX5daRnMSfQJpjEmYaDZf5/HByfZP1kAAAAAAAAAAAAAAAAAAAAAODP25UrV8ZOASbl8uXLY6cAAAAAAAAAAADAHXIuEmC6nNMFAAAAAAAAAAAA4P/Sxk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOlqYycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1sRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLra2AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMF1t7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK42dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFcbOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAApquNnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA09XGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6WpjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLWxEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutrYCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXW3sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrjZ2AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVxs7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmq42dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADTtRg7gaqqmu1qvnd0x+GX7n0wz2HYRuHL5V6cwnbRovhnnn8uih/Ce1BVdWP1ThR/9tSpOIfHPvHJKL7N8mf561++FsVfffXFKP6B9z0UxVdV3XfPhSh+WN/5N/1HrTZR/GqzjuL35ssovqpqNsyz+PAeVFW9ff2NKP769bej+EsXL0XxVVXLcHyszXGcQ9Usih6G8BqqarfO3ofDxUEUv5ntoviqqmGXfZezWX4fW8t+YxjS8im/hqohit6F8VVVraXj29k4h90sqztm4buw3ub38eQ4G59OLw7jHJaL7Fludln8/kFe/22Os7Hl5u1fxTkcHLwnip+1bIy9+trzUXxV1YXz90bx99z1UJzDfFhF8Tdv/C7O4ZUfZbX8g+97OPv3X30hiq+qOlrdjuIvveeuOIcPvf+JKH5zK7uG/bP7UXxV1Tefzb6rhx54IM5hFs6381lWw1ZVrVbZd5nOt22e106zDvchl64nsrpjmOV1S2oW3oOqDs8yDe/wLu124boqfBeq8jXRPBybqqqGbdaHXIQ17Ou//HUUX1X1xlG2Rv/k+7Laq6pqfu5cFP/W21nt9PBdp6P4qqrz5+6P4n9y7ZdxDjfXt6L4U7OTOIff/+paFJ/WDDdu5L3c2oVzXYd+STpfpna7/N/ftXDO79DzSftvm/A5bLZ5DzLtW6V7hlVV83k6X+Z1R/pNzCq7hme+m/cqHnn/I1H8hVN5D7LCfZ50XbZJ68eq2qXvQoclVVpL96jFR18bjjxP/SGFHvNEtkeyC+f8e07l65FPfezjUfz3Xn4pzuF3Rzej+Fd/cjXO4fNP/WMU/x/PfDWK/8KXvxzFV1W98Mx/RfG3N/le/I2TbD1x+uB8FH/vhYtRfFXVucNsXdahfKtt2Ls6OMj2wS+cvyeKr6r66r//SxT/90/9c5zDc996Ooo/WeXr21k412zD2qfLbBv3EDukENdO2b+/m8C6rE/lltbBeRZpL3Yb9lGrwzmftKfdowZdzLMadH8vew4nx/n4uAnPfPXYY0nfx1lYy/foW7Wwb7Xd5T2f+JXuMMClOcQ9ow7jY3oNPXqx63X2be8vszMJffrZ2W8ch+fWqqqWy+ycdTzXVVWL95Cz+F2Ha0jvQ3wPqmoens1Ia4Y+Y0t4rrbDd7kLew3pnL+3l/8dTHofN5v8m0jfhx5nGtI5O55v432mivdve6yy0/uwt5fNt9sO69spfBPzlj3LRXgfq6o24VyVvo353mvVyTo7B5muR3pIv8qhw75jurbsYR7/PdD4e3brdfa3D/OwDq/Kz4YMQ4e+UzhOx723Dt9E+j7uOtzHuFWR9hkqv4ZZ2P/r0SdI59vbR9nfPlRVLRbT+O8eAAAAAAAAAAAAAAAAAAAAAIBxXLlyZewUYFIuX748dgoAAAAAAAAAAAB/lpxpBJguZ2wBAAAAAAAAAAAAmKo2dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFcbOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAApquNnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA09XGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA6WpjJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdLWxEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgutrYCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwXW3sBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACYrjZ2AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVxs7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACmq42dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADT1cZOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDpamMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMB0tbETAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC62tgJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBdi7ETqKpq83mdPnvhjuOHWX4Zh2daFP/mm7+Pc3jj2uvZDwybKPxk9U7271fVu991dxT/yCN/E+cwG3ZR/E9f+1acwy9+8XYU//inPhrFt738m5gPQxR/++goziG1v9iL4ufzbFyoqprvZ8/ijd/8Ns7h+ju3ovj3vvfBKL7Hfbxx+2YUv79/EOewXOxnP7DOxuiqqmHI3qfdbhnF7y1uRPFVVUMdZvG7HqXLPAufZc9y3vLxcahZGB/eg6oawvm2VTbPVFVttidR/HaXxe/vn4niq6qGbRa/2uRjyzycL5fLbHy8+c7tKL6q6vou+64unXlvnMPR8fUo/rdv/zSK/+Ajj0XxVVW79fko/tqbL8Y5XLv2myj+3e++GOewPJ3VDW/++mdRfIdSvj786Eei+PvveyjOYbPO4m9ts3nixW9/L0ugqh79wPuj+O02HOSrqrVwzs6n29rtsjk/XQ/M53ndUmHtxP9K36d8aVizNu6zHMJeyVQM4Xe92eXj2zDLnmUL34WjVThRVdU9F98TxbeW1/KnsmV+rdarKP6uC1n9WFX1g5d+FMXvH+bf5UE4tFzPPqmqymeq9VG2vq1ZPkgv5tnaMu0zVFVVOD6FQ1P1KL7iuWbI58phlj2L3Sy9Dx3u4y78jQmUoPE1VNUsfKnXYU/7/OlzUXxV1ZmDU1H8cpmNTVVVR8dp7ROOb/E3VdVm2Us9dPgud+k432GeaOF812F0in9hEhnEewOZ5SJvni3OZePTX37wkTiH166+EsW/cRynUO3qf0fxf/u5p6L4/3z2a1F8VdUTf/14FP/qj38S5/DW79NaPPsy77/0aPbvV9Vskc11zz73dJzD/kHWl//Mpz8fxb/w/fwaFotsH/wbX//XOIe/++I/RfE/fDE/L/XOzfRsR1i/dVjfbsNafLvNez67cH17apl9U+su9V/2Gz1q0Nay9yGto6s67LGE17Du8D7u7WdNyE2H81LpEjntiadriaq8/9cjh/S7SsemWfg+V1XdPs4K4YODsKle+fu069Dz2YWHjRaLbHxbdfiu9/eyOX+dHkioqhbuY8/C73LRYd/zZJXt8+zvh2diq2oTnl1La4aqqnWYwzw8l7HocKYh7eUuOvRLuuzTJP9+h/pvln7XHc6WpPNEpfNlhwZg+j6me/lVHfrJHeT3IazlV2HPqUMOPaTj/HFY/y328rku3b/tctQo3XfskET6G2ntlZ5vqcrX2D3OIKZjS4cE4p/YhnNdPFdWxdfRwvj0HlTl7+O8w3y7Dc9p93ifFuHaMBJw2/0AACAASURBVE2hx/iYznU9xoX0OuLaq8OZhrSP2mN0TXPoMTbMOvztAQAAAAAAAAAAAAAAAAAAAABwZ65cuTJ2CjAply9fHjsFAAAAAAAAAAAA7oAzkQDT5YwuAAAAAAAAAAAAAH/K2tgJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADBdbewEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJiuNnYCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAExXGzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKarjZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANPVxk4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOlqYycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHS1sRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLra2AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMF1t7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAmK42dgIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFcbOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAApquNnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA09XGTgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOB/2Lezb0vK8g7Ab9XeZ+qJnkCaeVJQiIomCrpMNJplzHDhbf+BfRlvXFGjiaBoEk3AgXkINjIIzdDQ3afPOXuoXOBtVtbi961VJTzP/a/2u2tXffMGAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLr6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLrmYxdQVbUx26prj972gfPbR7bjGn775C+i/GqxGdewt7iUXWAYovh999yXfX5VnT5xW5RfLS/GNTz22K+yC3T7cQ0PfvHeKL+/OIjyy4P8O6yGLrtAF+bfLyKK9+uwhj77/KqqF158Pspf97EzcQ07hw5H+T78LbtVFK+qqq3trI19d3c3ruHEkVmU74ZlXEMf3szZPPsthzoS5auq+r6PrzG2YciehdWqwT3o8vYpNqyzeIMSZn04Bhw2ovhqsZV9flUdO3w0yu8u8j5/ucrapz+8+XqUP3nyeJSvqrpp8+NR/t3Lz8Y1XL20iPJ33fFgVsA6+/yqqsXitSj/8stvxzXcfc+fRfkXzue/5cHyapTfmmdt04MPfC3KV1XtX92Lr5F6/NmnovzOVtbGfuL2W6N8VdVikbWPq1XWV1ZVbW1l44bVOq+hn2U19H02dupnWb4qXi6pIb1AVaUz5GGd1dDgK8TT/K7BOkE6P13H97HBjWxxjdAsfK/6Bks+L732ZpS/8dQ1WQENfofZKutvD/byBZN7drLl/XU4P/3FU09G+aqq44ez5/FgnfcTtcz6/NlGvj9xcDWb221v7kT5dYN3Ir5GPmypIRz79PNw3BP3+FVDOIbsunzdKe3vhnTdqklfGe4tdPn26XKVtfPpOPp94TMZjp1OXnMi+/yqevF356P8Ow32y2694/YofzJt4Bo8j/0sWwcdwrXg9y8S7jXlFTS5RmL8mUCbeVkXttNd+DytDvJ10Hk4qTlzzam4hqP33R/lf/7kb+Ia3gz3T58J1/8+/ekHonxV1c9+9cso/5l7s/Xoqqqto9n89viJW6L8usvOllRVvXcley9Pnbo+ruHY0WNR/qGHvxflv/pX34ryVVUPP/TdKL8xz/YMq6p+8P3vRPlv/u234xoeffQnUX53L3um+3k27qmqWq/DNZsGc5p0/e3q7pXs81usy6ejrwZj0FVaQlxB1Tr8Hl14HzcavBPLcO2syR5LOI5N98v6Fust4W/ZN1iYj9fvwnyLNcjtI9nZteV+vk7Qx+tOcQmVznCXy6yv25jn/UR6VqnF2lnatqT7juvwHlTl7dO6wZmG9NXe3Mj7qvRsxth7+VX5evK6wdmQ9J1I9/JbjBnSfZquQSO9CP/7MI/bpnwPuu+yNjY9j1BVNYT3sc05n3EnFLN5vjewCsfyLcagcZ89gbNK6TXaHBNK34kWfX74v4GwhBZtSzp+a/NOhOO3sM9Pz1S8f5Gwr2vRvoVjp1SLad08nFel55urGvzts8lRynDNJuxnWvyW6Vh+1uA/dmnbko6DW8wt03HsFP6rGI8fq81/DwAAAAAAAAAAAAAAAAAAAADgo+rcuXNjlwCTcvbs2bFLAAAAAAAAAAAA+MhxnhHgw80ZXQAAAAAAAAAAAAD4v/VjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdPVjFwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAdM3HLqCqqrqq2dYHj//0kR/HJVx76roof/HSy3EN89lGlP/CFz4X5bv1kShfVfXOWy9G+SeffiKu4aYbro3yN9x4e1zD5cuXo/x6mEX5/cUQ5auqZlkJtb0VXqCqVuvseyzWqyi/d+lSlK+quunGW6P8xtZmXMPb716M8nt72ecf3snbls35qSi/s/FKXMPlK1ei/JHtnbiGvtL3Kn8vU+v1fpTv+ryGvuui/DBk+Ta/Q1pDgxsZ15AbKusnZvPsO+wvsn6mqmrWb0f5rsveqaqqN1/P2sjTp2+J8tuzrI2vqlot343yRw9/LK7h2KFrovxqtRvl37jwfJSvqnrpfHYfrz9zfVzD737/THaBcPxYVXXmuuNR/t67H4zy+8tw8FVV852sbXno4UfiGu66644ov7GRjYP7Pu/runDMMJ/nfX4XDn76Wd5fD0P2XqX3cWjwXqc1pPkW+o3xx/Lh0KtNCeHzmA5h+wZj4PSR7hs8juthHeXns3xJeffqIsrv72fj4J1sGbaqqt565aUof9cn74prePtiNn47/9qrUX5rJ1jU/6PLV7N11GX2OFdVVR+uIS7XeRHzcJ6+Wi6j/NBgmSDtJvp5g44mbGT3l9m8bGs7fyeG8HmsIWtfq6rW4X1chV+h6/Jxz+Zm9lsslvl9nIXzgdWqQQ3hfGJzI7uPfYOBy+mTJ6L8zu7VuIbfnz8f5U/enfX5O+u8kd5bjT+YT9flW0zLurC3SucjLea36SXSdYaqBvOy0LLBx6/Ci8w28/3bnUNHo/z99306ruHx3/w2yr+y90aU7zfyueXnP/OlKP/kC9k9qKr63D0PRPm9ZXYmYTbPJ7jzPhvAbd58d1zD6288lV2gz8Ze//rj72efX1Vf/9o/RPmHHvrnuIbw2Fn98EffiWv4m298O8o/8vMfRvn9/WxeV1W1sRWe7QjX3qqqhvAa+R5J3uGmQ4YWI45ZOCdpMe6Jx4BhDf0872+78CvM5vkYdBa286suXP9b5mdD0knNrMHeZyysIZ0XVlX1lbWPabtQVTWE68FDg72m+HkIX+wW7WMX34fx+6p52DZV3+A+hs/C1f38fMqhnUPZBZrsxadnGrJPXzd4J9LxW5O1s/RsR15CbD7L7uMy3G+rqrhxWS6yvYEWv8PIy39Vlfd1iwa/ZZ+e2Qq/w7rBHvQU3ut0fpue2R/C8WNVm3Y+lq4TtNlkiaRn/pucB033eVqsE6QXSH/LCTzPq/RAQTX4LT4E9yGdC7SoYd5g3WkWnpdahGOneYO9qrS/bdHPpK386iAbO7XoZtKxV4v1u43weWjRV429Fw8AAAAAAAAAAAAAAAAAAAAAYzl37tzYJcCknD17duwSAAAAAAAAAAAA/iQ5kwjw4eWMLQAAAAAAAAAAAABMWz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMVz92AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABM13zsAqqqdnev1KOPPvqB89vb23ENb7z5UpS//sw1cQ133valKD8fss//9W8eyi5QVRfeeCPK33//J+MaDh/aiPKL/StxDVcuXYzyx0+cjPKbG32Ur6parbIHatbP4hr2V/tR/ure1Sh/zbG8bemG8D6E73VV1bBeRfm9RXYfD23nXc168Ycof3jzWFzDq5cuZDUcOhzXULUZpbt11j5Wl72TVVXLZXaNvrbiGob4GuuR81U1dFG86/J+YqishgbNWw1D1r6tK8vvHM77uncvvRnlh2X2Haqq7rzlvigfdjNV67xtWayyPntW+W+5tbUb5X/12H9F+Y0Gfd2p06ej/BtvvRzXMOuztuWOO7Lnuarq+ms/FuVXwyLKv/te/k48/9wTUf7ee/N52cFBdh+GddZTLMM+ooXZLG9bwu62Zg36/PUQ9tphPP78qkrvQh+2TVVVffg89F1Ww3qdj0FXDa6RajGGjD6/SQHZRYYGRTz+8rtR/rO3ZOtWVVV7i6yf2N/P8tedOh7lq6puu+WmKP/rJ7L+uqpqth22cOGC8mIvGwNXVXWzcN2oa9A2hc18v8prmM+zfuLg4CDKd2E/U1XVhf1lnw9barnK7sP2drZ2tneQvxPrcF1+WOe/ZfpepY/Tcpm/UwerbD6wtZmtw1ZVrYfse6yXWV9XVbUZfo9Vupbb4r0O55ZHdnbiGg5fzd7t98I2+lAfrutXVTeBIwGz+IHIx8FdOhYP50Rt5hOZFvOJuIawo1iGa0ZV+bpTt7+Ma6hwzebkPG/fbr/zzij/5LNPR/k/vJPtj1RVHTl0NMrvHuRjp9lG1s73q0NRfrXIn8dhlY7l83HwjTfdHeWPn74+yj/39DNRvqrqRw9/L8p/46t/F9fw8E9/EOUX4fivquq73/unKP/33/rHKP+fv/xZlK+qunQ5e6bn87xt2djIxm/pHD09C/D+RdJ10LyEeF19CmOn9D42WNdfhn1N32BymP8U2bMwm+dzqlW4VtFih6YL70O8hhiulVRVrfb3ovw6PctZeRubvlNVVUP4XqXfIX2W/niRsS8QXyNt35Zhu1BVtQ73J7Y38zPSi/CZbrE/kfb5cfsYpf94jfRsx/ivRFxCi/MI63DNp8W5inR/YRHuo8ebNO9fJEq3GEYvwkOpLcag6Xrycpn2+Q3OS4X3ocWcKF+TzvLzBuf3FmGfnfZTVXl/26JtSC+RPk+zBp1dOu5I+5mqfNwxjH56Lr+PLfaq0n3H9GxvizHD/l42v91usA+evlUt2rdlOPaZheet0jlVC03eifCZbrGGmEprSM/HVDUYv03g/B0AAAAAAAAAAAAAAAAAAAAAfBDnzp0buwSYlLNnz45dAgAAAAAAAAAAwEeSM40AH27O6QIAAAAAAAAAAADAh1s/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATFc/dgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATNd87AKqqrqq6mv1gfMHVy/GNXzq7r+I8ieOXx/XMO8vRfmf/uTfo/ywWkf5qqovPXBvlD/Y34tr2N1dRPm33n4nruH48RNRvuviEmLzjY0of/Fi/l4Old2IWT+L8vv7B1G+qmpne5nVcJA9z1VVR44civLL5VaUf/W1V6N8VdUNN9yUXaDBO3Xz0ey9Pn/hjbiGM9dl92E2y56ng4Psea6q2tw4EuXXQ1xC1fDBxxxVVV2X5fs+y1dVrYesfRuGBi9FeIkWXV3fZ1fpw37irQuvR/mqqvlGNhzf2T4T17A8yMZfXWVjhs159ju8bz+LD3mf/+hjz0f5a6+9Ocq/+fYrUb6q6so7f4jyO1un4ho++9k/j/L7+dCpKnwmn3rmfJTvVnl/e/fHb4/yBwd5XzX2lGZoMGbo0olZk+527DvZ4D6kJvBbtrgHQ/hQrsN8+vktpGO3qvyd2NrajPJXdq9G+aqq1Tpbf9veyuboVVWLVbre0sc1XHsiW6uY9dkz3XX5GPTx534d5T/xqTvjGt55680o/9bF96L81XAuUVXVhfOy2Tybj1RVHRxk84nNPq+hn2Xv1Wwju4/zWd5GLxZZG3npvbyNPXbsmii/XGRj8dMnT0f5qqq77vx4lF8v8j5/qOx57LrsnZjNdqN8VdWLLz4R5S9cuBzXsBqyNZ/Dhw7HNezvX4nyfZ99h3Ttrapqtcom+qsGc+xbz9wQ5Z95JlszuuH+z0f5qqqtq1kbm9/FqtWQjiHz9i2ekqRzy/Dj3y8h/hJxDen8chjyMwmpeH7a5c/jOrwP63W+fnfztddF+T6cG/7u+eeifFXVsy+/EOW//sW/jGu4FJ4p2BrSRe0Gaz7hb7kOxz1VVUO4VnH00PEo/5UHvhrlq6oe+Y+Ho/zP//uRuIYHv/LNKH/hlWx/o6rqYJXtn/7bQ/8S5b/85b+O8lVVVy7/PsoPDcbBTz39P1kNYZ+f9zI1ibHTapWe7ch/yy4cd8xmWRvbYuTVhf1Eiz2WLuzvhrS/bLDHsrWZ7U8cLPIzDfGbFc7rwu2RqqrqKlxPnoVnS6pqtd6O8n34Xlfl86p0v63N/vH4++Dp/uvBIhvLx21TVXVd9l62mKMP4cvdoq+ah23s/kHWxm422KtK95DXDRrZdNwSf36DayzD9eD0vxNV+W+Zjr3S9ZqqfKWhyVmncFLS4p0Ywv3bdP2vbzGODq8xa9EuhDWswv+4tTgvFa+JxxXkv2WTGuKLhGfnWrzXEzg/l75VfTj+WzYZfY0vXfNJ++vDOztRvqpquczGLaswX5XPiZqs+YRjl7yN/tNvF6oa7BvGRUxhjt+gnwifh7SNrqop3EoAAAAAAAAAAAAAAAAAAAAA/gSdO3du7BJgUs6ePTt2CQAAAAAAAAAAAB9JzjQCfHg5owsAAAAAAAAAAAAA/H/6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8KJC/AAAIABJREFUAAAAAAAAAAAAYLr6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLr6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLr6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLr6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLr6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLr6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLr6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLr6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLr6sQsAAAAAAAAAAAAAAAAAAAAAAAAAAOB/2bmTWMvuOj/g33Pufe+5ylWey3jATB4Au4GGGAJN0uqsWkoWUe86JWWbLBIpkbJKVtn0LsMyUqJkl1IUKVlkESnK0CHdkCYGi8lN04DBjYemMbbL5ap6793hZEFFsiICxt9D7i34fCQkVL6/837nf89//t8DAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/xl0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+GnedAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7a9x1AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3HXCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv8ZdJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/lruOoEkmaZt1turbzv+00/+Wp3DON5Vxb/wwh/WOXzj289W8e986I4q/oELt1XxSXJ6/biKPz45qXPYZqri77zzzjqHo6Nbqvipu4WyBH7ktVdeqeLHsW9ehnHsclh08dev98/jOHZ14uDooM5htV5X8eOwqOKXy8MqPkneuHylir/rjj6Hq2P3Xdx3V9fPJMnXn/laFf/Ag/dW8bedu7uKT5JMR1X4kFWfwrDp4qeubdlOfb2esq3ih3Rl8KOLDFX42IUnSbZTdx/bTVeOt527vYpPkoPD81X8dt31M0kypmsjh6Hr8w+XXZ1KkuNrb38ukSRfKdvXJLn73geq+FffeKmKPz6+VsUnyV13nKviP/IrH69zWF0/reJvO9/dQ5L87u//zyr+8cceqeJPT7uxW5Jcu9aNYxflODypu4lsy0nROMM9zDGv6nUFOc1wF8POc5jhHsoHsi2DJJnKZ7qtE/tgjnIcy0Hk9WvXq/gXX36tik/6sc+9y26OniSn625eNcf63YN3dOuQp5tuLvCN575ZxSfJo4+8u4q/5aDvqw4WXTncctDVqc0M61YnJ93YZ7Pqxo9Jshy7erUq61SSDOXj0Pa3V6++3iWQ5H3veUcVf++FD9U53HbuQhU/pHwWNjOsW627tYpxhn5ive3uY7vp6vVi7PeqPvLYb1Tx2w/2a2fPvfTtKv6PvvGtOoezZ7o1n3X5XX79239cxSfJBx9+rIrflmOGJLlWrjs9Xt7DZ7/85So+SZ78yK9U8dNmhvnI6Qxr0qWpnZO0HfYM89t2vWOo7yHZbru+qq2XY7volHa1Jdls++d5tequcXDQ9/kH5V74fXd35yqunj5YxSfJK8//sIp/+tvP1Dl84MGHq/jjcs9vUc5nkmSRcu+zX9LOZtW1kZvTshzLMXCS3H5Xd2brtVe7MxFJ8sUvfK6K/9RH+/N3V653bcO46M4TfP/7f1LFJ8md599bxR+d757HJJmG7gzhVLYNmxnGf2O7zzPDmnjbZy+WM5ztWJdnGsauHFbl30+SxaI7D9Du0dy4ShXdnk8ZZ+hvN+X5veWiz2G7bQ+llntd5TpDkizLPZbNputnkmQYyu9y2Z+rXa3ac2OdYYZDX/2+4Qz7juU16vZthuZxU559m6ONXpTt08lpv88zTbutE+1ZgCRZlG3DwRyHMUttOczRtqxOuudptZqjr+rGkO3zvJ5hTbw+YzPDGmT7PCxnyGEsrzG1aw0zjP/atdT2d1lJPwbdlOvRbT+VpB4Hz3Hiq62XU1mOSX8fbTM/zbAu3/b69Zwq/fmSdj4xx4jh5j/F2Hvjard/nPTz/PZ3gskMbcsM4+C2r1q37dsM99CPnfqa2bZP7bncebRtdN/X7YNphr4GAAAAAAAAAAAAAAAAAAAAgJvPpUuXdp0C7JWLFy/uOgUAAAAAAAAAAICbjvOIAPwkzugCAAAAAAAAAAAAAD9v464TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/jbtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID9Ne46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD217jrBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX+OuEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgf427TgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA/TXuOgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA9te46wQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA2F/jrhMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYH+Nu04AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgP017joBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPbXuOsEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhf464TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/jbtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID9Ne46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD213LXCSTJ2bO35WMf/c23Hb/Jts7hS1/9r1X8a6+9UefwxOPvr+LP3XpQxW9X16r4JDk5Oa3ipwx1DnfffXcVv9ps6hymTFX8UFfNvmrffsedVfxi7L/L4/J5Wm26tuHoqKtTSbKduufp+Hhd53DruVur+NOTLocHH3igik+Sy5dfr+KPt92zlCS3HJ6p4odt/zy9611d+/bSDy5X8e+4511VfJKsTlblFfq2ZTuNVXzbvA1lH5Ekw9DVy2nblUGSTFNXEFP6HBbjLVX8ctH1l1evnVTxSbJZvVzFLxbn6xyGoesnXn75j6v4F194tYpPkvO331bFH93alUGSvHr5hSp+HBdV/GOPPlHFJ8m9F95bxc8wbMm11fUq/unPf7nO4YOPPlzFn5x0bcOtZ89W8UmyLsfBm3U/JxrKZ3ocy/56jjFD2WePQ59Db/c5DHtQDnUOc9xCOQTcbsvncYY5evtMnz/Xt2/fef5Pq/g7z3d9/mbbr0GennYd5mLRj6Pff6EbRx8e9PPb77z4YhV/fPVqFb9Y9nXiuee68d+HPvx4ncNi2dWry5d/2GZQxieHB4dV/MmqX/PJ1LWxc9TL03Ic3D7Rd9/TzamS5P773lfFLxbds5Ak164ddzksu2d6KvvrOa4xTH1ftS2v0e7zbNf95HJbrluty/gkue/CY138vXfUOTz11FNV/HbdjRmGg65OJsmzz32zir/7jnvqHM6e7caQJyddG//hh7v2NUmefvrpKv4TH/t4ncPpQVevhrK/TpKU6x1tj9+30KnHLUM/bMl225XjaTl+Wy77ffBFue40xzrBshxDbmdYb1kNXVkuN9347QP3P1LFJ8nXDrpxw+lLfV/1TL5VxX/4/ker+JNVP3aahn5u12rnVe0Znc223/N79zu7fZrbb3u2zuG5Z5+r4j/z2f9U5/DxP//pKv7o8P4qfoZl0ByfdudTFqdHdQ6/9om/WMX/3h98toqv+8qk7i+3M3S4Q7suP8MZwnZ/YmrHfzOMGdqR+Cy7RO18oIyfyvN/Sb9P0z4LN65SRe/DXlX7RM2SQpnDZoa2pdWu/21X/Qx3XHRj0GGGCW47hmwn+odH/Zr4atWdxWzPZSTJtt1jmSOHcg93L840tBeYoZto60S7RbKYYV2+LYbDw75etklMZWfV/wYlaatEO2ZIkrFs5+c4s9W2sctld66i7qfSn3GZI4fTcu2qrZfrGcZebV83wwy7Pu+esR+/Te0ecvs8zjAnascMR0f9ms/xcbdH0jdvM6y3lEnMMQat10vKvz/Hnl97D4tyTjXHNU5P+zNbB+U5xLrPn2HM0LYt0xxP1BybwIU5Vq36r7Ivg/ZMwnrd/l4yWc5wNhcAAAAAAAAAAAAAAAAAAACAn82lS5d2nQLslYsXL+46BQAAAAAAgJ2ZY//QfgsAAPB2OdMIwP+LNScAAAAAAAAAAAAA4GYw7joBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPbXuOsEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANhf464TAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGB/jbtOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAID9Nf60DwzD8NAwDL87DMPXh2F4ZhiGv3Pj3//hMAwvDMPwpRv/+8tvivn7wzB8axiGbwzD8Js/zxsAAAAAAAAAAAAAAAAAAAAAAAAAYL94jx0AAAAAAAAAAAAAAAAAAAAAAAAAb5V32AEAAAAAAAAAAAAAAAAAAADcHJZv4TPrJH9vmqanh2E4n+SLwzD85xv/7Z9O0/SP3vzhYRgeT/LbSZ5I8kCS/zIMw2PTNG3mTBwAAAAAAAAAAAAAAAAAAAAAAACAveU9dgAAAAAAAAAAAAAAAAAAAAAAAAC8Vd5hBwAAAAAAAAAAAAAAAAAAAHATGH/aB6Zpemmapqdv/P8rSb6e5MGfEPJXk/ybaZpOpmn6TpJvJfnEHMkCAAAAAAAAAAAAAAAAAAAAAAAAsP+8xw4AAAAAAAAAAAAAAAAAAAAAAACAt8o77AAAAAAAAAAAAAAAAAAAAABuDuPP8uFhGN6T5KNJPn/jn/72MAxfGYbhXw3DcOeNf3swyffeFPZ8fvKLJwAAAAAAAAAAAAAAAAAAAAAAAAD4BeU9dgAAAAAAAAAAAAAAAAAAAAAAAAC8Vd5hBwAAAAAAAAAAAAAAAAAAALC/xrf6wWEYziX5d0n+7jRNryf5Z0keTvKrSV5K8o//z0d/TPj0Y673N4Zh+MIwDF94+eUf/MyJAwAAAAAAAAAAAAAAAAAAAAAAALDffp7vsfvBD7zHDgAAAAAAAAAAAAAAAAAAAAAAAOAXydzvsLtxTe+xAwAAAAAAAAAAAAAAAAAAAJjJ+FY+NAzDQX70Eol/PU3Tv0+SaZq+P03TZpqmbZJ/keQTNz7+fJKH3hT+ziQv/t/XnKbpn0/T9OQ0TU/ec8+F5h4AAAAAAAAAAAAAAAAAAAAAAAAA2DM/7/fYXbjgPXYAAAAAAAAAAAAAAAAAAAAAAAAAvyh+Hu+wu3EN77EDAAAAAAAAAAAAAAAAAAAAmMn40z4wDMOQ5F8m+fo0Tf/kTf9+/5s+9ltJvnbj//+HJL89DMPRMAzvTfJokv81X8oAAAAAAAAAAAAAAAAAAAAAAAAA7DPvsQMAAAAAAAAAAAAAAAAAAAAAAADgrfIOOwAAAAAAAAAAAAAAAAAAAICbw/ItfObTSf56kq8Ow/ClG//2D5L8tWEYfjXJlOS7Sf5mkkzT9MwwDP82yR8mWSf5W9M0beZOHAAAAAAAAAAAAAAAAAAAAAAAAIC95T12AAAAAAAAAAAAAAAAAAAAAAAAALxV3mEHAAAAAAAAAAAAAAAAAAAAcBNY/rQPTNP0+0mGH/Of/uNPiPmdJL9T5AUAAAAAAAAAAAAAAAAAAAAAAADATcp77AAAAAAAAAAAAAAAAAAAAAAAAAB4q7zDDgAAAAAAAAAAAAAAAAAAAODmMO46AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD217jrBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYX+OuEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgfy13nUCSDMMmB+Nrbzv+c5//fJ3DmVu6ovjUX/j1OofTq2+/DJLk9Pr1Kv7k+kkVnySHh0dd/FEXnySbzVTFb7ebOofFcqzip2mo4occVvFJcnDYlePq9FqdwzR138WQrhwXy0UVnyQnp129Wiz6ZvrK61eq+FvP3FrFb07XVXySnLvtfBX/yutd+5okd58/U8VPq/55On/+oSr++ub5Kv7K65er+CS55eiWKn4Y+nJM3cZ27WOyLeOTIV292k4HdQ5lE5spXV+ZJNtNV5ar9XEVvxxn+C6H+6r4w4O+HK9df7GKf+57f1rFf+D9j1fxSfLsc89W8afrVZ3D4bIbx37yyY9W8Zvt2So+SY7KIeTX/qj7HpIk2659e+D+e+oU1qtuDDqWfdXpDGOntpHe1n1dMrZj8bGcU7UdVZLFDOXQmsoU+lLgR/qSnKZu3LAt48f04+ixrJerdb/e8sKV0+4C264cNzPcw1hO88ehH//dfq6b3z7zne/WOZxZlut3B22d6Ot1OR3JF5/6Sp1Dqx0Gl81CkmS76ZJYluuwSbJedeOvYYYOt57bLbskPvjBR7q/n2Q67uZE601fkOPYXWO96ir2VPYzc5hj/NeOgsexG3dM7SA4yXbq6nX5KP3Iumxb0s9vf/2Tf6WKf/aFrq969rvdmlOSXF13+xvrV/s1n7tWd1XxRxe69b83rrxexSfJQ++4v4p/+ukv1Dk89sSHqviDGcbBi3aOXXb67ZwqSaa2lZ6hjW2byMWi6yeGOQah7brTpp8btmPI8khEkmS17S5yVM7rxm3fRn/svg9U8f/te5+rczh8pZvoHz3c7dldf2OG9eRygtuO/5JksezKcb3p6vV63Y/lDxZd23Dv+cfqHO77RHeNl1/9szqH01XXNpy/tTsbcnx8tYpPkqnczx+3M6w7Xe3K8S998jeq+M984TNVfJKU3cwMpyqSZTmGnMo9wyQZ6/atbaNnmOCWA5c55vn1YkWbwwy3sCzPIa7LffQkGepy2P2Yod0jmWP3dyjPO63KNaMkGcq6PZTlOMf8tj93tnvlEcScrvo5UbtW0cYnybacI7dnQ5Jk0/aXdTnsvq87naNtacuhjD+YYc9vLM/cn5Z7hklydNgdwGvHoO3ZlCT1d7mZYe2sHTu15/eSvk6s92Azvr3C8qD/HUu5hNj/tmuGvYW2n5hl77M+79S3b+30sv0m5tgbGMbuu7h2rfvNZpIsy3WCtpmfoUpkKhd9NjP0VXOc06n+/gzX6Jc6+nJclWdk5pgbrsv2qc1hH+5hjudpLM+N1Wbo69rvYrsH/e3BYf87ve0M+1UAAAAAAAAAAAAAAAAAAAAAv0wuXbq06xRgr1y8eHHXKQAAAAAAADexdv9tH/Yq7CECAAC7Yj4CAAAAAAAAAAAAAADAL7tx1wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/GXScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP4ad50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPtr3HUCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvcdcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALC/xl0nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMD+GnedAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD7a9x1AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADsr3HXCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwv8ZdJwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADA/hp3nQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+2vcdQIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7K9x1wkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsL/GXScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP4ad50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPtruesEkuTKlTfymd/77NuOv//BB+ocHn3kfVX8669dqXNYjkMVf7JaVfFnz5+r4pNkLONP1909JMn69LSKv3z5tTqH+x94VxU/jGer+GmqwpMk63VXjsen/Xd5cHjYXaB8njbbbff3k2To6vX169frFO66864q/uiWoyp+u+0fyLZ9O3/m9jqHy6+/UsWfPdt9D0myPd1U8e84f38V/90ffrOKT5JHzj5RxZ+uTuocxnT1sg3fztBIDzkoL9APAYe2IGboq6apa6encuSyGNqRT3Jw2F3j+z/4Vp3D955/tYq/864LVfx3X+rbltPTrr984P6+jX7Puz9ZxR8fX63iz53v+usk+R+fe6qKf/8j76lzOC3HkOPY18upHLsMZQ6z3EMZP059DkM5Dt4H7T3M0NXNYI4Ot7/Erk3l+GsYZhi/lc/TcrGo4jczzMuuXOv6qrtnaN+OT7q1iuX5bp3hgbvOV/FJcv62bv3tjavd95Ak33nppSp+mvo2/vh0XcWvtt38eJpjzaesV9tNdw9JPydpxx3DYvfjlhkexxyd6dqGK1cu1zncXq4bfeCxbj06m35OtBi6Nnozw5hjs9ntGHSWtqU0SwmU45Zt20bPsXbWzkdmWPNpv41pOq4zODntnsn3PfjhKv7111+u4pPk5T97o7vApq+Xr77ywyp+2HRj+aMz/ZrP7bd3eyQPPfjOOoevfO2rVfyn/tyTdQ5Tuv2Fdl61naGfqPcXZlivaVvpRTm/neUe6q6mz2Eoz4bMUQ7tckc79mn3eJJkXd7Dw488Uudw4ZZureC/f/HpKv5DT3yoik+SzbprH4cZxm9H6/Z56v7+MMP4r16XL5vHJFmtunnZHXf25yrGcv+1PROxWJb76EkODsq99BnqxLo8F7G61sV/6slPVfFJ8rkbSYWAAAAgAElEQVSn/qCK32y65zlJpqmrWIuhPLeWpD1NObZjhjm0z/QMaz5z9DWNOb6Gfq9q92P5ur+cZSzf3cUsT1J5H3OcB2jPJGzK9btZzgKUi/tztI99Oe5+PbgthznWYttnepZyLMuhXbNZjv1ZzKlsoWaplmUO7fO0Xnf7xzeSKMNnOO9e/o6ltZihn2nv4fCoH0dvy7X94/J3MElysOzmE8tl1zbMMW5pn+nr1/u9qnaOvSzn+buuk3Np+6p6rSOp29i2q7p+0j+Phwdd+3TmzJk6h/UMZ4Uac0yv2zHDHHa9XTbHvG5TPgtzfJdtvZxjXrZpDwvV61b9fKQth314nurf787QLmzW5VrFHAt47U/kZqiXe7EeDAAAAAAAAAAAAAAAAAAAAPD/0aVLl3adAuyVixcv7joFAAAAAADgJrUPe29tDvZKAACAXdqHeRUAv7isfQEAAAAAAAAAAAAAvwzGXScAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwP4ad50AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPtr3HUCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOyvcdcJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8b3burVeS6roD+Krd3ecMM4fBzHB1bMAERcIXxDXxJYkSS5GVrzAfcL5BlIcoSpTEgAOOUWxFMRZEJGBjBxNgLpxzursqD0OkvCSR+W9R1eT3e2YVq6qr9l5r730GAAAAAIDlanMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBytbkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC52twJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBcbe4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFiuNncCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACxXmzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJarzZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMvV5k4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOVqcycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHK1uRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLna3AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsFxt7gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWK713AlUVV28dLGee+H5Tx0/dbiNW7fOovjWVnEO47SL4i+dXI7id9vTKL6qajtm93B6dh7nsAp/i4ce/lKcwzgdxdeI/v/j+/E1Wsvu4fjCxTiH7S57J4+Ps3fh9Cx7n6uqVqtsfLp65e48hyF7Dmdn2fj4wc0Po/iqqsuXrkTxdx2fxDn8/J1/jeLb0aU4h6Pj7Lscpux9fPjS1Si+qurXN38dxX8hnOuqqra3s7GlbTZR/FhDFF9VNVSWQwvHhaqqYQovkMZXVfooh1X2HI9qzBKoqjfeeC2Kn1b5NzG07EHuWla/7bb5c3z0sSei+Mcf/p04h+0+G1tWq6zu+P5Lr0TxVVVPPP7lKP7sNKsZqqqOj7K5bj/m79N+ygao9ZAOTj3miUwbWp5DeB/hz1BDPFFVTR3m7FyPCTO1hBwyU/hCjR3Gltay7yr9pj66eTOKr6r61Y3bUfz99+Z1y3E4PK02WR184a7jLIGqevOtf4vi3zu9EeewDsf51ZT3E+fjPoofx+y77jLXhZeYwnuoqhrCJMawp9nutlF8VdVqnd1D6zBf3z7Navl1uF5TVfW1J78Yxa922dpZ2+XroPtt+D52qN/2Uza2xNIitvJaPq0ZqjrUTuH/v8c9pHqkME3pXJO/T7tddiNjZWPD00/+cRRfVfXDsxej+Js38tqphf3A2QdZ/XffhYej+Kqqd9/O9mmuPPBQnMNjDzwYxb/yg5fiHJ595ukofgy/yw7lX43pXNNhrlqF/e16na3L7/b5fL/bZ991eh7hzjXC2mkJdUeYQ+vwTUzh+ZRHTu6Jc/irn/40iv/ucy9E8X/+g5ej+Kqq7z37bBR/o8M5nynsSYbwm6oOe6fpZ7nddTgvdZR92ft93hueb7O1gnGXbg7kaz4V1vLp2FRVtQoHyfQ8wXSWN0XffuHbUfzfvfq3cQ7jPvu29x3WQYcKa6dVuN8W1j13LhJeo0Pdkl4jXWvoslKR3kOPLMLfMn6OHRZc0j27JaydpWd07iQRhocN6tThFsbwfezRG67W2VnKeA+5w7uwCfvTscOa+moVzrfhnmFV1XG41nB+ntWwPeaJdGzpMd/mZxrCtY4O5zLS57gOx4Wq/Dmmz2Hq8Bw34Rnp+Xd5qssYG39VPerg0D6cb9Mxvip/J7fbfL0k1cIaMh0Xqqp26X5+h99y7o/74kn+d1XpXLUNz5ZU5WNL2tP02FtYh+9Tj7+/TWvIMewn0j2eqqp9+F2nPVVVfh/pN3VHWPssYP82PYcY9wJVtV5n39X5efY3IJujrH6sys98bZbwzyQsoC8DAAAAAAAAAAAAAAAAAAAA+E1cv3597hRgUa5duzZ3CgAAAAAAwIGy99bH5+U5pvdh3woAAAAAAAAAAAAAAAAAAIBD1OZOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDlanMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBytbkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC52twJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBcbe4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFiuNncCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACxXmzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJarzZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMvV5k4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOVqcycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHK1uRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLna3AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsFxt7gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWK42dwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALFebOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlms9dwJVVTVV7fdjEL+PU2jDURQ/1DbOYWhZDm21ieKP2gdRfFXVz3/xVhR/6dLFOIfL95xE8dtdFl9VNQwfR/FtOM7+/+sHoviqqt02u4fNZohzON+eRfHvvfdhFH/l6n1RfFXVXatsmN3tgrHxE/vwp9iFQ+zVex/KLlBVrbKxYbvL38e7v3BvFP/6z/4xzuGbX382ir8x3ozi1xcfjOKrqqYPs3ni1kfncQ6XTrIx8vw8y+HoqEXxVVXTlMWPPWqn8DZWQ3gTVTVM2Xx5NNyI4r//kx9H8VVVjz30RBT/9js/jXOYWjZXnd3M6uCvPvlUFF9Vdfny/VH8lH+W9e4770bx77+XjdG//fijUXxV1ZiWHcMqzmE3pmND/mOuVlndMLQwfsjrls+DKZ3shvxdaLWA3yJMIX6OC9Djk1itsvFplRY+VfWzt38ZxV84yu5h3eFB7na7KH6a8v72q7+V9WXrTbZ29vqb70TxVVXHl7P4k+FSnMOtm7ei+NUq/ybGbfY+rcMcprjwycfYoTr0RGFfFZY9NXQYH9PaZ9zn/e3+PFuD/NbvfiPOYRizNZfVKruHKa7Dq8awFh87zBP0qf/SXyLNoYU9VVXVEPYDPeqWacr3DVPps9yenWb//w49+nNPfyeK/5sX/yzOoYZs7ezD29l68l23szWjqqrdmN3DZpMfKTg7zd6nrzz2lTiHF3/8WhT/3FPPRPGrDi36bpuNLesO9VsqrcV7LHXE80SeQo0LWLNJa/H0DvYdnsE2OWdUVfsOdfB3v57tcfz1j/4hiv/T3/tmFF9V9RevvBzF/+EzT8c53L6Z9TTptmPrM7iEF8hz2O+za/QZmbLn0NI9mg7ryelcNXTYL1sdZeuYUzrGd3iQ2/Osbvn95/8gzuEHr/4wij8Na6+qqmnK3odpnL+/HcLveuoxuqTv5Mx1z51rhGN0hyQ2R9kZm/Nt1t9uO3xTFy5ciOLHLnsD8/c06frbep31+a3lc12N2dr+0GHdKd7jCOPH8BlU5eNTj950iGunDnVHuI+d7k+MY4c17XAtdx2eiajqUEOGr1OP/Y30GvsO80Rad8TvwjrrJaqqtuFefo+5roXvdI+9+PjQVpjDvsM+eHoHm7A3rao6D/cGjsIa9iw8819VNaVzfoePYhPWbz3m2/Q20t+ipX/UVPl6y3mHnub4OOtp4h67w/u4C8enMazdqvLaJ+2JlnAut3X4ruM1nwWc80nPBvcoGdJ+Ivqb+k+k/W16HnTbYb5Nz/Z2+buBvKmJc1jA8AIAAAAAAAAAAAAAAAAAAAAckOvXr8+dAizKtWvX5k4BAAAAAAA4UO+//779N/hv0u/B3h0AAIcorWP1lQAAAAAAAAAAAAAAAPx/1+ZOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDlanMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBytbkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC52twJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBcbe4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFiuNncCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACxXmzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJarzZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMvV5k4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOVqcycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHK1uRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLna3AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsFxt7gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWK42dwIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALFebOwEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlqvNnQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy7WeO4E7xhrGjz99+HQeZ9BWD0TxU4dHOdUUxe/22yh+u7sZxVdV3Xf//dkFhvw5bnerMP4/4hw264tR/G5/FsX3eB/bKnuOH934KM5hu82+7atXHozi1+EzqKqapjGKv/3x7TiHzfFxFr++K4ofw2+yqmoadlkO+/w5Xj65EsW/8PQjcQ6/vP1GFH/36stR/Ji9zlVVdfWex6P4d3/+z3EO0yp7ny4eZ+/CkE33VVU11ZDFd/gth1U217R1Pjac3fpVFP/aP/1LFP/wg1+K4quqfvHr17MLrI7iHO4+uRDFP/PUd6L4049uRfFVVUct+ya+//cvxzk88sVsnH/ggayOHjuMLa1l8atVeIGqGsd9FN9ajzo4u482hM8he527GKb5k0hf6fnvYBl6PIcOw8vsVqvsSWzW+djy4Vn2JMfxNIq/enISxVdVbcL6raUTTVWd77NC9vW334ziL5zkX9XNj7L1u5OTrEevqpqOs3f67OPsHqqq9tusLzteZWsdHVqiGtPGqstklY0tU1h7pbVbVdUQ1k7n5/newHe++a0ofrXL15324dr+efhWp+sM/3WVuaV3MU3ZPQwdnuPc93DnIuH7FOYwpT1Vhxxq6jG+zd+VTGOWw7qF63f7/Le8fZrVDE9+7Yk4h5+8lq3LH13KavFty/Ycq6p2Y7b+lu4ZVuV7VS1c/6uqunudraUebbI6erfN6+h0AW+VfteVz1Vj2Nel9WNV3p+m+793rpHF95hmWniRMbyJHn3ZEF5k06F2+uDj7GzHHz3zTBT/l6+8FMVXVf3JC1lP9KN3svWWqqpvXHk4ij8Py7fdAtbEhw5z3RRv6Oc5rMIxNh2b9vu8lk+fY1bBfnKNcL5crcOaIVxTr6raVFj/neZz/rNPZWPsy6/me8jpnls63/ZYrhkq+y367GOHZ2TSMzYL6PF7pLDbZSNUutax3myi+Kqq7S7rq7qs38U/xvzrqOmZhvRdqqr4pU7P21dVTWHdkFZe6R5NVf5b9lhPHsPaqcce8hRONulZ8S7nQdN19S4HQtPxLfyue+xvhMYO/UTaE6W1U4911HyMnX+/rEdvmI5P6Vrs1GGvKl3TztcZ8jNX6XeZrjNUdaghewxv4be92+Xv0yas51v8TeQPcn+e9RPHR9laR1WHMwnhO52e/6vqUbfEKdQ+rKX3PXqaUPpbdjmPkO4TdVj0mfuMTI93Id277HE+Oa1btrtszl93uId8vu3wPoa/ZXyetKqWsG4EAAAAAAAAAAAAAAAAAAAAfDauX78+dwqwKNeuXZs7BQAAAAAAAFiEz8N+8hLuwR4kAAC/qSXUsQAsl7UGAAAAAAAAAAAAAID/W5s7AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACWq82dAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADL1eZOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDlanMnAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBytbkTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGC52twJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALBcbe4EAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFiuNncCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACxXmzsBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJarzZ0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMvV5k4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOVqcycAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwHK1uRMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYLna3AkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAsFxt7gQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWK5hmqa5c6hhGP69qt76X/6T+6rqvc8oHQAAgN70NAAAwCHT0wAAAIdKPwMAABwyPQ0AAHCo9DOfnUenabp/7iQAAADm5t+xAwAAPuf0NAAAwKHSzwAAAIdMTwMAABwq/QwAAHDI9DSfDf+GHQAAwCf8O3YAAMDnmH4GAAA4ZHoaAADgkOlpAACAQ6WfAQAADpme5rPxP/47dsM0TZ91Mr+xYRhenabp+bnzAAAA+DT0NAAAwCHT0wAAAIdKPwMAABwyPQ0AAHCo9DMAAAAsjV4VAAA4ZHoaAADgUOlnAACAQ6anAQAADpV+BgAAOGR6GgAAAJZGrwoAABwq/QwAAHDI9DQAAMAh09MAAACHSj8DAAAcMj3N/NrcCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXG3uBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+s537CdW0LMMAft2fVosKMiIRE5KYRbaZJEQQwjbluJlaBOOiJAJbjFDQxtrUsk0FQQlFwxhUIpTkQvqDBK0qKwZ1GqShpMzBWQQVBMXY0+K8yjCe75yJ4jzvffj94PB973O+A/fibC7u77kAAAAAAAAAAAAAAAAAAABYr83sAa7S12cPAAAA8D+QaQAAgM5kGgAAoCt5BgAA6EymAQAAupJnAAAAWBtZFQAA6EymAQAAupJnAACAzmQaAACgK3kGAADoTKYBAABgbWRVAACgK3kGAADoTKYBAAA6k2kAAICu5BkAAKAzmWayGmPMngEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAldrMHgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9drMHgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACA9drMHmA/VXVXVT1bVeer6oHZ8wAAAOylqp6rqqer6kxV/Wo5e3NV/aSqfre8Xjd7TgAAgCSpqlNVdbGqnrnsbNcMUzu+suxsnqqqW+dNDgAAsDXTfL6q/rzsas5U1d2X/e4zS6Z5tqo+MGdqAACApKpuqqqfVtW5qjpbVZ9czu1pAACA1dsj09jTAAAAsGL4jncAAAeMSURBVDp67AAAgE702AEAAJ3osQMAALrSYQcAAHSmxw4AAOhKhx0AAACd6LADAAC60WMHAAB0oscOAADoSo8dAADQlQ47AACgMz12PWxmD7CXqromyVeTHEtyS5J7quqWuVMBAADs631jjKNjjPcszw8keWKMcSTJE8szAADAGpxOctcVZ9syzLEkR5af+5I8eEAzAgAAbHM6r840SfLlZVdzdIzxeJIs3zs7keRdy998bfl+GgAAwAyXknx6jPHOJLcnObnkFnsaAACgg22ZJrGnAQAAYEX02AEAAE3psQMAALo4HT12AABAT6ejww4AAOhLjx0AANCVDjsAAABa0GEHAAA0pscOAADo4nT02AEAAD2djh47AACgJx12AABAZ3rsGtjMHmAftyU5P8b4/RjjX0keTnJ88kwAAAD/reNJHlreP5TkgxNnAQAAeMUY42dJ/nLF8bYMczzJt8aOnyd5U1XdcDCTAgAAvNqWTLPN8SQPjzH+Ocb4Q5Lz2fl+GgAAwIEbY1wYY/xmef/3JOeS3Bh7GgAAoIE9Ms029jQAAADMoscOAAA4DPTYAQAAq6THDgAA6EqHHQAA0JkeOwAAoCsddgAAADSiww4AADgs9NgBAACrpMcOAADoSo8dAADQlQ47AACgMz12PWxmD7CPG5P86bLn57P3PxEAAMBsI8mPq+rXVXXfcnb9GONCshOWk7x12nQAAAD725Zh7G0AAIAu7q+qp6rqVFVdt5zJNAAAwCpV1duTvDvJL2JPAwAANHNFpknsaQAAAFgXmRQAAOhGjx0AANCd+1EAAEBn7kYBAACt6LEDAAC60mEHAADAysmkAABAR3rsAACA7tyPAgAAOnM/CgAAaEOHHQAA0Jkeu/XazB5gH7XL2TjwKQAAAK7eHWOMW5McS3Kyqt47eyAAAID/E3sbAACggweTvCPJ0SQXknxxOZdpAACA1amqNyT5XpJPjTH+ttdHdzmTaQAAgKl2yTT2NAAAAKyNTAoAAHSjxw4AADis7G0AAIC1czcKAABoRY8dAADQlQ47AAAAGpBJAQCAjvTYAQAAh5XdDQAAsHbuRwEAAG3osAMAADrTY7dum9kD7OP5JDdd9vy2JC9MmgUAAGBfY4wXlteLSR5NcluSF6vqhiRZXi/OmxAAAGBf2zKMvQ0AALB6Y4wXxxgvjTH+neQb2dnVJDINAACwMlX1muxcuPr2GOP7y7E9DQAA0MJumcaeBgAAgBWSSQEAgFb02AEAAIeA+1EAAEBL7kYBAACd6LEDAAC60mEHAABAEzIpAADQjh47AADgEHA/CgAAaMn9KAAAoAsddgAAQGd67NZvM3uAfTyZ5EhV3VxVr01yIsljk2cCAADYVVW9vqre+PL7JO9P8kx2csy9y8fuTfKDORMCAABclW0Z5rEkH60dtyf56xjjwowBAQAAtnn5wtXiQ9nZ1SQ7meZEVb2uqm5OciTJLw96PgAAgCSpqkryzSTnxhhfuuxX9jQAAMDqbcs09jQAAACskB47AACgDT12AADAIeF+FAAA0JK7UQAAQBd67AAAgK502AEAANCIDjsAAKAVPXYAAMAh4X4UAADQkvtRAABABzrsAACAzvTY9XDt7AH2Msa4VFX3J/lRkmuSnBpjnJ08FgAAwDbXJ3l0Jw/n2iTfGWP8sKqeTPJIVX08yR+TfHjijAAAAK+oqu8muTPJW6rq+SSfS/KF7J5hHk9yd5LzSf6R5GMHPjAAAMBltmSaO6vqaJKR5Lkkn0iSMcbZqnokyW+TXEpycozx0oy5AQAAktyR5CNJnq6qM8vZZ2NPAwAA9LAt09xjTwMAAMCa6LEDAACa0WMHAAC0oscOAADoSocdAADQnB47AACgKx12AAAAtKDDDgAAaEiPHQAA0IoeOwAAoCs9dgAAQGM67AAAgM702DVQY4zZMwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwUpvZAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXpvZAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXpvZAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXpvZAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXpvZAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXpvZAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXpvZAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXv8Bkrm1fi7PNtIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 18432x18432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current percentage of epoch: 0.01\n",
      "Train (epoch 1/15) [0/800 (0%)]\tLoss: 0.344465\tAccuracy: 94.65179443359375\n",
      "learning rate 1e-05\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9148,  2.4331,  2.9264,  3.1704,  3.3780],\n",
      "          [ 2.4175,  2.6807,  3.2546,  3.6095,  3.9462],\n",
      "          [ 2.8932,  3.2225,  3.9347,  4.4044,  4.8373],\n",
      "          [ 3.0905,  3.4851,  4.2581,  4.7770,  5.1690]],\n",
      "\n",
      "         [[-1.9148, -2.4329, -2.9263, -3.1702, -3.3778],\n",
      "          [-2.4174, -2.6804, -3.2543, -3.6091, -3.9459],\n",
      "          [-2.8931, -3.2222, -3.9343, -4.4040, -4.8369],\n",
      "          [-3.0903, -3.4848, -4.2577, -4.7766, -5.1685]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2629,  1.5547,  1.7596,  1.8354,  1.8074],\n",
      "          [ 1.5707,  1.7553,  1.8862,  1.9957,  2.0033],\n",
      "          [ 1.7918,  1.9417,  2.0645,  2.1879,  2.2221],\n",
      "          [ 1.9255,  2.1103,  2.2297,  2.3186,  2.3475]],\n",
      "\n",
      "         [[-1.2630, -1.5547, -1.7596, -1.8353, -1.8074],\n",
      "          [-1.5708, -1.7552, -1.8861, -1.9956, -2.0032],\n",
      "          [-1.7918, -1.9416, -2.0643, -2.1878, -2.2219],\n",
      "          [-1.9255, -2.1102, -2.2296, -2.3185, -2.3474]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5258,  0.7133,  0.7866,  0.7475,  0.7120],\n",
      "          [ 0.5384,  0.7046,  0.7283,  0.6343,  0.5799],\n",
      "          [ 0.4598,  0.5100,  0.4784,  0.3253,  0.2414],\n",
      "          [ 0.6089,  0.7029,  0.7241,  0.5659,  0.4536]],\n",
      "\n",
      "         [[-0.5258, -0.7133, -0.7866, -0.7475, -0.7120],\n",
      "          [-0.5385, -0.7046, -0.7282, -0.6343, -0.5799],\n",
      "          [-0.4599, -0.5099, -0.4784, -0.3252, -0.2413],\n",
      "          [-0.6089, -0.7028, -0.7240, -0.5658, -0.4535]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8976,  1.0958,  1.2261,  1.3034,  1.3523],\n",
      "          [ 1.0474,  1.1417,  1.1655,  1.2591,  1.3057],\n",
      "          [ 1.1115,  1.1115,  1.0619,  1.1642,  1.2179],\n",
      "          [ 1.1423,  1.1441,  1.0772,  1.2025,  1.2706]],\n",
      "\n",
      "         [[-0.8977, -1.0959, -1.2261, -1.3034, -1.3523],\n",
      "          [-1.0475, -1.1416, -1.1654, -1.2591, -1.3056],\n",
      "          [-1.1115, -1.1114, -1.0618, -1.1641, -1.2178],\n",
      "          [-1.1424, -1.1441, -1.0771, -1.2024, -1.2705]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3182,  0.2568,  0.1020, -0.0331, -0.1723],\n",
      "          [ 0.3050,  0.2693,  0.0983, -0.0170, -0.1500],\n",
      "          [ 0.2117,  0.1801,  0.0461, -0.0420, -0.1420],\n",
      "          [ 0.0141, -0.0604, -0.1543, -0.2440, -0.3070]],\n",
      "\n",
      "         [[-0.3183, -0.2569, -0.1020,  0.0331,  0.1722],\n",
      "          [-0.3050, -0.2692, -0.0983,  0.0170,  0.1501],\n",
      "          [-0.2117, -0.1801, -0.0460,  0.0421,  0.1421],\n",
      "          [-0.0141,  0.0604,  0.1544,  0.2440,  0.3071]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 1 1]\n",
      " [0 0 0 1 1]\n",
      " [0 0 0 1 1]\n",
      " [0 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4872,  0.6589,  0.7459,  0.7636,  0.8019],\n",
      "          [ 0.4916,  0.6478,  0.6909,  0.6699,  0.6870],\n",
      "          [ 0.4459,  0.5528,  0.5914,  0.5636,  0.5771],\n",
      "          [ 0.4644,  0.6239,  0.7610,  0.7957,  0.8366]],\n",
      "\n",
      "         [[-0.4872, -0.6589, -0.7459, -0.7636, -0.8019],\n",
      "          [-0.4916, -0.6477, -0.6908, -0.6698, -0.6869],\n",
      "          [-0.4459, -0.5527, -0.5913, -0.5635, -0.5770],\n",
      "          [-0.4644, -0.6238, -0.7609, -0.7957, -0.8365]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9042,  1.0900,  1.2452,  1.3286,  1.3676],\n",
      "          [ 1.1384,  1.2266,  1.3085,  1.4120,  1.4862],\n",
      "          [ 1.2985,  1.3238,  1.3924,  1.5234,  1.6410],\n",
      "          [ 1.4247,  1.4854,  1.5867,  1.7105,  1.8187]],\n",
      "\n",
      "         [[-0.9043, -1.0900, -1.2452, -1.3286, -1.3676],\n",
      "          [-1.1384, -1.2265, -1.3084, -1.4119, -1.4862],\n",
      "          [-1.2985, -1.3237, -1.3922, -1.5232, -1.6409],\n",
      "          [-1.4247, -1.4853, -1.5865, -1.7104, -1.8186]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0657,  1.3386,  1.5639,  1.7164,  1.8359],\n",
      "          [ 1.2788,  1.4680,  1.6609,  1.8596,  2.0122],\n",
      "          [ 1.4646,  1.5918,  1.7247,  1.9119,  2.0979],\n",
      "          [ 1.6474,  1.8030,  1.9408,  2.1053,  2.2945]],\n",
      "\n",
      "         [[-1.0658, -1.3386, -1.5639, -1.7164, -1.8359],\n",
      "          [-1.2788, -1.4678, -1.6607, -1.8594, -2.0121],\n",
      "          [-1.4645, -1.5916, -1.7245, -1.9117, -2.0977],\n",
      "          [-1.6473, -1.8028, -1.9406, -2.1051, -2.2943]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.5748,  1.9390,  2.3697,  2.5632,  2.7199],\n",
      "          [ 1.9652,  2.1527,  2.5909,  2.8574,  3.1252],\n",
      "          [ 2.3718,  2.5744,  3.1093,  3.4613,  3.8231],\n",
      "          [ 2.5907,  2.8481,  3.4509,  3.8274,  4.2098]],\n",
      "\n",
      "         [[-1.5748, -1.9390, -2.3696, -2.5631, -2.7197],\n",
      "          [-1.9652, -2.1526, -2.5907, -2.8572, -3.1249],\n",
      "          [-2.3717, -2.5742, -3.1090, -3.4610, -3.8227],\n",
      "          [-2.5906, -2.8478, -3.4506, -3.8271, -4.2094]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7005,  0.8029,  0.7945,  0.5908,  0.3978],\n",
      "          [ 0.7708,  0.8510,  0.8603,  0.6902,  0.5535],\n",
      "          [ 0.7302,  0.7587,  0.7839,  0.6710,  0.5869],\n",
      "          [ 0.7815,  0.8405,  0.8583,  0.7280,  0.6326]],\n",
      "\n",
      "         [[-0.7006, -0.8030, -0.7945, -0.5909, -0.3979],\n",
      "          [-0.7708, -0.8510, -0.8603, -0.6901, -0.5535],\n",
      "          [-0.7302, -0.7587, -0.7838, -0.6710, -0.5868],\n",
      "          [-0.7815, -0.8405, -0.8583, -0.7279, -0.6325]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7191,  0.9614,  1.1634,  1.2849,  1.4324],\n",
      "          [ 0.9030,  1.2018,  1.4008,  1.5192,  1.6654],\n",
      "          [ 1.0407,  1.3808,  1.5844,  1.6972,  1.8288],\n",
      "          [ 1.1496,  1.4769,  1.6574,  1.7790,  1.9211]],\n",
      "\n",
      "         [[-0.7192, -0.9614, -1.1634, -1.2848, -1.4324],\n",
      "          [-0.9030, -1.2017, -1.4007, -1.5191, -1.6653],\n",
      "          [-1.0406, -1.3806, -1.5842, -1.6970, -1.8286],\n",
      "          [-1.1496, -1.4767, -1.6573, -1.7789, -1.9209]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.5255,  1.9347,  2.2526,  2.4249,  2.5121],\n",
      "          [ 1.8955,  2.1721,  2.4053,  2.5834,  2.7515],\n",
      "          [ 2.1328,  2.3511,  2.5637,  2.7396,  2.9223],\n",
      "          [ 2.3017,  2.5723,  2.8229,  3.0064,  3.2263]],\n",
      "\n",
      "         [[-1.5255, -1.9347, -2.2526, -2.4248, -2.5120],\n",
      "          [-1.8955, -2.1719, -2.4050, -2.5832, -2.7513],\n",
      "          [-2.1328, -2.3509, -2.5635, -2.7394, -2.9221],\n",
      "          [-2.3016, -2.5721, -2.8226, -3.0062, -3.2261]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1223,  1.3821,  1.6098,  1.7396,  1.8061],\n",
      "          [ 1.4085,  1.5427,  1.6721,  1.8272,  1.9406],\n",
      "          [ 1.5573,  1.6257,  1.7120,  1.9077,  2.0726],\n",
      "          [ 1.6797,  1.8030,  1.9026,  2.1245,  2.2959]],\n",
      "\n",
      "         [[-1.1224, -1.3821, -1.6098, -1.7396, -1.8061],\n",
      "          [-1.4086, -1.5427, -1.6720, -1.8271, -1.9405],\n",
      "          [-1.5573, -1.6256, -1.7118, -1.9076, -2.0725],\n",
      "          [-1.6797, -1.8029, -1.9024, -2.1244, -2.2958]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6561,  0.7919,  0.8727,  0.8657,  0.9062],\n",
      "          [ 0.6988,  0.8150,  0.8916,  0.8829,  0.9353],\n",
      "          [ 0.7175,  0.8503,  0.9383,  0.9247,  0.9771],\n",
      "          [ 0.6167,  0.7314,  0.8454,  0.8410,  0.9129]],\n",
      "\n",
      "         [[-0.6562, -0.7919, -0.8727, -0.8657, -0.9062],\n",
      "          [-0.6988, -0.8149, -0.8914, -0.8828, -0.9351],\n",
      "          [-0.7175, -0.8502, -0.9381, -0.9246, -0.9770],\n",
      "          [-0.6167, -0.7313, -0.8452, -0.8409, -0.9127]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3092,  1.6378,  1.8816,  2.0131,  2.0317],\n",
      "          [ 1.5888,  1.7455,  1.8808,  2.0236,  2.0946],\n",
      "          [ 1.7318,  1.8010,  1.8853,  1.9830,  2.0382],\n",
      "          [ 1.8201,  1.9337,  2.0082,  2.0563,  2.0809]],\n",
      "\n",
      "         [[-1.3092, -1.6378, -1.8816, -2.0130, -2.0317],\n",
      "          [-1.5888, -1.7454, -1.8807, -2.0234, -2.0945],\n",
      "          [-1.7318, -1.8009, -1.8851, -1.9829, -2.0381],\n",
      "          [-1.8201, -1.9336, -2.0080, -2.0561, -2.0808]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6912,  0.7477,  0.6991,  0.4682,  0.1905],\n",
      "          [ 0.8534,  0.8733,  0.8202,  0.5991,  0.3028],\n",
      "          [ 0.8969,  0.8588,  0.8081,  0.5759,  0.2488],\n",
      "          [ 0.9612,  0.9159,  0.8299,  0.5778,  0.2714]],\n",
      "\n",
      "         [[-0.6913, -0.7477, -0.6991, -0.4682, -0.1906],\n",
      "          [-0.8534, -0.8732, -0.8202, -0.5990, -0.3027],\n",
      "          [-0.8969, -0.8587, -0.8081, -0.5759, -0.2488],\n",
      "          [-0.9612, -0.9158, -0.8299, -0.5777, -0.2714]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.0200,  0.0426,  0.1231,  0.4443,  0.7165],\n",
      "          [ 0.0383,  0.0972,  0.0643,  0.4516,  0.7793],\n",
      "          [ 0.0044,  0.0339,  0.0063,  0.4709,  0.8608],\n",
      "          [ 0.0614,  0.0816,  0.0716,  0.5770,  0.9913]],\n",
      "\n",
      "         [[-0.0201, -0.0426, -0.1231, -0.4443, -0.7165],\n",
      "          [-0.0383, -0.0971, -0.0642, -0.4516, -0.7793],\n",
      "          [-0.0045, -0.0339, -0.0063, -0.4709, -0.8608],\n",
      "          [-0.0614, -0.0815, -0.0716, -0.5769, -0.9913]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1065,  1.3426,  1.4823,  1.5277,  1.5376],\n",
      "          [ 1.3070,  1.3775,  1.3438,  1.3503,  1.3657],\n",
      "          [ 1.3686,  1.3066,  1.1548,  1.1377,  1.1540],\n",
      "          [ 1.3605,  1.2703,  1.0942,  1.0574,  1.0581]],\n",
      "\n",
      "         [[-1.1066, -1.3426, -1.4822, -1.5276, -1.5376],\n",
      "          [-1.3070, -1.3774, -1.3437, -1.3502, -1.3656],\n",
      "          [-1.3685, -1.3065, -1.1547, -1.1376, -1.1538],\n",
      "          [-1.3605, -1.2702, -1.0941, -1.0573, -1.0580]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6813,  0.8184,  0.8934,  0.9670,  1.0581],\n",
      "          [ 0.6971,  0.8176,  0.8843,  0.9974,  1.1018],\n",
      "          [ 0.6425,  0.7607,  0.8488,  0.9780,  1.0710],\n",
      "          [ 0.6524,  0.8291,  0.9615,  1.1072,  1.2438]],\n",
      "\n",
      "         [[-0.6814, -0.8184, -0.8935, -0.9671, -1.0582],\n",
      "          [-0.6971, -0.8175, -0.8843, -0.9974, -1.1018],\n",
      "          [-0.6425, -0.7606, -0.8488, -0.9779, -1.0710],\n",
      "          [-0.6524, -0.8291, -0.9614, -1.1072, -1.2438]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6568,  0.8030,  0.9100,  1.0402,  1.2047],\n",
      "          [ 0.7759,  0.9189,  0.9950,  1.1663,  1.3933],\n",
      "          [ 0.8254,  0.9972,  1.1104,  1.3250,  1.5821],\n",
      "          [ 0.7992,  0.9866,  1.1376,  1.3634,  1.6116]],\n",
      "\n",
      "         [[-0.6569, -0.8030, -0.9099, -1.0401, -1.2047],\n",
      "          [-0.7759, -0.9188, -0.9949, -1.1662, -1.3932],\n",
      "          [-0.8254, -0.9970, -1.1103, -1.3249, -1.5820],\n",
      "          [-0.7992, -0.9865, -1.1375, -1.3633, -1.6115]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.6807,  2.1265,  2.5524,  2.7308,  2.8815],\n",
      "          [ 2.0932,  2.3950,  2.8137,  3.0669,  3.3059],\n",
      "          [ 2.4284,  2.7484,  3.2298,  3.5526,  3.8620],\n",
      "          [ 2.5137,  2.9031,  3.3988,  3.7359,  4.0648]],\n",
      "\n",
      "         [[-1.6807, -2.1265, -2.5523, -2.7307, -2.8813],\n",
      "          [-2.0932, -2.3948, -2.8135, -3.0666, -3.3056],\n",
      "          [-2.4283, -2.7482, -3.2295, -3.5523, -3.8617],\n",
      "          [-2.5136, -2.9028, -3.3985, -3.7356, -4.0644]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2594,  0.2915,  0.2278,  0.2263,  0.2535],\n",
      "          [ 0.3095,  0.4038,  0.3112,  0.3321,  0.3774],\n",
      "          [ 0.2494,  0.3180,  0.2222,  0.2691,  0.3399],\n",
      "          [ 0.2557,  0.3328,  0.2651,  0.3549,  0.4608]],\n",
      "\n",
      "         [[-0.2595, -0.2916, -0.2279, -0.2264, -0.2535],\n",
      "          [-0.3095, -0.4037, -0.3111, -0.3321, -0.3774],\n",
      "          [-0.2495, -0.3180, -0.2222, -0.2691, -0.3399],\n",
      "          [-0.2558, -0.3328, -0.2651, -0.3548, -0.4608]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7237,  0.8255,  0.8974,  0.9312,  0.9083],\n",
      "          [ 0.8179,  0.8792,  0.8842,  0.9692,  0.9427],\n",
      "          [ 0.8607,  0.9714,  0.9634,  1.0670,  1.0730],\n",
      "          [ 0.8720,  1.0582,  1.0448,  1.0907,  1.0940]],\n",
      "\n",
      "         [[-0.7238, -0.8255, -0.8974, -0.9313, -0.9083],\n",
      "          [-0.8180, -0.8792, -0.8841, -0.9691, -0.9426],\n",
      "          [-0.8607, -0.9713, -0.9634, -1.0670, -1.0729],\n",
      "          [-0.8720, -1.0582, -1.0448, -1.0907, -1.0940]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2544,  1.5831,  1.8388,  1.9852,  2.1107],\n",
      "          [ 1.5827,  1.8415,  2.0378,  2.2312,  2.4248],\n",
      "          [ 1.8196,  2.0543,  2.2182,  2.4527,  2.6814],\n",
      "          [ 1.9401,  2.1909,  2.3534,  2.5845,  2.7990]],\n",
      "\n",
      "         [[-1.2545, -1.5831, -1.8387, -1.9851, -2.1106],\n",
      "          [-1.5827, -1.8414, -2.0377, -2.2310, -2.4247],\n",
      "          [-1.8196, -2.0541, -2.2180, -2.4525, -2.6812],\n",
      "          [-1.9400, -2.1907, -2.3532, -2.5843, -2.7989]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1082,  1.3334,  1.4685,  1.4098,  1.3309],\n",
      "          [ 1.3440,  1.4430,  1.4508,  1.3291,  1.2405],\n",
      "          [ 1.4979,  1.5313,  1.4845,  1.3345,  1.2391],\n",
      "          [ 1.5271,  1.5330,  1.4676,  1.2961,  1.1950]],\n",
      "\n",
      "         [[-1.1082, -1.3334, -1.4685, -1.4098, -1.3308],\n",
      "          [-1.3440, -1.4429, -1.4506, -1.3289, -1.2403],\n",
      "          [-1.4979, -1.5311, -1.4843, -1.3343, -1.2389],\n",
      "          [-1.5271, -1.5328, -1.4674, -1.2959, -1.1948]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7951,  2.2451,  2.7131,  2.9277,  3.1136],\n",
      "          [ 2.2094,  2.4465,  2.9694,  3.2999,  3.6151],\n",
      "          [ 2.6656,  2.9376,  3.5847,  4.0285,  4.4553],\n",
      "          [ 2.8657,  3.2463,  3.9651,  4.4536,  4.8247]],\n",
      "\n",
      "         [[-1.7951, -2.2450, -2.7130, -2.9276, -3.1134],\n",
      "          [-2.2094, -2.4463, -2.9691, -3.2996, -3.6148],\n",
      "          [-2.6655, -2.9373, -3.5844, -4.0282, -4.4549],\n",
      "          [-2.8656, -3.2460, -3.9648, -4.4532, -4.8242]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.4924,  1.8788,  2.2272,  2.3470,  2.4149],\n",
      "          [ 1.9367,  2.1988,  2.4693,  2.6179,  2.7380],\n",
      "          [ 2.1998,  2.3975,  2.6661,  2.8660,  3.0368],\n",
      "          [ 2.3269,  2.5913,  2.8604,  3.0927,  3.2870]],\n",
      "\n",
      "         [[-1.4924, -1.8787, -2.2271, -2.3469, -2.4148],\n",
      "          [-1.9367, -2.1986, -2.4691, -2.6177, -2.7378],\n",
      "          [-2.1997, -2.3973, -2.6659, -2.8657, -3.0365],\n",
      "          [-2.3268, -2.5911, -2.8602, -3.0925, -3.2867]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0233,  1.1912,  1.2941,  1.3052,  1.3261],\n",
      "          [ 1.2374,  1.3314,  1.4061,  1.4498,  1.5163],\n",
      "          [ 1.3546,  1.4093,  1.5060,  1.6090,  1.7337],\n",
      "          [ 1.3849,  1.4252,  1.5170,  1.6172,  1.7485]],\n",
      "\n",
      "         [[-1.0234, -1.1912, -1.2940, -1.3051, -1.3261],\n",
      "          [-1.2374, -1.3313, -1.4060, -1.4496, -1.5161],\n",
      "          [-1.3546, -1.4092, -1.5059, -1.6088, -1.7335],\n",
      "          [-1.3849, -1.4251, -1.5168, -1.6171, -1.7483]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8468,  1.0580,  1.1990,  1.2534,  1.3033],\n",
      "          [ 1.0446,  1.2273,  1.3407,  1.4392,  1.5205],\n",
      "          [ 1.2141,  1.3837,  1.5217,  1.6340,  1.7227],\n",
      "          [ 1.3908,  1.5753,  1.7268,  1.7528,  1.7745]],\n",
      "\n",
      "         [[-0.8468, -1.0580, -1.1990, -1.2534, -1.3033],\n",
      "          [-1.0446, -1.2272, -1.3406, -1.4391, -1.5204],\n",
      "          [-1.2141, -1.3836, -1.5216, -1.6339, -1.7225],\n",
      "          [-1.3908, -1.5752, -1.7266, -1.7527, -1.7744]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0349,  1.2320,  1.3677,  1.3760,  1.3795],\n",
      "          [ 1.2404,  1.3430,  1.4021,  1.3963,  1.4193],\n",
      "          [ 1.4032,  1.4910,  1.5374,  1.5199,  1.5415],\n",
      "          [ 1.4519,  1.5443,  1.5895,  1.5368,  1.5329]],\n",
      "\n",
      "         [[-1.0349, -1.2320, -1.3676, -1.3760, -1.3794],\n",
      "          [-1.2403, -1.3429, -1.4020, -1.3961, -1.4192],\n",
      "          [-1.4032, -1.4908, -1.5372, -1.5197, -1.5413],\n",
      "          [-1.4519, -1.5441, -1.5893, -1.5366, -1.5327]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0216,  1.2447,  1.3889,  1.4262,  1.4713],\n",
      "          [ 1.2297,  1.4043,  1.5079,  1.6131,  1.7163],\n",
      "          [ 1.3758,  1.5582,  1.6699,  1.8228,  1.9712],\n",
      "          [ 1.4844,  1.7288,  1.8455,  1.9961,  2.1413]],\n",
      "\n",
      "         [[-1.0217, -1.2447, -1.3888, -1.4261, -1.4713],\n",
      "          [-1.2297, -1.4042, -1.5077, -1.6130, -1.7162],\n",
      "          [-1.3758, -1.5581, -1.6698, -1.8227, -1.9711],\n",
      "          [-1.4844, -1.7287, -1.8454, -1.9959, -2.1412]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.6031,  2.0444,  2.4530,  2.6191,  2.7558],\n",
      "          [ 2.0104,  2.3307,  2.7863,  3.0392,  3.2786],\n",
      "          [ 2.3713,  2.7049,  3.2650,  3.6014,  3.9231],\n",
      "          [ 2.5427,  2.9141,  3.5293,  3.8923,  4.2055]],\n",
      "\n",
      "         [[-1.6032, -2.0444, -2.4529, -2.6189, -2.7557],\n",
      "          [-2.0104, -2.3305, -2.7861, -3.0389, -3.2784],\n",
      "          [-2.3713, -2.7047, -3.2647, -3.6011, -3.9228],\n",
      "          [-2.5426, -2.9139, -3.5290, -3.8920, -4.2052]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7007,  0.8967,  1.0618,  1.2099,  1.4184],\n",
      "          [ 0.7789,  0.9748,  1.1267,  1.2768,  1.4833],\n",
      "          [ 0.7686,  0.9783,  1.1670,  1.2941,  1.4677],\n",
      "          [ 0.8223,  1.0392,  1.2770,  1.3694,  1.4847]],\n",
      "\n",
      "         [[-0.7008, -0.8967, -1.0618, -1.2099, -1.4184],\n",
      "          [-0.7789, -0.9747, -1.1266, -1.2768, -1.4833],\n",
      "          [-0.7686, -0.9782, -1.1668, -1.2940, -1.4676],\n",
      "          [-0.8223, -1.0391, -1.2769, -1.3694, -1.4846]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7100,  0.8314,  0.8552,  0.8447,  0.8768],\n",
      "          [ 0.8056,  0.8851,  0.8668,  0.8603,  0.9221],\n",
      "          [ 0.8220,  0.8621,  0.8271,  0.8271,  0.9144],\n",
      "          [ 0.7913,  0.8272,  0.8044,  0.8147,  0.9239]],\n",
      "\n",
      "         [[-0.7101, -0.8314, -0.8552, -0.8447, -0.8768],\n",
      "          [-0.8057, -0.8851, -0.8667, -0.8602, -0.9220],\n",
      "          [-0.8220, -0.8620, -0.8270, -0.8269, -0.9142],\n",
      "          [-0.7913, -0.8271, -0.8043, -0.8145, -0.9237]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9311,  1.1529,  1.3129,  1.4108,  1.5224],\n",
      "          [ 1.1393,  1.3145,  1.4589,  1.5769,  1.7209],\n",
      "          [ 1.2770,  1.4282,  1.5920,  1.7352,  1.9081],\n",
      "          [ 1.3941,  1.5750,  1.7909,  1.9503,  2.1364]],\n",
      "\n",
      "         [[-0.9312, -1.1529, -1.3129, -1.4108, -1.5224],\n",
      "          [-1.1393, -1.3144, -1.4588, -1.5768, -1.7208],\n",
      "          [-1.2769, -1.4281, -1.5919, -1.7351, -1.9079],\n",
      "          [-1.3941, -1.5749, -1.7907, -1.9501, -2.1363]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4393,  0.5979,  0.7059,  0.7969,  0.9043],\n",
      "          [ 0.5271,  0.7387,  0.8491,  0.9550,  1.0777],\n",
      "          [ 0.5566,  0.7689,  0.9058,  1.0348,  1.1659],\n",
      "          [ 0.6241,  0.8264,  0.9767,  1.1368,  1.2800]],\n",
      "\n",
      "         [[-0.4394, -0.5979, -0.7059, -0.7969, -0.9044],\n",
      "          [-0.5271, -0.7387, -0.8490, -0.9550, -1.0777],\n",
      "          [-0.5567, -0.7688, -0.9058, -1.0347, -1.1659],\n",
      "          [-0.6241, -0.8263, -0.9767, -1.1367, -1.2800]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9783,  1.2446,  1.4019,  1.4971,  1.5991],\n",
      "          [ 1.2368,  1.4779,  1.5921,  1.6990,  1.8185],\n",
      "          [ 1.4565,  1.6795,  1.7803,  1.9066,  2.0242],\n",
      "          [ 1.6729,  1.9483,  2.1323,  2.2788,  2.3640]],\n",
      "\n",
      "         [[-0.9784, -1.2446, -1.4019, -1.4970, -1.5991],\n",
      "          [-1.2368, -1.4778, -1.5919, -1.6988, -1.8183],\n",
      "          [-1.4565, -1.6794, -1.7802, -1.9064, -2.0240],\n",
      "          [-1.6729, -1.9481, -2.1321, -2.2786, -2.3638]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9790,  1.2078,  1.3667,  1.3804,  1.3034],\n",
      "          [ 1.1933,  1.3260,  1.4200,  1.4719,  1.4331],\n",
      "          [ 1.2930,  1.3641,  1.4529,  1.5457,  1.5399],\n",
      "          [ 1.3849,  1.4731,  1.5760,  1.6704,  1.6877]],\n",
      "\n",
      "         [[-0.9791, -1.2078, -1.3668, -1.3805, -1.3034],\n",
      "          [-1.1933, -1.3260, -1.4200, -1.4719, -1.4330],\n",
      "          [-1.2930, -1.3640, -1.4528, -1.5456, -1.5398],\n",
      "          [-1.3849, -1.4731, -1.5759, -1.6703, -1.6876]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5062,  0.5484,  0.5505,  0.4678,  0.4227],\n",
      "          [ 0.6164,  0.6938,  0.7354,  0.6884,  0.6771],\n",
      "          [ 0.7388,  0.8820,  1.0224,  1.0344,  1.0651],\n",
      "          [ 0.8291,  0.9707,  1.1112,  1.1286,  1.1674]],\n",
      "\n",
      "         [[-0.5063, -0.5484, -0.5506, -0.4678, -0.4227],\n",
      "          [-0.6164, -0.6937, -0.7353, -0.6883, -0.6770],\n",
      "          [-0.7388, -0.8819, -1.0223, -1.0343, -1.0650],\n",
      "          [-0.8291, -0.9706, -1.1111, -1.1284, -1.1673]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.0809, -0.1261, -0.2241, -0.2557, -0.2405],\n",
      "          [-0.1233, -0.0412, -0.1095, -0.0985, -0.0561],\n",
      "          [-0.2528, -0.1726, -0.2132, -0.1525, -0.0605],\n",
      "          [-0.2394, -0.1193, -0.1117, -0.0261,  0.0851]],\n",
      "\n",
      "         [[ 0.0808,  0.1260,  0.2241,  0.2557,  0.2405],\n",
      "          [ 0.1233,  0.0412,  0.1096,  0.0985,  0.0561],\n",
      "          [ 0.2528,  0.1727,  0.2133,  0.1526,  0.0606],\n",
      "          [ 0.2394,  0.1194,  0.1118,  0.0262, -0.0850]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1015,  1.3323,  1.4356,  1.3434,  1.2674],\n",
      "          [ 1.3734,  1.4883,  1.4845,  1.3862,  1.3532],\n",
      "          [ 1.5583,  1.5627,  1.4647,  1.3870,  1.4208],\n",
      "          [ 1.7669,  1.7883,  1.7205,  1.7753,  1.9222]],\n",
      "\n",
      "         [[-1.1015, -1.3323, -1.4356, -1.3434, -1.2674],\n",
      "          [-1.3734, -1.4882, -1.4844, -1.3861, -1.3532],\n",
      "          [-1.5582, -1.5626, -1.4645, -1.3869, -1.4207],\n",
      "          [-1.7668, -1.7882, -1.7204, -1.7752, -1.9221]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 2.0240,  2.5887,  3.1004,  3.3482,  3.5467],\n",
      "          [ 2.5659,  2.8388,  3.4748,  3.8998,  4.2652],\n",
      "          [ 3.0677,  3.4658,  4.2646,  4.8220,  5.2158],\n",
      "          [ 3.3015,  3.8313,  4.7074,  5.2428,  5.6232]],\n",
      "\n",
      "         [[-2.0240, -2.5885, -3.1002, -3.3480, -3.5465],\n",
      "          [-2.5657, -2.8386, -3.4745, -3.8994, -4.2648],\n",
      "          [-3.0675, -3.4655, -4.2642, -4.8216, -5.2153],\n",
      "          [-3.3012, -3.8309, -4.7069, -5.2423, -5.6226]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.4594,  1.8437,  2.1606,  2.2860,  2.3606],\n",
      "          [ 1.8554,  2.1388,  2.3946,  2.5167,  2.6185],\n",
      "          [ 2.1486,  2.3946,  2.6484,  2.7808,  2.8739],\n",
      "          [ 2.3084,  2.5634,  2.8558,  3.0222,  3.1539]],\n",
      "\n",
      "         [[-1.4595, -1.8436, -2.1605, -2.2859, -2.3605],\n",
      "          [-1.8554, -2.1387, -2.3944, -2.5165, -2.6183],\n",
      "          [-2.1486, -2.3944, -2.6482, -2.7806, -2.8736],\n",
      "          [-2.3083, -2.5632, -2.8555, -3.0220, -3.1537]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0241,  1.2587,  1.4572,  1.5276,  1.5219],\n",
      "          [ 1.2854,  1.4430,  1.5942,  1.7243,  1.7516],\n",
      "          [ 1.4780,  1.5977,  1.7221,  1.8845,  1.9073],\n",
      "          [ 1.6183,  1.7845,  1.9294,  2.0920,  2.1125]],\n",
      "\n",
      "         [[-1.0241, -1.2587, -1.4572, -1.5276, -1.5219],\n",
      "          [-1.2854, -1.4430, -1.5941, -1.7242, -1.7515],\n",
      "          [-1.4780, -1.5976, -1.7220, -1.8844, -1.9072],\n",
      "          [-1.6183, -1.7844, -1.9293, -2.0919, -2.1124]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.3245, -0.5057, -0.7559, -0.9448, -1.0894],\n",
      "          [-0.3077, -0.3690, -0.6686, -0.9221, -1.1415],\n",
      "          [-0.3449, -0.4396, -0.7578, -0.9763, -1.1334],\n",
      "          [-0.1414, -0.2400, -0.5153, -0.7270, -0.8658]],\n",
      "\n",
      "         [[ 0.3244,  0.5057,  0.7559,  0.9447,  1.0894],\n",
      "          [ 0.3076,  0.3690,  0.6687,  0.9221,  1.1416],\n",
      "          [ 0.3449,  0.4397,  0.7578,  0.9764,  1.1335],\n",
      "          [ 0.1413,  0.2400,  0.5153,  0.7270,  0.8658]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8879,  1.1228,  1.2962,  1.3469,  1.3744],\n",
      "          [ 1.1096,  1.3397,  1.4650,  1.4583,  1.4307],\n",
      "          [ 1.2150,  1.4164,  1.5101,  1.4740,  1.4143],\n",
      "          [ 1.2783,  1.4677,  1.5098,  1.4050,  1.2867]],\n",
      "\n",
      "         [[-0.8880, -1.1228, -1.2962, -1.3469, -1.3744],\n",
      "          [-1.1097, -1.3396, -1.4649, -1.4582, -1.4306],\n",
      "          [-1.2150, -1.4163, -1.5100, -1.4739, -1.4141],\n",
      "          [-1.2783, -1.4676, -1.5096, -1.4049, -1.2866]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5857,  0.6639,  0.7027,  0.7249,  0.7815],\n",
      "          [ 0.6240,  0.6679,  0.7032,  0.7841,  0.8878],\n",
      "          [ 0.6339,  0.6756,  0.7401,  0.8413,  0.9579],\n",
      "          [ 0.6659,  0.7274,  0.8171,  0.9035,  1.0145]],\n",
      "\n",
      "         [[-0.5858, -0.6639, -0.7027, -0.7249, -0.7815],\n",
      "          [-0.6240, -0.6678, -0.7031, -0.7840, -0.8877],\n",
      "          [-0.6339, -0.6755, -0.7400, -0.8412, -0.9577],\n",
      "          [-0.6659, -0.7273, -0.8169, -0.9034, -1.0143]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.5502, -0.7280, -0.8497, -0.9675, -1.0310],\n",
      "          [-0.7072, -0.7230, -0.8080, -0.9552, -1.0598],\n",
      "          [-0.8613, -0.8506, -0.8507, -0.9423, -1.0093],\n",
      "          [-0.8894, -0.8737, -0.8029, -0.8493, -0.8892]],\n",
      "\n",
      "         [[ 0.5501,  0.7280,  0.8496,  0.9675,  1.0309],\n",
      "          [ 0.7071,  0.7231,  0.8081,  0.9554,  1.0599],\n",
      "          [ 0.8613,  0.8507,  0.8509,  0.9424,  1.0094],\n",
      "          [ 0.8894,  0.8738,  0.8031,  0.8495,  0.8893]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5558,  0.6477,  0.7606,  0.7874,  0.8636],\n",
      "          [ 0.6471,  0.7642,  0.8692,  0.8311,  0.8172],\n",
      "          [ 0.6928,  0.8847,  1.0133,  0.9239,  0.8304],\n",
      "          [ 0.6009,  0.7636,  0.8324,  0.7158,  0.6415]],\n",
      "\n",
      "         [[-0.5559, -0.6477, -0.7606, -0.7875, -0.8636],\n",
      "          [-0.6471, -0.7641, -0.8692, -0.8310, -0.8172],\n",
      "          [-0.6928, -0.8847, -1.0132, -0.9238, -0.8303],\n",
      "          [-0.6009, -0.7635, -0.8323, -0.7157, -0.6414]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4798,  0.5686,  0.6527,  0.7379,  0.8105],\n",
      "          [ 0.5861,  0.6980,  0.7997,  0.9440,  1.0505],\n",
      "          [ 0.6538,  0.7709,  0.9163,  1.0967,  1.1845],\n",
      "          [ 0.6815,  0.8119,  0.9745,  1.1722,  1.2629]],\n",
      "\n",
      "         [[-0.4799, -0.5686, -0.6527, -0.7379, -0.8105],\n",
      "          [-0.5861, -0.6979, -0.7996, -0.9439, -1.0504],\n",
      "          [-0.6538, -0.7708, -0.9162, -1.0966, -1.1844],\n",
      "          [-0.6815, -0.8118, -0.9744, -1.1721, -1.2628]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8835,  1.0542,  1.1752,  1.2979,  1.4345],\n",
      "          [ 1.0715,  1.2010,  1.2751,  1.4964,  1.7119],\n",
      "          [ 1.2367,  1.3669,  1.4030,  1.6590,  1.9037],\n",
      "          [ 1.3564,  1.4973,  1.5044,  1.7364,  1.9701]],\n",
      "\n",
      "         [[-0.8836, -1.0542, -1.1752, -1.2979, -1.4345],\n",
      "          [-1.0715, -1.2010, -1.2750, -1.4963, -1.7118],\n",
      "          [-1.2367, -1.3668, -1.4029, -1.6589, -1.9035],\n",
      "          [-1.3564, -1.4972, -1.5043, -1.7363, -1.9700]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5688,  0.5899,  0.6300,  0.6230,  0.6272],\n",
      "          [ 0.7479,  0.7441,  0.7848,  0.8256,  0.8263],\n",
      "          [ 0.9121,  0.8911,  0.9077,  0.9677,  0.9016],\n",
      "          [ 1.0571,  1.0682,  1.0746,  1.1285,  0.9959]],\n",
      "\n",
      "         [[-0.5689, -0.5899, -0.6300, -0.6231, -0.6272],\n",
      "          [-0.7480, -0.7441, -0.7848, -0.8256, -0.8263],\n",
      "          [-0.9121, -0.8910, -0.9077, -0.9677, -0.9016],\n",
      "          [-1.0571, -1.0682, -1.0746, -1.1285, -0.9959]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.5305,  1.9285,  2.2693,  2.4200,  2.5094],\n",
      "          [ 1.9269,  2.1981,  2.4867,  2.7328,  2.9433],\n",
      "          [ 2.1969,  2.4158,  2.7102,  2.9868,  3.2114],\n",
      "          [ 2.3544,  2.6531,  3.0066,  3.3130,  3.5565]],\n",
      "\n",
      "         [[-1.5305, -1.9285, -2.2692, -2.4199, -2.5093],\n",
      "          [-1.9268, -2.1980, -2.4865, -2.7326, -2.9431],\n",
      "          [-2.1968, -2.4157, -2.7100, -2.9866, -3.2111],\n",
      "          [-2.3543, -2.6529, -3.0064, -3.3127, -3.5562]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.5345, -0.7165, -0.7962, -0.6483, -0.3935],\n",
      "          [-0.7647, -0.8540, -0.9284, -0.7262, -0.4365],\n",
      "          [-0.9419, -1.0126, -1.0347, -0.7670, -0.4330],\n",
      "          [-0.9472, -0.9845, -0.9904, -0.7148, -0.3563]],\n",
      "\n",
      "         [[ 0.5344,  0.7165,  0.7962,  0.6483,  0.3935],\n",
      "          [ 0.7647,  0.8541,  0.9285,  0.7263,  0.4365],\n",
      "          [ 0.9419,  1.0128,  1.0349,  0.7671,  0.4330],\n",
      "          [ 0.9472,  0.9846,  0.9905,  0.7149,  0.3564]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2596,  0.1777,  0.0909,  0.0333,  0.0292],\n",
      "          [ 0.1544,  0.0027, -0.1539, -0.2009, -0.1698],\n",
      "          [ 0.0652, -0.0785, -0.2363, -0.2535, -0.1769],\n",
      "          [-0.0433, -0.1452, -0.2480, -0.2716, -0.1895]],\n",
      "\n",
      "         [[-0.2596, -0.1777, -0.0909, -0.0333, -0.0292],\n",
      "          [-0.1544, -0.0026,  0.1540,  0.2011,  0.1699],\n",
      "          [-0.0652,  0.0787,  0.2364,  0.2537,  0.1771],\n",
      "          [ 0.0433,  0.1453,  0.2482,  0.2717,  0.1896]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8290,  1.0725,  1.2888,  1.4357,  1.6229],\n",
      "          [ 1.0236,  1.2874,  1.5297,  1.7117,  1.9285],\n",
      "          [ 1.2059,  1.5034,  1.7558,  1.9570,  2.1820],\n",
      "          [ 1.3281,  1.5965,  1.8154,  2.0063,  2.2577]],\n",
      "\n",
      "         [[-0.8291, -1.0725, -1.2888, -1.4357, -1.6229],\n",
      "          [-1.0236, -1.2873, -1.5296, -1.7115, -1.9284],\n",
      "          [-1.2059, -1.5033, -1.7556, -1.9569, -2.1818],\n",
      "          [-1.3281, -1.5963, -1.8152, -2.0061, -2.2575]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4505,  0.5309,  0.5148,  0.5747,  0.6524],\n",
      "          [ 0.5576,  0.6826,  0.6515,  0.7663,  0.8848],\n",
      "          [ 0.5853,  0.6912,  0.6603,  0.8149,  0.9761],\n",
      "          [ 0.6508,  0.7416,  0.6985,  0.8392,  0.9866]],\n",
      "\n",
      "         [[-0.4506, -0.5309, -0.5148, -0.5747, -0.6524],\n",
      "          [-0.5576, -0.6826, -0.6515, -0.7662, -0.8847],\n",
      "          [-0.5853, -0.6911, -0.6602, -0.8148, -0.9760],\n",
      "          [-0.6508, -0.7415, -0.6984, -0.8391, -0.9865]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8981,  1.1418,  1.3220,  1.4175,  1.5307],\n",
      "          [ 1.1080,  1.3625,  1.5325,  1.6401,  1.7569],\n",
      "          [ 1.2995,  1.5809,  1.7373,  1.8347,  1.9475],\n",
      "          [ 1.4223,  1.6996,  1.8289,  1.8978,  2.0075]],\n",
      "\n",
      "         [[-0.8982, -1.1418, -1.3219, -1.4174, -1.5307],\n",
      "          [-1.1080, -1.3624, -1.5323, -1.6399, -1.7568],\n",
      "          [-1.2995, -1.5807, -1.7371, -1.8345, -1.9473],\n",
      "          [-1.4223, -1.6995, -1.8287, -1.8976, -2.0073]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.0999, -0.2334, -0.3559, -0.3947, -0.3686],\n",
      "          [-0.1942, -0.2570, -0.3875, -0.4301, -0.4394],\n",
      "          [-0.3464, -0.3948, -0.5154, -0.5585, -0.6341],\n",
      "          [-0.2975, -0.3033, -0.4092, -0.4186, -0.4748]],\n",
      "\n",
      "         [[ 0.0998,  0.2334,  0.3559,  0.3947,  0.3686],\n",
      "          [ 0.1941,  0.2571,  0.3876,  0.4302,  0.4395],\n",
      "          [ 0.3464,  0.3949,  0.5155,  0.5587,  0.6342],\n",
      "          [ 0.2975,  0.3035,  0.4094,  0.4187,  0.4749]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8600,  1.0706,  1.2202,  1.2446,  1.2085],\n",
      "          [ 1.0033,  1.1626,  1.2718,  1.2712,  1.2296],\n",
      "          [ 1.0393,  1.1664,  1.2999,  1.3254,  1.3193],\n",
      "          [ 1.0440,  1.1893,  1.3466,  1.3744,  1.3851]],\n",
      "\n",
      "         [[-0.8601, -1.0707, -1.2202, -1.2446, -1.2085],\n",
      "          [-1.0033, -1.1625, -1.2717, -1.2711, -1.2295],\n",
      "          [-1.0394, -1.1663, -1.2998, -1.3253, -1.3192],\n",
      "          [-1.0440, -1.1893, -1.3465, -1.3744, -1.3850]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6003,  0.5772,  0.5240,  0.3749,  0.1977],\n",
      "          [ 0.6454,  0.5099,  0.3970,  0.2465,  0.0836],\n",
      "          [ 0.6453,  0.4586,  0.3575,  0.1974,  0.0425],\n",
      "          [ 0.5729,  0.3465,  0.2237,  0.0414, -0.1265]],\n",
      "\n",
      "         [[-0.6003, -0.5772, -0.5240, -0.3750, -0.1978],\n",
      "          [-0.6454, -0.5099, -0.3969, -0.2465, -0.0836],\n",
      "          [-0.6453, -0.4586, -0.3574, -0.1972, -0.0424],\n",
      "          [-0.5729, -0.3464, -0.2236, -0.0413,  0.1266]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6959,  0.8545,  0.9323,  0.9510,  0.9886],\n",
      "          [ 0.8246,  0.9749,  1.0628,  1.1195,  1.1898],\n",
      "          [ 0.8848,  0.9913,  1.0912,  1.1677,  1.2591],\n",
      "          [ 1.0122,  1.1314,  1.2508,  1.3493,  1.4769]],\n",
      "\n",
      "         [[-0.6959, -0.8545, -0.9323, -0.9510, -0.9886],\n",
      "          [-0.8247, -0.9748, -1.0628, -1.1194, -1.1897],\n",
      "          [-0.8848, -0.9912, -1.0911, -1.1676, -1.2591],\n",
      "          [-1.0122, -1.1313, -1.2507, -1.3492, -1.4768]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8869,  1.0540,  1.1561,  1.2116,  1.2866],\n",
      "          [ 1.0166,  1.1057,  1.1797,  1.2986,  1.4299],\n",
      "          [ 1.0870,  1.1353,  1.2213,  1.3924,  1.5602],\n",
      "          [ 1.2024,  1.3133,  1.4572,  1.6750,  1.8561]],\n",
      "\n",
      "         [[-0.8870, -1.0540, -1.1561, -1.2116, -1.2866],\n",
      "          [-1.0166, -1.1056, -1.1796, -1.2985, -1.4298],\n",
      "          [-1.0870, -1.1352, -1.2212, -1.3923, -1.5601],\n",
      "          [-1.2024, -1.3132, -1.4571, -1.6749, -1.8560]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1769,  1.4910,  1.7596,  1.8549,  1.9155],\n",
      "          [ 1.3967,  1.5662,  1.7255,  1.7779,  1.8235],\n",
      "          [ 1.5341,  1.5909,  1.6463,  1.6533,  1.6857],\n",
      "          [ 1.5380,  1.5652,  1.5754,  1.6069,  1.7168]],\n",
      "\n",
      "         [[-1.1769, -1.4910, -1.7595, -1.8548, -1.9154],\n",
      "          [-1.3966, -1.5660, -1.7253, -1.7777, -1.8233],\n",
      "          [-1.5340, -1.5907, -1.6461, -1.6531, -1.6855],\n",
      "          [-1.5380, -1.5651, -1.5753, -1.6068, -1.7166]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.6320,  2.0597,  2.4899,  2.6585,  2.7969],\n",
      "          [ 2.0593,  2.3563,  2.7561,  2.9763,  3.2010],\n",
      "          [ 2.4160,  2.7266,  3.1942,  3.4612,  3.7359],\n",
      "          [ 2.5713,  2.9091,  3.4127,  3.6839,  3.9683]],\n",
      "\n",
      "         [[-1.6320, -2.0596, -2.4898, -2.6584, -2.7967],\n",
      "          [-2.0592, -2.3562, -2.7559, -2.9761, -3.2007],\n",
      "          [-2.4159, -2.7264, -3.1939, -3.4609, -3.7356],\n",
      "          [-2.5712, -2.9089, -3.4124, -3.6836, -3.9680]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9020,  1.0894,  1.2116,  1.2040,  1.1566],\n",
      "          [ 1.1501,  1.2819,  1.3547,  1.3564,  1.3379],\n",
      "          [ 1.3396,  1.4354,  1.4946,  1.4908,  1.4814],\n",
      "          [ 1.5139,  1.6557,  1.7300,  1.6997,  1.6437]],\n",
      "\n",
      "         [[-0.9021, -1.0894, -1.2116, -1.2040, -1.1567],\n",
      "          [-1.1501, -1.2819, -1.3546, -1.3563, -1.3378],\n",
      "          [-1.3396, -1.4353, -1.4945, -1.4907, -1.4813],\n",
      "          [-1.5140, -1.6556, -1.7299, -1.6996, -1.6436]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7539,  2.2077,  2.6455,  2.8360,  2.9916],\n",
      "          [ 2.1994,  2.4911,  2.9683,  3.2606,  3.5372],\n",
      "          [ 2.6074,  2.9622,  3.5557,  3.9362,  4.2736],\n",
      "          [ 2.7682,  3.2024,  3.8526,  4.2499,  4.5283]],\n",
      "\n",
      "         [[-1.7539, -2.2076, -2.6454, -2.8358, -2.9914],\n",
      "          [-2.1993, -2.4909, -2.9681, -3.2603, -3.5369],\n",
      "          [-2.6073, -2.9620, -3.5554, -3.9358, -4.2733],\n",
      "          [-2.7681, -3.2021, -3.8523, -4.2496, -4.5279]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2104,  1.4328,  1.5544,  1.5360,  1.3899],\n",
      "          [ 1.4718,  1.4966,  1.5178,  1.5282,  1.4382],\n",
      "          [ 1.6611,  1.5888,  1.5666,  1.5976,  1.5450],\n",
      "          [ 1.8339,  1.7676,  1.7299,  1.7629,  1.7358]],\n",
      "\n",
      "         [[-1.2105, -1.4328, -1.5544, -1.5360, -1.3899],\n",
      "          [-1.4718, -1.4965, -1.5176, -1.5280, -1.4381],\n",
      "          [-1.6611, -1.5887, -1.5664, -1.5974, -1.5449],\n",
      "          [-1.8338, -1.7675, -1.7298, -1.7628, -1.7357]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9768,  2.5854,  3.0467,  3.2836,  3.4743],\n",
      "          [ 2.5284,  2.8595,  3.4808,  3.8556,  4.1638],\n",
      "          [ 2.9949,  3.4406,  4.2198,  4.7231,  5.0597],\n",
      "          [ 3.2376,  3.7680,  4.6258,  5.1438,  5.4814]],\n",
      "\n",
      "         [[-1.9768, -2.5853, -3.0465, -3.2834, -3.4741],\n",
      "          [-2.5283, -2.8593, -3.4805, -3.8552, -4.1634],\n",
      "          [-2.9947, -3.4402, -4.2194, -4.7227, -5.0592],\n",
      "          [-3.2374, -3.7677, -4.6254, -5.1433, -5.4809]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2511,  0.3003,  0.3327,  0.3646,  0.3922],\n",
      "          [ 0.4560,  0.6156,  0.6780,  0.7195,  0.6953],\n",
      "          [ 0.6083,  0.8314,  0.9868,  1.0136,  0.9089],\n",
      "          [ 0.6932,  0.8966,  1.1263,  1.1604,  1.0934]],\n",
      "\n",
      "         [[-0.2511, -0.3003, -0.3327, -0.3646, -0.3922],\n",
      "          [-0.4560, -0.6155, -0.6779, -0.7194, -0.6953],\n",
      "          [-0.6082, -0.8313, -0.9866, -1.0135, -0.9088],\n",
      "          [-0.6932, -0.8965, -1.1262, -1.1603, -1.0934]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.2270, -0.3575, -0.4211, -0.4946, -0.5218],\n",
      "          [-0.3525, -0.3883, -0.4171, -0.5135, -0.5730],\n",
      "          [-0.4579, -0.4367, -0.4224, -0.4927, -0.5439],\n",
      "          [-0.4706, -0.4242, -0.4032, -0.4764, -0.5070]],\n",
      "\n",
      "         [[ 0.2269,  0.3575,  0.4211,  0.4945,  0.5218],\n",
      "          [ 0.3525,  0.3884,  0.4172,  0.5136,  0.5731],\n",
      "          [ 0.4579,  0.4369,  0.4225,  0.4929,  0.5441],\n",
      "          [ 0.4706,  0.4243,  0.4033,  0.4766,  0.5072]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 2.1050,  2.7165,  3.2391,  3.4795,  3.6527],\n",
      "          [ 2.6699,  2.9257,  3.5403,  3.8877,  4.1835],\n",
      "          [ 3.1714,  3.5373,  4.3045,  4.7394,  5.1085],\n",
      "          [ 3.3687,  3.8124,  4.6254,  5.0851,  5.4018]],\n",
      "\n",
      "         [[-2.1050, -2.7163, -3.2389, -3.4793, -3.6524],\n",
      "          [-2.6698, -2.9254, -3.5400, -3.8872, -4.1831],\n",
      "          [-3.1712, -3.5370, -4.3041, -4.7389, -5.1080],\n",
      "          [-3.3685, -3.8120, -4.6249, -5.0846, -5.4012]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.3674, -0.5520, -0.6616, -0.7585, -0.8385],\n",
      "          [-0.4615, -0.5125, -0.5476, -0.6180, -0.7015],\n",
      "          [-0.4739, -0.4543, -0.4237, -0.4912, -0.5971],\n",
      "          [-0.3477, -0.2977, -0.2320, -0.3146, -0.4171]],\n",
      "\n",
      "         [[ 0.3673,  0.5520,  0.6616,  0.7585,  0.8384],\n",
      "          [ 0.4615,  0.5126,  0.5477,  0.6182,  0.7016],\n",
      "          [ 0.4739,  0.4544,  0.4238,  0.4913,  0.5972],\n",
      "          [ 0.3476,  0.2977,  0.2321,  0.3147,  0.4172]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5990,  0.8365,  1.0434,  1.2007,  1.3730],\n",
      "          [ 0.6402,  0.9010,  1.1431,  1.3280,  1.5250],\n",
      "          [ 0.6564,  0.9346,  1.2456,  1.4907,  1.7526],\n",
      "          [ 0.8096,  1.1963,  1.5845,  1.8408,  2.0989]],\n",
      "\n",
      "         [[-0.5991, -0.8365, -1.0434, -1.2007, -1.3730],\n",
      "          [-0.6402, -0.9009, -1.1430, -1.3279, -1.5249],\n",
      "          [-0.6564, -0.9346, -1.2455, -1.4906, -1.7525],\n",
      "          [-0.8096, -1.1962, -1.5844, -1.8407, -2.0988]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9683,  1.1757,  1.3113,  1.4141,  1.5279],\n",
      "          [ 1.1725,  1.3512,  1.4537,  1.6630,  1.8653],\n",
      "          [ 1.3634,  1.5891,  1.7186,  2.0010,  2.2668],\n",
      "          [ 1.4704,  1.7300,  1.8509,  2.1022,  2.3589]],\n",
      "\n",
      "         [[-0.9684, -1.1757, -1.3113, -1.4141, -1.5279],\n",
      "          [-1.1725, -1.3511, -1.4536, -1.6628, -1.8652],\n",
      "          [-1.3634, -1.5890, -1.7185, -2.0008, -2.2666],\n",
      "          [-1.4704, -1.7299, -1.8507, -2.1020, -2.3587]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.4047, -0.5132, -0.5485, -0.4279, -0.2155],\n",
      "          [-0.6585, -0.6779, -0.7447, -0.6503, -0.4988],\n",
      "          [-0.9218, -0.8968, -0.9317, -0.8409, -0.7087],\n",
      "          [-0.9658, -0.8488, -0.8308, -0.7627, -0.6914]],\n",
      "\n",
      "         [[ 0.4046,  0.5132,  0.5485,  0.4278,  0.2154],\n",
      "          [ 0.6585,  0.6779,  0.7448,  0.6504,  0.4988],\n",
      "          [ 0.9217,  0.8969,  0.9318,  0.8409,  0.7087],\n",
      "          [ 0.9658,  0.8489,  0.8309,  0.7627,  0.6914]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9351,  1.1863,  1.3127,  1.4060,  1.4691],\n",
      "          [ 1.1314,  1.3423,  1.4449,  1.5843,  1.6918],\n",
      "          [ 1.2258,  1.3547,  1.4487,  1.6283,  1.8090],\n",
      "          [ 1.4798,  1.6960,  1.8556,  2.0543,  2.2610]],\n",
      "\n",
      "         [[-0.9352, -1.1863, -1.3127, -1.4060, -1.4691],\n",
      "          [-1.1315, -1.3423, -1.4449, -1.5842, -1.6917],\n",
      "          [-1.2258, -1.3546, -1.4486, -1.6282, -1.8089],\n",
      "          [-1.4798, -1.6959, -1.8555, -2.0542, -2.2609]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2567,  0.1855,  0.0961,  0.0327, -0.0454],\n",
      "          [ 0.1732,  0.0102, -0.1888, -0.2779, -0.3464],\n",
      "          [ 0.0131, -0.2050, -0.4134, -0.5239, -0.5766],\n",
      "          [-0.2101, -0.4291, -0.5983, -0.6993, -0.7320]],\n",
      "\n",
      "         [[-0.2568, -0.1855, -0.0961, -0.0328,  0.0454],\n",
      "          [-0.1732, -0.0101,  0.1889,  0.2780,  0.3465],\n",
      "          [-0.0132,  0.2051,  0.4135,  0.5240,  0.5767],\n",
      "          [ 0.2101,  0.4292,  0.5983,  0.6994,  0.7321]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 1]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2338,  1.5023,  1.7099,  1.8086,  1.8822],\n",
      "          [ 1.5454,  1.7201,  1.8705,  2.0146,  2.1653],\n",
      "          [ 1.7468,  1.8812,  2.0210,  2.2230,  2.4465],\n",
      "          [ 1.8393,  1.9826,  2.1266,  2.3395,  2.5757]],\n",
      "\n",
      "         [[-1.2338, -1.5023, -1.7098, -1.8085, -1.8822],\n",
      "          [-1.5454, -1.7200, -1.8704, -2.0144, -2.1651],\n",
      "          [-1.7467, -1.8810, -2.0208, -2.2228, -2.4463],\n",
      "          [-1.8393, -1.9825, -2.1265, -2.3393, -2.5755]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0433,  1.2659,  1.4369,  1.4577,  1.3699],\n",
      "          [ 1.2940,  1.3955,  1.5014,  1.5461,  1.4927],\n",
      "          [ 1.4403,  1.4876,  1.5992,  1.6827,  1.6444],\n",
      "          [ 1.5797,  1.6741,  1.7896,  1.8323,  1.7820]],\n",
      "\n",
      "         [[-1.0433, -1.2659, -1.4369, -1.4577, -1.3699],\n",
      "          [-1.2940, -1.3954, -1.5014, -1.5460, -1.4927],\n",
      "          [-1.4403, -1.4875, -1.5991, -1.6826, -1.6443],\n",
      "          [-1.5797, -1.6740, -1.7895, -1.8322, -1.7819]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.1841, -0.2675, -0.3555, -0.3954, -0.3798],\n",
      "          [-0.1887, -0.1605, -0.2666, -0.3075, -0.3305],\n",
      "          [-0.2019, -0.1926, -0.2796, -0.2381, -0.2089],\n",
      "          [-0.0049, -0.0118, -0.1179, -0.0044,  0.1058]],\n",
      "\n",
      "         [[ 0.1840,  0.2675,  0.3555,  0.3954,  0.3798],\n",
      "          [ 0.1887,  0.1606,  0.2667,  0.3076,  0.3305],\n",
      "          [ 0.2019,  0.1927,  0.2797,  0.2382,  0.2090],\n",
      "          [ 0.0049,  0.0119,  0.1180,  0.0045, -0.1057]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.5886,  2.0180,  2.4151,  2.5771,  2.7059],\n",
      "          [ 1.9936,  2.3055,  2.7238,  2.9806,  3.2079],\n",
      "          [ 2.3631,  2.7012,  3.2181,  3.5279,  3.8040],\n",
      "          [ 2.4966,  2.8868,  3.4467,  3.7769,  3.9993]],\n",
      "\n",
      "         [[-1.5886, -2.0179, -2.4150, -2.5769, -2.7057],\n",
      "          [-1.9935, -2.3054, -2.7236, -2.9804, -3.2077],\n",
      "          [-2.3631, -2.7010, -3.2178, -3.5276, -3.8037],\n",
      "          [-2.4966, -2.8866, -3.4465, -3.7766, -3.9989]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.1494, -0.3129, -0.4161, -0.2874, -0.1234],\n",
      "          [-0.3542, -0.5253, -0.6713, -0.4535, -0.1824],\n",
      "          [-0.6361, -0.8161, -0.8990, -0.5867, -0.1906],\n",
      "          [-0.8438, -1.0140, -1.0695, -0.7565, -0.3518]],\n",
      "\n",
      "         [[ 0.1493,  0.3128,  0.4161,  0.2873,  0.1233],\n",
      "          [ 0.3542,  0.5253,  0.6713,  0.4535,  0.1825],\n",
      "          [ 0.6360,  0.8162,  0.8991,  0.5868,  0.1907],\n",
      "          [ 0.8438,  1.0140,  1.0696,  0.7566,  0.3518]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8823,  1.0748,  1.2050,  1.3443,  1.4197],\n",
      "          [ 1.0860,  1.2284,  1.2917,  1.5080,  1.6594],\n",
      "          [ 1.2374,  1.3584,  1.3867,  1.6200,  1.8138],\n",
      "          [ 1.3438,  1.4990,  1.5376,  1.7770,  1.9824]],\n",
      "\n",
      "         [[-0.8824, -1.0748, -1.2050, -1.3443, -1.4197],\n",
      "          [-1.0861, -1.2284, -1.2916, -1.5079, -1.6593],\n",
      "          [-1.2374, -1.3584, -1.3866, -1.6199, -1.8137],\n",
      "          [-1.3438, -1.4989, -1.5375, -1.7769, -1.9824]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4579,  0.5616,  0.6737,  0.7095,  0.7687],\n",
      "          [ 0.5799,  0.7559,  0.9142,  0.9680,  1.0185],\n",
      "          [ 0.7094,  0.9394,  1.1232,  1.1773,  1.2275],\n",
      "          [ 0.8107,  1.0496,  1.1900,  1.2206,  1.2832]],\n",
      "\n",
      "         [[-0.4580, -0.5616, -0.6737, -0.7095, -0.7687],\n",
      "          [-0.5799, -0.7558, -0.9141, -0.9679, -1.0184],\n",
      "          [-0.7094, -0.9393, -1.1230, -1.1771, -1.2273],\n",
      "          [-0.8106, -1.0495, -1.1899, -1.2204, -1.2830]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9564,  1.0888,  1.1294,  1.1420,  1.1630],\n",
      "          [ 1.1378,  1.1384,  1.0984,  1.1483,  1.2432],\n",
      "          [ 1.2020,  1.1007,  1.0325,  1.1070,  1.2471],\n",
      "          [ 1.2819,  1.2135,  1.1781,  1.2383,  1.3630]],\n",
      "\n",
      "         [[-0.9564, -1.0888, -1.1294, -1.1420, -1.1630],\n",
      "          [-1.1378, -1.1383, -1.0983, -1.1482, -1.2430],\n",
      "          [-1.2020, -1.1006, -1.0323, -1.1069, -1.2470],\n",
      "          [-1.2819, -1.2134, -1.1779, -1.2381, -1.3629]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8186,  2.3369,  2.7907,  3.0073,  3.1827],\n",
      "          [ 2.2847,  2.6116,  3.1733,  3.5121,  3.8140],\n",
      "          [ 2.7041,  3.1024,  3.8004,  4.2519,  4.6147],\n",
      "          [ 2.8843,  3.3635,  4.1191,  4.5924,  4.9342]],\n",
      "\n",
      "         [[-1.8186, -2.3368, -2.7906, -3.0071, -3.1825],\n",
      "          [-2.2846, -2.6114, -3.1730, -3.5118, -3.8136],\n",
      "          [-2.7040, -3.1021, -3.8001, -4.2516, -4.6142],\n",
      "          [-2.8842, -3.3632, -4.1188, -4.5920, -4.9337]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8851,  2.4379,  2.8885,  3.0992,  3.2563],\n",
      "          [ 2.4282,  2.7765,  3.3160,  3.6252,  3.8839],\n",
      "          [ 2.8598,  3.3294,  4.0035,  4.3917,  4.6943],\n",
      "          [ 3.0725,  3.6625,  4.4115,  4.7784,  5.0286]],\n",
      "\n",
      "         [[-1.8851, -2.4378, -2.8884, -3.0990, -3.2561],\n",
      "          [-2.4281, -2.7763, -3.3157, -3.6248, -3.8836],\n",
      "          [-2.8596, -3.3291, -4.0031, -4.3913, -4.6938],\n",
      "          [-3.0723, -3.6621, -4.4111, -4.7780, -5.0281]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5780,  0.6453,  0.6237,  0.6084,  0.5930],\n",
      "          [ 0.5786,  0.5699,  0.4811,  0.4920,  0.5197],\n",
      "          [ 0.5198,  0.4568,  0.3642,  0.4138,  0.4986],\n",
      "          [ 0.4792,  0.4308,  0.3690,  0.4432,  0.5607]],\n",
      "\n",
      "         [[-0.5781, -0.6453, -0.6237, -0.6084, -0.5930],\n",
      "          [-0.5787, -0.5698, -0.4811, -0.4919, -0.5196],\n",
      "          [-0.5198, -0.4568, -0.3641, -0.4137, -0.4985],\n",
      "          [-0.4793, -0.4307, -0.3689, -0.4431, -0.5606]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1966,  1.4948,  1.6915,  1.7763,  1.8588],\n",
      "          [ 1.5382,  1.8159,  1.9537,  2.0821,  2.1613],\n",
      "          [ 1.7575,  2.0153,  2.1495,  2.2981,  2.3436],\n",
      "          [ 1.9947,  2.3287,  2.5385,  2.7350,  2.8004]],\n",
      "\n",
      "         [[-1.1967, -1.4948, -1.6915, -1.7763, -1.8588],\n",
      "          [-1.5382, -1.8158, -1.9536, -2.0820, -2.1612],\n",
      "          [-1.7575, -2.0152, -2.1494, -2.2980, -2.3435],\n",
      "          [-1.9947, -2.3286, -2.5384, -2.7348, -2.8002]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0580,  1.2632,  1.4222,  1.4892,  1.5142],\n",
      "          [ 1.2843,  1.3918,  1.4883,  1.5723,  1.6282],\n",
      "          [ 1.4109,  1.4968,  1.6049,  1.6876,  1.7677],\n",
      "          [ 1.4780,  1.6247,  1.7554,  1.8101,  1.8669]],\n",
      "\n",
      "         [[-1.0580, -1.2632, -1.4222, -1.4892, -1.5142],\n",
      "          [-1.2843, -1.3918, -1.4882, -1.5722, -1.6281],\n",
      "          [-1.4109, -1.4967, -1.6048, -1.6875, -1.7675],\n",
      "          [-1.4780, -1.6246, -1.7553, -1.8100, -1.8668]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9357,  2.4757,  2.9945,  3.2603,  3.4972],\n",
      "          [ 2.4214,  2.7236,  3.3764,  3.7805,  4.1601],\n",
      "          [ 2.9244,  3.3299,  4.1649,  4.7211,  5.1536],\n",
      "          [ 3.1434,  3.6513,  4.5912,  5.1567,  5.5731]],\n",
      "\n",
      "         [[-1.9357, -2.4756, -2.9943, -3.2601, -3.4970],\n",
      "          [-2.4213, -2.7234, -3.3760, -3.7801, -4.1597],\n",
      "          [-2.9243, -3.3296, -4.1645, -4.7207, -5.1531],\n",
      "          [-3.1432, -3.6509, -4.5908, -5.1562, -5.5726]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2260,  0.1557,  0.1311, -0.2022, -0.5980],\n",
      "          [ 0.1079, -0.0253,  0.0033, -0.3627, -0.7747],\n",
      "          [-0.0131, -0.2518, -0.1838, -0.5843, -1.0221],\n",
      "          [ 0.0450, -0.1785, -0.0658, -0.4550, -0.8833]],\n",
      "\n",
      "         [[-0.2261, -0.1557, -0.1311,  0.2022,  0.5980],\n",
      "          [-0.1079,  0.0253, -0.0032,  0.3628,  0.7748],\n",
      "          [ 0.0130,  0.2519,  0.1839,  0.5844,  1.0222],\n",
      "          [-0.0451,  0.1785,  0.0658,  0.4551,  0.8833]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 1 1]\n",
      " [0 1 0 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1780,  1.4691,  1.7017,  1.8759,  2.0099],\n",
      "          [ 1.4426,  1.6268,  1.7975,  2.0227,  2.2074],\n",
      "          [ 1.6149,  1.7380,  1.8852,  2.1467,  2.3791],\n",
      "          [ 1.7897,  1.9631,  2.1480,  2.4153,  2.6647]],\n",
      "\n",
      "         [[-1.1781, -1.4690, -1.7017, -1.8759, -2.0098],\n",
      "          [-1.4426, -1.6267, -1.7974, -2.0226, -2.2073],\n",
      "          [-1.6149, -1.7379, -1.8850, -2.1465, -2.3789],\n",
      "          [-1.7897, -1.9630, -2.1478, -2.4151, -2.6645]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3641,  1.7171,  2.0149,  2.1540,  2.2553],\n",
      "          [ 1.7555,  2.0387,  2.3247,  2.5008,  2.6678],\n",
      "          [ 2.0212,  2.2664,  2.5796,  2.7924,  3.0004],\n",
      "          [ 2.2221,  2.5043,  2.8801,  3.1036,  3.3262]],\n",
      "\n",
      "         [[-1.3642, -1.7171, -2.0149, -2.1540, -2.2553],\n",
      "          [-1.7555, -2.0385, -2.3245, -2.5006, -2.6676],\n",
      "          [-2.0212, -2.2662, -2.5794, -2.7922, -3.0001],\n",
      "          [-2.2221, -2.5042, -2.8799, -3.1034, -3.3260]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1082,  1.3294,  1.4941,  1.5910,  1.6405],\n",
      "          [ 1.3456,  1.4497,  1.5608,  1.6976,  1.7932],\n",
      "          [ 1.4931,  1.5496,  1.6747,  1.8640,  2.0194],\n",
      "          [ 1.6020,  1.6937,  1.8559,  2.0451,  2.2103]],\n",
      "\n",
      "         [[-1.1082, -1.3294, -1.4941, -1.5910, -1.6405],\n",
      "          [-1.3456, -1.4496, -1.5607, -1.6975, -1.7931],\n",
      "          [-1.4931, -1.5495, -1.6746, -1.8639, -2.0193],\n",
      "          [-1.6020, -1.6936, -1.8558, -2.0449, -2.2102]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5819,  0.6450,  0.6809,  0.7040,  0.6872],\n",
      "          [ 0.6318,  0.6414,  0.6526,  0.7870,  0.8500],\n",
      "          [ 0.6679,  0.6964,  0.7101,  0.8483,  0.9424],\n",
      "          [ 0.7752,  0.9171,  0.9835,  1.0732,  1.1194]],\n",
      "\n",
      "         [[-0.5820, -0.6450, -0.6809, -0.7040, -0.6873],\n",
      "          [-0.6318, -0.6414, -0.6525, -0.7870, -0.8499],\n",
      "          [-0.6679, -0.6964, -0.7100, -0.8482, -0.9423],\n",
      "          [-0.7753, -0.9171, -0.9834, -1.0731, -1.1194]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1892,  1.4761,  1.7015,  1.8271,  1.8582],\n",
      "          [ 1.5034,  1.7078,  1.9014,  2.0745,  2.1320],\n",
      "          [ 1.7138,  1.8940,  2.1023,  2.2732,  2.3314],\n",
      "          [ 1.8244,  2.0539,  2.2773,  2.4029,  2.4438]],\n",
      "\n",
      "         [[-1.1893, -1.4761, -1.7015, -1.8271, -1.8582],\n",
      "          [-1.5035, -1.7077, -1.9013, -2.0744, -2.1319],\n",
      "          [-1.7138, -1.8939, -2.1022, -2.2731, -2.3312],\n",
      "          [-1.8244, -2.0538, -2.2772, -2.4027, -2.4437]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4589,  0.5175,  0.5022,  0.4791,  0.5158],\n",
      "          [ 0.5088,  0.5935,  0.5675,  0.5441,  0.5931],\n",
      "          [ 0.5239,  0.6438,  0.6568,  0.6431,  0.7111],\n",
      "          [ 0.4916,  0.6288,  0.6697,  0.6574,  0.7272]],\n",
      "\n",
      "         [[-0.4590, -0.5175, -0.5022, -0.4791, -0.5158],\n",
      "          [-0.5088, -0.5935, -0.5674, -0.5440, -0.5930],\n",
      "          [-0.5240, -0.6438, -0.6567, -0.6430, -0.7110],\n",
      "          [-0.4917, -0.6287, -0.6696, -0.6573, -0.7271]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2311,  0.3295,  0.3415,  0.5018,  0.6183],\n",
      "          [ 0.3815,  0.5616,  0.5005,  0.6498,  0.7874],\n",
      "          [ 0.4227,  0.6076,  0.5876,  0.7028,  0.8507],\n",
      "          [ 0.5379,  0.7883,  0.8461,  0.9076,  0.9957]],\n",
      "\n",
      "         [[-0.2311, -0.3295, -0.3415, -0.5018, -0.6183],\n",
      "          [-0.3815, -0.5616, -0.5004, -0.6497, -0.7874],\n",
      "          [-0.4227, -0.6075, -0.5875, -0.7027, -0.8507],\n",
      "          [-0.5379, -0.7882, -0.8459, -0.9075, -0.9956]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6812,  0.8248,  0.8875,  0.8745,  0.8608],\n",
      "          [ 0.8540,  1.0100,  1.0599,  1.0615,  1.0560],\n",
      "          [ 0.9803,  1.1409,  1.2074,  1.2309,  1.2439],\n",
      "          [ 1.0113,  1.1019,  1.1323,  1.1915,  1.2504]],\n",
      "\n",
      "         [[-0.6812, -0.8248, -0.8875, -0.8745, -0.8608],\n",
      "          [-0.8540, -1.0099, -1.0598, -1.0614, -1.0559],\n",
      "          [-0.9803, -1.1408, -1.2072, -1.2308, -1.2438],\n",
      "          [-1.0113, -1.1018, -1.1322, -1.1914, -1.2502]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1216,  1.3731,  1.5988,  1.6609,  1.6374],\n",
      "          [ 1.3458,  1.4302,  1.5642,  1.5738,  1.5264],\n",
      "          [ 1.4644,  1.4737,  1.6043,  1.6084,  1.5638],\n",
      "          [ 1.4906,  1.4774,  1.5836,  1.5257,  1.4245]],\n",
      "\n",
      "         [[-1.1217, -1.3731, -1.5988, -1.6609, -1.6374],\n",
      "          [-1.3458, -1.4302, -1.5641, -1.5737, -1.5263],\n",
      "          [-1.4644, -1.4736, -1.6042, -1.6082, -1.5636],\n",
      "          [-1.4906, -1.4773, -1.5835, -1.5256, -1.4244]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.4513,  1.8516,  2.1619,  2.3302,  2.4392],\n",
      "          [ 1.7442,  1.9834,  2.2152,  2.4128,  2.5927],\n",
      "          [ 1.9236,  2.0390,  2.2215,  2.4391,  2.6492],\n",
      "          [ 2.0796,  2.2208,  2.4057,  2.6283,  2.8600]],\n",
      "\n",
      "         [[-1.4514, -1.8515, -2.1618, -2.3301, -2.4391],\n",
      "          [-1.7442, -1.9832, -2.2150, -2.4126, -2.5925],\n",
      "          [-1.9235, -2.0388, -2.2213, -2.4388, -2.6489],\n",
      "          [-2.0795, -2.2206, -2.4055, -2.6281, -2.8597]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3931,  0.4533,  0.5218,  0.4884,  0.4242],\n",
      "          [ 0.4343,  0.5060,  0.6193,  0.6510,  0.5923],\n",
      "          [ 0.5011,  0.5812,  0.7436,  0.8401,  0.7816],\n",
      "          [ 0.5684,  0.6461,  0.7979,  0.9102,  0.8398]],\n",
      "\n",
      "         [[-0.3932, -0.4533, -0.5218, -0.4884, -0.4242],\n",
      "          [-0.4344, -0.5059, -0.6193, -0.6510, -0.5922],\n",
      "          [-0.5012, -0.5811, -0.7435, -0.8400, -0.7815],\n",
      "          [-0.5685, -0.6461, -0.7978, -0.9102, -0.8397]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3085,  0.2617,  0.1827,  0.1503,  0.1592],\n",
      "          [ 0.3641,  0.3417,  0.2626,  0.2359,  0.2362],\n",
      "          [ 0.4326,  0.4630,  0.4605,  0.4535,  0.4753],\n",
      "          [ 0.4567,  0.5015,  0.5408,  0.5380,  0.5467]],\n",
      "\n",
      "         [[-0.3086, -0.2617, -0.1827, -0.1503, -0.1592],\n",
      "          [-0.3641, -0.3416, -0.2625, -0.2359, -0.2361],\n",
      "          [-0.4327, -0.4629, -0.4604, -0.4534, -0.4752],\n",
      "          [-0.4568, -0.5014, -0.5407, -0.5379, -0.5466]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6903,  0.8498,  0.9661,  0.9450,  0.9445],\n",
      "          [ 0.7708,  0.8861,  0.9556,  0.9013,  0.9047],\n",
      "          [ 0.8123,  0.9063,  0.9768,  0.9370,  0.9596],\n",
      "          [ 0.7654,  0.8134,  0.8542,  0.7860,  0.7873]],\n",
      "\n",
      "         [[-0.6904, -0.8498, -0.9661, -0.9449, -0.9445],\n",
      "          [-0.7708, -0.8860, -0.9554, -0.9012, -0.9045],\n",
      "          [-0.8123, -0.9062, -0.9767, -0.9368, -0.9594],\n",
      "          [-0.7654, -0.8133, -0.8541, -0.7858, -0.7872]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1582,  0.1312,  0.1611,  0.2409,  0.3501],\n",
      "          [ 0.1360,  0.1222,  0.1389,  0.2717,  0.4548],\n",
      "          [ 0.1404,  0.1908,  0.2316,  0.4133,  0.6357],\n",
      "          [ 0.1295,  0.2385,  0.3039,  0.4658,  0.6775]],\n",
      "\n",
      "         [[-0.1583, -0.1312, -0.1611, -0.2409, -0.3502],\n",
      "          [-0.1360, -0.1221, -0.1387, -0.2716, -0.4548],\n",
      "          [-0.1404, -0.1907, -0.2314, -0.4132, -0.6356],\n",
      "          [-0.1295, -0.2384, -0.3037, -0.4657, -0.6774]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4503,  0.5608,  0.6390,  0.7351,  0.8443],\n",
      "          [ 0.5508,  0.6900,  0.7811,  0.9253,  1.0558],\n",
      "          [ 0.6907,  0.8330,  0.9289,  1.1039,  1.2432],\n",
      "          [ 0.8777,  1.0267,  1.1146,  1.2760,  1.4223]],\n",
      "\n",
      "         [[-0.4504, -0.5608, -0.6390, -0.7351, -0.8443],\n",
      "          [-0.5509, -0.6899, -0.7809, -0.9251, -1.0556],\n",
      "          [-0.6907, -0.8329, -0.9287, -1.1037, -1.2431],\n",
      "          [-0.8777, -1.0267, -1.1145, -1.2759, -1.4222]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9349,  1.1016,  1.2428,  1.3062,  1.3694],\n",
      "          [ 1.1315,  1.2108,  1.2855,  1.3644,  1.4420],\n",
      "          [ 1.3052,  1.3569,  1.3818,  1.4518,  1.5168],\n",
      "          [ 1.3666,  1.3880,  1.3716,  1.4307,  1.5220]],\n",
      "\n",
      "         [[-0.9350, -1.1016, -1.2427, -1.3062, -1.3694],\n",
      "          [-1.1315, -1.2107, -1.2853, -1.3642, -1.4419],\n",
      "          [-1.3052, -1.3568, -1.3816, -1.4516, -1.5166],\n",
      "          [-1.3665, -1.3879, -1.3714, -1.4305, -1.5218]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6823,  0.8132,  0.8736,  0.8703,  0.9159],\n",
      "          [ 0.8764,  1.0375,  1.1014,  1.1291,  1.2091],\n",
      "          [ 1.0353,  1.2340,  1.3357,  1.4101,  1.5042],\n",
      "          [ 1.1684,  1.3665,  1.4476,  1.4837,  1.5291]],\n",
      "\n",
      "         [[-0.6824, -0.8132, -0.8736, -0.8703, -0.9159],\n",
      "          [-0.8765, -1.0374, -1.1013, -1.1289, -1.2089],\n",
      "          [-1.0353, -1.2338, -1.3356, -1.4099, -1.5041],\n",
      "          [-1.1684, -1.3664, -1.4474, -1.4836, -1.5289]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9257,  2.4785,  2.9538,  3.1673,  3.3343],\n",
      "          [ 2.4369,  2.7630,  3.3117,  3.6237,  3.9019],\n",
      "          [ 2.8713,  3.2992,  3.9773,  4.3634,  4.7098],\n",
      "          [ 3.0372,  3.5673,  4.3096,  4.7224,  4.9891]],\n",
      "\n",
      "         [[-1.9257, -2.4784, -2.9536, -3.1671, -3.3341],\n",
      "          [-2.4368, -2.7628, -3.3113, -3.6233, -3.9015],\n",
      "          [-2.8712, -3.2989, -3.9769, -4.3630, -4.7093],\n",
      "          [-3.0370, -3.5669, -4.3092, -4.7220, -4.9886]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6012,  0.6869,  0.7233,  0.6534,  0.6012],\n",
      "          [ 0.6848,  0.7383,  0.7814,  0.7522,  0.7349],\n",
      "          [ 0.7321,  0.7870,  0.8846,  0.9414,  0.9757],\n",
      "          [ 0.8212,  0.9280,  1.0622,  1.1655,  1.2774]],\n",
      "\n",
      "         [[-0.6012, -0.6869, -0.7233, -0.6534, -0.6012],\n",
      "          [-0.6848, -0.7383, -0.7813, -0.7521, -0.7348],\n",
      "          [-0.7321, -0.7869, -0.8845, -0.9413, -0.9756],\n",
      "          [-0.8212, -0.9280, -1.0621, -1.1654, -1.2773]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.0882, -0.1468, -0.1839, -0.2148, -0.1648],\n",
      "          [-0.1236, -0.0879, -0.0820, -0.1145, -0.0707],\n",
      "          [-0.1767, -0.1037, -0.0005,  0.0184,  0.0801],\n",
      "          [-0.2157, -0.1765, -0.0462, -0.0191,  0.0736]],\n",
      "\n",
      "         [[ 0.0881,  0.1468,  0.1839,  0.2148,  0.1648],\n",
      "          [ 0.1236,  0.0880,  0.0821,  0.1146,  0.0708],\n",
      "          [ 0.1767,  0.1038,  0.0006, -0.0182, -0.0799],\n",
      "          [ 0.2157,  0.1766,  0.0463,  0.0193, -0.0734]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 0 0]\n",
      " [1 1 1 1 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0512,  1.2816,  1.4729,  1.6197,  1.7024],\n",
      "          [ 1.2615,  1.3326,  1.3930,  1.4804,  1.5441],\n",
      "          [ 1.3386,  1.3206,  1.3416,  1.3958,  1.4541],\n",
      "          [ 1.3649,  1.4004,  1.4600,  1.5340,  1.6128]],\n",
      "\n",
      "         [[-1.0513, -1.2816, -1.4729, -1.6197, -1.7024],\n",
      "          [-1.2615, -1.3326, -1.3929, -1.4803, -1.5440],\n",
      "          [-1.3386, -1.3206, -1.3415, -1.3956, -1.4540],\n",
      "          [-1.3649, -1.4003, -1.4599, -1.5338, -1.6127]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8880,  1.0908,  1.2266,  1.2665,  1.2748],\n",
      "          [ 1.0419,  1.1523,  1.2004,  1.2540,  1.2753],\n",
      "          [ 1.1586,  1.2196,  1.2321,  1.2852,  1.3304],\n",
      "          [ 1.2904,  1.3959,  1.4215,  1.4493,  1.4709]],\n",
      "\n",
      "         [[-0.8881, -1.0908, -1.2266, -1.2665, -1.2748],\n",
      "          [-1.0419, -1.1522, -1.2003, -1.2539, -1.2752],\n",
      "          [-1.1586, -1.2195, -1.2319, -1.2851, -1.3303],\n",
      "          [-1.2904, -1.3958, -1.4214, -1.4492, -1.4707]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3976,  0.3650,  0.2868,  0.3444,  0.4177],\n",
      "          [ 0.3691,  0.2952,  0.1632,  0.2844,  0.4118],\n",
      "          [ 0.3093,  0.2563,  0.1504,  0.2932,  0.4223],\n",
      "          [ 0.1812,  0.1480,  0.0622,  0.1957,  0.3087]],\n",
      "\n",
      "         [[-0.3976, -0.3650, -0.2869, -0.3444, -0.4178],\n",
      "          [-0.3691, -0.2952, -0.1632, -0.2843, -0.4118],\n",
      "          [-0.3093, -0.2563, -0.1503, -0.2931, -0.4223],\n",
      "          [-0.1812, -0.1480, -0.0622, -0.1957, -0.3086]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2000,  0.0942,  0.0738,  0.1756,  0.2729],\n",
      "          [ 0.2118,  0.0999,  0.0524,  0.2017,  0.2982],\n",
      "          [ 0.2382,  0.1915,  0.1948,  0.3573,  0.4455],\n",
      "          [ 0.2651,  0.3012,  0.2920,  0.4075,  0.4819]],\n",
      "\n",
      "         [[-0.2001, -0.0942, -0.0738, -0.1756, -0.2729],\n",
      "          [-0.2119, -0.0999, -0.0523, -0.2016, -0.2982],\n",
      "          [-0.2382, -0.1914, -0.1947, -0.3572, -0.4455],\n",
      "          [-0.2651, -0.3012, -0.2919, -0.4074, -0.4819]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1911,  0.1990,  0.1860,  0.1377,  0.1316],\n",
      "          [ 0.1430,  0.1790,  0.1504,  0.0925,  0.0961],\n",
      "          [ 0.0581,  0.1022,  0.1130,  0.0737,  0.0896],\n",
      "          [ 0.0740,  0.1818,  0.2655,  0.2188,  0.2221]],\n",
      "\n",
      "         [[-0.1912, -0.1990, -0.1860, -0.1376, -0.1316],\n",
      "          [-0.1430, -0.1789, -0.1502, -0.0924, -0.0960],\n",
      "          [-0.0581, -0.1021, -0.1128, -0.0736, -0.0894],\n",
      "          [-0.0740, -0.1817, -0.2654, -0.2187, -0.2220]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6966,  0.8667,  0.9631,  1.0262,  1.1127],\n",
      "          [ 0.8407,  1.0113,  1.1008,  1.1827,  1.2999],\n",
      "          [ 0.9072,  1.0486,  1.1546,  1.2608,  1.4152],\n",
      "          [ 0.9703,  1.1122,  1.2565,  1.3747,  1.5484]],\n",
      "\n",
      "         [[-0.6967, -0.8667, -0.9631, -1.0262, -1.1127],\n",
      "          [-0.8407, -1.0112, -1.1007, -1.1826, -1.2998],\n",
      "          [-0.9072, -1.0485, -1.1545, -1.2607, -1.4151],\n",
      "          [-0.9703, -1.1121, -1.2564, -1.3746, -1.5483]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9978,  1.2161,  1.3971,  1.5276,  1.5649],\n",
      "          [ 1.2728,  1.4254,  1.5764,  1.7457,  1.7779],\n",
      "          [ 1.4854,  1.5858,  1.6884,  1.8630,  1.8863],\n",
      "          [ 1.6071,  1.7266,  1.8415,  2.0713,  2.1226]],\n",
      "\n",
      "         [[-0.9978, -1.2161, -1.3971, -1.5276, -1.5649],\n",
      "          [-1.2728, -1.4253, -1.5763, -1.7456, -1.7778],\n",
      "          [-1.4854, -1.5857, -1.6882, -1.8628, -1.8862],\n",
      "          [-1.6071, -1.7265, -1.8414, -2.0711, -2.1224]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7598,  2.2212,  2.6633,  2.8574,  3.0107],\n",
      "          [ 2.1819,  2.4774,  2.9447,  3.2689,  3.5661],\n",
      "          [ 2.5886,  2.9323,  3.5368,  3.9576,  4.3186],\n",
      "          [ 2.7291,  3.1627,  3.8193,  4.2516,  4.5432]],\n",
      "\n",
      "         [[-1.7598, -2.2211, -2.6632, -2.8572, -3.0105],\n",
      "          [-2.1819, -2.4772, -2.9445, -3.2686, -3.5658],\n",
      "          [-2.5885, -2.9321, -3.5364, -3.9573, -4.3182],\n",
      "          [-2.7290, -3.1624, -3.8189, -4.2512, -4.5428]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8743,  1.0132,  1.1305,  1.2539,  1.4127],\n",
      "          [ 1.0549,  1.1809,  1.2847,  1.4472,  1.6430],\n",
      "          [ 1.1407,  1.2296,  1.3089,  1.4974,  1.7464],\n",
      "          [ 1.2214,  1.3206,  1.4182,  1.6669,  1.9582]],\n",
      "\n",
      "         [[-0.8744, -1.0133, -1.1305, -1.2539, -1.4127],\n",
      "          [-1.0549, -1.1808, -1.2847, -1.4471, -1.6430],\n",
      "          [-1.1407, -1.2295, -1.3088, -1.4973, -1.7462],\n",
      "          [-1.2214, -1.3205, -1.4181, -1.6669, -1.9581]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1827,  1.4190,  1.5925,  1.6925,  1.7637],\n",
      "          [ 1.4789,  1.5979,  1.6596,  1.7662,  1.8748],\n",
      "          [ 1.6522,  1.7184,  1.7197,  1.8186,  1.9341],\n",
      "          [ 1.6820,  1.7683,  1.7809,  1.8785,  1.9883]],\n",
      "\n",
      "         [[-1.1828, -1.4190, -1.5925, -1.6924, -1.7637],\n",
      "          [-1.4788, -1.5978, -1.6595, -1.7661, -1.8746],\n",
      "          [-1.6522, -1.7183, -1.7195, -1.8184, -1.9339],\n",
      "          [-1.6819, -1.7681, -1.7807, -1.8783, -1.9881]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4141,  0.4526,  0.4793,  0.4590,  0.4507],\n",
      "          [ 0.4224,  0.4598,  0.5083,  0.5130,  0.5417],\n",
      "          [ 0.3996,  0.4363,  0.5555,  0.6104,  0.6952],\n",
      "          [ 0.3704,  0.3937,  0.5176,  0.5722,  0.6517]],\n",
      "\n",
      "         [[-0.4142, -0.4526, -0.4793, -0.4590, -0.4507],\n",
      "          [-0.4224, -0.4597, -0.5082, -0.5129, -0.5416],\n",
      "          [-0.3996, -0.4362, -0.5554, -0.6103, -0.6951],\n",
      "          [-0.3704, -0.3936, -0.5175, -0.5720, -0.6516]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3110,  0.3416,  0.4017,  0.4182,  0.4787],\n",
      "          [ 0.3587,  0.4151,  0.4932,  0.4982,  0.5452],\n",
      "          [ 0.4149,  0.4910,  0.5971,  0.6071,  0.6565],\n",
      "          [ 0.4660,  0.5379,  0.6519,  0.6646,  0.7362]],\n",
      "\n",
      "         [[-0.3110, -0.3416, -0.4017, -0.4181, -0.4787],\n",
      "          [-0.3586, -0.4149, -0.4931, -0.4981, -0.5450],\n",
      "          [-0.4149, -0.4908, -0.5969, -0.6069, -0.6563],\n",
      "          [-0.4659, -0.5378, -0.6517, -0.6644, -0.7360]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9615,  1.1964,  1.3652,  1.4628,  1.5774],\n",
      "          [ 1.1693,  1.3457,  1.4982,  1.6220,  1.7790],\n",
      "          [ 1.3029,  1.4331,  1.5957,  1.7534,  1.9535],\n",
      "          [ 1.4196,  1.5643,  1.7746,  1.9562,  2.1759]],\n",
      "\n",
      "         [[-0.9616, -1.1964, -1.3652, -1.4627, -1.5774],\n",
      "          [-1.1693, -1.3456, -1.4981, -1.6219, -1.7789],\n",
      "          [-1.3029, -1.4330, -1.5955, -1.7532, -1.9534],\n",
      "          [-1.4195, -1.5642, -1.7745, -1.9560, -2.1758]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8925,  2.3952,  2.8734,  3.0701,  3.2278],\n",
      "          [ 2.3740,  2.6597,  3.1568,  3.4443,  3.7144],\n",
      "          [ 2.8160,  3.1614,  3.7747,  4.1326,  4.4560],\n",
      "          [ 2.9694,  3.3929,  4.0448,  4.3901,  4.6970]],\n",
      "\n",
      "         [[-1.8925, -2.3951, -2.8733, -3.0699, -3.2276],\n",
      "          [-2.3739, -2.6594, -3.1565, -3.4439, -3.7140],\n",
      "          [-2.8159, -3.1611, -3.7744, -4.1322, -4.4555],\n",
      "          [-2.9692, -3.3926, -4.0444, -4.3897, -4.6966]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7965,  2.2910,  2.7480,  2.9417,  3.0974],\n",
      "          [ 2.2643,  2.6039,  3.1191,  3.4111,  3.6724],\n",
      "          [ 2.6712,  3.0841,  3.7201,  4.0941,  4.4214],\n",
      "          [ 2.8110,  3.2924,  3.9653,  4.3600,  4.6413]],\n",
      "\n",
      "         [[-1.7965, -2.2909, -2.7479, -2.9415, -3.0972],\n",
      "          [-2.2642, -2.6037, -3.1188, -3.4108, -3.6720],\n",
      "          [-2.6711, -3.0839, -3.7198, -4.0937, -4.4210],\n",
      "          [-2.8109, -3.2921, -3.9650, -4.3596, -4.6409]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5675,  0.7063,  0.8853,  0.9742,  1.0331],\n",
      "          [ 0.6746,  0.8280,  1.0063,  1.0945,  1.1209],\n",
      "          [ 0.7631,  0.9649,  1.1305,  1.1829,  1.1512],\n",
      "          [ 0.7509,  0.9917,  1.1682,  1.1924,  1.1861]],\n",
      "\n",
      "         [[-0.5676, -0.7063, -0.8853, -0.9742, -1.0331],\n",
      "          [-0.6747, -0.8279, -1.0062, -1.0944, -1.1208],\n",
      "          [-0.7631, -0.9648, -1.1303, -1.1828, -1.1511],\n",
      "          [-0.7509, -0.9916, -1.1681, -1.1924, -1.1861]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0089,  1.2328,  1.3837,  1.4687,  1.5118],\n",
      "          [ 1.2707,  1.4414,  1.5215,  1.6320,  1.6981],\n",
      "          [ 1.4438,  1.6029,  1.6668,  1.7985,  1.8871],\n",
      "          [ 1.5503,  1.7552,  1.8325,  1.9609,  2.0456]],\n",
      "\n",
      "         [[-1.0090, -1.2328, -1.3837, -1.4686, -1.5118],\n",
      "          [-1.2707, -1.4414, -1.5214, -1.6319, -1.6980],\n",
      "          [-1.4438, -1.6028, -1.6667, -1.7984, -1.8869],\n",
      "          [-1.5503, -1.7551, -1.8323, -1.9608, -2.0455]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2530,  1.5875,  1.8714,  2.0394,  2.1794],\n",
      "          [ 1.5607,  1.8040,  2.0401,  2.2403,  2.4433],\n",
      "          [ 1.7354,  1.9047,  2.1234,  2.3493,  2.5923],\n",
      "          [ 1.9066,  2.1223,  2.3826,  2.6095,  2.8441]],\n",
      "\n",
      "         [[-1.2531, -1.5875, -1.8714, -2.0394, -2.1793],\n",
      "          [-1.5607, -1.8038, -2.0400, -2.2402, -2.4432],\n",
      "          [-1.7353, -1.9046, -2.1232, -2.3491, -2.5921],\n",
      "          [-1.9066, -2.1222, -2.3824, -2.6093, -2.8439]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1256,  1.4123,  1.6205,  1.8098,  1.9643],\n",
      "          [ 1.3904,  1.5829,  1.7179,  1.9600,  2.1701],\n",
      "          [ 1.5473,  1.6705,  1.7896,  2.0704,  2.3261],\n",
      "          [ 1.7193,  1.8784,  2.0402,  2.3379,  2.5998]],\n",
      "\n",
      "         [[-1.1256, -1.4123, -1.6205, -1.8098, -1.9642],\n",
      "          [-1.3904, -1.5828, -1.7178, -1.9599, -2.1700],\n",
      "          [-1.5473, -1.6704, -1.7895, -2.0702, -2.3259],\n",
      "          [-1.7193, -1.8782, -2.0400, -2.3378, -2.5996]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2901,  0.4466,  0.5830,  0.6027,  0.6044],\n",
      "          [ 0.3718,  0.6306,  0.7595,  0.6727,  0.5910],\n",
      "          [ 0.3634,  0.6487,  0.8360,  0.7394,  0.6281],\n",
      "          [ 0.3853,  0.6573,  0.8729,  0.7946,  0.6930]],\n",
      "\n",
      "         [[-0.2902, -0.4467, -0.5830, -0.6027, -0.6045],\n",
      "          [-0.3718, -0.6305, -0.7594, -0.6726, -0.5910],\n",
      "          [-0.3634, -0.6487, -0.8359, -0.7393, -0.6281],\n",
      "          [-0.3853, -0.6573, -0.8728, -0.7946, -0.6929]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7379,  2.1494,  2.5180,  2.6283,  2.6825],\n",
      "          [ 2.1715,  2.4044,  2.7071,  2.8255,  2.9207],\n",
      "          [ 2.5138,  2.7211,  3.0394,  3.1498,  3.2284],\n",
      "          [ 2.6853,  2.9653,  3.3054,  3.3902,  3.4544]],\n",
      "\n",
      "         [[-1.7379, -2.1494, -2.5179, -2.6281, -2.6824],\n",
      "          [-2.1714, -2.4042, -2.7069, -2.8252, -2.9205],\n",
      "          [-2.5137, -2.7208, -3.0392, -3.1496, -3.2281],\n",
      "          [-2.6852, -2.9651, -3.3051, -3.3899, -3.4541]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3456,  0.3265,  0.2928,  0.2708,  0.3087],\n",
      "          [ 0.4251,  0.4774,  0.4602,  0.4564,  0.5036],\n",
      "          [ 0.5274,  0.7060,  0.7704,  0.7941,  0.8537],\n",
      "          [ 0.3653,  0.4749,  0.4967,  0.4387,  0.4453]],\n",
      "\n",
      "         [[-0.3457, -0.3265, -0.2928, -0.2708, -0.3087],\n",
      "          [-0.4251, -0.4773, -0.4600, -0.4563, -0.5035],\n",
      "          [-0.5273, -0.7058, -0.7702, -0.7939, -0.8535],\n",
      "          [-0.3653, -0.4747, -0.4965, -0.4385, -0.4452]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9553,  1.2020,  1.3914,  1.5090,  1.5987],\n",
      "          [ 1.1648,  1.3638,  1.5088,  1.6729,  1.7930],\n",
      "          [ 1.3076,  1.4528,  1.5502,  1.7438,  1.8843],\n",
      "          [ 1.5115,  1.7007,  1.7878,  1.9870,  2.1069]],\n",
      "\n",
      "         [[-0.9553, -1.2020, -1.3914, -1.5090, -1.5987],\n",
      "          [-1.1648, -1.3637, -1.5088, -1.6728, -1.7929],\n",
      "          [-1.3076, -1.4527, -1.5501, -1.7437, -1.8842],\n",
      "          [-1.5115, -1.7006, -1.7877, -1.9869, -2.1068]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9793,  1.1465,  1.2313,  1.1761,  0.9995],\n",
      "          [ 1.2227,  1.3169,  1.3092,  1.2942,  1.1445],\n",
      "          [ 1.4064,  1.4569,  1.3456,  1.3012,  1.1358],\n",
      "          [ 1.5481,  1.6357,  1.5374,  1.4908,  1.3127]],\n",
      "\n",
      "         [[-0.9794, -1.1465, -1.2313, -1.1761, -0.9996],\n",
      "          [-1.2227, -1.3168, -1.3091, -1.2941, -1.1445],\n",
      "          [-1.4064, -1.4568, -1.3455, -1.3011, -1.1358],\n",
      "          [-1.5481, -1.6356, -1.5373, -1.4907, -1.3126]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9975,  1.2280,  1.3558,  1.2591,  1.1178],\n",
      "          [ 1.2399,  1.3842,  1.4332,  1.2549,  1.0718],\n",
      "          [ 1.3477,  1.4281,  1.4601,  1.2727,  1.0563],\n",
      "          [ 1.4381,  1.4969,  1.4995,  1.3136,  1.0709]],\n",
      "\n",
      "         [[-0.9976, -1.2280, -1.3558, -1.2591, -1.1178],\n",
      "          [-1.2399, -1.3841, -1.4330, -1.2548, -1.0717],\n",
      "          [-1.3477, -1.4280, -1.4599, -1.2725, -1.0561],\n",
      "          [-1.4381, -1.4968, -1.4994, -1.3135, -1.0708]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6178,  0.7316,  0.7719,  0.8675,  0.9857],\n",
      "          [ 0.7993,  0.9271,  0.8962,  1.0209,  1.1580],\n",
      "          [ 0.9404,  1.0873,  1.0709,  1.2246,  1.3776],\n",
      "          [ 1.0249,  1.1721,  1.1970,  1.3629,  1.5166]],\n",
      "\n",
      "         [[-0.6178, -0.7316, -0.7719, -0.8675, -0.9857],\n",
      "          [-0.7993, -0.9270, -0.8961, -1.0208, -1.1579],\n",
      "          [-0.9404, -1.0872, -1.0707, -1.2245, -1.3775],\n",
      "          [-1.0249, -1.1720, -1.1969, -1.3628, -1.5165]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9697,  1.1685,  1.3078,  1.4562,  1.6380],\n",
      "          [ 1.1866,  1.3095,  1.3546,  1.5455,  1.8022],\n",
      "          [ 1.3397,  1.4473,  1.4714,  1.6866,  1.9729],\n",
      "          [ 1.4069,  1.5436,  1.5885,  1.7834,  2.0507]],\n",
      "\n",
      "         [[-0.9697, -1.1685, -1.3078, -1.4562, -1.6379],\n",
      "          [-1.1866, -1.3094, -1.3544, -1.5454, -1.8021],\n",
      "          [-1.3397, -1.4471, -1.4712, -1.6865, -1.9727],\n",
      "          [-1.4069, -1.5435, -1.5884, -1.7832, -2.0505]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0948,  1.3452,  1.5454,  1.6595,  1.7323],\n",
      "          [ 1.3640,  1.5550,  1.6893,  1.8510,  1.9636],\n",
      "          [ 1.5435,  1.7051,  1.8029,  1.9699,  2.1005],\n",
      "          [ 1.6380,  1.8261,  1.9074,  2.0707,  2.2169]],\n",
      "\n",
      "         [[-1.0949, -1.3452, -1.5454, -1.6595, -1.7323],\n",
      "          [-1.3641, -1.5550, -1.6892, -1.8509, -1.9635],\n",
      "          [-1.5435, -1.7050, -1.8028, -1.9697, -2.1003],\n",
      "          [-1.6380, -1.8260, -1.9073, -2.0705, -2.2168]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9533,  1.2476,  1.4057,  1.4843,  1.5745],\n",
      "          [ 1.2050,  1.5494,  1.7337,  1.8526,  1.9574],\n",
      "          [ 1.3661,  1.7559,  1.9594,  2.0761,  2.1439],\n",
      "          [ 1.5361,  2.0005,  2.2124,  2.3221,  2.4209]],\n",
      "\n",
      "         [[-0.9533, -1.2476, -1.4057, -1.4843, -1.5744],\n",
      "          [-1.2051, -1.5493, -1.7337, -1.8525, -1.9573],\n",
      "          [-1.3662, -1.7558, -1.9593, -2.0759, -2.1437],\n",
      "          [-1.5361, -2.0004, -2.2123, -2.3219, -2.4208]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4568,  0.5620,  0.6207,  0.6674,  0.7600],\n",
      "          [ 0.5873,  0.7252,  0.7766,  0.8327,  0.9607],\n",
      "          [ 0.6455,  0.7964,  0.9049,  0.9788,  1.1126],\n",
      "          [ 0.6634,  0.7935,  0.9315,  1.0030,  1.1521]],\n",
      "\n",
      "         [[-0.4569, -0.5620, -0.6207, -0.6674, -0.7601],\n",
      "          [-0.5873, -0.7251, -0.7765, -0.8327, -0.9607],\n",
      "          [-0.6456, -0.7963, -0.9048, -0.9787, -1.1125],\n",
      "          [-0.6634, -0.7935, -0.9314, -1.0029, -1.1520]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.0389, -0.0518, -0.1475, -0.1600, -0.1388],\n",
      "          [-0.0084,  0.1166,  0.0278,  0.0381,  0.0689],\n",
      "          [-0.0791,  0.0239, -0.0656, -0.0490, -0.0068],\n",
      "          [-0.0250,  0.0823,  0.0287,  0.0533,  0.0986]],\n",
      "\n",
      "         [[ 0.0388,  0.0517,  0.1475,  0.1600,  0.1388],\n",
      "          [ 0.0084, -0.1166, -0.0278, -0.0381, -0.0688],\n",
      "          [ 0.0791, -0.0239,  0.0657,  0.0490,  0.0068],\n",
      "          [ 0.0249, -0.0823, -0.0287, -0.0533, -0.0986]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 0 0 0 0]\n",
      " [1 0 1 1 1]\n",
      " [1 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.6323, -0.8850, -1.0740, -1.2327, -1.3364],\n",
      "          [-0.8532, -0.9925, -1.2019, -1.4283, -1.5926],\n",
      "          [-1.0502, -1.1878, -1.3597, -1.5239, -1.6437],\n",
      "          [-1.1535, -1.3169, -1.4372, -1.5144, -1.5756]],\n",
      "\n",
      "         [[ 0.6322,  0.8850,  1.0740,  1.2327,  1.3364],\n",
      "          [ 0.8532,  0.9926,  1.2021,  1.4284,  1.5927],\n",
      "          [ 1.0502,  1.1879,  1.3598,  1.5241,  1.6438],\n",
      "          [ 1.1535,  1.3170,  1.4374,  1.5146,  1.5757]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8905,  2.4460,  2.9011,  3.1349,  3.3283],\n",
      "          [ 2.4281,  2.7708,  3.3160,  3.6558,  3.9581],\n",
      "          [ 2.8505,  3.3268,  4.0272,  4.4682,  4.7843],\n",
      "          [ 3.0363,  3.6129,  4.3823,  4.7913,  5.0960]],\n",
      "\n",
      "         [[-1.8905, -2.4459, -2.9009, -3.1347, -3.3281],\n",
      "          [-2.4280, -2.7706, -3.3157, -3.6554, -3.9578],\n",
      "          [-2.8504, -3.3265, -4.0268, -4.4678, -4.7838],\n",
      "          [-3.0361, -3.6126, -4.3819, -4.7908, -5.0955]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9562,  1.1743,  1.3154,  1.4020,  1.4377],\n",
      "          [ 1.1195,  1.2557,  1.2941,  1.4179,  1.4864],\n",
      "          [ 1.2193,  1.3155,  1.2810,  1.4005,  1.4836],\n",
      "          [ 1.2958,  1.4247,  1.3699,  1.4674,  1.5469]],\n",
      "\n",
      "         [[-0.9562, -1.1743, -1.3154, -1.4020, -1.4377],\n",
      "          [-1.1195, -1.2555, -1.2940, -1.4177, -1.4862],\n",
      "          [-1.2192, -1.3153, -1.2809, -1.4003, -1.4834],\n",
      "          [-1.2958, -1.4246, -1.3698, -1.4672, -1.5467]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.2163, -0.3109, -0.4704, -0.5707, -0.6117],\n",
      "          [-0.2519, -0.1789, -0.3016, -0.3907, -0.4276],\n",
      "          [-0.3811, -0.2927, -0.3894, -0.4521, -0.4609],\n",
      "          [-0.3827, -0.2672, -0.3189, -0.3490, -0.3261]],\n",
      "\n",
      "         [[ 0.2162,  0.3109,  0.4703,  0.5707,  0.6116],\n",
      "          [ 0.2518,  0.1789,  0.3016,  0.3908,  0.4277],\n",
      "          [ 0.3811,  0.2927,  0.3895,  0.4522,  0.4609],\n",
      "          [ 0.3826,  0.2673,  0.3189,  0.3491,  0.3262]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9827,  1.1959,  1.3679,  1.3971,  1.4130],\n",
      "          [ 1.1517,  1.3098,  1.4666,  1.5305,  1.5808],\n",
      "          [ 1.2551,  1.4461,  1.6563,  1.7476,  1.8197],\n",
      "          [ 1.2670,  1.4973,  1.6995,  1.7433,  1.7744]],\n",
      "\n",
      "         [[-0.9828, -1.1959, -1.3679, -1.3971, -1.4129],\n",
      "          [-1.1517, -1.3097, -1.4665, -1.5303, -1.5806],\n",
      "          [-1.2551, -1.4460, -1.6561, -1.7474, -1.8195],\n",
      "          [-1.2670, -1.4971, -1.6993, -1.7431, -1.7743]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.0725,  0.1683,  0.2254,  0.2221,  0.2930],\n",
      "          [ 0.0969,  0.3279,  0.4251,  0.3682,  0.4091],\n",
      "          [ 0.0607,  0.3212,  0.5133,  0.4422,  0.4769],\n",
      "          [ 0.0958,  0.3581,  0.6178,  0.5350,  0.5354]],\n",
      "\n",
      "         [[-0.0725, -0.1683, -0.2254, -0.2222, -0.2930],\n",
      "          [-0.0969, -0.3278, -0.4250, -0.3681, -0.4090],\n",
      "          [-0.0607, -0.3210, -0.5132, -0.4421, -0.4768],\n",
      "          [-0.0958, -0.3580, -0.6177, -0.5349, -0.5353]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2889,  0.3694,  0.4488,  0.5255,  0.6672],\n",
      "          [ 0.4633,  0.6565,  0.7658,  0.8587,  1.0361],\n",
      "          [ 0.5793,  0.8271,  0.9988,  1.1247,  1.3445],\n",
      "          [ 0.5920,  0.8254,  1.0287,  1.1934,  1.4277]],\n",
      "\n",
      "         [[-0.2890, -0.3694, -0.4488, -0.5255, -0.6672],\n",
      "          [-0.4634, -0.6565, -0.7657, -0.8586, -1.0360],\n",
      "          [-0.5793, -0.8270, -0.9987, -1.1246, -1.3443],\n",
      "          [-0.5920, -0.8253, -1.0286, -1.1933, -1.4276]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7732,  2.2082,  2.6235,  2.8156,  3.0143],\n",
      "          [ 2.2285,  2.5063,  2.9128,  3.2373,  3.5893],\n",
      "          [ 2.6330,  2.9707,  3.4862,  3.8940,  4.3213],\n",
      "          [ 2.8223,  3.3190,  3.9302,  4.3529,  4.6440]],\n",
      "\n",
      "         [[-1.7732, -2.2081, -2.6234, -2.8154, -3.0141],\n",
      "          [-2.2285, -2.5061, -2.9126, -3.2370, -3.5890],\n",
      "          [-2.6329, -2.9704, -3.4859, -3.8937, -4.3210],\n",
      "          [-2.8222, -3.3187, -3.9299, -4.3525, -4.6436]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0206,  1.2594,  1.4354,  1.5326,  1.5822],\n",
      "          [ 1.2384,  1.4052,  1.5324,  1.6971,  1.8142],\n",
      "          [ 1.4015,  1.5383,  1.6508,  1.8547,  1.9987],\n",
      "          [ 1.5345,  1.6969,  1.8216,  2.0332,  2.1859]],\n",
      "\n",
      "         [[-1.0207, -1.2594, -1.4353, -1.5326, -1.5822],\n",
      "          [-1.2384, -1.4051, -1.5323, -1.6970, -1.8141],\n",
      "          [-1.4015, -1.5382, -1.6506, -1.8546, -1.9985],\n",
      "          [-1.5345, -1.6968, -1.8215, -2.0330, -2.1857]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2216,  1.4906,  1.7022,  1.7588,  1.7149],\n",
      "          [ 1.4895,  1.6265,  1.7680,  1.8156,  1.7921],\n",
      "          [ 1.6487,  1.7394,  1.8772,  1.8989,  1.8783],\n",
      "          [ 1.7326,  1.8650,  2.0145,  1.9697,  1.9095]],\n",
      "\n",
      "         [[-1.2216, -1.4906, -1.7021, -1.7588, -1.7148],\n",
      "          [-1.4895, -1.6264, -1.7679, -1.8155, -1.7919],\n",
      "          [-1.6487, -1.7393, -1.8771, -1.8987, -1.8782],\n",
      "          [-1.7326, -1.8649, -2.0143, -1.9696, -1.9094]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8637,  1.0436,  1.1533,  1.2146,  1.2693],\n",
      "          [ 1.0531,  1.2161,  1.3023,  1.4006,  1.4614],\n",
      "          [ 1.1881,  1.3354,  1.3935,  1.4833,  1.5254],\n",
      "          [ 1.2519,  1.4066,  1.4907,  1.6124,  1.6577]],\n",
      "\n",
      "         [[-0.8638, -1.0436, -1.1533, -1.2146, -1.2693],\n",
      "          [-1.0531, -1.2160, -1.3022, -1.4005, -1.4613],\n",
      "          [-1.1881, -1.3352, -1.3934, -1.4832, -1.5252],\n",
      "          [-1.2519, -1.4065, -1.4906, -1.6123, -1.6576]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3738,  1.7035,  1.9831,  2.1683,  2.2647],\n",
      "          [ 1.7188,  1.9192,  2.1124,  2.3181,  2.4878],\n",
      "          [ 1.9387,  2.0737,  2.2340,  2.4540,  2.6415],\n",
      "          [ 2.1035,  2.2879,  2.4899,  2.7268,  2.9306]],\n",
      "\n",
      "         [[-1.3739, -1.7034, -1.9830, -2.1683, -2.2646],\n",
      "          [-1.7187, -1.9191, -2.1123, -2.3180, -2.4877],\n",
      "          [-1.9387, -2.0736, -2.2338, -2.4538, -2.6413],\n",
      "          [-2.1035, -2.2878, -2.4898, -2.7266, -2.9304]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1363,  1.4223,  1.6644,  1.7563,  1.8698],\n",
      "          [ 1.4400,  1.6947,  1.9366,  2.0207,  2.1490],\n",
      "          [ 1.7171,  1.9914,  2.2697,  2.3680,  2.4984],\n",
      "          [ 1.8510,  2.1133,  2.3955,  2.4366,  2.5218]],\n",
      "\n",
      "         [[-1.1364, -1.4223, -1.6644, -1.7563, -1.8698],\n",
      "          [-1.4399, -1.6946, -1.9364, -2.0206, -2.1488],\n",
      "          [-1.7170, -1.9913, -2.2696, -2.3678, -2.4983],\n",
      "          [-1.8509, -2.1131, -2.3953, -2.4364, -2.5216]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8982,  0.9879,  1.0838,  1.2110,  1.2896],\n",
      "          [ 1.2262,  1.2257,  1.1963,  1.3818,  1.5101],\n",
      "          [ 1.5181,  1.5179,  1.3938,  1.6168,  1.7367],\n",
      "          [ 1.6053,  1.5667,  1.4156,  1.6446,  1.8328]],\n",
      "\n",
      "         [[-0.8982, -0.9879, -1.0837, -1.2110, -1.2895],\n",
      "          [-1.2262, -1.2256, -1.1962, -1.3817, -1.5100],\n",
      "          [-1.5180, -1.5178, -1.3936, -1.6166, -1.7365],\n",
      "          [-1.6053, -1.5666, -1.4154, -1.6445, -1.8327]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.4315,  1.6940,  2.0352,  2.3696,  2.6400],\n",
      "          [ 1.6655,  1.7071,  2.0483,  2.5177,  2.9209],\n",
      "          [ 1.9852,  1.9889,  2.3918,  2.9313,  3.4283],\n",
      "          [ 2.2307,  2.2791,  2.7382,  3.2844,  3.8276]],\n",
      "\n",
      "         [[-1.4315, -1.6940, -2.0351, -2.3695, -2.6399],\n",
      "          [-1.6654, -1.7070, -2.0481, -2.5174, -2.9206],\n",
      "          [-1.9851, -1.9887, -2.3916, -2.9310, -3.4280],\n",
      "          [-2.2306, -2.2789, -2.7379, -3.2841, -3.8273]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5071,  0.6143,  0.6705,  0.6860,  0.7109],\n",
      "          [ 0.5357,  0.6453,  0.6903,  0.7052,  0.7313],\n",
      "          [ 0.4962,  0.5951,  0.6557,  0.6765,  0.7086],\n",
      "          [ 0.4802,  0.5958,  0.6776,  0.6832,  0.6942]],\n",
      "\n",
      "         [[-0.5071, -0.6143, -0.6705, -0.6860, -0.7109],\n",
      "          [-0.5357, -0.6452, -0.6903, -0.7051, -0.7312],\n",
      "          [-0.4962, -0.5950, -0.6556, -0.6764, -0.7085],\n",
      "          [-0.4802, -0.5957, -0.6775, -0.6832, -0.6941]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7636,  2.2601,  2.6977,  2.9043,  3.0744],\n",
      "          [ 2.2230,  2.5590,  3.1001,  3.4108,  3.6944],\n",
      "          [ 2.6385,  3.0305,  3.7138,  4.1393,  4.4888],\n",
      "          [ 2.8328,  3.3024,  4.0598,  4.5028,  4.8285]],\n",
      "\n",
      "         [[-1.7636, -2.2601, -2.6975, -2.9041, -3.0742],\n",
      "          [-2.2230, -2.5588, -3.0998, -3.4105, -3.6940],\n",
      "          [-2.6384, -3.0302, -3.7135, -4.1389, -4.4884],\n",
      "          [-2.8327, -3.3021, -4.0595, -4.5024, -4.8280]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2282,  1.5503,  1.8068,  1.9316,  2.0131],\n",
      "          [ 1.5524,  1.7733,  1.9616,  2.0810,  2.1791],\n",
      "          [ 1.7332,  1.8383,  1.9739,  2.0862,  2.1969],\n",
      "          [ 1.9061,  2.0426,  2.2192,  2.3243,  2.4257]],\n",
      "\n",
      "         [[-1.2282, -1.5503, -1.8068, -1.9316, -2.0130],\n",
      "          [-1.5524, -1.7732, -1.9615, -2.0808, -2.1789],\n",
      "          [-1.7332, -1.8382, -1.9737, -2.0860, -2.1967],\n",
      "          [-1.9061, -2.0424, -2.2190, -2.3241, -2.4256]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2143,  1.5212,  1.7516,  1.8638,  1.9401],\n",
      "          [ 1.5013,  1.6983,  1.8248,  1.9350,  2.0435],\n",
      "          [ 1.6654,  1.7651,  1.8232,  1.9254,  2.0533],\n",
      "          [ 1.8111,  1.9414,  2.0268,  2.1222,  2.2575]],\n",
      "\n",
      "         [[-1.2143, -1.5212, -1.7516, -1.8638, -1.9401],\n",
      "          [-1.5013, -1.6982, -1.8247, -1.9349, -2.0433],\n",
      "          [-1.6654, -1.7650, -1.8231, -1.9253, -2.0532],\n",
      "          [-1.8110, -1.9413, -2.0267, -2.1221, -2.2573]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9638,  2.5508,  3.0371,  3.2753,  3.4596],\n",
      "          [ 2.5098,  2.8501,  3.4411,  3.7963,  4.1056],\n",
      "          [ 2.9629,  3.4419,  4.1931,  4.6539,  4.9978],\n",
      "          [ 3.1594,  3.7472,  4.5704,  5.0098,  5.3297]],\n",
      "\n",
      "         [[-1.9638, -2.5507, -3.0369, -3.2751, -3.4593],\n",
      "          [-2.5097, -2.8498, -3.4408, -3.7959, -4.1052],\n",
      "          [-2.9628, -3.4416, -4.1927, -4.6534, -4.9974],\n",
      "          [-3.1593, -3.7469, -4.5700, -5.0093, -5.3291]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.0839,  0.1336,  0.2271,  0.3551,  0.5327],\n",
      "          [-0.0147,  0.0766,  0.1581,  0.2482,  0.3942],\n",
      "          [-0.1412, -0.0600,  0.0161,  0.1262,  0.2896],\n",
      "          [-0.2698, -0.2039, -0.1026,  0.0366,  0.2297]],\n",
      "\n",
      "         [[-0.0840, -0.1336, -0.2271, -0.3551, -0.5327],\n",
      "          [ 0.0147, -0.0765, -0.1580, -0.2482, -0.3941],\n",
      "          [ 0.1412,  0.0601, -0.0160, -0.1261, -0.2896],\n",
      "          [ 0.2698,  0.2040,  0.1027, -0.0365, -0.2296]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 1 0 0 0]\n",
      " [1 1 1 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1992,  0.2943,  0.3942,  0.3641,  0.3499],\n",
      "          [ 0.2019,  0.3374,  0.4514,  0.3832,  0.3444],\n",
      "          [ 0.1980,  0.3146,  0.4550,  0.4265,  0.3994],\n",
      "          [ 0.2952,  0.3836,  0.4879,  0.4413,  0.3963]],\n",
      "\n",
      "         [[-0.1993, -0.2943, -0.3942, -0.3640, -0.3499],\n",
      "          [-0.2019, -0.3373, -0.4512, -0.3831, -0.3443],\n",
      "          [-0.1980, -0.3144, -0.4548, -0.4263, -0.3993],\n",
      "          [-0.2952, -0.3835, -0.4877, -0.4412, -0.3962]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1104,  0.0667,  0.0426,  0.0441,  0.0853],\n",
      "          [ 0.0928,  0.0457, -0.0619, -0.0664,  0.0021],\n",
      "          [ 0.0465, -0.0051, -0.1224, -0.0904,  0.0276],\n",
      "          [-0.0353, -0.1096, -0.2202, -0.1177,  0.0901]],\n",
      "\n",
      "         [[-0.1104, -0.0667, -0.0426, -0.0441, -0.0852],\n",
      "          [-0.0928, -0.0456,  0.0621,  0.0665, -0.0020],\n",
      "          [-0.0465,  0.0052,  0.1225,  0.0906, -0.0275],\n",
      "          [ 0.0353,  0.1097,  0.2203,  0.1178, -0.0900]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 1 1 0]\n",
      " [0 1 1 1 0]\n",
      " [1 1 1 1 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1020,  1.3399,  1.5841,  1.8020,  1.9655],\n",
      "          [ 1.4174,  1.5514,  1.6805,  1.9525,  2.1560],\n",
      "          [ 1.6389,  1.7076,  1.7920,  2.0967,  2.3160],\n",
      "          [ 1.7505,  1.8573,  1.9787,  2.3116,  2.5530]],\n",
      "\n",
      "         [[-1.1020, -1.3399, -1.5840, -1.8020, -1.9655],\n",
      "          [-1.4174, -1.5513, -1.6803, -1.9523, -2.1558],\n",
      "          [-1.6389, -1.7075, -1.7918, -2.0965, -2.3158],\n",
      "          [-1.7505, -1.8572, -1.9786, -2.3115, -2.5528]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2716,  1.6861,  1.9642,  2.1542,  2.3225],\n",
      "          [ 1.6404,  2.0808,  2.3710,  2.6239,  2.8913],\n",
      "          [ 1.9219,  2.4131,  2.7820,  3.0747,  3.3468],\n",
      "          [ 2.1144,  2.6347,  3.0614,  3.3583,  3.6063]],\n",
      "\n",
      "         [[-1.2717, -1.6861, -1.9641, -2.1541, -2.3225],\n",
      "          [-1.6404, -2.0807, -2.3708, -2.6237, -2.8911],\n",
      "          [-1.9219, -2.4129, -2.7818, -3.0745, -3.3466],\n",
      "          [-2.1143, -2.6345, -3.0612, -3.3581, -3.6061]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8922,  2.4198,  2.8930,  3.1215,  3.3090],\n",
      "          [ 2.3947,  2.6922,  3.2571,  3.6049,  3.9237],\n",
      "          [ 2.8346,  3.2416,  3.9459,  4.4059,  4.7691],\n",
      "          [ 3.0194,  3.5252,  4.2900,  4.7490,  5.0901]],\n",
      "\n",
      "         [[-1.8922, -2.4197, -2.8928, -3.1213, -3.3088],\n",
      "          [-2.3946, -2.6920, -3.2568, -3.6046, -3.9233],\n",
      "          [-2.8345, -3.2413, -3.9456, -4.4055, -4.7686],\n",
      "          [-3.0192, -3.5249, -4.2896, -4.7486, -5.0896]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.6455,  2.1051,  2.5249,  2.6940,  2.8258],\n",
      "          [ 2.0922,  2.4406,  2.8704,  3.1204,  3.3320],\n",
      "          [ 2.4447,  2.8080,  3.3164,  3.6129,  3.8704],\n",
      "          [ 2.5866,  3.0385,  3.6084,  3.8997,  4.1426]],\n",
      "\n",
      "         [[-1.6455, -2.1050, -2.5248, -2.6939, -2.8257],\n",
      "          [-2.0921, -2.4404, -2.8702, -3.1201, -3.3317],\n",
      "          [-2.4446, -2.8078, -3.3161, -3.6126, -3.8701],\n",
      "          [-2.5865, -3.0382, -3.6081, -3.8994, -4.1423]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8490,  1.1172,  1.2867,  1.4421,  1.5989],\n",
      "          [ 0.9884,  1.2092,  1.3068,  1.4982,  1.7094],\n",
      "          [ 1.0500,  1.1986,  1.2259,  1.4328,  1.6608],\n",
      "          [ 1.1566,  1.3021,  1.2949,  1.4980,  1.7412]],\n",
      "\n",
      "         [[-0.8491, -1.1172, -1.2866, -1.4421, -1.5989],\n",
      "          [-0.9883, -1.2090, -1.3066, -1.4981, -1.7092],\n",
      "          [-1.0500, -1.1985, -1.2257, -1.4326, -1.6606],\n",
      "          [-1.1566, -1.3020, -1.2947, -1.4978, -1.7410]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6237,  0.6692,  0.6373,  0.5323,  0.4070],\n",
      "          [ 0.6974,  0.6906,  0.6177,  0.5263,  0.3897],\n",
      "          [ 0.7519,  0.7276,  0.6698,  0.6004,  0.4555],\n",
      "          [ 0.8132,  0.8081,  0.7772,  0.7246,  0.5883]],\n",
      "\n",
      "         [[-0.6237, -0.6692, -0.6373, -0.5323, -0.4070],\n",
      "          [-0.6974, -0.6905, -0.6176, -0.5262, -0.3896],\n",
      "          [-0.7519, -0.7275, -0.6697, -0.6003, -0.4553],\n",
      "          [-0.8132, -0.8080, -0.7771, -0.7245, -0.5882]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6500,  0.8508,  1.0144,  0.9561,  0.9083],\n",
      "          [ 0.7712,  1.0060,  1.1924,  1.0443,  0.8942],\n",
      "          [ 0.8464,  1.0657,  1.2813,  1.0901,  0.8562],\n",
      "          [ 0.8885,  1.0777,  1.3063,  1.1164,  0.8610]],\n",
      "\n",
      "         [[-0.6501, -0.8509, -1.0145, -0.9561, -0.9083],\n",
      "          [-0.7712, -1.0060, -1.1924, -1.0442, -0.8941],\n",
      "          [-0.8464, -1.0657, -1.2813, -1.0900, -0.8561],\n",
      "          [-0.8886, -1.0777, -1.3063, -1.1163, -0.8610]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.0671, -0.1640, -0.2490, -0.2766, -0.3145],\n",
      "          [-0.1890, -0.3478, -0.4881, -0.5131, -0.5614],\n",
      "          [-0.3104, -0.5936, -0.7370, -0.7661, -0.8215],\n",
      "          [-0.3346, -0.7300, -0.9200, -1.0413, -1.1525]],\n",
      "\n",
      "         [[ 0.0670,  0.1639,  0.2490,  0.2766,  0.3145],\n",
      "          [ 0.1889,  0.3478,  0.4882,  0.5132,  0.5615],\n",
      "          [ 0.3103,  0.5937,  0.7372,  0.7662,  0.8216],\n",
      "          [ 0.3345,  0.7301,  0.9201,  1.0413,  1.1526]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.5643, -0.8205, -1.0526, -1.2325, -1.3341],\n",
      "          [-0.7231, -0.8779, -1.1154, -1.3159, -1.4659],\n",
      "          [-0.8555, -1.0277, -1.2731, -1.4525, -1.6243],\n",
      "          [-0.8808, -1.1044, -1.3406, -1.4750, -1.6029]],\n",
      "\n",
      "         [[ 0.5642,  0.8205,  1.0526,  1.2325,  1.3341],\n",
      "          [ 0.7231,  0.8780,  1.1156,  1.3160,  1.4661],\n",
      "          [ 0.8555,  1.0278,  1.2733,  1.4527,  1.6244],\n",
      "          [ 0.8808,  1.1045,  1.3408,  1.4751,  1.6030]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5942,  0.6550,  0.6959,  0.7397,  0.7935],\n",
      "          [ 0.7343,  0.7778,  0.8095,  0.8829,  0.9720],\n",
      "          [ 0.8321,  0.8523,  0.8765,  0.9489,  1.0315],\n",
      "          [ 0.9118,  0.9289,  0.9685,  1.0316,  1.1197]],\n",
      "\n",
      "         [[-0.5943, -0.6550, -0.6959, -0.7398, -0.7936],\n",
      "          [-0.7344, -0.7777, -0.8094, -0.8828, -0.9720],\n",
      "          [-0.8322, -0.8522, -0.8764, -0.9488, -1.0314],\n",
      "          [-0.9118, -0.9289, -0.9684, -1.0315, -1.1196]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7418,  0.9226,  1.0639,  1.1909,  1.3271],\n",
      "          [ 0.8618,  0.9919,  1.0531,  1.2087,  1.3843],\n",
      "          [ 0.9520,  1.0258,  1.0301,  1.1834,  1.3510],\n",
      "          [ 1.1147,  1.2286,  1.2316,  1.3997,  1.5511]],\n",
      "\n",
      "         [[-0.7419, -0.9226, -1.0639, -1.1909, -1.3271],\n",
      "          [-0.8618, -0.9918, -1.0530, -1.2086, -1.3842],\n",
      "          [-0.9520, -1.0257, -1.0300, -1.1832, -1.3509],\n",
      "          [-1.1147, -1.2285, -1.2314, -1.3996, -1.5510]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6406,  0.7445,  0.8346,  0.8042,  0.8210],\n",
      "          [ 0.7280,  0.8319,  0.9545,  0.9111,  0.9195],\n",
      "          [ 0.7790,  0.9208,  1.1184,  1.0829,  1.0824],\n",
      "          [ 0.7907,  0.9549,  1.1766,  1.1486,  1.1576]],\n",
      "\n",
      "         [[-0.6407, -0.7445, -0.8345, -0.8042, -0.8210],\n",
      "          [-0.7280, -0.8317, -0.9543, -0.9109, -0.9194],\n",
      "          [-0.7790, -0.9207, -1.1182, -1.0828, -1.0822],\n",
      "          [-0.7907, -0.9548, -1.1764, -1.1484, -1.1574]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3410,  1.6571,  1.9552,  2.1489,  2.2621],\n",
      "          [ 1.6753,  1.8675,  2.0864,  2.3200,  2.5137],\n",
      "          [ 1.8829,  2.0254,  2.2282,  2.4957,  2.7162],\n",
      "          [ 1.9794,  2.1384,  2.3671,  2.6250,  2.8436]],\n",
      "\n",
      "         [[-1.3410, -1.6571, -1.9551, -2.1488, -2.2620],\n",
      "          [-1.6753, -1.8674, -2.0862, -2.3198, -2.5135],\n",
      "          [-1.8828, -2.0253, -2.2280, -2.4955, -2.7160],\n",
      "          [-1.9794, -2.1383, -2.3670, -2.6249, -2.8434]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2108,  0.2107,  0.1975,  0.1509,  0.1590],\n",
      "          [ 0.1981,  0.2170,  0.2291,  0.1906,  0.1972],\n",
      "          [ 0.1900,  0.1974,  0.2578,  0.2659,  0.2905],\n",
      "          [ 0.3116,  0.3124,  0.3374,  0.3291,  0.3574]],\n",
      "\n",
      "         [[-0.2108, -0.2107, -0.1975, -0.1509, -0.1590],\n",
      "          [-0.1981, -0.2169, -0.2290, -0.1905, -0.1971],\n",
      "          [-0.1900, -0.1972, -0.2576, -0.2657, -0.2903],\n",
      "          [-0.3117, -0.3123, -0.3373, -0.3289, -0.3572]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0878,  1.3051,  1.4627,  1.4736,  1.4006],\n",
      "          [ 1.2680,  1.3061,  1.3572,  1.3667,  1.2840],\n",
      "          [ 1.3351,  1.2839,  1.3074,  1.2942,  1.1739],\n",
      "          [ 1.3681,  1.3567,  1.3528,  1.2359,  1.0366]],\n",
      "\n",
      "         [[-1.0879, -1.3051, -1.4627, -1.4736, -1.4006],\n",
      "          [-1.2681, -1.3060, -1.3571, -1.3667, -1.2839],\n",
      "          [-1.3351, -1.2839, -1.3073, -1.2941, -1.1738],\n",
      "          [-1.3681, -1.3566, -1.3527, -1.2358, -1.0365]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.0279, -0.0671, -0.2125, -0.3720, -0.5074],\n",
      "          [ 0.0031, -0.0182, -0.1680, -0.3410, -0.4880],\n",
      "          [-0.0982, -0.0978, -0.2215, -0.3979, -0.5483],\n",
      "          [-0.2184, -0.2218, -0.3192, -0.4976, -0.6265]],\n",
      "\n",
      "         [[-0.0280,  0.0671,  0.2124,  0.3720,  0.5074],\n",
      "          [-0.0032,  0.0182,  0.1681,  0.3410,  0.4880],\n",
      "          [ 0.0982,  0.0979,  0.2216,  0.3979,  0.5484],\n",
      "          [ 0.2184,  0.2218,  0.3192,  0.4977,  0.6265]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 1 1 1 1]\n",
      " [0 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1825,  1.4694,  1.7045,  1.8470,  1.9056],\n",
      "          [ 1.4904,  1.6986,  1.9135,  2.1272,  2.2348],\n",
      "          [ 1.7120,  1.9124,  2.1696,  2.4160,  2.5441],\n",
      "          [ 1.8717,  2.1402,  2.4402,  2.6405,  2.7439]],\n",
      "\n",
      "         [[-1.1825, -1.4694, -1.7045, -1.8470, -1.9056],\n",
      "          [-1.4904, -1.6985, -1.9134, -2.1270, -2.2347],\n",
      "          [-1.7120, -1.9123, -2.1695, -2.4159, -2.5440],\n",
      "          [-1.8717, -2.1401, -2.4400, -2.6403, -2.7438]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.0229,  0.0338, -0.0816, -0.1677, -0.2264],\n",
      "          [ 0.0543,  0.2248,  0.1335,  0.0284, -0.0818],\n",
      "          [-0.0544,  0.1236,  0.0684,  0.0024, -0.0514],\n",
      "          [-0.1470,  0.0313,  0.0048, -0.0407, -0.0692]],\n",
      "\n",
      "         [[-0.0230, -0.0339,  0.0815,  0.1676,  0.2264],\n",
      "          [-0.0544, -0.2248, -0.1335, -0.0283,  0.0819],\n",
      "          [ 0.0543, -0.1236, -0.0683, -0.0024,  0.0515],\n",
      "          [ 0.1470, -0.0313, -0.0048,  0.0407,  0.0693]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 1 1 1]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 1]\n",
      " [1 0 0 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8914,  2.4813,  2.9069,  3.1214,  3.2881],\n",
      "          [ 2.4275,  2.8041,  3.3440,  3.6820,  3.9598],\n",
      "          [ 2.8248,  3.3332,  4.0132,  4.4473,  4.7137],\n",
      "          [ 3.0024,  3.6209,  4.3812,  4.7630,  5.0525]],\n",
      "\n",
      "         [[-1.8914, -2.4812, -2.9067, -3.1212, -3.2879],\n",
      "          [-2.4274, -2.8039, -3.3437, -3.6817, -3.9595],\n",
      "          [-2.8246, -3.3329, -4.0128, -4.4470, -4.7133],\n",
      "          [-3.0022, -3.6206, -4.3808, -4.7626, -5.0520]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2184,  0.1939,  0.2771,  0.6752,  1.0093],\n",
      "          [ 0.2978,  0.2093,  0.1770,  0.6473,  1.0543],\n",
      "          [ 0.3593,  0.2325,  0.1724,  0.6523,  1.0491],\n",
      "          [ 0.3862,  0.2777,  0.2114,  0.7268,  1.1183]],\n",
      "\n",
      "         [[-0.2185, -0.1939, -0.2771, -0.6753, -1.0094],\n",
      "          [-0.2978, -0.2092, -0.1770, -0.6472, -1.0542],\n",
      "          [-0.3593, -0.2325, -0.1724, -0.6523, -1.0490],\n",
      "          [-0.3862, -0.2777, -0.2114, -0.7268, -1.1183]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1861,  1.4860,  1.7158,  1.8541,  1.9718],\n",
      "          [ 1.5042,  1.7340,  1.9047,  2.0680,  2.2378],\n",
      "          [ 1.7227,  1.9146,  2.0542,  2.2238,  2.4038],\n",
      "          [ 1.8308,  2.0435,  2.2095,  2.3816,  2.5510]],\n",
      "\n",
      "         [[-1.1861, -1.4860, -1.7158, -1.8541, -1.9718],\n",
      "          [-1.5042, -1.7339, -1.9045, -2.0679, -2.2377],\n",
      "          [-1.7227, -1.9145, -2.0540, -2.2236, -2.4036],\n",
      "          [-1.8307, -2.0434, -2.2094, -2.3814, -2.5508]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1619,  0.2168,  0.1991,  0.2228,  0.2901],\n",
      "          [ 0.2516,  0.4344,  0.4363,  0.4868,  0.5657],\n",
      "          [ 0.2863,  0.5107,  0.5463,  0.6170,  0.6896],\n",
      "          [ 0.3320,  0.5467,  0.6026,  0.6670,  0.7300]],\n",
      "\n",
      "         [[-0.1620, -0.2168, -0.1991, -0.2228, -0.2901],\n",
      "          [-0.2516, -0.4344, -0.4362, -0.4867, -0.5657],\n",
      "          [-0.2863, -0.5106, -0.5462, -0.6169, -0.6895],\n",
      "          [-0.3320, -0.5466, -0.6025, -0.6669, -0.7299]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1610,  0.1918,  0.2151,  0.1683,  0.1353],\n",
      "          [ 0.1582,  0.2528,  0.2917,  0.2072,  0.1387],\n",
      "          [ 0.1359,  0.2586,  0.3505,  0.2625,  0.1597],\n",
      "          [ 0.1212,  0.2346,  0.3499,  0.2914,  0.1679]],\n",
      "\n",
      "         [[-0.1611, -0.1918, -0.2151, -0.1682, -0.1353],\n",
      "          [-0.1582, -0.2527, -0.2915, -0.2071, -0.1386],\n",
      "          [-0.1359, -0.2584, -0.3503, -0.2623, -0.1596],\n",
      "          [-0.1211, -0.2344, -0.3497, -0.2913, -0.1679]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1572,  1.4245,  1.6394,  1.7366,  1.8112],\n",
      "          [ 1.4544,  1.6437,  1.8189,  1.9416,  2.0719],\n",
      "          [ 1.6483,  1.7955,  1.9594,  2.1023,  2.2634],\n",
      "          [ 1.7859,  1.9723,  2.1771,  2.3056,  2.4604]],\n",
      "\n",
      "         [[-1.1573, -1.4245, -1.6394, -1.7365, -1.8112],\n",
      "          [-1.4544, -1.6436, -1.8188, -1.9415, -2.0717],\n",
      "          [-1.6482, -1.7954, -1.9593, -2.1021, -2.2632],\n",
      "          [-1.7859, -1.9721, -2.1769, -2.3054, -2.4602]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.1368, -0.2604, -0.3332, -0.4772, -0.6063],\n",
      "          [-0.2711, -0.3279, -0.3546, -0.4774, -0.5812],\n",
      "          [-0.3811, -0.3660, -0.3040, -0.3419, -0.4113],\n",
      "          [-0.4502, -0.4430, -0.4073, -0.4792, -0.5967]],\n",
      "\n",
      "         [[ 0.1368,  0.2604,  0.3332,  0.4771,  0.6062],\n",
      "          [ 0.2711,  0.3280,  0.3547,  0.4775,  0.5813],\n",
      "          [ 0.3811,  0.3662,  0.3041,  0.3420,  0.4115],\n",
      "          [ 0.4502,  0.4431,  0.4074,  0.4794,  0.5968]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.4221,  1.7551,  2.0222,  2.1537,  2.2767],\n",
      "          [ 1.7672,  1.9576,  2.1253,  2.2682,  2.4425],\n",
      "          [ 1.9940,  2.1184,  2.2696,  2.4494,  2.6794],\n",
      "          [ 2.1290,  2.2754,  2.4371,  2.6442,  2.9135]],\n",
      "\n",
      "         [[-1.4221, -1.7551, -2.0221, -2.1537, -2.2766],\n",
      "          [-1.7672, -1.9575, -2.1251, -2.2680, -2.4423],\n",
      "          [-1.9939, -2.1182, -2.2694, -2.4492, -2.6792],\n",
      "          [-2.1290, -2.2752, -2.4368, -2.6440, -2.9133]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9640,  1.2046,  1.4060,  1.6142,  1.8085],\n",
      "          [ 1.2244,  1.4152,  1.5420,  1.7811,  2.0297],\n",
      "          [ 1.3758,  1.5221,  1.6117,  1.8702,  2.1470],\n",
      "          [ 1.4213,  1.5719,  1.6488,  1.9201,  2.1962]],\n",
      "\n",
      "         [[-0.9641, -1.2046, -1.4060, -1.6142, -1.8085],\n",
      "          [-1.2244, -1.4151, -1.5419, -1.7809, -2.0296],\n",
      "          [-1.3758, -1.5220, -1.6116, -1.8701, -2.1469],\n",
      "          [-1.4213, -1.5718, -1.6487, -1.9200, -2.1961]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2374,  1.5538,  1.7857,  1.9094,  1.9971],\n",
      "          [ 1.5490,  1.7641,  1.9088,  2.0291,  2.1424],\n",
      "          [ 1.7209,  1.8481,  1.9225,  2.0306,  2.1393],\n",
      "          [ 1.8717,  2.0298,  2.1186,  2.2036,  2.2893]],\n",
      "\n",
      "         [[-1.2375, -1.5538, -1.7857, -1.9094, -1.9970],\n",
      "          [-1.5490, -1.7640, -1.9087, -2.0290, -2.1422],\n",
      "          [-1.7209, -1.8480, -1.9223, -2.0305, -2.1391],\n",
      "          [-1.8716, -2.0296, -2.1184, -2.2034, -2.2892]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5274,  0.6033,  0.6235,  0.7096,  0.7992],\n",
      "          [ 0.6615,  0.7207,  0.7000,  0.8731,  1.0767],\n",
      "          [ 0.7497,  0.7880,  0.7972,  1.0713,  1.3730],\n",
      "          [ 0.8296,  0.8252,  0.8030,  1.0729,  1.3666]],\n",
      "\n",
      "         [[-0.5275, -0.6033, -0.6235, -0.7096, -0.7992],\n",
      "          [-0.6614, -0.7206, -0.6999, -0.8730, -1.0766],\n",
      "          [-0.7497, -0.7879, -0.7970, -1.0711, -1.3729],\n",
      "          [-0.8295, -0.8251, -0.8029, -1.0727, -1.3664]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7799,  0.9749,  1.0573,  1.1740,  1.2765],\n",
      "          [ 0.9401,  1.1241,  1.1762,  1.3471,  1.5105],\n",
      "          [ 0.9868,  1.1193,  1.1517,  1.3436,  1.5529],\n",
      "          [ 1.2227,  1.4549,  1.5775,  1.8195,  2.0624]],\n",
      "\n",
      "         [[-0.7800, -0.9749, -1.0573, -1.1740, -1.2765],\n",
      "          [-0.9401, -1.1241, -1.1761, -1.3470, -1.5104],\n",
      "          [-0.9868, -1.1192, -1.1516, -1.3435, -1.5528],\n",
      "          [-1.2227, -1.4548, -1.5774, -1.8194, -2.0623]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3181,  1.6508,  1.9056,  1.9983,  2.0473],\n",
      "          [ 1.5518,  1.7292,  1.9076,  2.0194,  2.0840],\n",
      "          [ 1.6958,  1.7665,  1.8750,  1.9736,  2.0645],\n",
      "          [ 1.8476,  1.9702,  2.0712,  2.1515,  2.2655]],\n",
      "\n",
      "         [[-1.3182, -1.6508, -1.9055, -1.9982, -2.0473],\n",
      "          [-1.5518, -1.7291, -1.9074, -2.0192, -2.0838],\n",
      "          [-1.6957, -1.7663, -1.8748, -1.9733, -2.0642],\n",
      "          [-1.8475, -1.9700, -2.0710, -2.1512, -2.2653]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3173,  1.6513,  1.9259,  2.0676,  2.0925],\n",
      "          [ 1.6381,  1.8544,  2.0757,  2.2752,  2.3714],\n",
      "          [ 1.8458,  2.0452,  2.3056,  2.5365,  2.6841],\n",
      "          [ 1.9483,  2.1947,  2.4627,  2.6519,  2.7935]],\n",
      "\n",
      "         [[-1.3173, -1.6513, -1.9258, -2.0675, -2.0924],\n",
      "          [-1.6381, -1.8543, -2.0755, -2.2750, -2.3713],\n",
      "          [-1.8458, -2.0451, -2.3054, -2.5364, -2.6840],\n",
      "          [-1.9483, -2.1946, -2.4626, -2.6517, -2.7934]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2228,  1.5342,  1.7757,  1.9106,  1.9592],\n",
      "          [ 1.4919,  1.6867,  1.8760,  2.0473,  2.1428],\n",
      "          [ 1.5599,  1.7144,  1.9470,  2.1340,  2.2498],\n",
      "          [ 1.6149,  1.8762,  2.1665,  2.3357,  2.4426]],\n",
      "\n",
      "         [[-1.2229, -1.5342, -1.7757, -1.9106, -1.9592],\n",
      "          [-1.4919, -1.6866, -1.8759, -2.0472, -2.1427],\n",
      "          [-1.5599, -1.7143, -1.9469, -2.1339, -2.2496],\n",
      "          [-1.6149, -1.8761, -2.1664, -2.3355, -2.4425]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9334,  1.2369,  1.4751,  1.6437,  1.7838],\n",
      "          [ 1.1997,  1.5171,  1.7264,  1.8964,  2.0299],\n",
      "          [ 1.3627,  1.6720,  1.8815,  2.0706,  2.2130],\n",
      "          [ 1.4889,  1.8117,  2.0239,  2.1814,  2.2766]],\n",
      "\n",
      "         [[-0.9335, -1.2369, -1.4751, -1.6436, -1.7838],\n",
      "          [-1.1997, -1.5170, -1.7263, -1.8963, -2.0298],\n",
      "          [-1.3627, -1.6720, -1.8814, -2.0705, -2.2129],\n",
      "          [-1.4889, -1.8116, -2.0238, -2.1813, -2.2764]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.6167,  2.0580,  2.4702,  2.5457,  2.6213],\n",
      "          [ 2.0361,  2.3412,  2.8249,  2.9499,  3.1047],\n",
      "          [ 2.4583,  2.7904,  3.4222,  3.5862,  3.6929],\n",
      "          [ 2.6489,  2.9774,  3.6411,  3.8129,  3.9208]],\n",
      "\n",
      "         [[-1.6167, -2.0580, -2.4701, -2.5456, -2.6212],\n",
      "          [-2.0360, -2.3410, -2.8247, -2.9496, -3.1045],\n",
      "          [-2.4582, -2.7901, -3.4219, -3.5859, -3.6926],\n",
      "          [-2.6488, -2.9772, -3.6408, -3.8126, -3.9205]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8272,  1.0110,  1.1754,  1.2781,  1.3983],\n",
      "          [ 0.8885,  0.9878,  1.1005,  1.2419,  1.3904],\n",
      "          [ 0.8983,  0.9780,  1.0829,  1.2556,  1.4311],\n",
      "          [ 0.9635,  1.1331,  1.2709,  1.4472,  1.6205]],\n",
      "\n",
      "         [[-0.8273, -1.0110, -1.1754, -1.2781, -1.3983],\n",
      "          [-0.8885, -0.9877, -1.1004, -1.2418, -1.3903],\n",
      "          [-0.8983, -0.9779, -1.0828, -1.2554, -1.4310],\n",
      "          [-0.9635, -1.1330, -1.2708, -1.4471, -1.6204]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6792,  0.7042,  0.6572,  0.6474,  0.6983],\n",
      "          [ 0.7543,  0.6898,  0.5981,  0.6490,  0.7850],\n",
      "          [ 0.7633,  0.6452,  0.5485,  0.6769,  0.9086],\n",
      "          [ 0.8158,  0.7215,  0.6329,  0.8016,  1.0637]],\n",
      "\n",
      "         [[-0.6793, -0.7042, -0.6572, -0.6474, -0.6983],\n",
      "          [-0.7543, -0.6897, -0.5980, -0.6489, -0.7849],\n",
      "          [-0.7633, -0.6451, -0.5484, -0.6768, -0.9085],\n",
      "          [-0.8158, -0.7214, -0.6327, -0.8015, -1.0636]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0999,  1.2660,  1.3320,  1.3966,  1.4779],\n",
      "          [ 1.3678,  1.4177,  1.3898,  1.5278,  1.7016],\n",
      "          [ 1.5448,  1.5232,  1.4456,  1.6145,  1.8370],\n",
      "          [ 1.6903,  1.7035,  1.6318,  1.7774,  1.9813]],\n",
      "\n",
      "         [[-1.1000, -1.2660, -1.3320, -1.3966, -1.4778],\n",
      "          [-1.3678, -1.4176, -1.3897, -1.5277, -1.7015],\n",
      "          [-1.5448, -1.5231, -1.4454, -1.6143, -1.8369],\n",
      "          [-1.6903, -1.7034, -1.6317, -1.7773, -1.9812]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7300,  2.1631,  2.6109,  2.8134,  2.9914],\n",
      "          [ 2.1090,  2.3372,  2.8395,  3.1621,  3.4597],\n",
      "          [ 2.4976,  2.7082,  3.3149,  3.7442,  4.1819],\n",
      "          [ 2.7195,  2.9692,  3.6395,  4.0978,  4.5249]],\n",
      "\n",
      "         [[-1.7301, -2.1630, -2.6108, -2.8133, -2.9913],\n",
      "          [-2.1089, -2.3370, -2.8392, -3.1618, -3.4594],\n",
      "          [-2.4975, -2.7080, -3.3146, -3.7439, -4.1815],\n",
      "          [-2.7194, -2.9689, -3.6392, -4.0975, -4.5245]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0179,  1.2754,  1.4617,  1.5067,  1.5505],\n",
      "          [ 1.2661,  1.4711,  1.5766,  1.5854,  1.6337],\n",
      "          [ 1.4334,  1.6191,  1.7039,  1.6979,  1.7406],\n",
      "          [ 1.4739,  1.6425,  1.7025,  1.6754,  1.7073]],\n",
      "\n",
      "         [[-1.0180, -1.2753, -1.4617, -1.5066, -1.5505],\n",
      "          [-1.2661, -1.4710, -1.5764, -1.5852, -1.6335],\n",
      "          [-1.4334, -1.6190, -1.7037, -1.6977, -1.7405],\n",
      "          [-1.4739, -1.6423, -1.7023, -1.6753, -1.7071]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6680,  0.7112,  0.7343,  0.8484,  0.8833],\n",
      "          [ 0.7813,  0.7527,  0.7341,  0.9408,  1.0192],\n",
      "          [ 0.8199,  0.7292,  0.7041,  0.9421,  1.0349],\n",
      "          [ 0.9656,  0.9083,  0.8855,  1.0831,  1.1362]],\n",
      "\n",
      "         [[-0.6681, -0.7112, -0.7343, -0.8484, -0.8833],\n",
      "          [-0.7813, -0.7526, -0.7341, -0.9408, -1.0192],\n",
      "          [-0.8199, -0.7292, -0.7040, -0.9421, -1.0349],\n",
      "          [-0.9656, -0.9083, -0.8855, -1.0831, -1.1363]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2652,  1.6189,  1.9088,  2.0042,  2.0848],\n",
      "          [ 1.5200,  1.7562,  1.9695,  2.0355,  2.1207],\n",
      "          [ 1.7001,  1.8556,  2.0030,  2.0693,  2.1817],\n",
      "          [ 1.8292,  1.9961,  2.1231,  2.2171,  2.3726]],\n",
      "\n",
      "         [[-1.2653, -1.6189, -1.9088, -2.0042, -2.0847],\n",
      "          [-1.5200, -1.7561, -1.9693, -2.0353, -2.1205],\n",
      "          [-1.7000, -1.8554, -2.0028, -2.0691, -2.1815],\n",
      "          [-1.8292, -1.9959, -2.1229, -2.2169, -2.3724]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4820,  0.6032,  0.7255,  0.7411,  0.8012],\n",
      "          [ 0.5377,  0.6883,  0.8156,  0.8156,  0.8767],\n",
      "          [ 0.5829,  0.7550,  0.8936,  0.8845,  0.9335],\n",
      "          [ 0.6181,  0.8024,  0.9381,  0.9265,  0.9736]],\n",
      "\n",
      "         [[-0.4820, -0.6032, -0.7255, -0.7411, -0.8012],\n",
      "          [-0.5377, -0.6882, -0.8154, -0.8155, -0.8766],\n",
      "          [-0.5829, -0.7549, -0.8934, -0.8844, -0.9334],\n",
      "          [-0.6181, -0.8022, -0.9379, -0.9263, -0.9734]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 2.0787,  2.6986,  3.1926,  3.4301,  3.6128],\n",
      "          [ 2.6659,  2.9664,  3.5944,  3.9446,  4.2461],\n",
      "          [ 3.1404,  3.5455,  4.3259,  4.7833,  5.1745],\n",
      "          [ 3.3533,  3.8446,  4.7015,  5.1903,  5.5369]],\n",
      "\n",
      "         [[-2.0787, -2.6985, -3.1924, -3.4299, -3.6126],\n",
      "          [-2.6658, -2.9662, -3.5940, -3.9442, -4.2457],\n",
      "          [-3.1402, -3.5451, -4.3255, -4.7828, -5.1740],\n",
      "          [-3.3530, -3.8442, -4.7011, -5.1898, -5.5363]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5882,  0.6961,  0.7629,  0.8400,  0.9118],\n",
      "          [ 0.7024,  0.7763,  0.8004,  0.9006,  0.9852],\n",
      "          [ 0.7847,  0.8577,  0.9173,  1.0580,  1.1648],\n",
      "          [ 0.9281,  1.0646,  1.1364,  1.2119,  1.2770]],\n",
      "\n",
      "         [[-0.5883, -0.6961, -0.7629, -0.8401, -0.9118],\n",
      "          [-0.7024, -0.7762, -0.8003, -0.9005, -0.9851],\n",
      "          [-0.7847, -0.8576, -0.9172, -1.0579, -1.1647],\n",
      "          [-0.9281, -1.0645, -1.1362, -1.2118, -1.2769]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8197,  0.8858,  0.9607,  0.5458,  0.0654],\n",
      "          [ 1.0334,  1.0498,  1.1180,  0.6078, -0.0255],\n",
      "          [ 1.2131,  1.2417,  1.2774,  0.7033, -0.0310],\n",
      "          [ 1.1432,  1.2186,  1.2135,  0.6389, -0.0265]],\n",
      "\n",
      "         [[-0.8198, -0.8859, -0.9608, -0.5459, -0.0655],\n",
      "          [-1.0334, -1.0498, -1.1179, -0.6078,  0.0255],\n",
      "          [-1.2132, -1.2417, -1.2773, -0.7033,  0.0310],\n",
      "          [-1.1433, -1.2185, -1.2135, -0.6389,  0.0264]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1192,  0.1735,  0.2245,  0.3188,  0.4486],\n",
      "          [ 0.1478,  0.2891,  0.3561,  0.4650,  0.5984],\n",
      "          [ 0.1643,  0.3278,  0.3740,  0.4924,  0.6001],\n",
      "          [ 0.2258,  0.3862,  0.4190,  0.5399,  0.6740]],\n",
      "\n",
      "         [[-0.1193, -0.1735, -0.2245, -0.3188, -0.4486],\n",
      "          [-0.1478, -0.2890, -0.3559, -0.4649, -0.5983],\n",
      "          [-0.1643, -0.3276, -0.3738, -0.4923, -0.6000],\n",
      "          [-0.2258, -0.3861, -0.4189, -0.5398, -0.6739]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.4141,  1.7834,  2.0699,  2.2459,  2.3430],\n",
      "          [ 1.7574,  2.0377,  2.2849,  2.5264,  2.6857],\n",
      "          [ 1.9763,  2.2149,  2.4430,  2.7198,  2.9294],\n",
      "          [ 2.1406,  2.4623,  2.7228,  2.9829,  3.1767]],\n",
      "\n",
      "         [[-1.4141, -1.7834, -2.0698, -2.2458, -2.3430],\n",
      "          [-1.7573, -2.0376, -2.2847, -2.5262, -2.6855],\n",
      "          [-1.9763, -2.2147, -2.4428, -2.7196, -2.9292],\n",
      "          [-2.1406, -2.4622, -2.7226, -2.9827, -3.1765]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.2334, -0.4286, -0.6385, -0.7710, -0.8689],\n",
      "          [-0.3091, -0.4456, -0.6890, -0.8118, -0.8918],\n",
      "          [-0.3874, -0.5004, -0.7024, -0.7753, -0.8339],\n",
      "          [-0.2881, -0.3683, -0.5050, -0.5384, -0.5432]],\n",
      "\n",
      "         [[ 0.2333,  0.4286,  0.6385,  0.7710,  0.8689],\n",
      "          [ 0.3091,  0.4457,  0.6891,  0.8119,  0.8919],\n",
      "          [ 0.3874,  0.5005,  0.7026,  0.7754,  0.8341],\n",
      "          [ 0.2881,  0.3684,  0.5052,  0.5386,  0.5433]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.4671,  1.8310,  2.1376,  2.2794,  2.3557],\n",
      "          [ 1.8395,  2.0852,  2.3109,  2.4429,  2.5824],\n",
      "          [ 2.0882,  2.2852,  2.4877,  2.6160,  2.7720],\n",
      "          [ 2.2486,  2.4784,  2.7095,  2.8447,  3.0171]],\n",
      "\n",
      "         [[-1.4672, -1.8310, -2.1376, -2.2794, -2.3557],\n",
      "          [-1.8395, -2.0851, -2.3107, -2.4427, -2.5822],\n",
      "          [-2.0881, -2.2851, -2.4875, -2.6158, -2.7718],\n",
      "          [-2.2485, -2.4782, -2.7093, -2.8445, -3.0169]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9782,  1.2177,  1.3592,  1.4746,  1.6304],\n",
      "          [ 1.1571,  1.3527,  1.4259,  1.5690,  1.7729],\n",
      "          [ 1.2233,  1.4002,  1.4508,  1.6187,  1.8537],\n",
      "          [ 1.3045,  1.5311,  1.6024,  1.7684,  1.9880]],\n",
      "\n",
      "         [[-0.9782, -1.2177, -1.3592, -1.4746, -1.6304],\n",
      "          [-1.1571, -1.3527, -1.4258, -1.5689, -1.7728],\n",
      "          [-1.2233, -1.4001, -1.4507, -1.6186, -1.8535],\n",
      "          [-1.3045, -1.5310, -1.6023, -1.7683, -1.9880]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4473,  0.4752,  0.5237,  0.4973,  0.5318],\n",
      "          [ 0.5668,  0.5890,  0.6442,  0.6050,  0.6055],\n",
      "          [ 0.7071,  0.7435,  0.8033,  0.7344,  0.6638],\n",
      "          [ 0.7658,  0.7959,  0.8424,  0.7844,  0.7049]],\n",
      "\n",
      "         [[-0.4474, -0.4752, -0.5237, -0.4973, -0.5318],\n",
      "          [-0.5668, -0.5889, -0.6440, -0.6049, -0.6054],\n",
      "          [-0.7071, -0.7433, -0.8032, -0.7342, -0.6637],\n",
      "          [-0.7658, -0.7958, -0.8422, -0.7843, -0.7048]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7121,  0.8120,  0.8989,  0.8998,  0.9114],\n",
      "          [ 0.7846,  0.8015,  0.8619,  0.8799,  0.9125],\n",
      "          [ 0.8618,  0.8484,  0.8902,  0.9039,  0.9305],\n",
      "          [ 0.9667,  0.9823,  1.0136,  1.0010,  1.0435]],\n",
      "\n",
      "         [[-0.7121, -0.8119, -0.8989, -0.8998, -0.9113],\n",
      "          [-0.7846, -0.8014, -0.8617, -0.8797, -0.9124],\n",
      "          [-0.8618, -0.8483, -0.8900, -0.9036, -0.9303],\n",
      "          [-0.9667, -0.9821, -1.0134, -1.0008, -1.0433]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1373,  1.4433,  1.6922,  1.8465,  1.9920],\n",
      "          [ 1.4489,  1.7278,  1.9527,  2.1357,  2.3149],\n",
      "          [ 1.7336,  2.0231,  2.2711,  2.4696,  2.6633],\n",
      "          [ 1.8870,  2.1737,  2.4261,  2.5814,  2.7530]],\n",
      "\n",
      "         [[-1.1373, -1.4433, -1.6921, -1.8465, -1.9920],\n",
      "          [-1.4489, -1.7277, -1.9525, -2.1355, -2.3147],\n",
      "          [-1.7335, -2.0229, -2.2708, -2.4694, -2.6631],\n",
      "          [-1.8870, -2.1735, -2.4258, -2.5811, -2.7528]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8490,  0.9157,  0.9476,  0.8769,  0.6969],\n",
      "          [ 0.9859,  0.9010,  0.8408,  0.8412,  0.7442],\n",
      "          [ 1.0277,  0.8767,  0.8248,  0.8721,  0.8178],\n",
      "          [ 1.1077,  1.0018,  0.9432,  0.9607,  0.8876]],\n",
      "\n",
      "         [[-0.8491, -0.9158, -0.9476, -0.8770, -0.6969],\n",
      "          [-0.9860, -0.9009, -0.8407, -0.8412, -0.7442],\n",
      "          [-1.0277, -0.8767, -0.8247, -0.8720, -0.8177],\n",
      "          [-1.1078, -1.0018, -0.9431, -0.9606, -0.8875]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2891,  1.5886,  1.8316,  1.9845,  2.0425],\n",
      "          [ 1.6317,  1.8310,  1.9973,  2.1921,  2.3107],\n",
      "          [ 1.8550,  2.0383,  2.2154,  2.4233,  2.5763],\n",
      "          [ 1.9376,  2.1627,  2.3399,  2.5248,  2.6712]],\n",
      "\n",
      "         [[-1.2892, -1.5886, -1.8316, -1.9845, -2.0425],\n",
      "          [-1.6317, -1.8309, -1.9972, -2.1920, -2.3106],\n",
      "          [-1.8550, -2.0382, -2.2152, -2.4232, -2.5761],\n",
      "          [-1.9376, -2.1626, -2.3397, -2.5247, -2.6711]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9619,  1.2128,  1.3855,  1.4188,  1.4347],\n",
      "          [ 1.1608,  1.3676,  1.5133,  1.5379,  1.5661],\n",
      "          [ 1.2699,  1.4366,  1.5853,  1.6322,  1.6684],\n",
      "          [ 1.4361,  1.6894,  1.9395,  2.0691,  2.1712]],\n",
      "\n",
      "         [[-0.9620, -1.2128, -1.3855, -1.4188, -1.4347],\n",
      "          [-1.1608, -1.3675, -1.5132, -1.5378, -1.5660],\n",
      "          [-1.2699, -1.4366, -1.5852, -1.6320, -1.6682],\n",
      "          [-1.4362, -1.6893, -1.9394, -2.0690, -2.1710]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0462,  1.2857,  1.4839,  1.6226,  1.7059],\n",
      "          [ 1.2877,  1.4383,  1.5426,  1.7136,  1.8440],\n",
      "          [ 1.3971,  1.4918,  1.5524,  1.7395,  1.9000],\n",
      "          [ 1.4533,  1.5920,  1.6586,  1.8275,  1.9710]],\n",
      "\n",
      "         [[-1.0463, -1.2857, -1.4839, -1.6226, -1.7059],\n",
      "          [-1.2878, -1.4382, -1.5425, -1.7135, -1.8439],\n",
      "          [-1.3971, -1.4917, -1.5523, -1.7393, -1.8999],\n",
      "          [-1.4533, -1.5919, -1.6584, -1.8274, -1.9709]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9929,  1.1003,  1.1626,  1.1621,  1.1962],\n",
      "          [ 1.1524,  1.1231,  1.1068,  1.1260,  1.1927],\n",
      "          [ 1.3041,  1.2390,  1.1968,  1.2249,  1.3100],\n",
      "          [ 1.3734,  1.3050,  1.2579,  1.2877,  1.4224]],\n",
      "\n",
      "         [[-0.9929, -1.1003, -1.1626, -1.1621, -1.1961],\n",
      "          [-1.1524, -1.1229, -1.1066, -1.1258, -1.1926],\n",
      "          [-1.3040, -1.2389, -1.1965, -1.2247, -1.3098],\n",
      "          [-1.3734, -1.3049, -1.2576, -1.2875, -1.4222]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0136,  1.2538,  1.3641,  1.4762,  1.5792],\n",
      "          [ 1.2087,  1.4046,  1.5321,  1.7407,  1.9391],\n",
      "          [ 1.2565,  1.3767,  1.5027,  1.7419,  2.0280],\n",
      "          [ 1.2913,  1.4495,  1.6239,  1.8899,  2.2520]],\n",
      "\n",
      "         [[-1.0137, -1.2538, -1.3641, -1.4763, -1.5792],\n",
      "          [-1.2088, -1.4045, -1.5321, -1.7407, -1.9390],\n",
      "          [-1.2565, -1.3767, -1.5027, -1.7418, -2.0279],\n",
      "          [-1.2914, -1.4495, -1.6238, -1.8898, -2.2519]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3479,  0.3974,  0.3924,  0.4484,  0.5116],\n",
      "          [ 0.3421,  0.3689,  0.2878,  0.3622,  0.4422],\n",
      "          [ 0.2509,  0.2481,  0.1761,  0.2940,  0.4129],\n",
      "          [ 0.1554,  0.1447,  0.0928,  0.2606,  0.4523]],\n",
      "\n",
      "         [[-0.3480, -0.3974, -0.3924, -0.4484, -0.5116],\n",
      "          [-0.3422, -0.3688, -0.2877, -0.3622, -0.4422],\n",
      "          [-0.2509, -0.2480, -0.1760, -0.2940, -0.4129],\n",
      "          [-0.1554, -0.1447, -0.0927, -0.2605, -0.4523]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7121,  2.2053,  2.6380,  2.8134,  2.9482],\n",
      "          [ 2.1581,  2.5336,  2.9906,  3.2338,  3.4454],\n",
      "          [ 2.5624,  2.9773,  3.5279,  3.8109,  4.0338],\n",
      "          [ 2.6964,  3.1661,  3.7294,  3.9966,  4.2013]],\n",
      "\n",
      "         [[-1.7121, -2.2053, -2.6379, -2.8133, -2.9480],\n",
      "          [-2.1580, -2.5334, -2.9904, -3.2335, -3.4451],\n",
      "          [-2.5623, -2.9770, -3.5276, -3.8106, -4.0334],\n",
      "          [-2.6963, -3.1658, -3.7291, -3.9962, -4.2009]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.0954, -0.1134, -0.1830, -0.2084, -0.1824],\n",
      "          [-0.1633, -0.0612, -0.1237, -0.1556, -0.1322],\n",
      "          [-0.3418, -0.2529, -0.2804, -0.2918, -0.2581],\n",
      "          [-0.4061, -0.3123, -0.2947, -0.3149, -0.3096]],\n",
      "\n",
      "         [[ 0.0953,  0.1134,  0.1829,  0.2084,  0.1824],\n",
      "          [ 0.1633,  0.0612,  0.1238,  0.1557,  0.1323],\n",
      "          [ 0.3418,  0.2530,  0.2805,  0.2919,  0.2582],\n",
      "          [ 0.4061,  0.3123,  0.2948,  0.3150,  0.3097]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3527,  1.6472,  1.8907,  1.9685,  2.0187],\n",
      "          [ 1.7227,  1.9032,  2.0850,  2.1600,  2.2324],\n",
      "          [ 1.9696,  2.1038,  2.2890,  2.3795,  2.4816],\n",
      "          [ 2.1539,  2.3570,  2.6213,  2.7518,  2.8925]],\n",
      "\n",
      "         [[-1.3527, -1.6472, -1.8906, -1.9685, -2.0186],\n",
      "          [-1.7226, -1.9031, -2.0849, -2.1598, -2.2323],\n",
      "          [-1.9695, -2.1037, -2.2888, -2.3793, -2.4814],\n",
      "          [-2.1538, -2.3569, -2.6211, -2.7516, -2.8922]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9390,  1.2056,  1.4769,  1.7706,  2.0570],\n",
      "          [ 1.1753,  1.4033,  1.6132,  1.9569,  2.2944],\n",
      "          [ 1.3093,  1.5134,  1.6814,  2.0990,  2.5068],\n",
      "          [ 1.3803,  1.6469,  1.8126,  2.2551,  2.6691]],\n",
      "\n",
      "         [[-0.9391, -1.2057, -1.4769, -1.7706, -2.0569],\n",
      "          [-1.1753, -1.4032, -1.6131, -1.9568, -2.2942],\n",
      "          [-1.3093, -1.5133, -1.6813, -2.0989, -2.5067],\n",
      "          [-1.3803, -1.6468, -1.8125, -2.2549, -2.6689]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9324,  2.5243,  2.9742,  3.1578,  3.3041],\n",
      "          [ 2.4679,  2.8313,  3.4431,  3.7380,  4.0044],\n",
      "          [ 2.9048,  3.3380,  4.1103,  4.5201,  4.8249],\n",
      "          [ 3.1093,  3.6172,  4.4838,  4.8893,  5.2062]],\n",
      "\n",
      "         [[-1.9324, -2.5242, -2.9740, -3.1576, -3.3038],\n",
      "          [-2.4678, -2.8311, -3.4428, -3.7376, -4.0040],\n",
      "          [-2.9046, -3.3377, -4.1100, -4.5197, -4.8244],\n",
      "          [-3.1091, -3.6169, -4.4834, -4.8888, -5.2057]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2595,  1.6308,  1.9223,  2.0581,  2.1688],\n",
      "          [ 1.5819,  1.9058,  2.1473,  2.2715,  2.3814],\n",
      "          [ 1.7997,  2.0960,  2.2992,  2.4112,  2.5068],\n",
      "          [ 1.9025,  2.1977,  2.3781,  2.4937,  2.6129]],\n",
      "\n",
      "         [[-1.2595, -1.6308, -1.9222, -2.0580, -2.1687],\n",
      "          [-1.5818, -1.9057, -2.1471, -2.2713, -2.3812],\n",
      "          [-1.7996, -2.0959, -2.2990, -2.4110, -2.5065],\n",
      "          [-1.9025, -2.1975, -2.3779, -2.4935, -2.6127]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.1915, -0.3605, -0.5335, -0.7907, -1.0214],\n",
      "          [-0.3255, -0.4379, -0.5738, -0.8349, -1.0800],\n",
      "          [-0.4234, -0.5422, -0.6541, -0.9162, -1.1631],\n",
      "          [-0.4698, -0.6445, -0.7873, -1.0826, -1.3306]],\n",
      "\n",
      "         [[ 0.1914,  0.3605,  0.5335,  0.7907,  1.0214],\n",
      "          [ 0.3254,  0.4379,  0.5739,  0.8350,  1.0801],\n",
      "          [ 0.4234,  0.5423,  0.6543,  0.9163,  1.1633],\n",
      "          [ 0.4697,  0.6445,  0.7874,  1.0827,  1.3307]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 2.0621,  2.7085,  3.2219,  3.4982,  3.7218],\n",
      "          [ 2.6504,  2.9971,  3.6529,  4.0493,  4.4039],\n",
      "          [ 3.1150,  3.6365,  4.4721,  4.9828,  5.3719],\n",
      "          [ 3.3310,  3.9728,  4.8751,  5.3399,  5.7166]],\n",
      "\n",
      "         [[-2.0620, -2.7084, -3.2217, -3.4979, -3.7215],\n",
      "          [-2.6502, -2.9968, -3.6525, -4.0489, -4.4034],\n",
      "          [-3.1148, -3.6362, -4.4716, -4.9823, -5.3713],\n",
      "          [-3.3308, -3.9725, -4.8746, -5.3393, -5.7160]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0921,  1.3289,  1.4913,  1.5498,  1.5716],\n",
      "          [ 1.4096,  1.5560,  1.6460,  1.7253,  1.7467],\n",
      "          [ 1.6347,  1.7002,  1.7452,  1.8126,  1.8302],\n",
      "          [ 1.9075,  2.0423,  2.1944,  2.2696,  2.3158]],\n",
      "\n",
      "         [[-1.0921, -1.3289, -1.4913, -1.5498, -1.5716],\n",
      "          [-1.4096, -1.5559, -1.6459, -1.7252, -1.7465],\n",
      "          [-1.6346, -1.7001, -1.7451, -1.8125, -1.8301],\n",
      "          [-1.9075, -2.0422, -2.1943, -2.2694, -2.3157]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.4443,  1.8700,  2.2706,  2.4444,  2.5862],\n",
      "          [ 1.8200,  2.1714,  2.5859,  2.8281,  3.0716],\n",
      "          [ 2.1192,  2.4777,  2.9765,  3.2986,  3.6283],\n",
      "          [ 2.3056,  2.6844,  3.2312,  3.5791,  3.9181]],\n",
      "\n",
      "         [[-1.4443, -1.8700, -2.2705, -2.4443, -2.5860],\n",
      "          [-1.8199, -2.1712, -2.5857, -2.8278, -3.0714],\n",
      "          [-2.1191, -2.4775, -2.9762, -3.2983, -3.6280],\n",
      "          [-2.3056, -2.6842, -3.2309, -3.5789, -3.9178]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0512,  1.3383,  1.5486,  1.6448,  1.6674],\n",
      "          [ 1.3483,  1.6203,  1.7932,  1.9373,  1.9897],\n",
      "          [ 1.5451,  1.8019,  1.9748,  2.1338,  2.1812],\n",
      "          [ 1.6030,  1.8253,  1.9755,  2.0753,  2.0852]],\n",
      "\n",
      "         [[-1.0513, -1.3383, -1.5486, -1.6448, -1.6674],\n",
      "          [-1.3483, -1.6202, -1.7931, -1.9371, -1.9896],\n",
      "          [-1.5450, -1.8018, -1.9747, -2.1336, -2.1810],\n",
      "          [-1.6029, -1.8252, -1.9753, -2.0751, -2.0851]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7240,  0.8796,  0.9941,  1.2474,  1.5043],\n",
      "          [ 0.9585,  1.0685,  1.0625,  1.3674,  1.7089],\n",
      "          [ 1.1106,  1.1943,  1.1505,  1.4975,  1.8741],\n",
      "          [ 1.1706,  1.2404,  1.2225,  1.6265,  2.0433]],\n",
      "\n",
      "         [[-0.7241, -0.8796, -0.9941, -1.2474, -1.5043],\n",
      "          [-0.9585, -1.0684, -1.0624, -1.3673, -1.7088],\n",
      "          [-1.1106, -1.1941, -1.1504, -1.4974, -1.8740],\n",
      "          [-1.1706, -1.2403, -1.2223, -1.6264, -2.0432]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2666,  0.2093,  0.1533,  0.0188, -0.0709],\n",
      "          [ 0.3262,  0.2766,  0.2287,  0.0607, -0.0565],\n",
      "          [ 0.4022,  0.3459,  0.3229,  0.1559,  0.0230],\n",
      "          [ 0.4707,  0.3561,  0.3103,  0.1216, -0.0447]],\n",
      "\n",
      "         [[-0.2667, -0.2094, -0.1533, -0.0188,  0.0709],\n",
      "          [-0.3262, -0.2766, -0.2286, -0.0606,  0.0566],\n",
      "          [-0.4022, -0.3458, -0.3227, -0.1557, -0.0229],\n",
      "          [-0.4707, -0.3560, -0.3102, -0.1215,  0.0448]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5879,  0.6264,  0.6479,  0.6190,  0.6691],\n",
      "          [ 0.5667,  0.5056,  0.4605,  0.4357,  0.5253],\n",
      "          [ 0.5084,  0.4137,  0.3602,  0.3842,  0.5248],\n",
      "          [ 0.3481,  0.2126,  0.1751,  0.3012,  0.5454]],\n",
      "\n",
      "         [[-0.5879, -0.6264, -0.6479, -0.6190, -0.6691],\n",
      "          [-0.5667, -0.5055, -0.4604, -0.4356, -0.5252],\n",
      "          [-0.5084, -0.4136, -0.3601, -0.3841, -0.5247],\n",
      "          [-0.3481, -0.2125, -0.1750, -0.3011, -0.5454]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1278,  1.3562,  1.5444,  1.6421,  1.6226],\n",
      "          [ 1.4234,  1.5298,  1.6512,  1.8106,  1.8470],\n",
      "          [ 1.6198,  1.6715,  1.7702,  1.9325,  1.9816],\n",
      "          [ 1.7418,  1.8366,  1.9345,  2.0692,  2.1112]],\n",
      "\n",
      "         [[-1.1279, -1.3562, -1.5444, -1.6421, -1.6226],\n",
      "          [-1.4234, -1.5298, -1.6511, -1.8105, -1.8469],\n",
      "          [-1.6198, -1.6714, -1.7701, -1.9324, -1.9815],\n",
      "          [-1.7418, -1.8365, -1.9344, -2.0691, -2.1111]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.0150, -0.0278, -0.0619, -0.0839, -0.0481],\n",
      "          [ 0.0317,  0.0411, -0.0415, -0.1111, -0.0919],\n",
      "          [ 0.0525,  0.0735, -0.0178, -0.0889, -0.0627],\n",
      "          [ 0.1587,  0.1731,  0.0782, -0.0046,  0.0098]],\n",
      "\n",
      "         [[-0.0150,  0.0278,  0.0619,  0.0839,  0.0482],\n",
      "          [-0.0317, -0.0410,  0.0416,  0.1113,  0.0920],\n",
      "          [-0.0525, -0.0733,  0.0180,  0.0891,  0.0629],\n",
      "          [-0.1586, -0.1730, -0.0780,  0.0048, -0.0097]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 1 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 0 0 1 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2636,  1.5978,  1.8440,  1.9570,  2.0469],\n",
      "          [ 1.5686,  1.8361,  2.0795,  2.2432,  2.3935],\n",
      "          [ 1.7880,  2.0250,  2.2828,  2.4650,  2.6390],\n",
      "          [ 2.0136,  2.3172,  2.6459,  2.8431,  3.0165]],\n",
      "\n",
      "         [[-1.2636, -1.5978, -1.8439, -1.9569, -2.0469],\n",
      "          [-1.5686, -1.8360, -2.0793, -2.2430, -2.3933],\n",
      "          [-1.7880, -2.0248, -2.2826, -2.4648, -2.6388],\n",
      "          [-2.0135, -2.3171, -2.6457, -2.8429, -3.0163]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0824,  1.3603,  1.5934,  1.6836,  1.7815],\n",
      "          [ 1.2590,  1.4770,  1.6620,  1.7460,  1.8570],\n",
      "          [ 1.3416,  1.5659,  1.7299,  1.8005,  1.8991],\n",
      "          [ 1.3091,  1.5844,  1.7413,  1.7924,  1.8682]],\n",
      "\n",
      "         [[-1.0824, -1.3603, -1.5934, -1.6836, -1.7815],\n",
      "          [-1.2590, -1.4770, -1.6619, -1.7459, -1.8569],\n",
      "          [-1.3416, -1.5658, -1.7298, -1.8004, -1.8990],\n",
      "          [-1.3091, -1.5843, -1.7412, -1.7923, -1.8681]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9768,  1.1849,  1.3612,  1.3871,  1.4218],\n",
      "          [ 1.2187,  1.3767,  1.5735,  1.6113,  1.6543],\n",
      "          [ 1.4207,  1.5524,  1.7911,  1.8475,  1.9068],\n",
      "          [ 1.5101,  1.5977,  1.8140,  1.8601,  1.9406]],\n",
      "\n",
      "         [[-0.9769, -1.1848, -1.3611, -1.3870, -1.4218],\n",
      "          [-1.2187, -1.3765, -1.5732, -1.6111, -1.6540],\n",
      "          [-1.4207, -1.5522, -1.7908, -1.8472, -1.9065],\n",
      "          [-1.5101, -1.5975, -1.8138, -1.8599, -1.9403]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2164,  0.1878,  0.2205,  0.1571,  0.1462],\n",
      "          [ 0.1514,  0.1373,  0.2268,  0.2115,  0.2447],\n",
      "          [ 0.1042,  0.0923,  0.2251,  0.2626,  0.3429],\n",
      "          [ 0.2143,  0.2433,  0.3723,  0.3663,  0.4026]],\n",
      "\n",
      "         [[-0.2165, -0.1878, -0.2205, -0.1572, -0.1462],\n",
      "          [-0.1515, -0.1372, -0.2267, -0.2115, -0.2447],\n",
      "          [-0.1042, -0.0921, -0.2249, -0.2625, -0.3428],\n",
      "          [-0.2144, -0.2432, -0.3722, -0.3662, -0.4025]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5497,  0.6348,  0.6585,  0.6499,  0.6306],\n",
      "          [ 0.6495,  0.7253,  0.7219,  0.7074,  0.6768],\n",
      "          [ 0.6741,  0.7178,  0.7304,  0.7294,  0.7056],\n",
      "          [ 0.7285,  0.7760,  0.8000,  0.7994,  0.7859]],\n",
      "\n",
      "         [[-0.5498, -0.6348, -0.6585, -0.6499, -0.6306],\n",
      "          [-0.6495, -0.7253, -0.7218, -0.7074, -0.6767],\n",
      "          [-0.6741, -0.7177, -0.7303, -0.7293, -0.7055],\n",
      "          [-0.7285, -0.7759, -0.7999, -0.7993, -0.7858]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9379,  2.4952,  2.9658,  3.1987,  3.3884],\n",
      "          [ 2.4888,  2.8033,  3.3598,  3.7099,  4.0322],\n",
      "          [ 2.9401,  3.3832,  4.0886,  4.5405,  4.8955],\n",
      "          [ 3.1380,  3.6659,  4.4419,  4.8960,  5.2161]],\n",
      "\n",
      "         [[-1.9379, -2.4951, -2.9657, -3.1985, -3.3882],\n",
      "          [-2.4887, -2.8030, -3.3595, -3.7096, -4.0319],\n",
      "          [-2.9399, -3.3829, -4.0882, -4.5401, -4.8951],\n",
      "          [-3.1378, -3.6656, -4.4415, -4.8955, -5.2156]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4527,  0.4917,  0.4668,  0.4247,  0.4516],\n",
      "          [ 0.5187,  0.5847,  0.5434,  0.4615,  0.4605],\n",
      "          [ 0.5566,  0.6739,  0.6924,  0.6004,  0.5751],\n",
      "          [ 0.5813,  0.7216,  0.8301,  0.7571,  0.7457]],\n",
      "\n",
      "         [[-0.4527, -0.4917, -0.4667, -0.4246, -0.4515],\n",
      "          [-0.5187, -0.5846, -0.5433, -0.4614, -0.4604],\n",
      "          [-0.5566, -0.6737, -0.6922, -0.6002, -0.5750],\n",
      "          [-0.5813, -0.7215, -0.8299, -0.7569, -0.7456]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1246,  1.3868,  1.5449,  1.6257,  1.7251],\n",
      "          [ 1.4373,  1.6438,  1.7549,  1.8728,  1.9940],\n",
      "          [ 1.5891,  1.7065,  1.7747,  1.9360,  2.1345],\n",
      "          [ 1.7223,  1.8211,  1.8492,  1.9571,  2.1352]],\n",
      "\n",
      "         [[-1.1246, -1.3868, -1.5449, -1.6257, -1.7250],\n",
      "          [-1.4373, -1.6436, -1.7547, -1.8727, -1.9939],\n",
      "          [-1.5891, -1.7063, -1.7746, -1.9358, -2.1344],\n",
      "          [-1.7222, -1.8210, -1.8491, -1.9570, -2.1350]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9922,  1.2544,  1.4849,  1.6407,  1.7511],\n",
      "          [ 1.2290,  1.4549,  1.6236,  1.8043,  1.9362],\n",
      "          [ 1.3935,  1.6258,  1.7726,  1.9662,  2.1193],\n",
      "          [ 1.4823,  1.7594,  1.9220,  2.1386,  2.2985]],\n",
      "\n",
      "         [[-0.9923, -1.2544, -1.4849, -1.6407, -1.7511],\n",
      "          [-1.2290, -1.4548, -1.6235, -1.8042, -1.9361],\n",
      "          [-1.3935, -1.6257, -1.7725, -1.9661, -2.1192],\n",
      "          [-1.4823, -1.7593, -1.9219, -2.1385, -2.2984]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9880,  2.5811,  3.0751,  3.3130,  3.4983],\n",
      "          [ 2.5412,  2.8756,  3.4731,  3.8240,  4.1343],\n",
      "          [ 3.0056,  3.4786,  4.2386,  4.6964,  5.0518],\n",
      "          [ 3.2030,  3.7792,  4.6105,  5.0631,  5.3829]],\n",
      "\n",
      "         [[-1.9880, -2.5810, -3.0749, -3.3127, -3.4981],\n",
      "          [-2.5410, -2.8753, -3.4728, -3.8236, -4.1339],\n",
      "          [-3.0054, -3.4782, -4.2382, -4.6960, -5.0513],\n",
      "          [-3.2028, -3.7789, -4.6100, -5.0626, -5.3824]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2007,  1.4939,  1.7141,  1.8473,  1.9471],\n",
      "          [ 1.4842,  1.7027,  1.8537,  2.0165,  2.1529],\n",
      "          [ 1.6692,  1.8726,  2.0279,  2.2084,  2.3868],\n",
      "          [ 1.7951,  2.0426,  2.2112,  2.3685,  2.5239]],\n",
      "\n",
      "         [[-1.2008, -1.4939, -1.7141, -1.8473, -1.9470],\n",
      "          [-1.4842, -1.7026, -1.8535, -2.0163, -2.1528],\n",
      "          [-1.6692, -1.8725, -2.0277, -2.2082, -2.3866],\n",
      "          [-1.7951, -2.0425, -2.2110, -2.3684, -2.5237]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.2951, -0.2861, -0.2414, -0.2633, -0.1863],\n",
      "          [-0.3594, -0.1087,  0.0776,  0.0647,  0.1218],\n",
      "          [-0.3990, -0.0429,  0.2474,  0.3068,  0.3985],\n",
      "          [-0.5372, -0.2740, -0.0235,  0.0646,  0.1884]],\n",
      "\n",
      "         [[ 0.2950,  0.2860,  0.2414,  0.2633,  0.1863],\n",
      "          [ 0.3594,  0.1088, -0.0774, -0.0645, -0.1217],\n",
      "          [ 0.3990,  0.0430, -0.2472, -0.3066, -0.3984],\n",
      "          [ 0.5372,  0.2741,  0.0236, -0.0645, -0.1883]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 0 0 0]\n",
      " [1 1 0 0 0]\n",
      " [1 1 1 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9170,  2.4695,  2.9351,  3.1430,  3.2972],\n",
      "          [ 2.4157,  2.7238,  3.2704,  3.5793,  3.8417],\n",
      "          [ 2.8422,  3.2389,  3.9126,  4.3203,  4.6493],\n",
      "          [ 3.0075,  3.5036,  4.2280,  4.6420,  4.9010]],\n",
      "\n",
      "         [[-1.9170, -2.4694, -2.9349, -3.1428, -3.2969],\n",
      "          [-2.4156, -2.7236, -3.2701, -3.5790, -3.8413],\n",
      "          [-2.8421, -3.2386, -3.9123, -4.3199, -4.6489],\n",
      "          [-3.0073, -3.5032, -4.2277, -4.6416, -4.9005]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3011,  1.6175,  1.8732,  2.0559,  2.2122],\n",
      "          [ 1.6438,  1.8581,  2.0398,  2.2435,  2.3986],\n",
      "          [ 1.8984,  2.0639,  2.1989,  2.4193,  2.5538],\n",
      "          [ 1.9829,  2.1347,  2.2998,  2.5653,  2.7463]],\n",
      "\n",
      "         [[-1.3012, -1.6174, -1.8731, -2.0558, -2.2122],\n",
      "          [-1.6438, -1.8579, -2.0396, -2.2433, -2.3984],\n",
      "          [-1.8984, -2.0637, -2.1987, -2.4191, -2.5536],\n",
      "          [-1.9828, -2.1346, -2.2996, -2.5651, -2.7461]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6669,  0.8028,  0.9157,  0.9490,  1.0223],\n",
      "          [ 0.7824,  0.9277,  1.0544,  1.1076,  1.1967],\n",
      "          [ 0.9010,  1.0852,  1.2349,  1.2975,  1.3941],\n",
      "          [ 0.9840,  1.1725,  1.3027,  1.3405,  1.4415]],\n",
      "\n",
      "         [[-0.6670, -0.8028, -0.9156, -0.9490, -1.0222],\n",
      "          [-0.7824, -0.9276, -1.0542, -1.1074, -1.1966],\n",
      "          [-0.9010, -1.0850, -1.2347, -1.2973, -1.3939],\n",
      "          [-0.9840, -1.1724, -1.3025, -1.3403, -1.4413]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8409,  0.9295,  0.9709,  0.9798,  0.9900],\n",
      "          [ 0.9082,  0.8765,  0.8239,  0.8421,  0.8570],\n",
      "          [ 0.8753,  0.7764,  0.7000,  0.7132,  0.7469],\n",
      "          [ 0.8604,  0.8076,  0.7422,  0.7442,  0.7503]],\n",
      "\n",
      "         [[-0.8409, -0.9295, -0.9708, -0.9798, -0.9899],\n",
      "          [-0.9083, -0.8764, -0.8238, -0.8419, -0.8569],\n",
      "          [-0.8753, -0.7763, -0.6999, -0.7130, -0.7468],\n",
      "          [-0.8604, -0.8076, -0.7420, -0.7440, -0.7502]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7517,  2.2241,  2.6723,  2.8741,  3.0551],\n",
      "          [ 2.1921,  2.5270,  3.0255,  3.3011,  3.5721],\n",
      "          [ 2.5670,  2.9817,  3.5910,  3.9446,  4.2898],\n",
      "          [ 2.6932,  3.1977,  3.8620,  4.2345,  4.5401]],\n",
      "\n",
      "         [[-1.7517, -2.2240, -2.6722, -2.8739, -3.0549],\n",
      "          [-2.1920, -2.5268, -3.0252, -3.3008, -3.5718],\n",
      "          [-2.5669, -2.9814, -3.5906, -3.9442, -4.2894],\n",
      "          [-2.6931, -3.1975, -3.8617, -4.2341, -4.5397]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6436,  0.6963,  0.7419,  0.7618,  0.8070],\n",
      "          [ 0.7004,  0.6919,  0.7126,  0.7584,  0.8499],\n",
      "          [ 0.7839,  0.8332,  0.8762,  0.9049,  0.9625],\n",
      "          [ 0.9247,  1.1018,  1.1906,  1.2168,  1.2758]],\n",
      "\n",
      "         [[-0.6437, -0.6964, -0.7419, -0.7618, -0.8070],\n",
      "          [-0.7004, -0.6919, -0.7125, -0.7583, -0.8498],\n",
      "          [-0.7839, -0.8331, -0.8761, -0.9048, -0.9624],\n",
      "          [-0.9247, -1.1017, -1.1905, -1.2167, -1.2758]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6603,  0.6368,  0.6085,  0.5918,  0.5213],\n",
      "          [ 0.7723,  0.6413,  0.6002,  0.7426,  0.8118],\n",
      "          [ 0.8812,  0.7459,  0.7717,  1.0091,  1.1269],\n",
      "          [ 0.9942,  0.8922,  0.9224,  1.1168,  1.1824]],\n",
      "\n",
      "         [[-0.6604, -0.6368, -0.6086, -0.5918, -0.5214],\n",
      "          [-0.7723, -0.6412, -0.6001, -0.7426, -0.8117],\n",
      "          [-0.8812, -0.7458, -0.7716, -1.0090, -1.1268],\n",
      "          [-0.9942, -0.8921, -0.9223, -1.1167, -1.1823]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0441,  1.2190,  1.3441,  1.3369,  1.2649],\n",
      "          [ 1.2174,  1.2332,  1.2421,  1.2051,  1.1361],\n",
      "          [ 1.2922,  1.2491,  1.2463,  1.2503,  1.2446],\n",
      "          [ 1.3234,  1.3071,  1.2843,  1.2574,  1.2190]],\n",
      "\n",
      "         [[-1.0442, -1.2190, -1.3441, -1.3369, -1.2649],\n",
      "          [-1.2174, -1.2331, -1.2420, -1.2050, -1.1360],\n",
      "          [-1.2923, -1.2491, -1.2462, -1.2502, -1.2445],\n",
      "          [-1.3234, -1.3070, -1.2842, -1.2573, -1.2189]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2759,  0.1729, -0.0010, -0.2385, -0.4300],\n",
      "          [ 0.2315,  0.0849, -0.0789, -0.3006, -0.4633],\n",
      "          [ 0.1588, -0.0300, -0.1533, -0.3848, -0.5455],\n",
      "          [ 0.0826, -0.0862, -0.1572, -0.4101, -0.6002]],\n",
      "\n",
      "         [[-0.2760, -0.1729,  0.0010,  0.2384,  0.4300],\n",
      "          [-0.2315, -0.0849,  0.0790,  0.3007,  0.4633],\n",
      "          [-0.1588,  0.0300,  0.1533,  0.3849,  0.5456],\n",
      "          [-0.0827,  0.0862,  0.1573,  0.4102,  0.6003]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 1 1 1 1]\n",
      " [0 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.5514,  1.9128,  2.2060,  2.2934,  2.3264],\n",
      "          [ 1.8885,  2.0538,  2.2383,  2.2873,  2.3106],\n",
      "          [ 2.1011,  2.1646,  2.2830,  2.3090,  2.3250],\n",
      "          [ 2.1915,  2.2665,  2.3834,  2.4180,  2.4713]],\n",
      "\n",
      "         [[-1.5514, -1.9127, -2.2059, -2.2933, -2.3263],\n",
      "          [-1.8884, -2.0536, -2.2381, -2.2870, -2.3104],\n",
      "          [-2.1010, -2.1644, -2.2828, -2.3088, -2.3248],\n",
      "          [-2.1914, -2.2663, -2.3832, -2.4178, -2.4711]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8745,  1.1044,  1.2641,  1.4259,  1.5631],\n",
      "          [ 1.0050,  1.1536,  1.2500,  1.4480,  1.6387],\n",
      "          [ 1.0338,  1.0892,  1.1523,  1.3872,  1.6385],\n",
      "          [ 1.1875,  1.2976,  1.4029,  1.6887,  1.9803]],\n",
      "\n",
      "         [[-0.8745, -1.1044, -1.2641, -1.4259, -1.5631],\n",
      "          [-1.0050, -1.1535, -1.2499, -1.4479, -1.6387],\n",
      "          [-1.0338, -1.0891, -1.1522, -1.3871, -1.6384],\n",
      "          [-1.1876, -1.2975, -1.4028, -1.6886, -1.9802]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9244,  1.1343,  1.2573,  1.2270,  1.0669],\n",
      "          [ 1.1099,  1.2444,  1.3084,  1.2749,  1.0939],\n",
      "          [ 1.1809,  1.2444,  1.3163,  1.2925,  1.1289],\n",
      "          [ 1.3289,  1.4468,  1.5837,  1.5412,  1.3690]],\n",
      "\n",
      "         [[-0.9245, -1.1343, -1.2573, -1.2270, -1.0669],\n",
      "          [-1.1099, -1.2443, -1.3083, -1.2748, -1.0939],\n",
      "          [-1.1809, -1.2444, -1.3162, -1.2924, -1.1289],\n",
      "          [-1.3289, -1.4467, -1.5836, -1.5411, -1.3689]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5872,  0.6619,  0.6953,  0.7411,  0.7959],\n",
      "          [ 0.7300,  0.7881,  0.7750,  0.8422,  0.8961],\n",
      "          [ 0.8336,  0.8935,  0.8803,  0.9114,  0.9027],\n",
      "          [ 0.7376,  0.7765,  0.8577,  0.9401,  0.9569]],\n",
      "\n",
      "         [[-0.5873, -0.6619, -0.6953, -0.7411, -0.7960],\n",
      "          [-0.7300, -0.7880, -0.7750, -0.8422, -0.8960],\n",
      "          [-0.8337, -0.8935, -0.8803, -0.9113, -0.9027],\n",
      "          [-0.7376, -0.7764, -0.8577, -0.9401, -0.9569]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1810,  1.4630,  1.7857,  2.0400,  2.3172],\n",
      "          [ 1.4704,  1.6356,  1.9397,  2.1927,  2.4864],\n",
      "          [ 1.7606,  1.8981,  2.2642,  2.6088,  3.0068],\n",
      "          [ 2.0189,  2.1789,  2.6396,  3.0355,  3.4798]],\n",
      "\n",
      "         [[-1.1810, -1.4630, -1.7856, -2.0399, -2.3171],\n",
      "          [-1.4704, -1.6355, -1.9395, -2.1925, -2.4862],\n",
      "          [-1.7605, -1.8979, -2.2640, -2.6086, -3.0066],\n",
      "          [-2.0188, -2.1787, -2.6393, -3.0353, -3.4795]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0662,  1.2691,  1.3832,  1.5181,  1.6497],\n",
      "          [ 1.2906,  1.4005,  1.4731,  1.7130,  1.9458],\n",
      "          [ 1.3791,  1.4136,  1.4855,  1.7970,  2.1268],\n",
      "          [ 1.4523,  1.4986,  1.5893,  1.9290,  2.2737]],\n",
      "\n",
      "         [[-1.0663, -1.2691, -1.3832, -1.5181, -1.6497],\n",
      "          [-1.2906, -1.4004, -1.4730, -1.7129, -1.9457],\n",
      "          [-1.3791, -1.4135, -1.4854, -1.7968, -2.1266],\n",
      "          [-1.4523, -1.4985, -1.5892, -1.9289, -2.2735]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0750,  1.2522,  1.2860,  1.3002,  1.1788],\n",
      "          [ 1.3230,  1.3378,  1.2212,  1.2289,  1.0775],\n",
      "          [ 1.4482,  1.3678,  1.1687,  1.1303,  0.9571],\n",
      "          [ 1.5870,  1.5051,  1.3630,  1.2653,  1.0560]],\n",
      "\n",
      "         [[-1.0750, -1.2522, -1.2859, -1.3002, -1.1788],\n",
      "          [-1.3230, -1.3377, -1.2211, -1.2288, -1.0774],\n",
      "          [-1.4482, -1.3677, -1.1686, -1.1302, -0.9569],\n",
      "          [-1.5870, -1.5051, -1.3629, -1.2652, -1.0559]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.6018, -0.7977, -0.9318, -1.1248, -1.2598],\n",
      "          [-0.8061, -0.8598, -0.9647, -1.2501, -1.4923],\n",
      "          [-0.9863, -1.0145, -1.0456, -1.3154, -1.5709],\n",
      "          [-1.0589, -1.1617, -1.1810, -1.4442, -1.6828]],\n",
      "\n",
      "         [[ 0.6017,  0.7977,  0.9318,  1.1248,  1.2598],\n",
      "          [ 0.8061,  0.8599,  0.9648,  1.2502,  1.4924],\n",
      "          [ 0.9863,  1.0147,  1.0458,  1.3156,  1.5710],\n",
      "          [ 1.0589,  1.1618,  1.1812,  1.4444,  1.6829]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.3661, -0.5393, -0.6870, -0.7249, -0.7492],\n",
      "          [-0.3675, -0.3834, -0.5139, -0.5147, -0.5134],\n",
      "          [-0.3269, -0.2411, -0.2867, -0.2137, -0.1754],\n",
      "          [-0.3071, -0.3029, -0.3900, -0.3291, -0.3160]],\n",
      "\n",
      "         [[ 0.3661,  0.5393,  0.6869,  0.7249,  0.7492],\n",
      "          [ 0.3675,  0.3835,  0.5140,  0.5149,  0.5135],\n",
      "          [ 0.3269,  0.2412,  0.2868,  0.2138,  0.1756],\n",
      "          [ 0.3071,  0.3030,  0.3901,  0.3293,  0.3161]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0086,  1.2714,  1.4817,  1.6038,  1.7315],\n",
      "          [ 1.2756,  1.5271,  1.6972,  1.8086,  1.9266],\n",
      "          [ 1.5114,  1.8154,  1.9936,  2.0964,  2.1817],\n",
      "          [ 1.5702,  1.9101,  2.0874,  2.1890,  2.2574]],\n",
      "\n",
      "         [[-1.0087, -1.2714, -1.4817, -1.6037, -1.7315],\n",
      "          [-1.2756, -1.5270, -1.6971, -1.8084, -1.9265],\n",
      "          [-1.5113, -1.8153, -1.9935, -2.0962, -2.1815],\n",
      "          [-1.5702, -1.9100, -2.0872, -2.1888, -2.2572]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9987,  1.2556,  1.4222,  1.5054,  1.6087],\n",
      "          [ 1.2463,  1.4615,  1.5411,  1.6185,  1.7494],\n",
      "          [ 1.4441,  1.6617,  1.7038,  1.7820,  1.9261],\n",
      "          [ 1.5101,  1.7078,  1.7173,  1.7685,  1.9013]],\n",
      "\n",
      "         [[-0.9988, -1.2556, -1.4221, -1.5054, -1.6086],\n",
      "          [-1.2463, -1.4614, -1.5409, -1.6183, -1.7493],\n",
      "          [-1.4440, -1.6615, -1.7036, -1.7818, -1.9259],\n",
      "          [-1.5101, -1.7077, -1.7171, -1.7684, -1.9011]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8283,  0.9446,  1.0273,  1.1017,  1.2103],\n",
      "          [ 0.9310,  0.9572,  0.9930,  1.1029,  1.2784],\n",
      "          [ 0.9475,  0.9290,  0.9699,  1.1177,  1.3513],\n",
      "          [ 0.9666,  0.9895,  1.0624,  1.2184,  1.4641]],\n",
      "\n",
      "         [[-0.8284, -0.9446, -1.0273, -1.1017, -1.2102],\n",
      "          [-0.9310, -0.9571, -0.9929, -1.1028, -1.2783],\n",
      "          [-0.9475, -0.9289, -0.9697, -1.1175, -1.3511],\n",
      "          [-0.9666, -0.9894, -1.0622, -1.2182, -1.4639]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8493,  0.9869,  1.0164,  1.1082,  1.2478],\n",
      "          [ 1.0183,  1.0848,  0.9934,  1.1333,  1.3412],\n",
      "          [ 1.1329,  1.1749,  1.0630,  1.2778,  1.5420],\n",
      "          [ 1.2783,  1.3642,  1.2685,  1.4773,  1.7294]],\n",
      "\n",
      "         [[-0.8493, -0.9870, -1.0164, -1.1082, -1.2478],\n",
      "          [-1.0183, -1.0847, -0.9933, -1.1333, -1.3411],\n",
      "          [-1.1329, -1.1748, -1.0629, -1.2778, -1.5419],\n",
      "          [-1.2783, -1.3641, -1.2683, -1.4772, -1.7293]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6401,  0.8189,  0.9661,  1.0759,  1.2014],\n",
      "          [ 0.7659,  0.9750,  1.1221,  1.2629,  1.4193],\n",
      "          [ 0.8538,  1.0935,  1.2614,  1.4235,  1.6042],\n",
      "          [ 0.9729,  1.2312,  1.3969,  1.5467,  1.7298]],\n",
      "\n",
      "         [[-0.6401, -0.8189, -0.9661, -1.0759, -1.2014],\n",
      "          [-0.7659, -0.9749, -1.1220, -1.2628, -1.4192],\n",
      "          [-0.8538, -1.0934, -1.2613, -1.4234, -1.6041],\n",
      "          [-0.9729, -1.2311, -1.3968, -1.5466, -1.7297]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3530,  0.4282,  0.4282,  0.4133,  0.4260],\n",
      "          [ 0.2968,  0.3387,  0.3053,  0.3002,  0.3063],\n",
      "          [ 0.1789,  0.1179,  0.0531,  0.0633,  0.0627],\n",
      "          [ 0.1856,  0.1126,  0.0385,  0.0275, -0.0115]],\n",
      "\n",
      "         [[-0.3531, -0.4282, -0.4283, -0.4133, -0.4260],\n",
      "          [-0.2968, -0.3386, -0.3052, -0.3002, -0.3062],\n",
      "          [-0.1789, -0.1178, -0.0530, -0.0632, -0.0626],\n",
      "          [-0.1856, -0.1125, -0.0384, -0.0275,  0.0116]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7526,  0.9523,  1.1449,  1.2193,  1.2351],\n",
      "          [ 0.9725,  1.1212,  1.2537,  1.3310,  1.3241],\n",
      "          [ 1.1252,  1.2178,  1.3455,  1.4376,  1.4471],\n",
      "          [ 1.2366,  1.3408,  1.5123,  1.6629,  1.7587]],\n",
      "\n",
      "         [[-0.7527, -0.9523, -1.1449, -1.2193, -1.2350],\n",
      "          [-0.9725, -1.1211, -1.2536, -1.3309, -1.3239],\n",
      "          [-1.1252, -1.2177, -1.3454, -1.4375, -1.4469],\n",
      "          [-1.2366, -1.3407, -1.5122, -1.6628, -1.7586]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.0726, -0.1328, -0.2624, -0.3310, -0.3364],\n",
      "          [-0.1676, -0.1311, -0.2509, -0.2890, -0.2729],\n",
      "          [-0.3354, -0.2993, -0.4063, -0.4199, -0.3856],\n",
      "          [-0.3959, -0.3358, -0.4193, -0.4080, -0.3487]],\n",
      "\n",
      "         [[ 0.0725,  0.1328,  0.2624,  0.3309,  0.3364],\n",
      "          [ 0.1675,  0.1312,  0.2510,  0.2891,  0.2730],\n",
      "          [ 0.3354,  0.2994,  0.4064,  0.4200,  0.3858],\n",
      "          [ 0.3958,  0.3359,  0.4194,  0.4081,  0.3489]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2735,  1.5729,  1.7713,  1.7868,  1.7072],\n",
      "          [ 1.6487,  1.8757,  2.0182,  2.0593,  2.0090],\n",
      "          [ 1.9228,  2.1153,  2.2289,  2.2760,  2.2042],\n",
      "          [ 2.0820,  2.2735,  2.4050,  2.4573,  2.4308]],\n",
      "\n",
      "         [[-1.2735, -1.5729, -1.7713, -1.7868, -1.7072],\n",
      "          [-1.6487, -1.8756, -2.0180, -2.0591, -2.0089],\n",
      "          [-1.9228, -2.1151, -2.2287, -2.2758, -2.2041],\n",
      "          [-2.0820, -2.2733, -2.4048, -2.4571, -2.4306]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5221,  0.4898,  0.3775,  0.3350,  0.3222],\n",
      "          [ 0.6663,  0.6323,  0.4609,  0.4297,  0.4440],\n",
      "          [ 0.7548,  0.7525,  0.6252,  0.6407,  0.6990],\n",
      "          [ 0.8134,  0.8059,  0.7044,  0.6979,  0.7378]],\n",
      "\n",
      "         [[-0.5222, -0.4899, -0.3775, -0.3350, -0.3222],\n",
      "          [-0.6663, -0.6322, -0.4608, -0.4296, -0.4438],\n",
      "          [-0.7548, -0.7524, -0.6251, -0.6406, -0.6988],\n",
      "          [-0.8134, -0.8059, -0.7042, -0.6978, -0.7377]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7717,  2.2648,  2.7078,  2.9105,  3.0764],\n",
      "          [ 2.2376,  2.5787,  3.1212,  3.4406,  3.7201],\n",
      "          [ 2.6257,  3.0211,  3.6911,  4.1103,  4.4453],\n",
      "          [ 2.7980,  3.2939,  4.0375,  4.4597,  4.7885]],\n",
      "\n",
      "         [[-1.7717, -2.2647, -2.7077, -2.9104, -3.0763],\n",
      "          [-2.2376, -2.5785, -3.1209, -3.4403, -3.7197],\n",
      "          [-2.6256, -3.0209, -3.6907, -4.1100, -4.4449],\n",
      "          [-2.7979, -3.2936, -4.0371, -4.4593, -4.7880]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7709,  0.9794,  1.1595,  1.3526,  1.5427],\n",
      "          [ 0.9532,  1.1615,  1.3013,  1.5266,  1.7339],\n",
      "          [ 1.0364,  1.2263,  1.3490,  1.6189,  1.8529],\n",
      "          [ 1.1340,  1.3394,  1.4535,  1.7562,  2.0212]],\n",
      "\n",
      "         [[-0.7709, -0.9795, -1.1595, -1.3526, -1.5427],\n",
      "          [-0.9533, -1.1615, -1.3013, -1.5265, -1.7338],\n",
      "          [-1.0364, -1.2262, -1.3489, -1.6188, -1.8528],\n",
      "          [-1.1340, -1.3394, -1.4534, -1.7561, -2.0211]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.1935, -0.4294, -0.5698, -0.5851, -0.4909],\n",
      "          [-0.3908, -0.6222, -0.7808, -0.7247, -0.5824],\n",
      "          [-0.5816, -0.7803, -0.8961, -0.7506, -0.5669],\n",
      "          [-0.9349, -1.2212, -1.3362, -1.0977, -0.7901]],\n",
      "\n",
      "         [[ 0.1934,  0.4294,  0.5697,  0.5851,  0.4908],\n",
      "          [ 0.3907,  0.6223,  0.7809,  0.7247,  0.5824],\n",
      "          [ 0.5816,  0.7804,  0.8962,  0.7507,  0.5669],\n",
      "          [ 0.9349,  1.2213,  1.3363,  1.0977,  0.7901]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9395,  1.1363,  1.2108,  1.2465,  1.2459],\n",
      "          [ 1.1730,  1.3012,  1.3015,  1.3509,  1.3798],\n",
      "          [ 1.3370,  1.3977,  1.3548,  1.4024,  1.4306],\n",
      "          [ 1.5595,  1.6500,  1.6759,  1.7611,  1.8038]],\n",
      "\n",
      "         [[-0.9395, -1.1363, -1.2108, -1.2465, -1.2459],\n",
      "          [-1.1730, -1.3012, -1.3015, -1.3508, -1.3798],\n",
      "          [-1.3370, -1.3976, -1.3547, -1.4023, -1.4306],\n",
      "          [-1.5595, -1.6499, -1.6758, -1.7610, -1.8037]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7336,  0.8694,  0.8888,  1.0657,  1.2713],\n",
      "          [ 0.8437,  0.9618,  0.9612,  1.2859,  1.6054],\n",
      "          [ 0.8752,  0.9376,  0.9062,  1.2791,  1.6256],\n",
      "          [ 1.0299,  1.1228,  1.1057,  1.4962,  1.8486]],\n",
      "\n",
      "         [[-0.7337, -0.8694, -0.8889, -1.0658, -1.2714],\n",
      "          [-0.8438, -0.9617, -0.9612, -1.2859, -1.6053],\n",
      "          [-0.8752, -0.9376, -0.9062, -1.2790, -1.6255],\n",
      "          [-1.0299, -1.1228, -1.1057, -1.4961, -1.8485]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0022,  1.2350,  1.4209,  1.6157,  1.8065],\n",
      "          [ 1.2519,  1.4112,  1.5091,  1.7289,  1.9480],\n",
      "          [ 1.4385,  1.5379,  1.5914,  1.8206,  2.0452],\n",
      "          [ 1.5350,  1.6428,  1.7354,  2.0057,  2.2509]],\n",
      "\n",
      "         [[-1.0022, -1.2350, -1.4208, -1.6157, -1.8065],\n",
      "          [-1.2519, -1.4111, -1.5090, -1.7288, -1.9479],\n",
      "          [-1.4385, -1.5378, -1.5912, -1.8205, -2.0451],\n",
      "          [-1.5350, -1.6427, -1.7353, -2.0055, -2.2508]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2106,  0.2002,  0.1622,  0.1577,  0.1648],\n",
      "          [ 0.1828,  0.2396,  0.2043,  0.2281,  0.2239],\n",
      "          [ 0.0913,  0.2015,  0.1994,  0.2482,  0.2355],\n",
      "          [ 0.0429,  0.1868,  0.2079,  0.2656,  0.2540]],\n",
      "\n",
      "         [[-0.2107, -0.2003, -0.1622, -0.1578, -0.1649],\n",
      "          [-0.1828, -0.2396, -0.2043, -0.2280, -0.2239],\n",
      "          [-0.0914, -0.2014, -0.1993, -0.2482, -0.2354],\n",
      "          [-0.0430, -0.1867, -0.2079, -0.2656, -0.2539]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5808,  0.6992,  0.7594,  0.7671,  0.7649],\n",
      "          [ 0.7467,  0.8993,  0.9326,  0.9629,  0.9304],\n",
      "          [ 0.9175,  1.0954,  1.1425,  1.1848,  1.1375],\n",
      "          [ 1.0770,  1.2206,  1.2253,  1.2056,  1.1674]],\n",
      "\n",
      "         [[-0.5809, -0.6993, -0.7593, -0.7671, -0.7649],\n",
      "          [-0.7467, -0.8992, -0.9325, -0.9628, -0.9303],\n",
      "          [-0.9175, -1.0953, -1.1423, -1.1846, -1.1374],\n",
      "          [-1.0770, -1.2205, -1.2251, -1.2055, -1.1673]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1429,  1.4188,  1.6630,  1.8078,  1.9670],\n",
      "          [ 1.4037,  1.5968,  1.8210,  1.9839,  2.1782],\n",
      "          [ 1.6116,  1.7876,  2.0329,  2.2392,  2.4904],\n",
      "          [ 1.7581,  1.9670,  2.2630,  2.4956,  2.7711]],\n",
      "\n",
      "         [[-1.1429, -1.4188, -1.6629, -1.8077, -1.9669],\n",
      "          [-1.4037, -1.5967, -1.8208, -1.9838, -2.1780],\n",
      "          [-1.6115, -1.7874, -2.0327, -2.2390, -2.4902],\n",
      "          [-1.7580, -1.9669, -2.2628, -2.4954, -2.7709]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9668,  1.2202,  1.4457,  1.6025,  1.6999],\n",
      "          [ 1.2946,  1.5315,  1.7153,  1.8863,  1.9834],\n",
      "          [ 1.4799,  1.7052,  1.8551,  2.0446,  2.1464],\n",
      "          [ 1.5442,  1.7899,  1.9439,  2.1749,  2.3120]],\n",
      "\n",
      "         [[-0.9669, -1.2202, -1.4457, -1.6025, -1.6999],\n",
      "          [-1.2946, -1.5314, -1.7153, -1.8862, -1.9833],\n",
      "          [-1.4800, -1.7051, -1.8550, -2.0445, -2.1463],\n",
      "          [-1.5442, -1.7898, -1.9438, -2.1748, -2.3119]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8047,  0.9574,  1.0775,  1.1412,  1.1882],\n",
      "          [ 0.9722,  1.0829,  1.1534,  1.2338,  1.2708],\n",
      "          [ 1.1249,  1.2511,  1.2850,  1.3590,  1.3560],\n",
      "          [ 1.1783,  1.3150,  1.3394,  1.4275,  1.4849]],\n",
      "\n",
      "         [[-0.8048, -0.9574, -1.0775, -1.1412, -1.1882],\n",
      "          [-0.9722, -1.0828, -1.1533, -1.2337, -1.2707],\n",
      "          [-1.1249, -1.2510, -1.2849, -1.3588, -1.3559],\n",
      "          [-1.1783, -1.3150, -1.3393, -1.4275, -1.4848]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6766,  0.7750,  0.7848,  0.8742,  1.0355],\n",
      "          [ 0.8250,  0.8822,  0.8297,  0.9787,  1.2303],\n",
      "          [ 0.9127,  0.9516,  0.9076,  1.1221,  1.4549],\n",
      "          [ 0.8187,  0.7880,  0.7423,  0.9939,  1.3808]],\n",
      "\n",
      "         [[-0.6767, -0.7750, -0.7848, -0.8742, -1.0355],\n",
      "          [-0.8250, -0.8821, -0.8296, -0.9786, -1.2302],\n",
      "          [-0.9127, -0.9515, -0.9074, -1.1220, -1.4547],\n",
      "          [-0.8187, -0.7879, -0.7421, -0.9938, -1.3807]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7766,  0.9757,  1.1171,  1.2232,  1.3059],\n",
      "          [ 0.8953,  1.0447,  1.1251,  1.1954,  1.2509],\n",
      "          [ 0.9266,  1.0249,  1.0894,  1.1339,  1.1628],\n",
      "          [ 0.9849,  1.0871,  1.1539,  1.1824,  1.1988]],\n",
      "\n",
      "         [[-0.7766, -0.9758, -1.1171, -1.2232, -1.3059],\n",
      "          [-0.8953, -1.0446, -1.1250, -1.1953, -1.2508],\n",
      "          [-0.9266, -1.0248, -1.0893, -1.1338, -1.1627],\n",
      "          [-0.9849, -1.0870, -1.1537, -1.1823, -1.1987]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9639,  0.9896,  0.9273,  0.8400,  0.7934],\n",
      "          [ 1.1224,  0.9612,  0.7844,  0.7328,  0.7422],\n",
      "          [ 1.1843,  0.8900,  0.6657,  0.6548,  0.6974],\n",
      "          [ 1.2349,  0.9279,  0.7179,  0.7306,  0.8024]],\n",
      "\n",
      "         [[-0.9640, -0.9896, -0.9273, -0.8400, -0.7934],\n",
      "          [-1.1224, -0.9611, -0.7842, -0.7326, -0.7420],\n",
      "          [-1.1843, -0.8898, -0.6656, -0.6547, -0.6973],\n",
      "          [-1.2349, -0.9278, -0.7177, -0.7305, -0.8023]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.5409, -0.7902, -0.8928, -0.8353, -0.7175],\n",
      "          [-0.7960, -1.0067, -1.1893, -1.1975, -1.0996],\n",
      "          [-1.0700, -1.3837, -1.6247, -1.6864, -1.6240],\n",
      "          [-1.1640, -1.5132, -1.7834, -1.9209, -1.9537]],\n",
      "\n",
      "         [[ 0.5408,  0.7902,  0.8928,  0.8352,  0.7174],\n",
      "          [ 0.7960,  1.0068,  1.1893,  1.1975,  1.0996],\n",
      "          [ 1.0700,  1.3838,  1.6248,  1.6865,  1.6241],\n",
      "          [ 1.1640,  1.5133,  1.7835,  1.9210,  1.9538]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5119,  0.5624,  0.4465,  0.2992,  0.1869],\n",
      "          [ 0.4689,  0.4693,  0.3122,  0.2161,  0.1681],\n",
      "          [ 0.3095,  0.2119,  0.0708,  0.0631,  0.1516],\n",
      "          [ 0.3109,  0.2374,  0.1583,  0.1875,  0.3492]],\n",
      "\n",
      "         [[-0.5120, -0.5624, -0.4465, -0.2992, -0.1870],\n",
      "          [-0.4690, -0.4693, -0.3121, -0.2161, -0.1681],\n",
      "          [-0.3095, -0.2119, -0.0707, -0.0630, -0.1516],\n",
      "          [-0.3109, -0.2374, -0.1582, -0.1875, -0.3492]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1958,  0.2287,  0.1928,  0.1510,  0.1294],\n",
      "          [ 0.2305,  0.3403,  0.2893,  0.2451,  0.2359],\n",
      "          [ 0.1586,  0.2369,  0.1843,  0.1765,  0.2119],\n",
      "          [ 0.1433,  0.2349,  0.2300,  0.2480,  0.2831]],\n",
      "\n",
      "         [[-0.1959, -0.2288, -0.1928, -0.1511, -0.1294],\n",
      "          [-0.2306, -0.3403, -0.2893, -0.2450, -0.2359],\n",
      "          [-0.1587, -0.2369, -0.1842, -0.1765, -0.2119],\n",
      "          [-0.1433, -0.2349, -0.2300, -0.2479, -0.2831]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3664,  0.4842,  0.6132,  0.8293,  1.0231],\n",
      "          [ 0.4550,  0.5892,  0.6770,  0.9582,  1.1725],\n",
      "          [ 0.5678,  0.6861,  0.7430,  1.0124,  1.1946],\n",
      "          [ 0.7891,  0.9276,  0.9484,  1.1464,  1.3233]],\n",
      "\n",
      "         [[-0.3664, -0.4842, -0.6132, -0.8293, -1.0231],\n",
      "          [-0.4550, -0.5891, -0.6769, -0.9581, -1.1724],\n",
      "          [-0.5679, -0.6861, -0.7429, -1.0123, -1.1945],\n",
      "          [-0.7892, -0.9275, -0.9483, -1.1463, -1.3232]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3715,  0.3278,  0.2570,  0.2783,  0.4052],\n",
      "          [ 0.3509,  0.2715,  0.1473,  0.1858,  0.3534],\n",
      "          [ 0.2074,  0.1335,  0.0802,  0.1725,  0.4057],\n",
      "          [ 0.1888,  0.2225,  0.2816,  0.3710,  0.5957]],\n",
      "\n",
      "         [[-0.3716, -0.3278, -0.2570, -0.2783, -0.4053],\n",
      "          [-0.3509, -0.2715, -0.1472, -0.1857, -0.3534],\n",
      "          [-0.2074, -0.1334, -0.0801, -0.1724, -0.4057],\n",
      "          [-0.1888, -0.2224, -0.2815, -0.3710, -0.5956]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5746,  0.7021,  0.8315,  0.8807,  0.9696],\n",
      "          [ 0.6963,  0.8463,  0.9987,  1.0502,  1.1422],\n",
      "          [ 0.8157,  0.9987,  1.1815,  1.2450,  1.3486],\n",
      "          [ 0.9195,  1.1119,  1.2909,  1.3411,  1.4523]],\n",
      "\n",
      "         [[-0.5746, -0.7021, -0.8315, -0.8807, -0.9695],\n",
      "          [-0.6963, -0.8462, -0.9985, -1.0501, -1.1420],\n",
      "          [-0.8156, -0.9986, -1.1813, -1.2448, -1.3484],\n",
      "          [-0.9195, -1.1117, -1.2906, -1.3408, -1.4521]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.0265, -0.0312, -0.0234, -0.0018,  0.0810],\n",
      "          [-0.0103,  0.0082,  0.0484,  0.0592,  0.1255],\n",
      "          [-0.0089,  0.0768,  0.1633,  0.1677,  0.2336],\n",
      "          [-0.1699, -0.1558, -0.0943, -0.1200, -0.0608]],\n",
      "\n",
      "         [[-0.0266,  0.0312,  0.0234,  0.0018, -0.0810],\n",
      "          [ 0.0103, -0.0081, -0.0483, -0.0591, -0.1254],\n",
      "          [ 0.0089, -0.0767, -0.1631, -0.1676, -0.2335],\n",
      "          [ 0.1699,  0.1559,  0.0944,  0.1201,  0.0609]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 1 1 1 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0270,  1.2958,  1.4977,  1.5853,  1.6580],\n",
      "          [ 1.1918,  1.4271,  1.6000,  1.6979,  1.7616],\n",
      "          [ 1.2728,  1.5144,  1.6970,  1.8108,  1.8626],\n",
      "          [ 1.2737,  1.5243,  1.7098,  1.8391,  1.9016]],\n",
      "\n",
      "         [[-1.0271, -1.2958, -1.4977, -1.5853, -1.6580],\n",
      "          [-1.1918, -1.4270, -1.5999, -1.6978, -1.7615],\n",
      "          [-1.2728, -1.5143, -1.6969, -1.8107, -1.8625],\n",
      "          [-1.2737, -1.5242, -1.7097, -1.8390, -1.9015]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6616,  0.8351,  0.8767,  0.9586,  1.0117],\n",
      "          [ 0.8486,  1.0240,  1.0068,  1.1445,  1.2576],\n",
      "          [ 0.9461,  1.0434,  0.9971,  1.1899,  1.3859],\n",
      "          [ 1.2054,  1.3374,  1.3579,  1.6021,  1.8450]],\n",
      "\n",
      "         [[-0.6617, -0.8351, -0.8767, -0.9586, -1.0118],\n",
      "          [-0.8486, -1.0240, -1.0068, -1.1444, -1.2576],\n",
      "          [-0.9461, -1.0433, -0.9970, -1.1898, -1.3858],\n",
      "          [-1.2054, -1.3373, -1.3578, -1.6020, -1.8449]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9300,  2.4754,  2.9915,  3.2343,  3.4289],\n",
      "          [ 2.4201,  2.7405,  3.3860,  3.7366,  4.0231],\n",
      "          [ 2.9389,  3.3797,  4.1880,  4.6697,  4.9878],\n",
      "          [ 3.1788,  3.7427,  4.6386,  5.0809,  5.4015]],\n",
      "\n",
      "         [[-1.9300, -2.4753, -2.9914, -3.2341, -3.4286],\n",
      "          [-2.4200, -2.7403, -3.3857, -3.7363, -4.0227],\n",
      "          [-2.9388, -3.3794, -4.1876, -4.6693, -4.9873],\n",
      "          [-3.1786, -3.7424, -4.6381, -5.0804, -5.4010]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2565,  1.5175,  1.7532,  1.8641,  1.9306],\n",
      "          [ 1.5263,  1.6351,  1.7810,  1.9233,  2.0514],\n",
      "          [ 1.6961,  1.7322,  1.8417,  1.9941,  2.1492],\n",
      "          [ 1.7888,  1.8393,  1.9439,  2.0727,  2.2152]],\n",
      "\n",
      "         [[-1.2565, -1.5175, -1.7532, -1.8641, -1.9306],\n",
      "          [-1.5263, -1.6349, -1.7808, -1.9231, -2.0513],\n",
      "          [-1.6961, -1.7320, -1.8415, -1.9939, -2.1490],\n",
      "          [-1.7888, -1.8392, -1.9437, -2.0725, -2.2150]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2986,  0.4800,  0.6453,  0.7445,  0.8819],\n",
      "          [ 0.4076,  0.6886,  0.8736,  0.9218,  0.9775],\n",
      "          [ 0.5211,  0.7895,  1.0553,  1.1601,  1.2199],\n",
      "          [ 0.7401,  0.9640,  1.2503,  1.4275,  1.5373]],\n",
      "\n",
      "         [[-0.2987, -0.4801, -0.6453, -0.7445, -0.8819],\n",
      "          [-0.4076, -0.6885, -0.8735, -0.9217, -0.9773],\n",
      "          [-0.5211, -0.7894, -1.0551, -1.1600, -1.2197],\n",
      "          [-0.7401, -0.9640, -1.2502, -1.4273, -1.5371]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2769,  1.5441,  1.7849,  1.8881,  1.9022],\n",
      "          [ 1.6250,  1.8006,  2.0214,  2.1895,  2.2179],\n",
      "          [ 1.8422,  1.9912,  2.2539,  2.4216,  2.4487],\n",
      "          [ 1.9714,  2.1858,  2.4748,  2.5995,  2.5913]],\n",
      "\n",
      "         [[-1.2769, -1.5442, -1.7849, -1.8881, -1.9022],\n",
      "          [-1.6250, -1.8006, -2.0213, -2.1894, -2.2177],\n",
      "          [-1.8422, -1.9911, -2.2538, -2.4215, -2.4485],\n",
      "          [-1.9714, -2.1857, -2.4746, -2.5993, -2.5912]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5268,  0.6831,  0.8663,  1.0319,  1.1341],\n",
      "          [ 0.6568,  0.8177,  0.9826,  1.1272,  1.1910],\n",
      "          [ 0.7509,  0.9427,  1.1432,  1.3107,  1.3689],\n",
      "          [ 0.8708,  1.0829,  1.2998,  1.4620,  1.5195]],\n",
      "\n",
      "         [[-0.5269, -0.6832, -0.8663, -1.0319, -1.1342],\n",
      "          [-0.6569, -0.8176, -0.9825, -1.1272, -1.1909],\n",
      "          [-0.7509, -0.9427, -1.1431, -1.3106, -1.3688],\n",
      "          [-0.8708, -1.0828, -1.2997, -1.4619, -1.5194]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1836,  1.4350,  1.6503,  1.8132,  1.9903],\n",
      "          [ 1.4975,  1.6503,  1.8228,  2.0610,  2.3384],\n",
      "          [ 1.7416,  1.8790,  2.0945,  2.3926,  2.7320],\n",
      "          [ 1.8649,  2.0243,  2.2661,  2.5296,  2.8503]],\n",
      "\n",
      "         [[-1.1837, -1.4350, -1.6502, -1.8132, -1.9903],\n",
      "          [-1.4974, -1.6501, -1.8226, -2.0608, -2.3383],\n",
      "          [-1.7416, -1.8789, -2.0943, -2.3923, -2.7318],\n",
      "          [-1.8648, -2.0241, -2.2659, -2.5294, -2.8501]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8491,  0.9689,  0.9972,  0.9312,  0.8408],\n",
      "          [ 0.9761,  1.0010,  0.9801,  0.9813,  0.9445],\n",
      "          [ 1.0561,  1.0319,  1.0090,  1.0344,  1.0447],\n",
      "          [ 1.2347,  1.2831,  1.2718,  1.2439,  1.2279]],\n",
      "\n",
      "         [[-0.8492, -0.9689, -0.9972, -0.9312, -0.8409],\n",
      "          [-0.9761, -1.0009, -0.9800, -0.9813, -0.9445],\n",
      "          [-1.0561, -1.0318, -1.0090, -1.0343, -1.0446],\n",
      "          [-1.2347, -1.2830, -1.2717, -1.2438, -1.2278]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8642,  1.0595,  1.1818,  1.2526,  1.3566],\n",
      "          [ 1.0518,  1.2275,  1.3120,  1.4023,  1.5310],\n",
      "          [ 1.2215,  1.4285,  1.4998,  1.5885,  1.7130],\n",
      "          [ 1.3402,  1.5783,  1.6511,  1.7065,  1.8130]],\n",
      "\n",
      "         [[-0.8643, -1.0595, -1.1817, -1.2526, -1.3566],\n",
      "          [-1.0518, -1.2274, -1.3119, -1.4021, -1.5308],\n",
      "          [-1.2215, -1.4283, -1.4996, -1.5883, -1.7128],\n",
      "          [-1.3402, -1.5781, -1.6509, -1.7063, -1.8128]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9664,  1.1461,  1.2822,  1.3641,  1.3619],\n",
      "          [ 1.2289,  1.3029,  1.3464,  1.4765,  1.5281],\n",
      "          [ 1.4228,  1.4215,  1.4108,  1.5624,  1.6439],\n",
      "          [ 1.5814,  1.6092,  1.6191,  1.8120,  1.9210]],\n",
      "\n",
      "         [[-0.9665, -1.1462, -1.2822, -1.3641, -1.3619],\n",
      "          [-1.2289, -1.3028, -1.3463, -1.4764, -1.5280],\n",
      "          [-1.4229, -1.4214, -1.4107, -1.5622, -1.6438],\n",
      "          [-1.5814, -1.6092, -1.6190, -1.8118, -1.9209]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7480,  2.2487,  2.6766,  2.8822,  3.0474],\n",
      "          [ 2.1993,  2.5447,  3.0674,  3.3763,  3.6524],\n",
      "          [ 2.5880,  2.9752,  3.6211,  4.0372,  4.4018],\n",
      "          [ 2.7662,  3.2330,  3.9428,  4.3988,  4.7207]],\n",
      "\n",
      "         [[-1.7480, -2.2486, -2.6764, -2.8820, -3.0472],\n",
      "          [-2.1992, -2.5445, -3.0672, -3.3760, -3.6521],\n",
      "          [-2.5879, -2.9749, -3.6208, -4.0369, -4.4014],\n",
      "          [-2.7660, -3.2327, -3.9425, -4.3984, -4.7203]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6818,  0.8478,  1.0126,  1.0511,  1.1209],\n",
      "          [ 0.7246,  0.8861,  1.0781,  1.1131,  1.1794],\n",
      "          [ 0.7722,  0.9641,  1.1848,  1.1851,  1.2287],\n",
      "          [ 0.8730,  1.1215,  1.3532,  1.3008,  1.3338]],\n",
      "\n",
      "         [[-0.6819, -0.8478, -1.0126, -1.0510, -1.1208],\n",
      "          [-0.7246, -0.8860, -1.0780, -1.1130, -1.1793],\n",
      "          [-0.7721, -0.9639, -1.1846, -1.1850, -1.2285],\n",
      "          [-0.8730, -1.1214, -1.3531, -1.3006, -1.3337]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9834,  1.1917,  1.3848,  1.4912,  1.6228],\n",
      "          [ 1.2454,  1.4180,  1.5988,  1.7401,  1.8804],\n",
      "          [ 1.5125,  1.7352,  1.9375,  2.0938,  2.2293],\n",
      "          [ 1.6414,  1.8827,  2.0815,  2.2417,  2.3996]],\n",
      "\n",
      "         [[-0.9835, -1.1917, -1.3848, -1.4911, -1.6228],\n",
      "          [-1.2453, -1.4178, -1.5987, -1.7399, -1.8802],\n",
      "          [-1.5124, -1.7351, -1.9373, -2.0936, -2.2291],\n",
      "          [-1.6414, -1.8825, -2.0813, -2.2415, -2.3994]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2715,  0.3563,  0.3673,  0.4271,  0.5088],\n",
      "          [ 0.3303,  0.4895,  0.4722,  0.5221,  0.5902],\n",
      "          [ 0.2735,  0.4084,  0.3868,  0.4455,  0.5240],\n",
      "          [ 0.2994,  0.4498,  0.4583,  0.5297,  0.6077]],\n",
      "\n",
      "         [[-0.2716, -0.3563, -0.3673, -0.4271, -0.5089],\n",
      "          [-0.3304, -0.4894, -0.4721, -0.5220, -0.5901],\n",
      "          [-0.2736, -0.4083, -0.3867, -0.4455, -0.5239],\n",
      "          [-0.2994, -0.4498, -0.4583, -0.5297, -0.6077]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.6956,  2.1313,  2.4870,  2.6423,  2.7639],\n",
      "          [ 2.0824,  2.3298,  2.6431,  2.9087,  3.1506],\n",
      "          [ 2.3930,  2.5723,  2.9014,  3.1959,  3.4615],\n",
      "          [ 2.5645,  2.7689,  3.1021,  3.3696,  3.6163]],\n",
      "\n",
      "         [[-1.6956, -2.1313, -2.4869, -2.6422, -2.7638],\n",
      "          [-2.0823, -2.3296, -2.6429, -2.9085, -3.1504],\n",
      "          [-2.3930, -2.5721, -2.9011, -3.1956, -3.4612],\n",
      "          [-2.5644, -2.7687, -3.1018, -3.3693, -3.6160]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5357,  0.6124,  0.6470,  0.5633,  0.5115],\n",
      "          [ 0.6098,  0.6776,  0.6918,  0.5642,  0.4952],\n",
      "          [ 0.6619,  0.7371,  0.7697,  0.6335,  0.5529],\n",
      "          [ 0.6860,  0.7446,  0.7597,  0.6328,  0.5500]],\n",
      "\n",
      "         [[-0.5358, -0.6124, -0.6469, -0.5633, -0.5115],\n",
      "          [-0.6098, -0.6775, -0.6916, -0.5641, -0.4951],\n",
      "          [-0.6618, -0.7370, -0.7696, -0.6334, -0.5527],\n",
      "          [-0.6860, -0.7445, -0.7596, -0.6326, -0.5499]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1738,  0.2299,  0.1818,  0.1764,  0.2102],\n",
      "          [ 0.2038,  0.3640,  0.3106,  0.3395,  0.4109],\n",
      "          [ 0.1224,  0.2889,  0.2623,  0.3453,  0.4714],\n",
      "          [ 0.1337,  0.3272,  0.3566,  0.4875,  0.6444]],\n",
      "\n",
      "         [[-0.1739, -0.2299, -0.1818, -0.1764, -0.2102],\n",
      "          [-0.2039, -0.3639, -0.3105, -0.3394, -0.4108],\n",
      "          [-0.1225, -0.2888, -0.2623, -0.3452, -0.4713],\n",
      "          [-0.1337, -0.3271, -0.3565, -0.4874, -0.6443]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5622,  0.6496,  0.6761,  0.6707,  0.6550],\n",
      "          [ 0.7036,  0.8289,  0.8198,  0.8399,  0.8359],\n",
      "          [ 0.8137,  0.9974,  0.9722,  0.9949,  1.0221],\n",
      "          [ 0.7685,  0.9680,  0.9456,  0.9738,  1.0465]],\n",
      "\n",
      "         [[-0.5623, -0.6496, -0.6761, -0.6707, -0.6550],\n",
      "          [-0.7036, -0.8288, -0.8197, -0.8398, -0.8358],\n",
      "          [-0.8137, -0.9973, -0.9721, -0.9947, -1.0220],\n",
      "          [-0.7685, -0.9679, -0.9455, -0.9737, -1.0464]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7248,  0.8974,  0.9779,  1.1351,  1.2874],\n",
      "          [ 0.9031,  1.0816,  1.1134,  1.3411,  1.5363],\n",
      "          [ 1.0059,  1.2070,  1.2098,  1.4197,  1.6008],\n",
      "          [ 1.0843,  1.3061,  1.3137,  1.4635,  1.6551]],\n",
      "\n",
      "         [[-0.7249, -0.8974, -0.9779, -1.1351, -1.2875],\n",
      "          [-0.9031, -1.0815, -1.1133, -1.3410, -1.5362],\n",
      "          [-1.0059, -1.2069, -1.2097, -1.4196, -1.6007],\n",
      "          [-1.0843, -1.3060, -1.3136, -1.4634, -1.6550]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0859,  1.3417,  1.5731,  1.6292,  1.6402],\n",
      "          [ 1.3888,  1.5847,  1.8222,  1.8789,  1.9108],\n",
      "          [ 1.6075,  1.7884,  2.0649,  2.1523,  2.2099],\n",
      "          [ 1.7598,  1.9901,  2.2983,  2.3508,  2.3744]],\n",
      "\n",
      "         [[-1.0859, -1.3418, -1.5731, -1.6292, -1.6402],\n",
      "          [-1.3888, -1.5846, -1.8221, -1.8789, -1.9107],\n",
      "          [-1.6075, -1.7883, -2.0648, -2.1522, -2.2098],\n",
      "          [-1.7598, -1.9900, -2.2981, -2.3507, -2.3743]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0668,  1.2698,  1.4507,  1.5475,  1.5949],\n",
      "          [ 1.3766,  1.4886,  1.5741,  1.6681,  1.7452],\n",
      "          [ 1.6285,  1.7157,  1.7033,  1.7629,  1.8030],\n",
      "          [ 1.8201,  1.9545,  1.9322,  1.9683,  1.9837]],\n",
      "\n",
      "         [[-1.0669, -1.2697, -1.4507, -1.5475, -1.5949],\n",
      "          [-1.3766, -1.4884, -1.5740, -1.6680, -1.7451],\n",
      "          [-1.6285, -1.7156, -1.7031, -1.7627, -1.8029],\n",
      "          [-1.8201, -1.9544, -1.9320, -1.9682, -1.9835]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9393,  2.4520,  2.9520,  3.1605,  3.3304],\n",
      "          [ 2.4276,  2.6950,  3.2390,  3.5451,  3.8443],\n",
      "          [ 2.8991,  3.2410,  3.9160,  4.3110,  4.7048],\n",
      "          [ 3.0978,  3.5679,  4.2970,  4.6952,  4.9919]],\n",
      "\n",
      "         [[-1.9393, -2.4518, -2.9519, -3.1603, -3.3302],\n",
      "          [-2.4275, -2.6947, -3.2387, -3.5447, -3.8439],\n",
      "          [-2.8989, -3.2407, -3.9156, -4.3105, -4.7044],\n",
      "          [-3.0976, -3.5676, -4.2965, -4.6948, -4.9914]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2559,  1.5497,  1.7944,  1.9436,  1.9847],\n",
      "          [ 1.5934,  1.7941,  1.9869,  2.1911,  2.2664],\n",
      "          [ 1.8155,  1.9958,  2.1921,  2.3787,  2.4688],\n",
      "          [ 1.9304,  2.1512,  2.3292,  2.4500,  2.5124]],\n",
      "\n",
      "         [[-1.2559, -1.5498, -1.7943, -1.9436, -1.9847],\n",
      "          [-1.5934, -1.7940, -1.9867, -2.1910, -2.2662],\n",
      "          [-1.8155, -1.9957, -2.1919, -2.3785, -2.4686],\n",
      "          [-1.9304, -2.1511, -2.3290, -2.4499, -2.5122]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8229,  2.3373,  2.7869,  3.0076,  3.1917],\n",
      "          [ 2.3143,  2.6401,  3.1790,  3.5118,  3.8199],\n",
      "          [ 2.7314,  3.1561,  3.8303,  4.2642,  4.6013],\n",
      "          [ 2.9143,  3.4184,  4.1522,  4.5829,  4.9005]],\n",
      "\n",
      "         [[-1.8230, -2.3372, -2.7867, -3.0075, -3.1915],\n",
      "          [-2.3142, -2.6399, -3.1787, -3.5115, -3.8196],\n",
      "          [-2.7313, -3.1559, -3.8299, -4.2638, -4.6009],\n",
      "          [-2.9141, -3.4181, -4.1518, -4.5825, -4.9000]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3455e-01,  1.5046e-01,  1.7201e-01,  4.0225e-01,  6.3989e-01],\n",
      "          [ 1.0973e-01,  1.4432e-01,  1.0403e-01,  3.8359e-01,  6.7065e-01],\n",
      "          [ 1.9512e-02,  4.0278e-02, -3.8851e-04,  3.2697e-01,  6.4546e-01],\n",
      "          [-1.5634e-02,  3.7367e-02, -2.6459e-02,  2.9875e-01,  6.3329e-01]],\n",
      "\n",
      "         [[-1.3464e-01, -1.5051e-01, -1.7206e-01, -4.0231e-01, -6.3995e-01],\n",
      "          [-1.0977e-01, -1.4430e-01, -1.0402e-01, -3.8360e-01, -6.7065e-01],\n",
      "          [-1.9548e-02, -4.0251e-02,  4.0149e-04, -3.2698e-01, -6.4546e-01],\n",
      "          [ 1.5599e-02, -3.7341e-02,  2.6467e-02, -2.9877e-01, -6.3331e-01]]]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 1 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0961,  1.3710,  1.5617,  1.6791,  1.7663],\n",
      "          [ 1.3468,  1.5486,  1.7133,  1.9042,  2.0778],\n",
      "          [ 1.4192,  1.5278,  1.6708,  1.9278,  2.1874],\n",
      "          [ 1.5088,  1.6307,  1.7980,  2.0222,  2.2807]],\n",
      "\n",
      "         [[-1.0961, -1.3710, -1.5617, -1.6791, -1.7663],\n",
      "          [-1.3468, -1.5485, -1.7132, -1.9041, -2.0777],\n",
      "          [-1.4192, -1.5277, -1.6707, -1.9277, -2.1873],\n",
      "          [-1.5088, -1.6306, -1.7979, -2.0221, -2.2806]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1922,  1.4882,  1.7306,  1.8596,  1.9433],\n",
      "          [ 1.5110,  1.7539,  1.9282,  2.0773,  2.2185],\n",
      "          [ 1.7237,  1.9567,  2.1001,  2.2760,  2.4730],\n",
      "          [ 1.8846,  2.1743,  2.3476,  2.5229,  2.7371]],\n",
      "\n",
      "         [[-1.1923, -1.4882, -1.7306, -1.8595, -1.9432],\n",
      "          [-1.5110, -1.7538, -1.9281, -2.0772, -2.2183],\n",
      "          [-1.7236, -1.9566, -2.1000, -2.2758, -2.4728],\n",
      "          [-1.8846, -2.1742, -2.3474, -2.5228, -2.7369]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2083,  0.2178,  0.2245,  0.2730,  0.3133],\n",
      "          [ 0.1369,  0.1144,  0.0596,  0.1039,  0.1672],\n",
      "          [-0.0210, -0.0888, -0.1304, -0.0831,  0.0108],\n",
      "          [-0.1751, -0.2134, -0.1978, -0.1906, -0.1560]],\n",
      "\n",
      "         [[-0.2083, -0.2178, -0.2245, -0.2730, -0.3133],\n",
      "          [-0.1369, -0.1144, -0.0596, -0.1039, -0.1671],\n",
      "          [ 0.0209,  0.0888,  0.1305,  0.0832, -0.0108],\n",
      "          [ 0.1750,  0.2135,  0.1979,  0.1906,  0.1560]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 1 1 1 0]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3275,  0.3243,  0.3046,  0.3233,  0.4533],\n",
      "          [ 0.3906,  0.4268,  0.3886,  0.4433,  0.6487],\n",
      "          [ 0.3892,  0.4644,  0.4616,  0.5571,  0.8065],\n",
      "          [ 0.3406,  0.4591,  0.4860,  0.5827,  0.8027]],\n",
      "\n",
      "         [[-0.3276, -0.3243, -0.3046, -0.3233, -0.4534],\n",
      "          [-0.3906, -0.4268, -0.3886, -0.4433, -0.6487],\n",
      "          [-0.3892, -0.4643, -0.4615, -0.5570, -0.8064],\n",
      "          [-0.3406, -0.4590, -0.4860, -0.5826, -0.8026]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1445,  1.4262,  1.6287,  1.7527,  1.8348],\n",
      "          [ 1.4455,  1.6449,  1.7580,  1.9210,  2.0781],\n",
      "          [ 1.6984,  1.8800,  1.9539,  2.1444,  2.3443],\n",
      "          [ 1.8098,  2.0054,  2.0797,  2.2810,  2.4834]],\n",
      "\n",
      "         [[-1.1446, -1.4262, -1.6286, -1.7526, -1.8348],\n",
      "          [-1.4455, -1.6448, -1.7579, -1.9209, -2.0780],\n",
      "          [-1.6984, -1.8799, -1.9538, -2.1442, -2.3441],\n",
      "          [-1.8098, -2.0053, -2.0795, -2.2808, -2.4832]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6085,  0.7375,  0.8732,  0.9416,  1.0571],\n",
      "          [ 0.7452,  0.8911,  1.0340,  1.0968,  1.2103],\n",
      "          [ 0.8758,  1.0599,  1.2262,  1.2910,  1.4035],\n",
      "          [ 0.9538,  1.1408,  1.3055,  1.3648,  1.4894]],\n",
      "\n",
      "         [[-0.6085, -0.7375, -0.8731, -0.9415, -1.0570],\n",
      "          [-0.7452, -0.8909, -1.0338, -1.0966, -1.2102],\n",
      "          [-0.8757, -1.0597, -1.2260, -1.2908, -1.4033],\n",
      "          [-0.9538, -1.1407, -1.3053, -1.3646, -1.4892]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9397,  1.1817,  1.4098,  1.7137,  1.9594],\n",
      "          [ 1.0982,  1.2393,  1.3546,  1.6902,  1.9930],\n",
      "          [ 1.0587,  1.1618,  1.2560,  1.6491,  1.9681],\n",
      "          [ 0.9537,  1.1012,  1.2222,  1.6879,  1.9867]],\n",
      "\n",
      "         [[-0.9398, -1.1817, -1.4098, -1.7137, -1.9593],\n",
      "          [-1.0982, -1.2393, -1.3545, -1.6901, -1.9929],\n",
      "          [-1.0588, -1.1617, -1.2559, -1.6490, -1.9680],\n",
      "          [-0.9538, -1.1012, -1.2221, -1.6878, -1.9866]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3202,  0.3981,  0.3679,  0.3445,  0.3331],\n",
      "          [ 0.3099,  0.4275,  0.3911,  0.4056,  0.4391],\n",
      "          [ 0.1912,  0.2771,  0.2961,  0.3790,  0.4888],\n",
      "          [ 0.3013,  0.4806,  0.5885,  0.6655,  0.7435]],\n",
      "\n",
      "         [[-0.3203, -0.3981, -0.3679, -0.3446, -0.3331],\n",
      "          [-0.3099, -0.4275, -0.3911, -0.4055, -0.4391],\n",
      "          [-0.1912, -0.2770, -0.2960, -0.3790, -0.4887],\n",
      "          [-0.3013, -0.4806, -0.5884, -0.6654, -0.7434]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3184,  1.6755,  1.9631,  2.0595,  2.1728],\n",
      "          [ 1.6463,  1.9586,  2.2283,  2.3198,  2.4592],\n",
      "          [ 1.8858,  2.2284,  2.5316,  2.6359,  2.7897],\n",
      "          [ 1.9879,  2.3520,  2.6647,  2.7442,  2.8869]],\n",
      "\n",
      "         [[-1.3185, -1.6755, -1.9630, -2.0594, -2.1727],\n",
      "          [-1.6462, -1.9585, -2.2281, -2.3196, -2.4590],\n",
      "          [-1.8857, -2.2282, -2.5314, -2.6357, -2.7894],\n",
      "          [-1.9879, -2.3518, -2.6645, -2.7439, -2.8867]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1456,  1.4277,  1.6847,  1.8187,  1.8883],\n",
      "          [ 1.4090,  1.6109,  1.8294,  1.9949,  2.0697],\n",
      "          [ 1.5352,  1.7101,  1.9027,  2.0533,  2.0735],\n",
      "          [ 1.5437,  1.7671,  1.9677,  2.1021,  2.0828]],\n",
      "\n",
      "         [[-1.1456, -1.4277, -1.6847, -1.8187, -1.8882],\n",
      "          [-1.4090, -1.6109, -1.8293, -1.9948, -2.0696],\n",
      "          [-1.5352, -1.7100, -1.9026, -2.0532, -2.0734],\n",
      "          [-1.5437, -1.7670, -1.9676, -2.1019, -2.0827]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9156,  1.0947,  1.2429,  1.1995,  1.1189],\n",
      "          [ 1.0856,  1.2445,  1.3848,  1.3212,  1.2472],\n",
      "          [ 1.2124,  1.3831,  1.4984,  1.3936,  1.3058],\n",
      "          [ 1.2298,  1.4081,  1.4778,  1.3515,  1.2264]],\n",
      "\n",
      "         [[-0.9156, -1.0947, -1.2429, -1.1995, -1.1190],\n",
      "          [-1.0856, -1.2445, -1.3847, -1.3211, -1.2471],\n",
      "          [-1.2124, -1.3830, -1.4983, -1.3935, -1.3057],\n",
      "          [-1.2298, -1.4080, -1.4777, -1.3514, -1.2264]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6163,  0.6784,  0.6253,  0.5405,  0.4427],\n",
      "          [ 0.6139,  0.5971,  0.4754,  0.4216,  0.3814],\n",
      "          [ 0.5026,  0.4332,  0.3078,  0.3015,  0.3318],\n",
      "          [ 0.3875,  0.3524,  0.2657,  0.2762,  0.3350]],\n",
      "\n",
      "         [[-0.6164, -0.6784, -0.6254, -0.5406, -0.4427],\n",
      "          [-0.6139, -0.5970, -0.4753, -0.4215, -0.3813],\n",
      "          [-0.5027, -0.4332, -0.3077, -0.3014, -0.3317],\n",
      "          [-0.3875, -0.3523, -0.2656, -0.2762, -0.3349]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5430,  0.6105,  0.6747,  0.6894,  0.7587],\n",
      "          [ 0.5877,  0.6312,  0.6842,  0.7086,  0.7765],\n",
      "          [ 0.6007,  0.6553,  0.7223,  0.7682,  0.8062],\n",
      "          [ 0.5942,  0.6889,  0.7965,  0.8562,  0.8545]],\n",
      "\n",
      "         [[-0.5431, -0.6105, -0.6747, -0.6894, -0.7587],\n",
      "          [-0.5877, -0.6312, -0.6841, -0.7084, -0.7765],\n",
      "          [-0.6007, -0.6552, -0.7222, -0.7681, -0.8061],\n",
      "          [-0.5942, -0.6888, -0.7964, -0.8561, -0.8544]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1716,  1.4095,  1.6388,  1.7681,  1.8180],\n",
      "          [ 1.4325,  1.5466,  1.7217,  1.8909,  2.0064],\n",
      "          [ 1.5376,  1.6168,  1.7813,  1.9474,  2.0771],\n",
      "          [ 1.5494,  1.7269,  1.9131,  2.0713,  2.1853]],\n",
      "\n",
      "         [[-1.1717, -1.4095, -1.6388, -1.7681, -1.8180],\n",
      "          [-1.4326, -1.5465, -1.7216, -1.8908, -2.0063],\n",
      "          [-1.5376, -1.6167, -1.7812, -1.9472, -2.0769],\n",
      "          [-1.5494, -1.7268, -1.9129, -2.0711, -2.1852]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5836,  0.6916,  0.7791,  0.8978,  1.0500],\n",
      "          [ 0.6606,  0.7576,  0.8007,  0.9348,  1.1130],\n",
      "          [ 0.6794,  0.7850,  0.7874,  0.9120,  1.0997],\n",
      "          [ 0.6618,  0.7813,  0.7827,  0.9400,  1.1973]],\n",
      "\n",
      "         [[-0.5836, -0.6916, -0.7791, -0.8979, -1.0500],\n",
      "          [-0.6606, -0.7575, -0.8006, -0.9347, -1.1129],\n",
      "          [-0.6794, -0.7849, -0.7873, -0.9119, -1.0997],\n",
      "          [-0.6617, -0.7812, -0.7826, -0.9399, -1.1973]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2743,  0.3414,  0.4062,  0.4034,  0.3659],\n",
      "          [ 0.3161,  0.4395,  0.5058,  0.5031,  0.4690],\n",
      "          [ 0.3057,  0.4669,  0.5747,  0.5835,  0.5513],\n",
      "          [ 0.2615,  0.4258,  0.5525,  0.5456,  0.4780]],\n",
      "\n",
      "         [[-0.2744, -0.3415, -0.4062, -0.4034, -0.3659],\n",
      "          [-0.3161, -0.4394, -0.5057, -0.5030, -0.4690],\n",
      "          [-0.3057, -0.4668, -0.5746, -0.5834, -0.5512],\n",
      "          [-0.2615, -0.4257, -0.5524, -0.5455, -0.4779]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2671,  1.4583,  1.5969,  1.6688,  1.6664],\n",
      "          [ 1.4731,  1.3425,  1.2384,  1.2686,  1.2878],\n",
      "          [ 1.4834,  1.1801,  1.0049,  1.0517,  1.1060],\n",
      "          [ 1.4506,  1.1921,  1.0616,  1.1270,  1.1694]],\n",
      "\n",
      "         [[-1.2672, -1.4583, -1.5969, -1.6688, -1.6664],\n",
      "          [-1.4731, -1.3424, -1.2383, -1.2685, -1.2877],\n",
      "          [-1.4834, -1.1800, -1.0048, -1.0516, -1.1059],\n",
      "          [-1.4506, -1.1920, -1.0614, -1.1268, -1.1692]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1357,  1.3808,  1.5585,  1.6546,  1.7282],\n",
      "          [ 1.4006,  1.5512,  1.6570,  1.7716,  1.8929],\n",
      "          [ 1.5514,  1.6443,  1.7229,  1.8550,  2.0064],\n",
      "          [ 1.7078,  1.8578,  1.9796,  2.0895,  2.2106]],\n",
      "\n",
      "         [[-1.1358, -1.3808, -1.5585, -1.6546, -1.7282],\n",
      "          [-1.4006, -1.5511, -1.6569, -1.7715, -1.8928],\n",
      "          [-1.5514, -1.6441, -1.7228, -1.8548, -2.0062],\n",
      "          [-1.7078, -1.8576, -1.9794, -2.0894, -2.2105]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4776,  0.4443,  0.4279,  0.4279,  0.4528],\n",
      "          [ 0.5975,  0.5101,  0.4149,  0.4003,  0.4366],\n",
      "          [ 0.7349,  0.6713,  0.5581,  0.5027,  0.4960],\n",
      "          [ 0.6994,  0.6148,  0.4900,  0.3835,  0.3797]],\n",
      "\n",
      "         [[-0.4777, -0.4443, -0.4279, -0.4279, -0.4528],\n",
      "          [-0.5975, -0.5100, -0.4147, -0.4002, -0.4365],\n",
      "          [-0.7348, -0.6711, -0.5579, -0.5025, -0.4958],\n",
      "          [-0.6994, -0.6147, -0.4898, -0.3834, -0.3796]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5361,  0.6766,  0.7957,  0.8490,  0.9075],\n",
      "          [ 0.5976,  0.7199,  0.7838,  0.8064,  0.8654],\n",
      "          [ 0.5583,  0.6520,  0.7173,  0.7479,  0.8229],\n",
      "          [ 0.5604,  0.6610,  0.7264,  0.7634,  0.8725]],\n",
      "\n",
      "         [[-0.5362, -0.6766, -0.7957, -0.8490, -0.9075],\n",
      "          [-0.5976, -0.7198, -0.7837, -0.8063, -0.8653],\n",
      "          [-0.5583, -0.6519, -0.7172, -0.7477, -0.8227],\n",
      "          [-0.5604, -0.6609, -0.7263, -0.7633, -0.8724]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8319,  1.0179,  1.1061,  1.1298,  1.1981],\n",
      "          [ 0.9996,  1.1591,  1.2068,  1.2360,  1.3375],\n",
      "          [ 1.1451,  1.3022,  1.3303,  1.3706,  1.4958],\n",
      "          [ 1.2564,  1.4039,  1.4327,  1.4737,  1.5896]],\n",
      "\n",
      "         [[-0.8320, -1.0179, -1.1061, -1.1297, -1.1980],\n",
      "          [-0.9996, -1.1591, -1.2067, -1.2359, -1.3374],\n",
      "          [-1.1451, -1.3021, -1.3302, -1.3705, -1.4957],\n",
      "          [-1.2564, -1.4038, -1.4326, -1.4736, -1.5895]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9680,  1.1856,  1.3822,  1.5326,  1.6666],\n",
      "          [ 1.1966,  1.3737,  1.5572,  1.7445,  1.9323],\n",
      "          [ 1.3185,  1.4867,  1.6989,  1.9241,  2.1734],\n",
      "          [ 1.4003,  1.6184,  1.8945,  2.1376,  2.4052]],\n",
      "\n",
      "         [[-0.9681, -1.1856, -1.3822, -1.5325, -1.6666],\n",
      "          [-1.1966, -1.3736, -1.5571, -1.7444, -1.9321],\n",
      "          [-1.3185, -1.4866, -1.6988, -1.9240, -2.1733],\n",
      "          [-1.4003, -1.6183, -1.8944, -2.1375, -2.4051]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2987,  1.6219,  1.8774,  2.0438,  2.1560],\n",
      "          [ 1.6089,  1.8130,  2.0177,  2.2258,  2.4091],\n",
      "          [ 1.8169,  1.9730,  2.1766,  2.4295,  2.6533],\n",
      "          [ 2.0280,  2.2462,  2.4820,  2.7527,  2.9879]],\n",
      "\n",
      "         [[-1.2988, -1.6219, -1.8774, -2.0438, -2.1560],\n",
      "          [-1.6089, -1.8129, -2.0175, -2.2257, -2.4090],\n",
      "          [-1.8168, -1.9729, -2.1765, -2.4294, -2.6531],\n",
      "          [-2.0280, -2.2460, -2.4819, -2.7525, -2.9877]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4872,  0.5130,  0.4420,  0.5228,  0.6108],\n",
      "          [ 0.6172,  0.6071,  0.4327,  0.5442,  0.6686],\n",
      "          [ 0.6512,  0.6118,  0.4555,  0.5881,  0.7460],\n",
      "          [ 0.7296,  0.7287,  0.6461,  0.7871,  0.9407]],\n",
      "\n",
      "         [[-0.4872, -0.5130, -0.4419, -0.5228, -0.6108],\n",
      "          [-0.6171, -0.6070, -0.4326, -0.5441, -0.6685],\n",
      "          [-0.6512, -0.6117, -0.4554, -0.5879, -0.7459],\n",
      "          [-0.7296, -0.7286, -0.6460, -0.7870, -0.9406]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3330,  0.3521,  0.3451,  0.2887,  0.2756],\n",
      "          [ 0.3325,  0.3387,  0.3021,  0.2347,  0.2477],\n",
      "          [ 0.2994,  0.2948,  0.2814,  0.2441,  0.3028],\n",
      "          [ 0.2617,  0.2486,  0.2496,  0.2108,  0.2758]],\n",
      "\n",
      "         [[-0.3330, -0.3521, -0.3451, -0.2886, -0.2756],\n",
      "          [-0.3325, -0.3386, -0.3020, -0.2346, -0.2476],\n",
      "          [-0.2994, -0.2947, -0.2813, -0.2439, -0.3026],\n",
      "          [-0.2617, -0.2485, -0.2495, -0.2106, -0.2757]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5750,  0.6814,  0.7058,  0.7288,  0.7640],\n",
      "          [ 0.6693,  0.7841,  0.7775,  0.8251,  0.8934],\n",
      "          [ 0.6810,  0.7976,  0.8092,  0.8859,  0.9766],\n",
      "          [ 0.6890,  0.8322,  0.8672,  0.9541,  1.0433]],\n",
      "\n",
      "         [[-0.5751, -0.6814, -0.7059, -0.7288, -0.7640],\n",
      "          [-0.6693, -0.7840, -0.7774, -0.8251, -0.8934],\n",
      "          [-0.6810, -0.7975, -0.8092, -0.8858, -0.9765],\n",
      "          [-0.6890, -0.8322, -0.8672, -0.9540, -1.0433]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.2698, -0.3725, -0.4111, -0.3504, -0.2285],\n",
      "          [-0.3953, -0.4458, -0.5186, -0.4891, -0.3922],\n",
      "          [-0.5454, -0.5906, -0.5996, -0.5490, -0.4599],\n",
      "          [-0.5668, -0.5585, -0.4693, -0.3952, -0.3190]],\n",
      "\n",
      "         [[ 0.2697,  0.3725,  0.4111,  0.3504,  0.2285],\n",
      "          [ 0.3953,  0.4459,  0.5188,  0.4892,  0.3923],\n",
      "          [ 0.5454,  0.5908,  0.5998,  0.5492,  0.4601],\n",
      "          [ 0.5668,  0.5587,  0.4695,  0.3954,  0.3191]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2037,  1.4640,  1.6915,  1.7719,  1.8532],\n",
      "          [ 1.4699,  1.6161,  1.7927,  1.8776,  1.9819],\n",
      "          [ 1.7005,  1.8182,  1.9846,  2.0647,  2.1712],\n",
      "          [ 1.8619,  2.0139,  2.1680,  2.2258,  2.3518]],\n",
      "\n",
      "         [[-1.2038, -1.4639, -1.6915, -1.7719, -1.8532],\n",
      "          [-1.4699, -1.6160, -1.7925, -1.8774, -1.9817],\n",
      "          [-1.7005, -1.8181, -1.9844, -2.0645, -2.1710],\n",
      "          [-1.8619, -2.0138, -2.1678, -2.2256, -2.3516]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.2249, -0.2974, -0.3282, -0.3797, -0.4110],\n",
      "          [-0.4811, -0.5105, -0.5202, -0.5396, -0.5278],\n",
      "          [-0.7243, -0.7492, -0.7105, -0.6260, -0.5143],\n",
      "          [-0.8401, -0.8333, -0.8050, -0.6921, -0.5413]],\n",
      "\n",
      "         [[ 0.2248,  0.2974,  0.3282,  0.3797,  0.4110],\n",
      "          [ 0.4811,  0.5106,  0.5203,  0.5397,  0.5279],\n",
      "          [ 0.7243,  0.7493,  0.7107,  0.6261,  0.5144],\n",
      "          [ 0.8401,  0.8334,  0.8051,  0.6922,  0.5414]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8484,  1.0617,  1.2786,  1.3587,  1.4428],\n",
      "          [ 1.1306,  1.3998,  1.6914,  1.7823,  1.8881],\n",
      "          [ 1.3828,  1.7437,  2.1366,  2.2677,  2.3891],\n",
      "          [ 1.4480,  1.8056,  2.2001,  2.3349,  2.4581]],\n",
      "\n",
      "         [[-0.8485, -1.0617, -1.2786, -1.3587, -1.4427],\n",
      "          [-1.1306, -1.3997, -1.6913, -1.7822, -1.8880],\n",
      "          [-1.3828, -1.7436, -2.1364, -2.2675, -2.3889],\n",
      "          [-1.4480, -1.8055, -2.2000, -2.3347, -2.4579]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2653,  1.5826,  1.8284,  1.9584,  2.0640],\n",
      "          [ 1.5768,  1.8122,  2.0308,  2.1966,  2.3268],\n",
      "          [ 1.8019,  2.0140,  2.2281,  2.4247,  2.5740],\n",
      "          [ 1.9370,  2.1761,  2.3956,  2.5863,  2.7472]],\n",
      "\n",
      "         [[-1.2653, -1.5826, -1.8284, -1.9584, -2.0640],\n",
      "          [-1.5768, -1.8121, -2.0307, -2.1964, -2.3267],\n",
      "          [-1.8018, -2.0139, -2.2279, -2.4246, -2.5738],\n",
      "          [-1.9370, -2.1760, -2.3954, -2.5862, -2.7471]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6103,  0.6291,  0.5842,  0.7100,  0.8495],\n",
      "          [ 0.7842,  0.7206,  0.5393,  0.7442,  0.9290],\n",
      "          [ 0.9546,  0.8337,  0.5881,  0.8514,  1.0741],\n",
      "          [ 1.0854,  0.8766,  0.5612,  0.8229,  1.0613]],\n",
      "\n",
      "         [[-0.6104, -0.6291, -0.5843, -0.7100, -0.8495],\n",
      "          [-0.7843, -0.7205, -0.5393, -0.7441, -0.9289],\n",
      "          [-0.9546, -0.8336, -0.5880, -0.8513, -1.0740],\n",
      "          [-1.0854, -0.8766, -0.5611, -0.8228, -1.0612]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7127,  0.8590,  0.9513,  0.8975,  0.8483],\n",
      "          [ 0.7959,  0.9396,  1.0515,  1.0323,  0.9987],\n",
      "          [ 0.9020,  1.1086,  1.2644,  1.2715,  1.2347],\n",
      "          [ 0.9703,  1.2016,  1.3517,  1.3672,  1.3243]],\n",
      "\n",
      "         [[-0.7128, -0.8590, -0.9513, -0.8975, -0.8483],\n",
      "          [-0.7959, -0.9395, -1.0514, -1.0322, -0.9986],\n",
      "          [-0.9020, -1.1085, -1.2643, -1.2714, -1.2346],\n",
      "          [-0.9703, -1.2016, -1.3516, -1.3671, -1.3242]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6601,  0.7816,  0.8546,  0.8627,  0.8910],\n",
      "          [ 0.8017,  0.9241,  0.9765,  0.9990,  1.0372],\n",
      "          [ 0.8487,  0.9723,  1.0556,  1.0840,  1.1258],\n",
      "          [ 0.8937,  1.0376,  1.1491,  1.2048,  1.2926]],\n",
      "\n",
      "         [[-0.6602, -0.7816, -0.8546, -0.8627, -0.8910],\n",
      "          [-0.8017, -0.9240, -0.9764, -0.9989, -1.0371],\n",
      "          [-0.8487, -0.9722, -1.0555, -1.0839, -1.1257],\n",
      "          [-0.8937, -1.0375, -1.1490, -1.2047, -1.2926]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8702,  2.3791,  2.8488,  3.0720,  3.2563],\n",
      "          [ 2.3563,  2.6421,  3.1790,  3.5122,  3.8233],\n",
      "          [ 2.7880,  3.1700,  3.8357,  4.2723,  4.6443],\n",
      "          [ 2.9582,  3.4370,  4.1594,  4.6088,  4.9312]],\n",
      "\n",
      "         [[-1.8702, -2.3790, -2.8487, -3.0718, -3.2561],\n",
      "          [-2.3562, -2.6419, -3.1787, -3.5118, -3.8229],\n",
      "          [-2.7879, -3.1697, -3.8354, -4.2719, -4.6438],\n",
      "          [-2.9580, -3.4367, -4.1590, -4.6084, -4.9308]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2871,  0.3536,  0.4342,  0.5385,  0.7056],\n",
      "          [ 0.4623,  0.5682,  0.5803,  0.6222,  0.7650],\n",
      "          [ 0.5710,  0.6385,  0.6283,  0.6499,  0.7654],\n",
      "          [ 0.8276,  0.9585,  0.9675,  0.9731,  1.0592]],\n",
      "\n",
      "         [[-0.2872, -0.3536, -0.4342, -0.5385, -0.7056],\n",
      "          [-0.4623, -0.5681, -0.5801, -0.6221, -0.7650],\n",
      "          [-0.5710, -0.6383, -0.6281, -0.6497, -0.7653],\n",
      "          [-0.8276, -0.9584, -0.9673, -0.9729, -1.0591]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0358,  1.3318,  1.5386,  1.6499,  1.7306],\n",
      "          [ 1.2796,  1.5262,  1.7026,  1.8284,  1.9503],\n",
      "          [ 1.4142,  1.6029,  1.7614,  1.9095,  2.0660],\n",
      "          [ 1.5715,  1.7939,  1.9592,  2.0981,  2.2478]],\n",
      "\n",
      "         [[-1.0359, -1.3318, -1.5386, -1.6499, -1.7306],\n",
      "          [-1.2796, -1.5262, -1.7025, -1.8282, -1.9501],\n",
      "          [-1.4142, -1.6028, -1.7613, -1.9094, -2.0659],\n",
      "          [-1.5715, -1.7938, -1.9591, -2.0980, -2.2476]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9726,  2.5853,  3.0363,  3.2480,  3.4152],\n",
      "          [ 2.5048,  2.8378,  3.4473,  3.7857,  4.0730],\n",
      "          [ 2.9435,  3.3682,  4.1321,  4.5825,  4.8886],\n",
      "          [ 3.1391,  3.6502,  4.4906,  4.9229,  5.2268]],\n",
      "\n",
      "         [[-1.9726, -2.5851, -3.0361, -3.2478, -3.4149],\n",
      "          [-2.5047, -2.8375, -3.4470, -3.7854, -4.0726],\n",
      "          [-2.9434, -3.3679, -4.1317, -4.5820, -4.8881],\n",
      "          [-3.1390, -3.6498, -4.4902, -4.9224, -5.2263]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3431,  1.6883,  1.9633,  2.1038,  2.1783],\n",
      "          [ 1.7112,  1.9868,  2.2168,  2.3890,  2.5306],\n",
      "          [ 1.9448,  2.2027,  2.4445,  2.6704,  2.8396],\n",
      "          [ 2.0718,  2.3497,  2.6227,  2.8846,  3.0792]],\n",
      "\n",
      "         [[-1.3432, -1.6882, -1.9633, -2.1038, -2.1782],\n",
      "          [-1.7112, -1.9867, -2.2166, -2.3889, -2.5305],\n",
      "          [-1.9447, -2.2026, -2.4443, -2.6702, -2.8394],\n",
      "          [-2.0718, -2.3496, -2.6226, -2.8844, -3.0790]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.2981, -0.4292, -0.4736, -0.4367, -0.4029],\n",
      "          [-0.5110, -0.5633, -0.6455, -0.6115, -0.5551],\n",
      "          [-0.8246, -0.8614, -0.9518, -0.9155, -0.8107],\n",
      "          [-1.0637, -1.1613, -1.2900, -1.3030, -1.2140]],\n",
      "\n",
      "         [[ 0.2980,  0.4292,  0.4736,  0.4366,  0.4028],\n",
      "          [ 0.5109,  0.5633,  0.6455,  0.6115,  0.5551],\n",
      "          [ 0.8246,  0.8615,  0.9518,  0.9155,  0.8107],\n",
      "          [ 1.0637,  1.1614,  1.2901,  1.3031,  1.2141]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0878,  1.4141,  1.6765,  1.9007,  2.0847],\n",
      "          [ 1.3738,  1.6521,  1.8606,  2.1013,  2.3235],\n",
      "          [ 1.5882,  1.8144,  1.9841,  2.2163,  2.4477],\n",
      "          [ 1.7509,  1.9819,  2.1674,  2.3831,  2.5842]],\n",
      "\n",
      "         [[-1.0879, -1.4141, -1.6765, -1.9007, -2.0846],\n",
      "          [-1.3738, -1.6520, -1.8605, -2.1012, -2.3233],\n",
      "          [-1.5881, -1.8143, -1.9840, -2.2162, -2.4475],\n",
      "          [-1.7508, -1.9818, -2.1673, -2.3829, -2.5840]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9683,  1.2216,  1.4085,  1.4345,  1.4785],\n",
      "          [ 1.1896,  1.4082,  1.5698,  1.6069,  1.6824],\n",
      "          [ 1.3540,  1.5496,  1.6954,  1.7680,  1.8962],\n",
      "          [ 1.4150,  1.6020,  1.6901,  1.7498,  1.9004]],\n",
      "\n",
      "         [[-0.9684, -1.2216, -1.4085, -1.4344, -1.4785],\n",
      "          [-1.1896, -1.4081, -1.5696, -1.6068, -1.6823],\n",
      "          [-1.3540, -1.5495, -1.6953, -1.7679, -1.8961],\n",
      "          [-1.4151, -1.6019, -1.6900, -1.7497, -1.9002]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8048,  0.9878,  1.1181,  1.2343,  1.2945],\n",
      "          [ 0.9977,  1.1066,  1.1646,  1.3228,  1.4287],\n",
      "          [ 1.1118,  1.1458,  1.1820,  1.3724,  1.5047],\n",
      "          [ 1.2326,  1.2462,  1.2750,  1.4886,  1.6391]],\n",
      "\n",
      "         [[-0.8049, -0.9878, -1.1181, -1.2343, -1.2945],\n",
      "          [-0.9978, -1.1065, -1.1645, -1.3227, -1.4286],\n",
      "          [-1.1119, -1.1458, -1.1819, -1.3723, -1.5046],\n",
      "          [-1.2326, -1.2461, -1.2749, -1.4885, -1.6390]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4672,  0.5606,  0.6216,  0.7415,  0.8792],\n",
      "          [ 0.4937,  0.6129,  0.6551,  0.8193,  0.9973],\n",
      "          [ 0.4552,  0.6186,  0.6950,  0.9226,  1.1559],\n",
      "          [ 0.4320,  0.6462,  0.7757,  1.0588,  1.3414]],\n",
      "\n",
      "         [[-0.4673, -0.5606, -0.6216, -0.7416, -0.8792],\n",
      "          [-0.4937, -0.6128, -0.6550, -0.8192, -0.9973],\n",
      "          [-0.4552, -0.6185, -0.6949, -0.9226, -1.1558],\n",
      "          [-0.4321, -0.6461, -0.7756, -1.0588, -1.3414]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.0390, -0.0112,  0.0291,  0.1369,  0.3351],\n",
      "          [-0.0528, -0.1256, -0.1352, -0.0423,  0.1826],\n",
      "          [-0.1359, -0.2286, -0.2705, -0.2014,  0.0233],\n",
      "          [-0.1361, -0.1776, -0.1450, -0.0643,  0.1952]],\n",
      "\n",
      "         [[-0.0391,  0.0112, -0.0291, -0.1369, -0.3351],\n",
      "          [ 0.0528,  0.1257,  0.1353,  0.0424, -0.1825],\n",
      "          [ 0.1359,  0.2287,  0.2707,  0.2015, -0.0232],\n",
      "          [ 0.1361,  0.1777,  0.1451,  0.0644, -0.1952]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 1 0 0 0]\n",
      " [1 1 1 1 0]\n",
      " [1 1 1 1 0]\n",
      " [1 1 1 1 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6428,  0.7459,  0.8796,  0.9694,  1.0487],\n",
      "          [ 0.8048,  0.8709,  1.0034,  1.1230,  1.2250],\n",
      "          [ 0.9242,  0.9609,  1.0770,  1.2074,  1.3099],\n",
      "          [ 1.0549,  1.0914,  1.1605,  1.2974,  1.4117]],\n",
      "\n",
      "         [[-0.6429, -0.7460, -0.8796, -0.9695, -1.0487],\n",
      "          [-0.8048, -0.8708, -1.0033, -1.1230, -1.2249],\n",
      "          [-0.9242, -0.9608, -1.0769, -1.2073, -1.3099],\n",
      "          [-1.0549, -1.0913, -1.1604, -1.2973, -1.4117]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5471,  0.6539,  0.7080,  0.7138,  0.7591],\n",
      "          [ 0.6386,  0.7499,  0.8041,  0.8190,  0.8808],\n",
      "          [ 0.6924,  0.7685,  0.8153,  0.8177,  0.8672],\n",
      "          [ 0.8581,  0.9453,  0.9834,  0.9650,  1.0400]],\n",
      "\n",
      "         [[-0.5472, -0.6539, -0.7079, -0.7137, -0.7591],\n",
      "          [-0.6386, -0.7498, -0.8039, -0.8189, -0.8806],\n",
      "          [-0.6924, -0.7683, -0.8151, -0.8175, -0.8670],\n",
      "          [-0.8581, -0.9452, -0.9832, -0.9649, -1.0398]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2519,  0.3737,  0.5576,  0.7655,  0.9856],\n",
      "          [ 0.2325,  0.4123,  0.6035,  0.7955,  0.9699],\n",
      "          [ 0.2106,  0.4420,  0.7056,  0.9108,  1.0311],\n",
      "          [ 0.1993,  0.5054,  0.8902,  1.1544,  1.2945]],\n",
      "\n",
      "         [[-0.2520, -0.3737, -0.5576, -0.7655, -0.9856],\n",
      "          [-0.2325, -0.4123, -0.6034, -0.7955, -0.9698],\n",
      "          [-0.2106, -0.4420, -0.7055, -0.9107, -1.0311],\n",
      "          [-0.1993, -0.5054, -0.8901, -1.1543, -1.2944]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9549,  2.5393,  3.0078,  3.2309,  3.3990],\n",
      "          [ 2.4963,  2.8371,  3.4086,  3.7445,  4.0238],\n",
      "          [ 2.9366,  3.4113,  4.1355,  4.5701,  4.8793],\n",
      "          [ 3.1223,  3.6981,  4.4884,  4.8991,  5.1848]],\n",
      "\n",
      "         [[-1.9549, -2.5392, -3.0076, -3.2307, -3.3988],\n",
      "          [-2.4962, -2.8369, -3.4083, -3.7441, -4.0234],\n",
      "          [-2.9364, -3.4110, -4.1351, -4.5696, -4.8788],\n",
      "          [-3.1221, -3.6978, -4.4880, -4.8986, -5.1843]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1296,  1.3856,  1.6562,  1.8109,  1.8919],\n",
      "          [ 1.4307,  1.6272,  1.8829,  2.0689,  2.2156],\n",
      "          [ 1.6538,  1.8436,  2.1230,  2.2984,  2.4340],\n",
      "          [ 1.7822,  1.9852,  2.3032,  2.4974,  2.6820]],\n",
      "\n",
      "         [[-1.1296, -1.3856, -1.6562, -1.8108, -1.8919],\n",
      "          [-1.4307, -1.6271, -1.8828, -2.0688, -2.2155],\n",
      "          [-1.6538, -1.8434, -2.1229, -2.2983, -2.4339],\n",
      "          [-1.7822, -1.9851, -2.3030, -2.4972, -2.6818]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4731,  0.5632,  0.5721,  0.5057,  0.4491],\n",
      "          [ 0.5003,  0.6077,  0.5884,  0.5005,  0.4482],\n",
      "          [ 0.4510,  0.5662,  0.5774,  0.4795,  0.4093],\n",
      "          [ 0.4202,  0.5581,  0.6354,  0.5770,  0.5323]],\n",
      "\n",
      "         [[-0.4732, -0.5632, -0.5721, -0.5057, -0.4492],\n",
      "          [-0.5003, -0.6077, -0.5883, -0.5004, -0.4481],\n",
      "          [-0.4511, -0.5661, -0.5773, -0.4794, -0.4092],\n",
      "          [-0.4203, -0.5580, -0.6353, -0.5769, -0.5322]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.6134, -0.9209, -1.1566, -1.2779, -1.3128],\n",
      "          [-0.9327, -1.2300, -1.4886, -1.5901, -1.6037],\n",
      "          [-1.1410, -1.5394, -1.7553, -1.7492, -1.7150],\n",
      "          [-1.1726, -1.6113, -1.8325, -1.7543, -1.6557]],\n",
      "\n",
      "         [[ 0.6133,  0.9208,  1.1566,  1.2778,  1.3128],\n",
      "          [ 0.9327,  1.2301,  1.4887,  1.5902,  1.6038],\n",
      "          [ 1.1410,  1.5395,  1.7554,  1.7493,  1.7151],\n",
      "          [ 1.1726,  1.6114,  1.8326,  1.7543,  1.6557]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7690,  0.9465,  1.0483,  1.0938,  1.1481],\n",
      "          [ 0.9358,  1.0939,  1.1597,  1.2051,  1.2759],\n",
      "          [ 1.0347,  1.1656,  1.1722,  1.1857,  1.1885],\n",
      "          [ 1.2247,  1.4164,  1.4685,  1.4979,  1.5173]],\n",
      "\n",
      "         [[-0.7691, -0.9466, -1.0483, -1.0938, -1.1481],\n",
      "          [-0.9358, -1.0938, -1.1597, -1.2051, -1.2759],\n",
      "          [-1.0347, -1.1656, -1.1722, -1.1856, -1.1884],\n",
      "          [-1.2247, -1.4164, -1.4685, -1.4979, -1.5173]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1607,  0.1631,  0.1970,  0.4179,  0.6135],\n",
      "          [ 0.1332,  0.1200,  0.0136,  0.1684,  0.3157],\n",
      "          [-0.0106, -0.0458, -0.1515, -0.0058,  0.1300],\n",
      "          [ 0.0296,  0.0477, -0.0522,  0.0180,  0.0615]],\n",
      "\n",
      "         [[-0.1608, -0.1632, -0.1971, -0.4180, -0.6135],\n",
      "          [-0.1333, -0.1200, -0.0136, -0.1684, -0.3156],\n",
      "          [ 0.0105,  0.0458,  0.1515,  0.0059, -0.1300],\n",
      "          [-0.0296, -0.0476,  0.0523, -0.0179, -0.0614]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 1 1 1 0]\n",
      " [0 0 1 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7853,  0.9792,  1.1548,  1.2612,  1.3439],\n",
      "          [ 0.9832,  1.1682,  1.3099,  1.4454,  1.5470],\n",
      "          [ 1.1169,  1.3126,  1.4611,  1.6033,  1.6969],\n",
      "          [ 1.2227,  1.4533,  1.6051,  1.7222,  1.7923]],\n",
      "\n",
      "         [[-0.7853, -0.9792, -1.1548, -1.2612, -1.3439],\n",
      "          [-0.9832, -1.1681, -1.3098, -1.4453, -1.5469],\n",
      "          [-1.1169, -1.3125, -1.4610, -1.6032, -1.6967],\n",
      "          [-1.2227, -1.4532, -1.6050, -1.7221, -1.7922]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.2292, -0.4373, -0.6186, -0.6961, -0.7035],\n",
      "          [-0.3536, -0.5223, -0.7226, -0.8115, -0.8142],\n",
      "          [-0.4786, -0.6280, -0.7679, -0.8393, -0.8615],\n",
      "          [-0.5055, -0.6431, -0.7312, -0.7777, -0.7554]],\n",
      "\n",
      "         [[ 0.2292,  0.4373,  0.6187,  0.6961,  0.7035],\n",
      "          [ 0.3536,  0.5225,  0.7227,  0.8116,  0.8143],\n",
      "          [ 0.4786,  0.6281,  0.7681,  0.8395,  0.8616],\n",
      "          [ 0.5055,  0.6432,  0.7314,  0.7778,  0.7555]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8288,  1.0358,  1.2433,  1.3878,  1.5355],\n",
      "          [ 1.0422,  1.2299,  1.3834,  1.5170,  1.6907],\n",
      "          [ 1.2108,  1.4320,  1.5903,  1.6990,  1.8558],\n",
      "          [ 1.1912,  1.3940,  1.5268,  1.5859,  1.6888]],\n",
      "\n",
      "         [[-0.8289, -1.0358, -1.2433, -1.3878, -1.5355],\n",
      "          [-1.0422, -1.2298, -1.3833, -1.5169, -1.6906],\n",
      "          [-1.2108, -1.4318, -1.5901, -1.6989, -1.8557],\n",
      "          [-1.1912, -1.3939, -1.5266, -1.5858, -1.6887]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2464,  0.2553,  0.1907,  0.1927,  0.2124],\n",
      "          [ 0.2940,  0.3591,  0.2355,  0.2492,  0.2882],\n",
      "          [ 0.2859,  0.3918,  0.2874,  0.3277,  0.3793],\n",
      "          [ 0.2718,  0.3795,  0.3158,  0.3715,  0.4197]],\n",
      "\n",
      "         [[-0.2465, -0.2554, -0.1907, -0.1927, -0.2124],\n",
      "          [-0.2940, -0.3590, -0.2355, -0.2492, -0.2881],\n",
      "          [-0.2859, -0.3917, -0.2873, -0.3276, -0.3792],\n",
      "          [-0.2718, -0.3794, -0.3158, -0.3715, -0.4197]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1099,  1.4297,  1.6689,  1.7467,  1.7678],\n",
      "          [ 1.3278,  1.5624,  1.7451,  1.8104,  1.8278],\n",
      "          [ 1.4622,  1.6053,  1.7555,  1.8397,  1.8902],\n",
      "          [ 1.5966,  1.7409,  1.8823,  1.9627,  2.0382]],\n",
      "\n",
      "         [[-1.1099, -1.4297, -1.6689, -1.7466, -1.7677],\n",
      "          [-1.3278, -1.5622, -1.7450, -1.8102, -1.8277],\n",
      "          [-1.4621, -1.6052, -1.7553, -1.8395, -1.8901],\n",
      "          [-1.5966, -1.7408, -1.8821, -1.9625, -2.0380]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1412,  1.3717,  1.6230,  1.8244,  1.9118],\n",
      "          [ 1.4364,  1.5563,  1.7511,  2.0078,  2.1437],\n",
      "          [ 1.5738,  1.6826,  1.8943,  2.2021,  2.3596],\n",
      "          [ 1.5674,  1.7239,  1.9374,  2.2067,  2.3286]],\n",
      "\n",
      "         [[-1.1412, -1.3717, -1.6230, -1.8244, -1.9118],\n",
      "          [-1.4365, -1.5563, -1.7510, -2.0076, -2.1436],\n",
      "          [-1.5738, -1.6825, -1.8942, -2.2020, -2.3595],\n",
      "          [-1.5674, -1.7239, -1.9373, -2.2066, -2.3285]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8568,  1.0562,  1.1493,  1.1768,  1.1819],\n",
      "          [ 0.9277,  1.0253,  1.0283,  1.0756,  1.1230],\n",
      "          [ 0.9261,  0.9435,  0.9029,  0.9741,  1.0489],\n",
      "          [ 0.9419,  0.9830,  0.9530,  1.0298,  1.1047]],\n",
      "\n",
      "         [[-0.8569, -1.0562, -1.1493, -1.1768, -1.1819],\n",
      "          [-0.9277, -1.0252, -1.0282, -1.0755, -1.1230],\n",
      "          [-0.9261, -0.9434, -0.9028, -0.9740, -1.0488],\n",
      "          [-0.9419, -0.9829, -0.9529, -1.0297, -1.1046]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.2010, -0.1961, -0.2509, -0.2790, -0.2709],\n",
      "          [-0.2711, -0.1176, -0.1643, -0.2029, -0.2083],\n",
      "          [-0.4334, -0.3129, -0.3570, -0.3756, -0.3600],\n",
      "          [-0.4093, -0.2959, -0.3226, -0.3330, -0.3214]],\n",
      "\n",
      "         [[ 0.2009,  0.1960,  0.2509,  0.2790,  0.2709],\n",
      "          [ 0.2711,  0.1177,  0.1644,  0.2030,  0.2084],\n",
      "          [ 0.4334,  0.3129,  0.3571,  0.3756,  0.3601],\n",
      "          [ 0.4093,  0.2959,  0.3227,  0.3330,  0.3215]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7186,  0.9243,  1.1312,  1.3297,  1.4923],\n",
      "          [ 0.9764,  1.1464,  1.2754,  1.5169,  1.6964],\n",
      "          [ 1.1229,  1.2485,  1.3677,  1.7063,  1.8849],\n",
      "          [ 1.2796,  1.4431,  1.5781,  1.9967,  2.1938]],\n",
      "\n",
      "         [[-0.7186, -0.9243, -1.1312, -1.3297, -1.4923],\n",
      "          [-0.9764, -1.1463, -1.2754, -1.5169, -1.6963],\n",
      "          [-1.1230, -1.2484, -1.3676, -1.7062, -1.8848],\n",
      "          [-1.2797, -1.4430, -1.5781, -1.9966, -2.1936]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2479,  0.1224, -0.0738, -0.2458, -0.3823],\n",
      "          [ 0.1168, -0.0896, -0.3680, -0.5415, -0.6574],\n",
      "          [-0.1102, -0.3972, -0.7241, -0.8920, -1.0037],\n",
      "          [-0.1218, -0.3135, -0.5383, -0.6117, -0.6290]],\n",
      "\n",
      "         [[-0.2480, -0.1224,  0.0738,  0.2457,  0.3823],\n",
      "          [-0.1169,  0.0897,  0.3681,  0.5415,  0.6575],\n",
      "          [ 0.1102,  0.3973,  0.7242,  0.8921,  1.0038],\n",
      "          [ 0.1218,  0.3136,  0.5384,  0.6118,  0.6291]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 1 1 1]\n",
      " [0 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.0175,  0.0264,  0.0296,  0.0753,  0.1831],\n",
      "          [-0.0428,  0.0958,  0.1357,  0.2117,  0.2893],\n",
      "          [-0.1604,  0.0116,  0.1176,  0.2205,  0.2694],\n",
      "          [-0.1456,  0.0072,  0.1516,  0.2696,  0.3303]],\n",
      "\n",
      "         [[-0.0176, -0.0264, -0.0296, -0.0754, -0.1831],\n",
      "          [ 0.0428, -0.0958, -0.1356, -0.2117, -0.2893],\n",
      "          [ 0.1604, -0.0115, -0.1175, -0.2204, -0.2694],\n",
      "          [ 0.1456, -0.0071, -0.1515, -0.2696, -0.3303]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6980,  0.7769,  0.8004,  0.7184,  0.6558],\n",
      "          [ 0.7683,  0.7857,  0.7709,  0.6933,  0.6563],\n",
      "          [ 0.7849,  0.7645,  0.7519,  0.6949,  0.6955],\n",
      "          [ 0.7579,  0.7161,  0.6848,  0.6094,  0.6051]],\n",
      "\n",
      "         [[-0.6980, -0.7769, -0.8004, -0.7184, -0.6557],\n",
      "          [-0.7683, -0.7856, -0.7707, -0.6932, -0.6561],\n",
      "          [-0.7849, -0.7643, -0.7517, -0.6947, -0.6954],\n",
      "          [-0.7579, -0.7160, -0.6846, -0.6093, -0.6049]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4205,  0.4381,  0.4772,  0.4558,  0.4431],\n",
      "          [ 0.3447,  0.3202,  0.3213,  0.2777,  0.2569],\n",
      "          [ 0.1993,  0.1757,  0.1703,  0.1053,  0.0689],\n",
      "          [-0.0243, -0.0472, -0.0799, -0.1739, -0.2269]],\n",
      "\n",
      "         [[-0.4206, -0.4381, -0.4772, -0.4558, -0.4431],\n",
      "          [-0.3448, -0.3201, -0.3213, -0.2777, -0.2569],\n",
      "          [-0.1994, -0.1757, -0.1702, -0.1052, -0.0689],\n",
      "          [ 0.0243,  0.0472,  0.0800,  0.1740,  0.2269]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7065,  0.8464,  0.9156,  0.9903,  1.0589],\n",
      "          [ 0.8564,  1.0024,  1.0672,  1.1983,  1.2878],\n",
      "          [ 1.0092,  1.1717,  1.2422,  1.4098,  1.4996],\n",
      "          [ 1.1620,  1.3560,  1.4360,  1.6259,  1.7578]],\n",
      "\n",
      "         [[-0.7066, -0.8464, -0.9156, -0.9904, -1.0589],\n",
      "          [-0.8565, -1.0024, -1.0672, -1.1983, -1.2878],\n",
      "          [-1.0093, -1.1716, -1.2422, -1.4097, -1.4996],\n",
      "          [-1.1620, -1.3560, -1.4360, -1.6258, -1.7578]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2846,  0.2325,  0.1876,  0.2369,  0.2528],\n",
      "          [ 0.2043,  0.0664, -0.0333,  0.0868,  0.1315],\n",
      "          [ 0.0930, -0.1058, -0.1979, -0.0605, -0.0123],\n",
      "          [ 0.0116, -0.1661, -0.2127, -0.0606,  0.0229]],\n",
      "\n",
      "         [[-0.2846, -0.2325, -0.1876, -0.2370, -0.2528],\n",
      "          [-0.2044, -0.0664,  0.0334, -0.0868, -0.1315],\n",
      "          [-0.0930,  0.1059,  0.1980,  0.0606,  0.0124],\n",
      "          [-0.0116,  0.1662,  0.2128,  0.0607, -0.0229]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 1 1 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2084,  1.5218,  1.7365,  1.8352,  1.9019],\n",
      "          [ 1.5005,  1.7541,  1.9217,  2.0521,  2.1778],\n",
      "          [ 1.7654,  2.0207,  2.1882,  2.3035,  2.4280],\n",
      "          [ 1.8758,  2.1094,  2.3002,  2.4101,  2.5326]],\n",
      "\n",
      "         [[-1.2085, -1.5217, -1.7365, -1.8352, -1.9018],\n",
      "          [-1.5005, -1.7539, -1.9216, -2.0520, -2.1777],\n",
      "          [-1.7653, -2.0206, -2.1880, -2.3033, -2.4278],\n",
      "          [-1.8758, -2.1093, -2.3000, -2.4099, -2.5324]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9151,  1.1511,  1.3343,  1.3768,  1.3917],\n",
      "          [ 1.0752,  1.2859,  1.4821,  1.5672,  1.6244],\n",
      "          [ 1.1867,  1.4146,  1.6533,  1.7750,  1.8607],\n",
      "          [ 1.2401,  1.5017,  1.7644,  1.8857,  1.9842]],\n",
      "\n",
      "         [[-0.9151, -1.1511, -1.3343, -1.3768, -1.3917],\n",
      "          [-1.0752, -1.2858, -1.4820, -1.5671, -1.6244],\n",
      "          [-1.1867, -1.4145, -1.6531, -1.7749, -1.8606],\n",
      "          [-1.2401, -1.5016, -1.7642, -1.8856, -1.9841]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5766,  0.7204,  0.8731,  0.9534,  1.0701],\n",
      "          [ 0.6997,  0.8675,  1.0341,  1.1083,  1.2233],\n",
      "          [ 0.8117,  1.0121,  1.2090,  1.2838,  1.3884],\n",
      "          [ 0.8843,  1.0903,  1.2888,  1.3424,  1.4493]],\n",
      "\n",
      "         [[-0.5766, -0.7203, -0.8731, -0.9533, -1.0701],\n",
      "          [-0.6997, -0.8673, -1.0339, -1.1082, -1.2231],\n",
      "          [-0.8117, -1.0119, -1.2088, -1.2836, -1.3882],\n",
      "          [-0.8842, -1.0901, -1.2886, -1.3422, -1.4491]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6730,  0.7767,  0.8689,  0.7941,  0.7072],\n",
      "          [ 0.7882,  0.8566,  0.9231,  0.8123,  0.7095],\n",
      "          [ 0.8392,  0.8773,  0.9406,  0.8190,  0.7143],\n",
      "          [ 0.9092,  0.9555,  1.0227,  0.8879,  0.7685]],\n",
      "\n",
      "         [[-0.6730, -0.7767, -0.8689, -0.7941, -0.7072],\n",
      "          [-0.7882, -0.8565, -0.9230, -0.8123, -0.7095],\n",
      "          [-0.8392, -0.8772, -0.9405, -0.8189, -0.7143],\n",
      "          [-0.9092, -0.9554, -1.0226, -0.8879, -0.7684]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1025,  1.4166,  1.6824,  1.9201,  2.1453],\n",
      "          [ 1.3590,  1.6323,  1.8185,  2.0935,  2.3448],\n",
      "          [ 1.5195,  1.7710,  1.9317,  2.2127,  2.4982],\n",
      "          [ 1.6578,  1.9932,  2.1952,  2.5082,  2.7933]],\n",
      "\n",
      "         [[-1.1025, -1.4165, -1.6824, -1.9200, -2.1453],\n",
      "          [-1.3590, -1.6322, -1.8183, -2.0933, -2.3446],\n",
      "          [-1.5195, -1.7708, -1.9315, -2.2125, -2.4981],\n",
      "          [-1.6578, -1.9931, -2.1951, -2.5081, -2.7931]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9688,  2.5457,  2.9948,  3.1422,  3.2461],\n",
      "          [ 2.5253,  2.8358,  3.3782,  3.5630,  3.7316],\n",
      "          [ 2.9360,  3.3108,  3.9667,  4.2267,  4.4768],\n",
      "          [ 3.0833,  3.5197,  4.1975,  4.4616,  4.7175]],\n",
      "\n",
      "         [[-1.9688, -2.5456, -2.9946, -3.1419, -3.2459],\n",
      "          [-2.5252, -2.8355, -3.3779, -3.5626, -3.7312],\n",
      "          [-2.9358, -3.3105, -3.9663, -4.2263, -4.4764],\n",
      "          [-3.0831, -3.5194, -4.1971, -4.4612, -4.7171]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 2.2621,  2.9275,  3.4759,  3.7848,  4.0369],\n",
      "          [ 2.8897,  3.1103,  3.7658,  4.2544,  4.6900],\n",
      "          [ 3.4391,  3.8373,  4.6618,  5.2787,  5.7999],\n",
      "          [ 3.6926,  4.2350,  5.1495,  5.7837,  6.1948]],\n",
      "\n",
      "         [[-2.2621, -2.9273, -3.4756, -3.7845, -4.0366],\n",
      "          [-2.8895, -3.1099, -3.7654, -4.2539, -4.6895],\n",
      "          [-3.4389, -3.8369, -4.6613, -5.2782, -5.7993],\n",
      "          [-3.6924, -4.2346, -5.1490, -5.7831, -6.1941]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3382,  1.6896,  1.9850,  2.1119,  2.2380],\n",
      "          [ 1.7641,  2.0511,  2.3104,  2.4460,  2.6079],\n",
      "          [ 2.0415,  2.3017,  2.6037,  2.7989,  3.0217],\n",
      "          [ 2.2237,  2.5199,  2.8601,  3.0458,  3.2538]],\n",
      "\n",
      "         [[-1.3382, -1.6896, -1.9849, -2.1119, -2.2379],\n",
      "          [-1.7640, -2.0509, -2.3102, -2.4458, -2.6077],\n",
      "          [-2.0414, -2.3016, -2.6035, -2.7986, -3.0214],\n",
      "          [-2.2236, -2.5197, -2.8599, -3.0456, -3.2535]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7606,  0.9304,  0.9930,  0.8938,  0.7764],\n",
      "          [ 0.9232,  1.1017,  1.1455,  1.0014,  0.8299],\n",
      "          [ 0.9934,  1.1686,  1.2386,  1.1210,  0.9573],\n",
      "          [ 1.0109,  1.1686,  1.2251,  1.1582,  1.0437]],\n",
      "\n",
      "         [[-0.7606, -0.9304, -0.9930, -0.8938, -0.7764],\n",
      "          [-0.9233, -1.1016, -1.1454, -1.0013, -0.8298],\n",
      "          [-0.9934, -1.1686, -1.2385, -1.1209, -0.9572],\n",
      "          [-1.0109, -1.1685, -1.2250, -1.1581, -1.0436]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2827,  1.4745,  1.5648,  1.5238,  1.4905],\n",
      "          [ 1.4164,  1.3988,  1.3200,  1.2627,  1.2621],\n",
      "          [ 1.4435,  1.3533,  1.1936,  1.1471,  1.1880],\n",
      "          [ 1.5450,  1.5901,  1.4629,  1.4003,  1.4212]],\n",
      "\n",
      "         [[-1.2828, -1.4745, -1.5647, -1.5237, -1.4905],\n",
      "          [-1.4163, -1.3986, -1.3199, -1.2625, -1.2619],\n",
      "          [-1.4435, -1.3531, -1.1934, -1.1469, -1.1878],\n",
      "          [-1.5450, -1.5899, -1.4627, -1.4002, -1.4210]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8762,  1.0739,  1.2114,  1.2987,  1.3413],\n",
      "          [ 1.0426,  1.1665,  1.2530,  1.3827,  1.4557],\n",
      "          [ 1.1464,  1.2109,  1.3164,  1.4847,  1.5926],\n",
      "          [ 1.2840,  1.3735,  1.5234,  1.7027,  1.8285]],\n",
      "\n",
      "         [[-0.8763, -1.0739, -1.2114, -1.2987, -1.3413],\n",
      "          [-1.0426, -1.1664, -1.2529, -1.3826, -1.4556],\n",
      "          [-1.1464, -1.2108, -1.3162, -1.4846, -1.5925],\n",
      "          [-1.2841, -1.3734, -1.5233, -1.7026, -1.8284]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0088,  1.2627,  1.4745,  1.5214,  1.5018],\n",
      "          [ 1.2491,  1.4256,  1.5574,  1.6302,  1.5474],\n",
      "          [ 1.2960,  1.4270,  1.5348,  1.6140,  1.5469],\n",
      "          [ 1.2545,  1.4393,  1.5624,  1.6726,  1.6937]],\n",
      "\n",
      "         [[-1.0089, -1.2627, -1.4745, -1.5214, -1.5018],\n",
      "          [-1.2491, -1.4255, -1.5573, -1.6300, -1.5473],\n",
      "          [-1.2960, -1.4269, -1.5347, -1.6138, -1.5467],\n",
      "          [-1.2545, -1.4392, -1.5622, -1.6725, -1.6936]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3371,  0.3868,  0.3950,  0.3628,  0.3605],\n",
      "          [ 0.4087,  0.4687,  0.4438,  0.4513,  0.4791],\n",
      "          [ 0.4739,  0.4793,  0.4437,  0.5188,  0.5549],\n",
      "          [ 0.7365,  0.7910,  0.7723,  0.9385,  1.0409]],\n",
      "\n",
      "         [[-0.3371, -0.3869, -0.3951, -0.3628, -0.3606],\n",
      "          [-0.4087, -0.4687, -0.4438, -0.4513, -0.4791],\n",
      "          [-0.4740, -0.4792, -0.4436, -0.5187, -0.5549],\n",
      "          [-0.7366, -0.7909, -0.7722, -0.9385, -1.0409]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2274,  1.4807,  1.6714,  1.7572,  1.8512],\n",
      "          [ 1.4782,  1.6137,  1.7496,  1.8759,  2.0352],\n",
      "          [ 1.6778,  1.7842,  1.9179,  2.0556,  2.2387],\n",
      "          [ 1.7877,  1.9271,  2.0868,  2.2150,  2.4086]],\n",
      "\n",
      "         [[-1.2275, -1.4807, -1.6714, -1.7571, -1.8511],\n",
      "          [-1.4782, -1.6136, -1.7495, -1.8757, -2.0351],\n",
      "          [-1.6777, -1.7840, -1.9177, -2.0554, -2.2385],\n",
      "          [-1.7877, -1.9270, -2.0866, -2.2148, -2.4084]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4177,  0.4222,  0.4553,  0.3803,  0.2706],\n",
      "          [ 0.4735,  0.4517,  0.4856,  0.4174,  0.3055],\n",
      "          [ 0.5397,  0.5511,  0.6525,  0.6249,  0.5298],\n",
      "          [ 0.5493,  0.5727,  0.6786,  0.6517,  0.5463]],\n",
      "\n",
      "         [[-0.4177, -0.4222, -0.4553, -0.3804, -0.2706],\n",
      "          [-0.4735, -0.4516, -0.4855, -0.4173, -0.3055],\n",
      "          [-0.5397, -0.5511, -0.6524, -0.6248, -0.5298],\n",
      "          [-0.5494, -0.5727, -0.6786, -0.6516, -0.5462]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3253,  0.3524,  0.3988,  0.4151,  0.4671],\n",
      "          [ 0.3691,  0.4215,  0.4738,  0.4816,  0.5268],\n",
      "          [ 0.4082,  0.4928,  0.5796,  0.5936,  0.6441],\n",
      "          [ 0.4073,  0.5101,  0.6317,  0.6529,  0.7152]],\n",
      "\n",
      "         [[-0.3254, -0.3524, -0.3988, -0.4151, -0.4671],\n",
      "          [-0.3691, -0.4214, -0.4737, -0.4815, -0.5266],\n",
      "          [-0.4082, -0.4926, -0.5794, -0.5934, -0.6439],\n",
      "          [-0.4073, -0.5100, -0.6315, -0.6527, -0.7150]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6646,  0.8312,  0.9498,  1.0181,  1.1176],\n",
      "          [ 0.8204,  1.0267,  1.1430,  1.2290,  1.3502],\n",
      "          [ 0.9529,  1.2084,  1.3292,  1.4159,  1.5430],\n",
      "          [ 1.0212,  1.2890,  1.3981,  1.4651,  1.5836]],\n",
      "\n",
      "         [[-0.6647, -0.8312, -0.9498, -1.0181, -1.1176],\n",
      "          [-0.8204, -1.0265, -1.1429, -1.2288, -1.3501],\n",
      "          [-0.9529, -1.2083, -1.3291, -1.4157, -1.5428],\n",
      "          [-1.0212, -1.2888, -1.3979, -1.4649, -1.5834]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2474,  1.6002,  1.8868,  2.0094,  2.1130],\n",
      "          [ 1.5600,  1.8623,  2.1295,  2.2483,  2.3407],\n",
      "          [ 1.8281,  2.1429,  2.4482,  2.5634,  2.6444],\n",
      "          [ 1.9567,  2.2810,  2.5996,  2.6955,  2.7636]],\n",
      "\n",
      "         [[-1.2475, -1.6002, -1.8867, -2.0093, -2.1130],\n",
      "          [-1.5600, -1.8622, -2.1293, -2.2481, -2.3406],\n",
      "          [-1.8280, -2.1428, -2.4479, -2.5632, -2.6442],\n",
      "          [-1.9567, -2.2809, -2.5994, -2.6953, -2.7634]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8547,  1.0041,  1.0482,  1.1039,  1.1680],\n",
      "          [ 1.0335,  1.1199,  1.0988,  1.1909,  1.2985],\n",
      "          [ 1.1517,  1.2133,  1.1641,  1.2786,  1.3799],\n",
      "          [ 1.2431,  1.3738,  1.3801,  1.5352,  1.6174]],\n",
      "\n",
      "         [[-0.8548, -1.0041, -1.0482, -1.1039, -1.1680],\n",
      "          [-1.0335, -1.1198, -1.0987, -1.1908, -1.2984],\n",
      "          [-1.1517, -1.2132, -1.1640, -1.2785, -1.3798],\n",
      "          [-1.2431, -1.3737, -1.3800, -1.5352, -1.6173]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9962,  1.2276,  1.3844,  1.4852,  1.5730],\n",
      "          [ 1.2354,  1.4226,  1.5115,  1.6415,  1.7470],\n",
      "          [ 1.3771,  1.5442,  1.5965,  1.7351,  1.8368],\n",
      "          [ 1.4625,  1.6558,  1.6931,  1.8290,  1.9272]],\n",
      "\n",
      "         [[-0.9963, -1.2276, -1.3844, -1.4852, -1.5730],\n",
      "          [-1.2354, -1.4226, -1.5115, -1.6415, -1.7469],\n",
      "          [-1.3771, -1.5441, -1.5964, -1.7350, -1.8367],\n",
      "          [-1.4625, -1.6558, -1.6930, -1.8289, -1.9271]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.4065,  1.7802,  2.1077,  2.3322,  2.4532],\n",
      "          [ 1.7562,  2.0223,  2.2795,  2.5302,  2.7532],\n",
      "          [ 1.9830,  2.1936,  2.4442,  2.7512,  3.0293],\n",
      "          [ 2.1438,  2.3876,  2.6795,  3.0189,  3.3058]],\n",
      "\n",
      "         [[-1.4065, -1.7802, -2.1077, -2.3321, -2.4531],\n",
      "          [-1.7561, -2.0222, -2.2793, -2.5301, -2.7530],\n",
      "          [-1.9830, -2.1935, -2.4440, -2.7510, -3.0290],\n",
      "          [-2.1438, -2.3874, -2.6793, -3.0186, -3.3055]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1088,  1.3210,  1.5173,  1.5941,  1.6591],\n",
      "          [ 1.3033,  1.3622,  1.5365,  1.6706,  1.8074],\n",
      "          [ 1.4965,  1.4945,  1.6760,  1.8474,  2.0403],\n",
      "          [ 1.6808,  1.7105,  1.9087,  2.0704,  2.2659]],\n",
      "\n",
      "         [[-1.1089, -1.3210, -1.5172, -1.5940, -1.6591],\n",
      "          [-1.3033, -1.3622, -1.5364, -1.6705, -1.8073],\n",
      "          [-1.4965, -1.4943, -1.6759, -1.8472, -2.0402],\n",
      "          [-1.6808, -1.7104, -1.9085, -2.0703, -2.2657]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2029,  1.4993,  1.7367,  1.9019,  1.9540],\n",
      "          [ 1.5099,  1.7397,  1.9441,  2.1311,  2.1992],\n",
      "          [ 1.6993,  1.9264,  2.1472,  2.2642,  2.3087],\n",
      "          [ 1.8013,  2.1097,  2.3522,  2.4146,  2.4398]],\n",
      "\n",
      "         [[-1.2030, -1.4993, -1.7367, -1.9019, -1.9540],\n",
      "          [-1.5100, -1.7397, -1.9440, -2.1310, -2.1991],\n",
      "          [-1.6993, -1.9263, -2.1471, -2.2640, -2.3085],\n",
      "          [-1.8013, -2.1097, -2.3520, -2.4144, -2.4397]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.6564,  2.1215,  2.5244,  2.7018,  2.8447],\n",
      "          [ 2.0741,  2.4099,  2.8628,  3.1202,  3.3619],\n",
      "          [ 2.4309,  2.7766,  3.3283,  3.6711,  3.9959],\n",
      "          [ 2.5750,  2.9794,  3.5776,  3.9449,  4.2584]],\n",
      "\n",
      "         [[-1.6565, -2.1214, -2.5243, -2.7017, -2.8446],\n",
      "          [-2.0741, -2.4098, -2.8625, -3.1199, -3.3616],\n",
      "          [-2.4308, -2.7764, -3.3280, -3.6708, -3.9955],\n",
      "          [-2.5749, -2.9792, -3.5773, -3.9445, -4.2581]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0755,  1.3147,  1.5020,  1.6190,  1.7381],\n",
      "          [ 1.2928,  1.4137,  1.4989,  1.5871,  1.7194],\n",
      "          [ 1.4083,  1.4614,  1.5031,  1.6151,  1.7826],\n",
      "          [ 1.4053,  1.4586,  1.5061,  1.7004,  1.9515]],\n",
      "\n",
      "         [[-1.0756, -1.3146, -1.5019, -1.6189, -1.7380],\n",
      "          [-1.2928, -1.4136, -1.4987, -1.5870, -1.7192],\n",
      "          [-1.4083, -1.4613, -1.5029, -1.6149, -1.7824],\n",
      "          [-1.4053, -1.4585, -1.5059, -1.7002, -1.9514]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8806,  1.0888,  1.2228,  1.3657,  1.4752],\n",
      "          [ 1.0770,  1.2368,  1.3193,  1.4905,  1.6489],\n",
      "          [ 1.1927,  1.3132,  1.3617,  1.5341,  1.7104],\n",
      "          [ 1.2728,  1.3899,  1.4657,  1.6141,  1.7589]],\n",
      "\n",
      "         [[-0.8807, -1.0888, -1.2228, -1.3657, -1.4752],\n",
      "          [-1.0770, -1.2367, -1.3192, -1.4904, -1.6488],\n",
      "          [-1.1927, -1.3132, -1.3616, -1.5340, -1.7104],\n",
      "          [-1.2728, -1.3898, -1.4656, -1.6140, -1.7588]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4183,  0.4153,  0.4026,  0.5545,  0.7614],\n",
      "          [ 0.4008,  0.3272,  0.2807,  0.5177,  0.8269],\n",
      "          [ 0.3211,  0.1840,  0.1792,  0.4599,  0.8131],\n",
      "          [ 0.3311,  0.2070,  0.2351,  0.4918,  0.8138]],\n",
      "\n",
      "         [[-0.4183, -0.4153, -0.4026, -0.5546, -0.7615],\n",
      "          [-0.4008, -0.3271, -0.2806, -0.5177, -0.8269],\n",
      "          [-0.3211, -0.1840, -0.1792, -0.4599, -0.8131],\n",
      "          [-0.3311, -0.2070, -0.2350, -0.4918, -0.8138]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3706,  0.4000,  0.4035,  0.4528,  0.5329],\n",
      "          [ 0.5364,  0.6279,  0.5886,  0.6284,  0.7180],\n",
      "          [ 0.6910,  0.8268,  0.7967,  0.7990,  0.8645],\n",
      "          [ 0.7490,  0.8361,  0.7594,  0.7206,  0.7721]],\n",
      "\n",
      "         [[-0.3707, -0.4000, -0.4035, -0.4528, -0.5329],\n",
      "          [-0.5364, -0.6278, -0.5885, -0.6283, -0.7179],\n",
      "          [-0.6910, -0.8267, -0.7966, -0.7989, -0.8644],\n",
      "          [-0.7490, -0.8361, -0.7593, -0.7205, -0.7721]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1207,  1.2701,  1.4197,  1.3536,  1.1950],\n",
      "          [ 1.3005,  1.2456,  1.3714,  1.3981,  1.2933],\n",
      "          [ 1.4232,  1.2618,  1.3936,  1.4373,  1.3487],\n",
      "          [ 1.5421,  1.4400,  1.5990,  1.6584,  1.5834]],\n",
      "\n",
      "         [[-1.1208, -1.2701, -1.4197, -1.3537, -1.1950],\n",
      "          [-1.3005, -1.2456, -1.3713, -1.3980, -1.2933],\n",
      "          [-1.4232, -1.2617, -1.3935, -1.4372, -1.3487],\n",
      "          [-1.5421, -1.4399, -1.5988, -1.6583, -1.5833]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3237,  1.6097,  1.8682,  1.9638,  1.9673],\n",
      "          [ 1.6966,  1.8934,  2.1220,  2.2598,  2.2890],\n",
      "          [ 1.9482,  2.1512,  2.4088,  2.5907,  2.6859],\n",
      "          [ 2.1174,  2.3848,  2.6754,  2.8599,  3.0156]],\n",
      "\n",
      "         [[-1.3238, -1.6097, -1.8681, -1.9638, -1.9672],\n",
      "          [-1.6965, -1.8932, -2.1219, -2.2596, -2.2888],\n",
      "          [-1.9482, -2.1510, -2.4086, -2.5906, -2.6857],\n",
      "          [-2.1173, -2.3847, -2.6752, -2.8597, -3.0154]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1589,  1.4180,  1.5960,  1.6783,  1.7731],\n",
      "          [ 1.4431,  1.6315,  1.7556,  1.8829,  2.0399],\n",
      "          [ 1.6398,  1.8242,  1.9666,  2.1511,  2.3608],\n",
      "          [ 1.7747,  1.9766,  2.1572,  2.3503,  2.5899]],\n",
      "\n",
      "         [[-1.1589, -1.4180, -1.5960, -1.6783, -1.7731],\n",
      "          [-1.4431, -1.6314, -1.7555, -1.8828, -2.0397],\n",
      "          [-1.6398, -1.8241, -1.9664, -2.1509, -2.3606],\n",
      "          [-1.7747, -1.9765, -2.1571, -2.3501, -2.5897]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9956,  1.2476,  1.4746,  1.6137,  1.7118],\n",
      "          [ 1.2755,  1.4880,  1.6881,  1.8739,  2.0291],\n",
      "          [ 1.4321,  1.6161,  1.7868,  2.0208,  2.2220],\n",
      "          [ 1.5352,  1.7441,  1.9039,  2.1361,  2.3221]],\n",
      "\n",
      "         [[-0.9957, -1.2476, -1.4746, -1.6137, -1.7119],\n",
      "          [-1.2756, -1.4879, -1.6880, -1.8738, -2.0290],\n",
      "          [-1.4322, -1.6160, -1.7867, -2.0207, -2.2219],\n",
      "          [-1.5352, -1.7441, -1.9038, -2.1360, -2.3220]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1202,  1.3858,  1.6052,  1.7374,  1.7739],\n",
      "          [ 1.4130,  1.5932,  1.7573,  1.9431,  2.0404],\n",
      "          [ 1.5843,  1.7372,  1.9012,  2.1078,  2.2350],\n",
      "          [ 1.6792,  1.8794,  2.0351,  2.2107,  2.3437]],\n",
      "\n",
      "         [[-1.1202, -1.3858, -1.6052, -1.7374, -1.7739],\n",
      "          [-1.4130, -1.5931, -1.7572, -1.9430, -2.0403],\n",
      "          [-1.5843, -1.7371, -1.9010, -2.1077, -2.2349],\n",
      "          [-1.6792, -1.8793, -2.0350, -2.2105, -2.3435]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9801,  1.2104,  1.3952,  1.5000,  1.5803],\n",
      "          [ 1.2270,  1.4030,  1.5437,  1.6941,  1.8146],\n",
      "          [ 1.3785,  1.5355,  1.6618,  1.8367,  1.9729],\n",
      "          [ 1.4972,  1.7100,  1.8522,  2.0278,  2.1517]],\n",
      "\n",
      "         [[-0.9802, -1.2104, -1.3952, -1.5000, -1.5803],\n",
      "          [-1.2270, -1.4030, -1.5436, -1.6940, -1.8145],\n",
      "          [-1.3785, -1.5354, -1.6617, -1.8366, -1.9728],\n",
      "          [-1.4972, -1.7099, -1.8521, -2.0277, -2.1516]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8866,  2.4347,  2.9016,  3.1355,  3.3290],\n",
      "          [ 2.3964,  2.7228,  3.3032,  3.6597,  3.9845],\n",
      "          [ 2.8286,  3.2685,  4.0017,  4.4744,  4.8237],\n",
      "          [ 3.0262,  3.5640,  4.3654,  4.8206,  5.1792]],\n",
      "\n",
      "         [[-1.8866, -2.4346, -2.9015, -3.1353, -3.3287],\n",
      "          [-2.3963, -2.7225, -3.3029, -3.6593, -3.9841],\n",
      "          [-2.8285, -3.2682, -4.0013, -4.4740, -4.8232],\n",
      "          [-3.0260, -3.5637, -4.3650, -4.8201, -5.1787]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1512,  1.4170,  1.5979,  1.7017,  1.7608],\n",
      "          [ 1.4134,  1.5932,  1.6777,  1.8375,  1.9417],\n",
      "          [ 1.6022,  1.7195,  1.7238,  1.8893,  1.9987],\n",
      "          [ 1.7194,  1.8345,  1.7893,  1.9386,  2.0438]],\n",
      "\n",
      "         [[-1.1513, -1.4169, -1.5979, -1.7017, -1.7607],\n",
      "          [-1.4134, -1.5931, -1.6776, -1.8373, -1.9415],\n",
      "          [-1.6022, -1.7193, -1.7236, -1.8892, -1.9985],\n",
      "          [-1.7194, -1.8343, -1.7891, -1.9384, -2.0437]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5905,  0.6149,  0.5761,  0.5806,  0.6263],\n",
      "          [ 0.6935,  0.6622,  0.5360,  0.5277,  0.5868],\n",
      "          [ 0.7013,  0.6453,  0.5070,  0.4760,  0.5268],\n",
      "          [ 0.7189,  0.6845,  0.5630,  0.5088,  0.5418]],\n",
      "\n",
      "         [[-0.5906, -0.6150, -0.5761, -0.5806, -0.6263],\n",
      "          [-0.6936, -0.6622, -0.5359, -0.5276, -0.5867],\n",
      "          [-0.7013, -0.6452, -0.5069, -0.4759, -0.5267],\n",
      "          [-0.7189, -0.6844, -0.5629, -0.5087, -0.5417]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9914,  1.1811,  1.2737,  1.2930,  1.3230],\n",
      "          [ 1.1506,  1.2437,  1.3039,  1.3503,  1.4227],\n",
      "          [ 1.2075,  1.2215,  1.2774,  1.3226,  1.4155],\n",
      "          [ 1.2211,  1.2410,  1.3165,  1.3122,  1.3351]],\n",
      "\n",
      "         [[-0.9914, -1.1811, -1.2737, -1.2930, -1.3230],\n",
      "          [-1.1506, -1.2436, -1.3038, -1.3502, -1.4226],\n",
      "          [-1.2075, -1.2214, -1.2772, -1.3225, -1.4154],\n",
      "          [-1.2211, -1.2409, -1.3164, -1.3121, -1.3350]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2336,  0.2536,  0.2677,  0.2849,  0.3357],\n",
      "          [ 0.1865,  0.2179,  0.1774,  0.1737,  0.2088],\n",
      "          [ 0.0718,  0.0677,  0.0327,  0.0372,  0.0722],\n",
      "          [ 0.0050,  0.0232,  0.0223, -0.0075, -0.0318]],\n",
      "\n",
      "         [[-0.2336, -0.2536, -0.2677, -0.2849, -0.3357],\n",
      "          [-0.1865, -0.2178, -0.1773, -0.1736, -0.2087],\n",
      "          [-0.0718, -0.0676, -0.0326, -0.0371, -0.0721],\n",
      "          [-0.0050, -0.0231, -0.0222,  0.0076,  0.0319]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1301,  1.4069,  1.6308,  1.7624,  1.8623],\n",
      "          [ 1.3788,  1.5613,  1.7213,  1.9095,  2.0905],\n",
      "          [ 1.5024,  1.6071,  1.7308,  1.9876,  2.2442],\n",
      "          [ 1.5839,  1.7001,  1.8325,  2.1066,  2.3828]],\n",
      "\n",
      "         [[-1.1302, -1.4068, -1.6308, -1.7624, -1.8623],\n",
      "          [-1.3788, -1.5612, -1.7212, -1.9094, -2.0903],\n",
      "          [-1.5023, -1.6070, -1.7307, -1.9874, -2.2440],\n",
      "          [-1.5839, -1.7000, -1.8323, -2.1064, -2.3826]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2134,  1.4836,  1.6936,  1.6977,  1.5986],\n",
      "          [ 1.5446,  1.7255,  1.8655,  1.8872,  1.7834],\n",
      "          [ 1.7888,  1.9486,  2.1238,  2.1776,  2.0880],\n",
      "          [ 1.9382,  2.1198,  2.2806,  2.2876,  2.1627]],\n",
      "\n",
      "         [[-1.2135, -1.4836, -1.6936, -1.6977, -1.5986],\n",
      "          [-1.5446, -1.7254, -1.8654, -1.8871, -1.7833],\n",
      "          [-1.7888, -1.9485, -2.1237, -2.1775, -2.0879],\n",
      "          [-1.9382, -2.1197, -2.2804, -2.2874, -2.1625]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1276,  1.4235,  1.6754,  1.8178,  1.8939],\n",
      "          [ 1.4451,  1.6888,  1.9086,  2.0786,  2.1846],\n",
      "          [ 1.6424,  1.8831,  2.1226,  2.3220,  2.4418],\n",
      "          [ 1.7537,  2.0317,  2.2705,  2.4500,  2.5470]],\n",
      "\n",
      "         [[-1.1276, -1.4235, -1.6754, -1.8178, -1.8939],\n",
      "          [-1.4451, -1.6888, -1.9085, -2.0785, -2.1845],\n",
      "          [-1.6424, -1.8830, -2.1225, -2.3219, -2.4417],\n",
      "          [-1.7537, -2.0316, -2.2703, -2.4499, -2.5469]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 2.0669,  2.7048,  3.2091,  3.4699,  3.6783],\n",
      "          [ 2.6532,  2.9851,  3.6253,  3.9991,  4.3307],\n",
      "          [ 3.1182,  3.6090,  4.4278,  4.9231,  5.3138],\n",
      "          [ 3.3512,  3.9702,  4.8615,  5.3088,  5.6779]],\n",
      "\n",
      "         [[-2.0669, -2.7047, -3.2089, -3.4696, -3.6780],\n",
      "          [-2.6531, -2.9848, -3.6249, -3.9986, -4.3302],\n",
      "          [-3.1181, -3.6086, -4.4274, -4.9226, -5.3132],\n",
      "          [-3.3510, -3.9698, -4.8611, -5.3083, -5.6773]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4345,  0.4090,  0.3118,  0.1617,  0.0318],\n",
      "          [ 0.4143,  0.3294,  0.1974,  0.0832, -0.0060],\n",
      "          [ 0.3733,  0.2413,  0.1166,  0.0522,  0.0222],\n",
      "          [ 0.3988,  0.2610,  0.1311,  0.0511,  0.0198]],\n",
      "\n",
      "         [[-0.4346, -0.4090, -0.3118, -0.1617, -0.0318],\n",
      "          [-0.4143, -0.3294, -0.1973, -0.0831,  0.0061],\n",
      "          [-0.3733, -0.2412, -0.1165, -0.0521, -0.0221],\n",
      "          [-0.3988, -0.2609, -0.1309, -0.0510, -0.0197]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7183,  0.9180,  0.9635,  0.9413,  0.9128],\n",
      "          [ 0.7674,  0.8864,  0.8664,  0.8189,  0.7901],\n",
      "          [ 0.7361,  0.7892,  0.7523,  0.6547,  0.5586],\n",
      "          [ 0.9111,  1.0672,  1.1512,  1.0983,  1.0244]],\n",
      "\n",
      "         [[-0.7184, -0.9181, -0.9635, -0.9413, -0.9129],\n",
      "          [-0.7674, -0.8864, -0.8664, -0.8189, -0.7901],\n",
      "          [-0.7361, -0.7892, -0.7522, -0.6547, -0.5586],\n",
      "          [-0.9111, -1.0671, -1.1512, -1.0982, -1.0244]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2255,  1.5500,  1.8017,  1.8751,  1.9111],\n",
      "          [ 1.5142,  1.7752,  1.9812,  2.0526,  2.1118],\n",
      "          [ 1.6840,  1.9043,  2.0931,  2.1506,  2.2178],\n",
      "          [ 1.7461,  1.9551,  2.1166,  2.1013,  2.1339]],\n",
      "\n",
      "         [[-1.2256, -1.5500, -1.8017, -1.8750, -1.9110],\n",
      "          [-1.5142, -1.7751, -1.9811, -2.0525, -2.1117],\n",
      "          [-1.6840, -1.9042, -2.0930, -2.1504, -2.2177],\n",
      "          [-1.7461, -1.9550, -2.1164, -2.1012, -2.1338]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2279,  1.4706,  1.7123,  1.7752,  1.7475],\n",
      "          [ 1.5508,  1.6975,  1.9074,  2.0177,  1.9709],\n",
      "          [ 1.7677,  1.8658,  2.0921,  2.2032,  2.1673],\n",
      "          [ 1.9089,  2.0624,  2.2806,  2.3491,  2.2810]],\n",
      "\n",
      "         [[-1.2280, -1.4707, -1.7123, -1.7752, -1.7475],\n",
      "          [-1.5508, -1.6974, -1.9073, -2.0176, -1.9708],\n",
      "          [-1.7677, -1.8657, -2.0920, -2.2031, -2.1672],\n",
      "          [-1.9089, -2.0623, -2.2804, -2.3489, -2.2808]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.0835, -0.3125, -0.4631, -0.4757, -0.4611],\n",
      "          [-0.0520, -0.2399, -0.3713, -0.3283, -0.2992],\n",
      "          [ 0.0742, -0.0270, -0.0422,  0.0583,  0.1063],\n",
      "          [ 0.1390,  0.0373,  0.0399,  0.1382,  0.2250]],\n",
      "\n",
      "         [[ 0.0834,  0.3125,  0.4631,  0.4757,  0.4610],\n",
      "          [ 0.0519,  0.2399,  0.3713,  0.3283,  0.2992],\n",
      "          [-0.0743,  0.0270,  0.0422, -0.0582, -0.1063],\n",
      "          [-0.1391, -0.0373, -0.0399, -0.1382, -0.2250]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4508,  0.4556,  0.3781,  0.2781,  0.2374],\n",
      "          [ 0.5025,  0.4849,  0.3610,  0.2950,  0.3126],\n",
      "          [ 0.4596,  0.3996,  0.2741,  0.2322,  0.2504],\n",
      "          [ 0.4602,  0.4178,  0.3535,  0.3126,  0.3105]],\n",
      "\n",
      "         [[-0.4509, -0.4556, -0.3781, -0.2782, -0.2375],\n",
      "          [-0.5026, -0.4848, -0.3609, -0.2949, -0.3126],\n",
      "          [-0.4596, -0.3995, -0.2740, -0.2321, -0.2504],\n",
      "          [-0.4603, -0.4178, -0.3535, -0.3125, -0.3105]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3169,  1.6567,  1.9533,  2.1361,  2.1865],\n",
      "          [ 1.6264,  1.8359,  2.0692,  2.2934,  2.4154],\n",
      "          [ 1.8002,  1.9778,  2.2342,  2.4547,  2.5939],\n",
      "          [ 1.8453,  2.0373,  2.2776,  2.4595,  2.5945]],\n",
      "\n",
      "         [[-1.3170, -1.6567, -1.9532, -2.1361, -2.1864],\n",
      "          [-1.6264, -1.8358, -2.0690, -2.2932, -2.4153],\n",
      "          [-1.8002, -1.9777, -2.2340, -2.4545, -2.5937],\n",
      "          [-1.8453, -2.0372, -2.2774, -2.4593, -2.5943]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6663,  0.7199,  0.7038,  0.7769,  0.8680],\n",
      "          [ 0.7993,  0.7584,  0.6470,  0.7895,  0.9156],\n",
      "          [ 0.9091,  0.8268,  0.6742,  0.8445,  0.9635],\n",
      "          [ 1.0217,  0.9781,  0.8265,  0.9834,  1.0941]],\n",
      "\n",
      "         [[-0.6663, -0.7199, -0.7039, -0.7770, -0.8681],\n",
      "          [-0.7994, -0.7584, -0.6469, -0.7895, -0.9156],\n",
      "          [-0.9092, -0.8267, -0.6741, -0.8444, -0.9634],\n",
      "          [-1.0217, -0.9780, -0.8264, -0.9834, -1.0941]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4654,  0.5814,  0.6380,  0.8773,  1.0837],\n",
      "          [ 0.5830,  0.7512,  0.7927,  1.1136,  1.3555],\n",
      "          [ 0.5812,  0.7440,  0.8054,  1.1821,  1.4177],\n",
      "          [ 0.6745,  0.7837,  0.8539,  1.2461,  1.4954]],\n",
      "\n",
      "         [[-0.4655, -0.5814, -0.6381, -0.8773, -1.0837],\n",
      "          [-0.5830, -0.7511, -0.7927, -1.1136, -1.3555],\n",
      "          [-0.5812, -0.7440, -0.8054, -1.1820, -1.4177],\n",
      "          [-0.6745, -0.7837, -0.8539, -1.2461, -1.4954]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9081,  1.1380,  1.2977,  1.4065,  1.4975],\n",
      "          [ 1.0551,  1.2350,  1.3662,  1.5197,  1.6471],\n",
      "          [ 1.1353,  1.2719,  1.3988,  1.5822,  1.7433],\n",
      "          [ 1.2760,  1.4418,  1.6111,  1.8188,  1.9831]],\n",
      "\n",
      "         [[-0.9082, -1.1380, -1.2977, -1.4065, -1.4976],\n",
      "          [-1.0551, -1.2350, -1.3661, -1.5196, -1.6471],\n",
      "          [-1.1353, -1.2718, -1.3987, -1.5821, -1.7432],\n",
      "          [-1.2760, -1.4418, -1.6110, -1.8187, -1.9830]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1813,  1.4716,  1.7236,  1.8632,  1.8697],\n",
      "          [ 1.4977,  1.6954,  1.8896,  2.0784,  2.1301],\n",
      "          [ 1.7165,  1.8768,  2.0659,  2.2599,  2.3386],\n",
      "          [ 1.8228,  2.0115,  2.1920,  2.3527,  2.4310]],\n",
      "\n",
      "         [[-1.1814, -1.4716, -1.7236, -1.8631, -1.8697],\n",
      "          [-1.4978, -1.6954, -1.8895, -2.0783, -2.1300],\n",
      "          [-1.7165, -1.8767, -2.0658, -2.2597, -2.3385],\n",
      "          [-1.8228, -2.0114, -2.1919, -2.3526, -2.4308]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8000,  2.2777,  2.7399,  2.9506,  3.1264],\n",
      "          [ 2.2519,  2.5543,  3.0905,  3.4142,  3.7146],\n",
      "          [ 2.6733,  3.0583,  3.7301,  4.1600,  4.5086],\n",
      "          [ 2.8422,  3.3221,  4.0532,  4.4879,  4.8027]],\n",
      "\n",
      "         [[-1.8000, -2.2776, -2.7398, -2.9504, -3.1262],\n",
      "          [-2.2518, -2.5541, -3.0902, -3.4139, -3.7142],\n",
      "          [-2.6732, -3.0580, -3.7298, -4.1596, -4.5082],\n",
      "          [-2.8420, -3.3219, -4.0529, -4.4875, -4.8022]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.0247, -0.0946, -0.2020, -0.3435, -0.4588],\n",
      "          [-0.0459, -0.0352, -0.1290, -0.2663, -0.3843],\n",
      "          [-0.0657, -0.0397, -0.1128, -0.2199, -0.3293],\n",
      "          [-0.0420, -0.0225, -0.0842, -0.1731, -0.2845]],\n",
      "\n",
      "         [[ 0.0246,  0.0946,  0.2020,  0.3434,  0.4588],\n",
      "          [ 0.0459,  0.0352,  0.1291,  0.2664,  0.3843],\n",
      "          [ 0.0656,  0.0397,  0.1129,  0.2199,  0.3293],\n",
      "          [ 0.0419,  0.0225,  0.0843,  0.1731,  0.2845]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 2.1300,  2.8061,  3.3490,  3.6398,  3.8378],\n",
      "          [ 2.7299,  3.0471,  3.7647,  4.2137,  4.5609],\n",
      "          [ 3.2327,  3.7306,  4.6466,  5.2411,  5.6220],\n",
      "          [ 3.4689,  4.0901,  5.0995,  5.6486,  6.0474]],\n",
      "\n",
      "         [[-2.1299, -2.8060, -3.3487, -3.6395, -3.8375],\n",
      "          [-2.7298, -3.0468, -3.7643, -4.2133, -4.5605],\n",
      "          [-3.2325, -3.7302, -4.6461, -5.2405, -5.6215],\n",
      "          [-3.4686, -4.0897, -5.0990, -5.6480, -6.0467]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.3459,  0.3654,  0.3654,  0.4169,  0.5016],\n",
      "          [ 0.3333,  0.3300,  0.2615,  0.3211,  0.4207],\n",
      "          [ 0.2503,  0.2451,  0.1860,  0.2831,  0.4059],\n",
      "          [ 0.1350,  0.1624,  0.1432,  0.2625,  0.4005]],\n",
      "\n",
      "         [[-0.3460, -0.3654, -0.3654, -0.4169, -0.5016],\n",
      "          [-0.3333, -0.3299, -0.2614, -0.3210, -0.4206],\n",
      "          [-0.2503, -0.2450, -0.1858, -0.2830, -0.4059],\n",
      "          [-0.1350, -0.1623, -0.1431, -0.2624, -0.4005]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7670,  0.9726,  1.1085,  1.2165,  1.2949],\n",
      "          [ 0.8885,  1.0752,  1.1599,  1.3049,  1.4126],\n",
      "          [ 0.8640,  1.0018,  1.0660,  1.2534,  1.3805],\n",
      "          [ 0.8249,  0.9362,  0.9802,  1.1814,  1.3265]],\n",
      "\n",
      "         [[-0.7670, -0.9726, -1.1085, -1.2165, -1.2949],\n",
      "          [-0.8885, -1.0752, -1.1598, -1.3048, -1.4126],\n",
      "          [-0.8640, -1.0017, -1.0660, -1.2533, -1.3804],\n",
      "          [-0.8249, -0.9361, -0.9801, -1.1813, -1.3265]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8735,  2.3861,  2.8573,  3.0586,  3.2230],\n",
      "          [ 2.3624,  2.6758,  3.1837,  3.4749,  3.7533],\n",
      "          [ 2.7908,  3.1802,  3.8088,  4.1782,  4.5226],\n",
      "          [ 2.9520,  3.4365,  4.1170,  4.4992,  4.7786]],\n",
      "\n",
      "         [[-1.8735, -2.3860, -2.8572, -3.0584, -3.2228],\n",
      "          [-2.3623, -2.6755, -3.1834, -3.4745, -3.7530],\n",
      "          [-2.7907, -3.1799, -3.8085, -4.1778, -4.5222],\n",
      "          [-2.9519, -3.4362, -4.1166, -4.4988, -4.7781]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1839,  0.2574,  0.2740,  0.2577,  0.2537],\n",
      "          [ 0.2295,  0.4050,  0.4076,  0.3478,  0.3187],\n",
      "          [ 0.1751,  0.3647,  0.3944,  0.3288,  0.2910],\n",
      "          [ 0.1616,  0.3625,  0.4349,  0.3665,  0.3188]],\n",
      "\n",
      "         [[-0.1840, -0.2574, -0.2741, -0.2578, -0.2537],\n",
      "          [-0.2295, -0.4049, -0.4076, -0.3477, -0.3186],\n",
      "          [-0.1751, -0.3647, -0.3943, -0.3288, -0.2909],\n",
      "          [-0.1616, -0.3624, -0.4348, -0.3664, -0.3187]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2798,  0.3351,  0.3404,  0.5269,  0.7231],\n",
      "          [ 0.3367,  0.4435,  0.3718,  0.5557,  0.7506],\n",
      "          [ 0.2645,  0.4038,  0.3354,  0.5462,  0.7647],\n",
      "          [ 0.2594,  0.4486,  0.3787,  0.5491,  0.7292]],\n",
      "\n",
      "         [[-0.2799, -0.3351, -0.3404, -0.5270, -0.7231],\n",
      "          [-0.3367, -0.4435, -0.3718, -0.5556, -0.7506],\n",
      "          [-0.2645, -0.4038, -0.3354, -0.5462, -0.7647],\n",
      "          [-0.2594, -0.4485, -0.3786, -0.5491, -0.7291]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6047,  0.7522,  0.9093,  0.9477,  0.9795],\n",
      "          [ 0.6926,  0.8305,  0.9992,  1.0393,  1.0478],\n",
      "          [ 0.7759,  0.9169,  1.1161,  1.1686,  1.1647],\n",
      "          [ 0.8645,  1.0023,  1.1775,  1.2390,  1.2428]],\n",
      "\n",
      "         [[-0.6048, -0.7522, -0.9094, -0.9477, -0.9795],\n",
      "          [-0.6926, -0.8304, -0.9991, -1.0392, -1.0477],\n",
      "          [-0.7759, -0.9168, -1.1160, -1.1685, -1.1646],\n",
      "          [-0.8645, -1.0023, -1.1774, -1.2389, -1.2427]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7385,  0.8448,  0.8462,  0.9199,  1.0034],\n",
      "          [ 0.8672,  0.8667,  0.7159,  0.7773,  0.8912],\n",
      "          [ 0.8814,  0.7801,  0.6074,  0.6907,  0.8567],\n",
      "          [ 1.0424,  0.9441,  0.8227,  0.9361,  1.1106]],\n",
      "\n",
      "         [[-0.7386, -0.8449, -0.8462, -0.9199, -1.0034],\n",
      "          [-0.8673, -0.8666, -0.7159, -0.7772, -0.8912],\n",
      "          [-0.8814, -0.7800, -0.6074, -0.6906, -0.8566],\n",
      "          [-1.0424, -0.9440, -0.8227, -0.9361, -1.1105]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0547,  1.2928,  1.4886,  1.5672,  1.6004],\n",
      "          [ 1.2790,  1.4363,  1.5831,  1.7026,  1.7783],\n",
      "          [ 1.4381,  1.5892,  1.7397,  1.8982,  2.0132],\n",
      "          [ 1.5216,  1.7104,  1.8743,  2.0219,  2.1229]],\n",
      "\n",
      "         [[-1.0548, -1.2928, -1.4886, -1.5672, -1.6004],\n",
      "          [-1.2791, -1.4362, -1.5830, -1.7025, -1.7782],\n",
      "          [-1.4381, -1.5891, -1.7395, -1.8980, -2.0130],\n",
      "          [-1.5216, -1.7103, -1.8741, -2.0217, -2.1228]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9566,  1.2077,  1.4029,  1.5108,  1.6507],\n",
      "          [ 1.1934,  1.4291,  1.6389,  1.7695,  1.9490],\n",
      "          [ 1.3548,  1.5781,  1.8272,  1.9981,  2.2252],\n",
      "          [ 1.4680,  1.7011,  1.9925,  2.1766,  2.4187]],\n",
      "\n",
      "         [[-0.9567, -1.2076, -1.4028, -1.5108, -1.6506],\n",
      "          [-1.1934, -1.4290, -1.6388, -1.7693, -1.9489],\n",
      "          [-1.3548, -1.5780, -1.8270, -1.9979, -2.2250],\n",
      "          [-1.4680, -1.7010, -1.9923, -2.1764, -2.4185]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4653,  0.6134,  0.7048,  0.7781,  0.9165],\n",
      "          [ 0.5905,  0.8259,  0.9145,  0.9781,  1.1034],\n",
      "          [ 0.6952,  0.9213,  1.0247,  1.1252,  1.2683],\n",
      "          [ 0.8759,  1.0917,  1.1742,  1.2687,  1.4276]],\n",
      "\n",
      "         [[-0.4653, -0.6134, -0.7048, -0.7781, -0.9165],\n",
      "          [-0.5905, -0.8257, -0.9143, -0.9780, -1.1033],\n",
      "          [-0.6951, -0.9212, -1.0245, -1.1251, -1.2682],\n",
      "          [-0.8759, -1.0915, -1.1741, -1.2686, -1.4275]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0689,  1.2672,  1.3886,  1.4596,  1.4868],\n",
      "          [ 1.3241,  1.4200,  1.4951,  1.6311,  1.7306],\n",
      "          [ 1.5324,  1.5668,  1.6325,  1.7665,  1.8993],\n",
      "          [ 1.7919,  1.8932,  1.9921,  2.1193,  2.2362]],\n",
      "\n",
      "         [[-1.0690, -1.2672, -1.3886, -1.4596, -1.4868],\n",
      "          [-1.3242, -1.4199, -1.4950, -1.6310, -1.7305],\n",
      "          [-1.5324, -1.5667, -1.6324, -1.7664, -1.8991],\n",
      "          [-1.7919, -1.8931, -1.9919, -2.1192, -2.2361]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.0757,  0.0605,  0.0159,  0.0119,  0.0460],\n",
      "          [ 0.0970,  0.1709,  0.1109,  0.1258,  0.1704],\n",
      "          [ 0.1129,  0.2383,  0.2198,  0.2567,  0.2964],\n",
      "          [ 0.1987,  0.3440,  0.3693,  0.3869,  0.4064]],\n",
      "\n",
      "         [[-0.0757, -0.0605, -0.0159, -0.0118, -0.0459],\n",
      "          [-0.0970, -0.1707, -0.1107, -0.1256, -0.1703],\n",
      "          [-0.1129, -0.2381, -0.2196, -0.2565, -0.2962],\n",
      "          [-0.1987, -0.3439, -0.3692, -0.3867, -0.4063]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2459,  1.6118,  1.8999,  2.0127,  2.1246],\n",
      "          [ 1.5637,  1.8944,  2.1875,  2.3147,  2.4519],\n",
      "          [ 1.7874,  2.0944,  2.4323,  2.5870,  2.7203],\n",
      "          [ 1.9610,  2.2910,  2.6800,  2.8720,  3.0107]],\n",
      "\n",
      "         [[-1.2460, -1.6118, -1.8999, -2.0127, -2.1246],\n",
      "          [-1.5637, -1.8943, -2.1874, -2.3145, -2.4518],\n",
      "          [-1.7874, -2.0942, -2.4321, -2.5868, -2.7201],\n",
      "          [-1.9610, -2.2909, -2.6798, -2.8718, -3.0105]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7845,  0.9321,  1.0329,  1.0238,  1.0212],\n",
      "          [ 0.8343,  0.9007,  0.9444,  0.9417,  0.9684],\n",
      "          [ 0.8409,  0.8702,  0.8684,  0.8546,  0.8624],\n",
      "          [ 0.8203,  0.8596,  0.8487,  0.8084,  0.7949]],\n",
      "\n",
      "         [[-0.7845, -0.9321, -1.0329, -1.0239, -1.0212],\n",
      "          [-0.8343, -0.9006, -0.9443, -0.9416, -0.9683],\n",
      "          [-0.8409, -0.8701, -0.8683, -0.8545, -0.8623],\n",
      "          [-0.8204, -0.8596, -0.8486, -0.8084, -0.7949]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9275,  1.1603,  1.3204,  1.2632,  1.1742],\n",
      "          [ 1.0270,  1.1899,  1.3095,  1.2183,  1.1142],\n",
      "          [ 1.0167,  1.1374,  1.2548,  1.1760,  1.1248],\n",
      "          [ 0.9539,  1.0987,  1.2265,  1.1540,  1.1316]],\n",
      "\n",
      "         [[-0.9275, -1.1603, -1.3203, -1.2632, -1.1742],\n",
      "          [-1.0270, -1.1898, -1.3094, -1.2182, -1.1141],\n",
      "          [-1.0167, -1.1373, -1.2547, -1.1759, -1.1247],\n",
      "          [-0.9540, -1.0987, -1.2265, -1.1540, -1.1315]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1266,  1.3069,  1.4405,  1.5331,  1.5502],\n",
      "          [ 1.3114,  1.3108,  1.3686,  1.5551,  1.7124],\n",
      "          [ 1.4280,  1.4323,  1.5474,  1.7962,  2.0379],\n",
      "          [ 1.4652,  1.6061,  1.7980,  2.0645,  2.3259]],\n",
      "\n",
      "         [[-1.1267, -1.3069, -1.4406, -1.5331, -1.5502],\n",
      "          [-1.3114, -1.3107, -1.3685, -1.5550, -1.7123],\n",
      "          [-1.4280, -1.4322, -1.5473, -1.7961, -2.0378],\n",
      "          [-1.4652, -1.6060, -1.7979, -2.0644, -2.3258]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8657,  2.3878,  2.8423,  3.0421,  3.1918],\n",
      "          [ 2.3703,  2.6920,  3.2140,  3.5143,  3.7726],\n",
      "          [ 2.7951,  3.2208,  3.8718,  4.2486,  4.5469],\n",
      "          [ 2.9677,  3.4909,  4.2072,  4.5761,  4.8120]],\n",
      "\n",
      "         [[-1.8657, -2.3877, -2.8421, -3.0419, -3.1916],\n",
      "          [-2.3702, -2.6918, -3.2137, -3.5140, -3.7723],\n",
      "          [-2.7950, -3.2205, -3.8715, -4.2483, -4.5465],\n",
      "          [-2.9675, -3.4906, -4.2068, -4.5757, -4.8115]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6468,  0.8485,  1.0332,  1.0587,  1.0566],\n",
      "          [ 0.8305,  1.1190,  1.4078,  1.4003,  1.3304],\n",
      "          [ 0.9538,  1.2622,  1.6149,  1.5456,  1.4082],\n",
      "          [ 1.1084,  1.4314,  1.7483,  1.5959,  1.4468]],\n",
      "\n",
      "         [[-0.6468, -0.8485, -1.0332, -1.0587, -1.0567],\n",
      "          [-0.8305, -1.1189, -1.4077, -1.4002, -1.3303],\n",
      "          [-0.9537, -1.2621, -1.6148, -1.5455, -1.4082],\n",
      "          [-1.1084, -1.4313, -1.7482, -1.5959, -1.4467]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.0921, -0.1464, -0.2706, -0.3604, -0.4479],\n",
      "          [-0.1170, -0.0850, -0.2359, -0.3353, -0.4504],\n",
      "          [-0.1203, -0.0964, -0.2371, -0.3230, -0.4202],\n",
      "          [ 0.1388,  0.1968,  0.1239,  0.0269, -0.0738]],\n",
      "\n",
      "         [[ 0.0920,  0.1464,  0.2706,  0.3604,  0.4479],\n",
      "          [ 0.1170,  0.0851,  0.2360,  0.3354,  0.4505],\n",
      "          [ 0.1203,  0.0965,  0.2372,  0.3231,  0.4203],\n",
      "          [-0.1388, -0.1967, -0.1239, -0.0269,  0.0739]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1709,  0.2001,  0.1623,  0.3094,  0.3693],\n",
      "          [ 0.2767,  0.2900,  0.1354,  0.3727,  0.5288],\n",
      "          [ 0.2909,  0.2249,  0.1264,  0.5252,  0.7960],\n",
      "          [ 0.5288,  0.5103,  0.5196,  1.0534,  1.4209]],\n",
      "\n",
      "         [[-0.1710, -0.2001, -0.1623, -0.3094, -0.3694],\n",
      "          [-0.2767, -0.2900, -0.1354, -0.3727, -0.5288],\n",
      "          [-0.2909, -0.2248, -0.1264, -0.5252, -0.7959],\n",
      "          [-0.5288, -0.5103, -0.5196, -1.0534, -1.4209]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0210,  1.3521,  1.6113,  1.7472,  1.8281],\n",
      "          [ 1.3389,  1.6776,  1.9094,  2.0285,  2.1121],\n",
      "          [ 1.5410,  1.8823,  2.1428,  2.2518,  2.3340],\n",
      "          [ 1.6419,  1.9699,  2.2422,  2.3187,  2.3549]],\n",
      "\n",
      "         [[-1.0211, -1.3521, -1.6112, -1.7471, -1.8281],\n",
      "          [-1.3389, -1.6774, -1.9093, -2.0284, -2.1119],\n",
      "          [-1.5409, -1.8822, -2.1426, -2.2516, -2.3339],\n",
      "          [-1.6418, -1.9698, -2.2420, -2.3185, -2.3547]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1908,  1.5241,  1.8281,  2.0424,  2.2398],\n",
      "          [ 1.5286,  1.8951,  2.2092,  2.4117,  2.6133],\n",
      "          [ 1.7499,  2.1390,  2.4947,  2.6931,  2.9115],\n",
      "          [ 1.9065,  2.3168,  2.7018,  2.8867,  3.0952]],\n",
      "\n",
      "         [[-1.1909, -1.5241, -1.8280, -2.0423, -2.2398],\n",
      "          [-1.5286, -1.8950, -2.2091, -2.4115, -2.6132],\n",
      "          [-1.7499, -2.1388, -2.4946, -2.6929, -2.9113],\n",
      "          [-1.9065, -2.3167, -2.7016, -2.8865, -3.0950]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8207,  1.0261,  1.1850,  1.2241,  1.1360],\n",
      "          [ 0.9660,  1.1226,  1.2500,  1.3391,  1.2860],\n",
      "          [ 1.0661,  1.2361,  1.3579,  1.4201,  1.3476],\n",
      "          [ 1.0206,  1.1729,  1.2701,  1.2891,  1.2109]],\n",
      "\n",
      "         [[-0.8208, -1.0261, -1.1850, -1.2241, -1.1360],\n",
      "          [-0.9660, -1.1226, -1.2499, -1.3391, -1.2860],\n",
      "          [-1.0662, -1.2360, -1.3579, -1.4200, -1.3476],\n",
      "          [-1.0207, -1.1729, -1.2701, -1.2890, -1.2109]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9973,  1.2452,  1.4540,  1.5790,  1.7012],\n",
      "          [ 1.1711,  1.3555,  1.4967,  1.6293,  1.7564],\n",
      "          [ 1.2498,  1.3815,  1.4848,  1.6494,  1.7993],\n",
      "          [ 1.3134,  1.4429,  1.5022,  1.6480,  1.7683]],\n",
      "\n",
      "         [[-0.9974, -1.2452, -1.4540, -1.5790, -1.7011],\n",
      "          [-1.1711, -1.3554, -1.4966, -1.6292, -1.7563],\n",
      "          [-1.2497, -1.3814, -1.4847, -1.6493, -1.7992],\n",
      "          [-1.3134, -1.4428, -1.5020, -1.6479, -1.7682]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0855,  1.3610,  1.5790,  1.6798,  1.6814],\n",
      "          [ 1.3462,  1.5543,  1.7037,  1.8195,  1.8459],\n",
      "          [ 1.4940,  1.6594,  1.8051,  1.9419,  2.0131],\n",
      "          [ 1.6290,  1.8118,  1.9491,  2.0575,  2.1220]],\n",
      "\n",
      "         [[-1.0856, -1.3610, -1.5790, -1.6798, -1.6814],\n",
      "          [-1.3463, -1.5543, -1.7036, -1.8194, -1.8458],\n",
      "          [-1.4940, -1.6593, -1.8050, -1.9418, -2.0130],\n",
      "          [-1.6291, -1.8117, -1.9490, -2.0573, -2.1219]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.6312, -0.9530, -1.1872, -1.3517, -1.4265],\n",
      "          [-0.8481, -1.0882, -1.3231, -1.5403, -1.6886],\n",
      "          [-0.9851, -1.2290, -1.4243, -1.5966, -1.7366],\n",
      "          [-0.9725, -1.2411, -1.4097, -1.5442, -1.6663]],\n",
      "\n",
      "         [[ 0.6311,  0.9529,  1.1871,  1.3517,  1.4265],\n",
      "          [ 0.8481,  1.0883,  1.3232,  1.5404,  1.6887],\n",
      "          [ 0.9851,  1.2291,  1.4244,  1.5968,  1.7368],\n",
      "          [ 0.9725,  1.2412,  1.4098,  1.5443,  1.6665]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0573,  1.2907,  1.4696,  1.5354,  1.6363],\n",
      "          [ 1.2808,  1.4409,  1.5763,  1.6642,  1.7925],\n",
      "          [ 1.4329,  1.5695,  1.7001,  1.8144,  1.9598],\n",
      "          [ 1.4375,  1.5733,  1.6904,  1.8193,  1.9815]],\n",
      "\n",
      "         [[-1.0574, -1.2907, -1.4696, -1.5354, -1.6363],\n",
      "          [-1.2808, -1.4408, -1.5761, -1.6640, -1.7923],\n",
      "          [-1.4329, -1.5693, -1.7000, -1.8142, -1.9597],\n",
      "          [-1.4375, -1.5732, -1.6903, -1.8191, -1.9813]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.7706,  2.2766,  2.7310,  2.9411,  3.1082],\n",
      "          [ 2.2419,  2.5996,  3.1558,  3.4699,  3.7477],\n",
      "          [ 2.6423,  3.0777,  3.7639,  4.1745,  4.5039],\n",
      "          [ 2.8256,  3.3694,  4.1232,  4.5278,  4.8296]],\n",
      "\n",
      "         [[-1.7706, -2.2765, -2.7309, -2.9410, -3.1080],\n",
      "          [-2.2418, -2.5994, -3.1555, -3.4696, -3.7474],\n",
      "          [-2.6422, -3.0774, -3.7636, -4.1742, -4.5035],\n",
      "          [-2.8255, -3.3691, -4.1229, -4.5274, -4.8292]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6954,  0.9016,  0.9619,  0.9758,  0.9465],\n",
      "          [ 0.8834,  1.0949,  1.1230,  1.1666,  1.1557],\n",
      "          [ 1.0802,  1.2819,  1.3646,  1.4353,  1.4563],\n",
      "          [ 1.2883,  1.5410,  1.6939,  1.7960,  1.8242]],\n",
      "\n",
      "         [[-0.6955, -0.9016, -0.9618, -0.9758, -0.9465],\n",
      "          [-0.8834, -1.0948, -1.1229, -1.1664, -1.1556],\n",
      "          [-1.0802, -1.2818, -1.3645, -1.4352, -1.4562],\n",
      "          [-1.2884, -1.5410, -1.6938, -1.7959, -1.8241]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7808,  0.9548,  1.1386,  1.2482,  1.3544],\n",
      "          [ 0.8975,  1.0241,  1.1643,  1.3240,  1.4665],\n",
      "          [ 0.9627,  1.0952,  1.2114,  1.4057,  1.5571],\n",
      "          [ 0.9739,  1.0894,  1.1427,  1.3303,  1.5181]],\n",
      "\n",
      "         [[-0.7809, -0.9548, -1.1386, -1.2482, -1.3544],\n",
      "          [-0.8975, -1.0240, -1.1641, -1.3239, -1.4664],\n",
      "          [-0.9627, -1.0951, -1.2112, -1.4056, -1.5570],\n",
      "          [-0.9739, -1.0893, -1.1426, -1.3302, -1.5180]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2793,  0.3630,  0.5032,  0.7406,  1.0130],\n",
      "          [ 0.2883,  0.3947,  0.5186,  0.8280,  1.1543],\n",
      "          [ 0.3424,  0.4502,  0.5985,  0.9892,  1.3772],\n",
      "          [ 0.4354,  0.5670,  0.7324,  1.2083,  1.6593]],\n",
      "\n",
      "         [[-0.2793, -0.3630, -0.5032, -0.7406, -1.0130],\n",
      "          [-0.2883, -0.3946, -0.5185, -0.8279, -1.1542],\n",
      "          [-0.3424, -0.4500, -0.5983, -0.9890, -1.3771],\n",
      "          [-0.4354, -0.5669, -0.7323, -1.2082, -1.6592]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1733,  1.3075,  1.4168,  1.6199,  1.6668],\n",
      "          [ 1.4866,  1.4236,  1.3661,  1.6557,  1.8077],\n",
      "          [ 1.6902,  1.5687,  1.4895,  1.8251,  2.0446],\n",
      "          [ 1.7758,  1.7073,  1.7141,  2.0908,  2.3250]],\n",
      "\n",
      "         [[-1.1734, -1.3074, -1.4168, -1.6199, -1.6668],\n",
      "          [-1.4866, -1.4235, -1.3660, -1.6556, -1.8076],\n",
      "          [-1.6902, -1.5685, -1.4894, -1.8250, -2.0445],\n",
      "          [-1.7757, -1.7072, -1.7139, -2.0907, -2.3248]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.6061,  2.0328,  2.3855,  2.5465,  2.6467],\n",
      "          [ 2.0224,  2.3201,  2.6029,  2.8435,  3.0362],\n",
      "          [ 2.3426,  2.6047,  2.8879,  3.1611,  3.3728],\n",
      "          [ 2.4787,  2.8192,  3.1416,  3.4396,  3.6857]],\n",
      "\n",
      "         [[-1.6061, -2.0328, -2.3854, -2.5464, -2.6465],\n",
      "          [-2.0223, -2.3199, -2.6027, -2.8433, -3.0359],\n",
      "          [-2.3425, -2.6045, -2.8876, -3.1608, -3.3725],\n",
      "          [-2.4786, -2.8190, -3.1413, -3.4393, -3.6854]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2604,  0.3162,  0.2576,  0.1798,  0.1453],\n",
      "          [ 0.2723,  0.3937,  0.3640,  0.3355,  0.3203],\n",
      "          [ 0.2664,  0.3537,  0.3388,  0.3306,  0.3235],\n",
      "          [ 0.3453,  0.3912,  0.3808,  0.4043,  0.4245]],\n",
      "\n",
      "         [[-0.2604, -0.3163, -0.2576, -0.1799, -0.1454],\n",
      "          [-0.2724, -0.3937, -0.3639, -0.3355, -0.3202],\n",
      "          [-0.2665, -0.3537, -0.3387, -0.3305, -0.3234],\n",
      "          [-0.3454, -0.3912, -0.3807, -0.4042, -0.4244]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4277,  0.5071,  0.4905,  0.6125,  0.7423],\n",
      "          [ 0.5300,  0.6455,  0.5834,  0.7649,  0.9380],\n",
      "          [ 0.5391,  0.6535,  0.6111,  0.8313,  1.0490],\n",
      "          [ 0.5608,  0.6798,  0.6700,  0.8910,  1.1176]],\n",
      "\n",
      "         [[-0.4278, -0.5071, -0.4905, -0.6126, -0.7424],\n",
      "          [-0.5300, -0.6454, -0.5834, -0.7649, -0.9379],\n",
      "          [-0.5391, -0.6535, -0.6111, -0.8313, -1.0489],\n",
      "          [-0.5608, -0.6798, -0.6699, -0.8909, -1.1176]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8245,  0.8775,  0.8482,  0.7293,  0.6173],\n",
      "          [ 0.9165,  0.8597,  0.8022,  0.7509,  0.7221],\n",
      "          [ 0.9911,  0.9134,  0.8299,  0.8040,  0.7976],\n",
      "          [ 1.0925,  1.0889,  1.0205,  0.9503,  0.8988]],\n",
      "\n",
      "         [[-0.8246, -0.8775, -0.8481, -0.7293, -0.6172],\n",
      "          [-0.9165, -0.8595, -0.8021, -0.7508, -0.7220],\n",
      "          [-0.9911, -0.9133, -0.8298, -0.8038, -0.7975],\n",
      "          [-1.0925, -1.0887, -1.0204, -0.9501, -0.8988]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4608,  0.4964,  0.4810,  0.5302,  0.5618],\n",
      "          [ 0.5331,  0.5399,  0.4477,  0.5090,  0.5714],\n",
      "          [ 0.5316,  0.5210,  0.4273,  0.5045,  0.5979],\n",
      "          [ 0.4257,  0.4017,  0.3168,  0.3917,  0.4724]],\n",
      "\n",
      "         [[-0.4608, -0.4964, -0.4810, -0.5302, -0.5618],\n",
      "          [-0.5331, -0.5399, -0.4476, -0.5089, -0.5713],\n",
      "          [-0.5316, -0.5209, -0.4272, -0.5044, -0.5977],\n",
      "          [-0.4257, -0.4016, -0.3167, -0.3915, -0.4722]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1630,  1.4321,  1.6604,  1.7624,  1.8150],\n",
      "          [ 1.4587,  1.6525,  1.8402,  1.9604,  2.0510],\n",
      "          [ 1.6555,  1.8639,  2.0845,  2.2440,  2.3889],\n",
      "          [ 1.7388,  1.9919,  2.2215,  2.3756,  2.5232]],\n",
      "\n",
      "         [[-1.1631, -1.4321, -1.6604, -1.7624, -1.8150],\n",
      "          [-1.4587, -1.6525, -1.8401, -1.9603, -2.0509],\n",
      "          [-1.6555, -1.8638, -2.0844, -2.2439, -2.3887],\n",
      "          [-1.7388, -1.9917, -2.2213, -2.3754, -2.5230]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2444,  0.2232,  0.1772,  0.2176,  0.3260],\n",
      "          [ 0.2588,  0.2935,  0.2634,  0.3616,  0.5136],\n",
      "          [ 0.2453,  0.3320,  0.3481,  0.4811,  0.6146],\n",
      "          [ 0.2404,  0.3698,  0.4554,  0.5982,  0.7218]],\n",
      "\n",
      "         [[-0.2445, -0.2232, -0.1772, -0.2176, -0.3261],\n",
      "          [-0.2588, -0.2934, -0.2634, -0.3615, -0.5136],\n",
      "          [-0.2453, -0.3319, -0.3480, -0.4811, -0.6146],\n",
      "          [-0.2405, -0.3697, -0.4553, -0.5982, -0.7217]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1394,  1.4433,  1.6697,  1.7928,  1.9318],\n",
      "          [ 1.3685,  1.6348,  1.8676,  2.0363,  2.2310],\n",
      "          [ 1.4635,  1.7224,  2.0009,  2.2236,  2.4646],\n",
      "          [ 1.5292,  1.8403,  2.1757,  2.4117,  2.6772]],\n",
      "\n",
      "         [[-1.1394, -1.4433, -1.6697, -1.7927, -1.9318],\n",
      "          [-1.3685, -1.6348, -1.8675, -2.0361, -2.2308],\n",
      "          [-1.4635, -1.7223, -2.0007, -2.2234, -2.4644],\n",
      "          [-1.5292, -1.8402, -2.1756, -2.4116, -2.6770]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3550,  1.6811,  1.9391,  2.0885,  2.2062],\n",
      "          [ 1.6353,  1.8268,  2.0239,  2.2190,  2.3871],\n",
      "          [ 1.8400,  1.9851,  2.1627,  2.3817,  2.5768],\n",
      "          [ 2.0135,  2.2202,  2.4268,  2.6434,  2.8513]],\n",
      "\n",
      "         [[-1.3551, -1.6810, -1.9390, -2.0884, -2.2061],\n",
      "          [-1.6353, -1.8267, -2.0237, -2.2188, -2.3869],\n",
      "          [-1.8400, -1.9850, -2.1625, -2.3815, -2.5766],\n",
      "          [-2.0134, -2.2201, -2.4266, -2.6432, -2.8510]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7398,  0.8281,  0.8428,  0.7790,  0.7682],\n",
      "          [ 0.8583,  0.9300,  0.9775,  0.9708,  1.0161],\n",
      "          [ 0.9440,  1.0269,  1.1393,  1.1782,  1.2568],\n",
      "          [ 0.9624,  1.0375,  1.1673,  1.1811,  1.2235]],\n",
      "\n",
      "         [[-0.7399, -0.8281, -0.8428, -0.7790, -0.7682],\n",
      "          [-0.8583, -0.9299, -0.9774, -0.9707, -1.0160],\n",
      "          [-0.9440, -1.0268, -1.1391, -1.1781, -1.2567],\n",
      "          [-0.9624, -1.0374, -1.1672, -1.1810, -1.2234]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2448,  1.5372,  1.7803,  1.9133,  1.9733],\n",
      "          [ 1.5496,  1.7094,  1.8638,  1.9937,  2.0837],\n",
      "          [ 1.7052,  1.8349,  1.9852,  2.1075,  2.2111],\n",
      "          [ 1.7872,  1.9650,  2.1016,  2.1626,  2.2195]],\n",
      "\n",
      "         [[-1.2449, -1.5372, -1.7802, -1.9133, -1.9733],\n",
      "          [-1.5496, -1.7093, -1.8637, -1.9935, -2.0836],\n",
      "          [-1.7052, -1.8348, -1.9851, -2.1074, -2.2109],\n",
      "          [-1.7872, -1.9649, -2.1014, -2.1624, -2.2193]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.2448,  0.3200,  0.3950,  0.4614,  0.5137],\n",
      "          [ 0.2716,  0.3621,  0.3901,  0.4502,  0.5343],\n",
      "          [ 0.3118,  0.4524,  0.4990,  0.5446,  0.6522],\n",
      "          [ 0.4194,  0.6581,  0.8205,  0.9272,  1.0935]],\n",
      "\n",
      "         [[-0.2449, -0.3200, -0.3950, -0.4614, -0.5137],\n",
      "          [-0.2716, -0.3620, -0.3900, -0.4500, -0.5341],\n",
      "          [-0.3118, -0.4523, -0.4989, -0.5445, -0.6521],\n",
      "          [-0.4194, -0.6580, -0.8204, -0.9271, -1.0934]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9607,  2.4994,  2.9989,  3.2386,  3.4449],\n",
      "          [ 2.4396,  2.6996,  3.3501,  3.7412,  4.0825],\n",
      "          [ 2.9393,  3.2828,  4.1272,  4.6814,  5.0641],\n",
      "          [ 3.2034,  3.6863,  4.6079,  5.1222,  5.5160]],\n",
      "\n",
      "         [[-1.9607, -2.4992, -2.9987, -3.2383, -3.4447],\n",
      "          [-2.4395, -2.6994, -3.3498, -3.7408, -4.0821],\n",
      "          [-2.9392, -3.2825, -4.1268, -4.6810, -5.0636],\n",
      "          [-3.2032, -3.6860, -4.6075, -5.1218, -5.5155]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0947,  1.4488,  1.6352,  1.7925,  1.9238],\n",
      "          [ 1.3593,  1.6826,  1.7981,  2.0022,  2.1757],\n",
      "          [ 1.4740,  1.7314,  1.7949,  2.0273,  2.2623],\n",
      "          [ 1.6085,  1.8992,  1.9614,  2.1875,  2.4600]],\n",
      "\n",
      "         [[-1.0948, -1.4488, -1.6352, -1.7925, -1.9238],\n",
      "          [-1.3593, -1.6826, -1.7980, -2.0020, -2.1756],\n",
      "          [-1.4740, -1.7313, -1.7948, -2.0271, -2.2621],\n",
      "          [-1.6085, -1.8991, -1.9613, -2.1873, -2.4598]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8911,  1.0429,  1.1260,  1.1552,  1.1855],\n",
      "          [ 1.0598,  1.1463,  1.1616,  1.2236,  1.2668],\n",
      "          [ 1.1156,  1.1940,  1.2145,  1.2771,  1.3488],\n",
      "          [ 1.1666,  1.3091,  1.3644,  1.4300,  1.5165]],\n",
      "\n",
      "         [[-0.8911, -1.0429, -1.1260, -1.1552, -1.1855],\n",
      "          [-1.0598, -1.1462, -1.1615, -1.2235, -1.2667],\n",
      "          [-1.1156, -1.1939, -1.2144, -1.2770, -1.3487],\n",
      "          [-1.1666, -1.3091, -1.3644, -1.4300, -1.5164]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.2546,  1.4994,  1.7570,  1.8552,  1.8842],\n",
      "          [ 1.6267,  1.7938,  2.0388,  2.1883,  2.2150],\n",
      "          [ 1.8749,  2.0347,  2.3368,  2.4767,  2.5023],\n",
      "          [ 1.9778,  2.1853,  2.4975,  2.6035,  2.5965]],\n",
      "\n",
      "         [[-1.2546, -1.4994, -1.7570, -1.8552, -1.8842],\n",
      "          [-1.6267, -1.7937, -2.0387, -2.1882, -2.2148],\n",
      "          [-1.8749, -2.0346, -2.3366, -2.4766, -2.5021],\n",
      "          [-1.9778, -2.1852, -2.4974, -2.6033, -2.5963]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1459,  0.1554,  0.1900,  0.2494,  0.3721],\n",
      "          [ 0.1309,  0.1915,  0.2479,  0.3108,  0.4308],\n",
      "          [ 0.1140,  0.2016,  0.3082,  0.3978,  0.5251],\n",
      "          [ 0.1654,  0.2810,  0.4388,  0.5540,  0.7182]],\n",
      "\n",
      "         [[-0.1460, -0.1554, -0.1899, -0.2494, -0.3721],\n",
      "          [-0.1309, -0.1914, -0.2477, -0.3107, -0.4306],\n",
      "          [-0.1140, -0.2014, -0.3080, -0.3976, -0.5250],\n",
      "          [-0.1654, -0.2809, -0.4386, -0.5538, -0.7180]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.0393, -0.1794, -0.2694, -0.3960, -0.4220],\n",
      "          [-0.1879, -0.3526, -0.4679, -0.6302, -0.6744],\n",
      "          [-0.3020, -0.5041, -0.6270, -0.7790, -0.8113],\n",
      "          [-0.3763, -0.6009, -0.7132, -0.8278, -0.8141]],\n",
      "\n",
      "         [[ 0.0392,  0.1794,  0.2694,  0.3960,  0.4220],\n",
      "          [ 0.1879,  0.3528,  0.4680,  0.6303,  0.6745],\n",
      "          [ 0.3020,  0.5043,  0.6273,  0.7792,  0.8114],\n",
      "          [ 0.3763,  0.6011,  0.7134,  0.8279,  0.8142]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[-0.8759, -1.3001, -1.5642, -1.6450, -1.6581],\n",
      "          [-1.1914, -1.5932, -1.9552, -2.0752, -2.0774],\n",
      "          [-1.4043, -1.8688, -2.2536, -2.3523, -2.3179],\n",
      "          [-1.5247, -2.0549, -2.4193, -2.4689, -2.4091]],\n",
      "\n",
      "         [[ 0.8758,  1.3001,  1.5642,  1.6450,  1.6582],\n",
      "          [ 1.1914,  1.5933,  1.9553,  2.0754,  2.0775],\n",
      "          [ 1.4043,  1.8689,  2.2538,  2.3525,  2.3181],\n",
      "          [ 1.5248,  2.0550,  2.4195,  2.4691,  2.4093]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4152,  0.5796,  0.6294,  0.7869,  0.8698],\n",
      "          [ 0.5395,  0.7349,  0.6861,  0.8536,  0.9436],\n",
      "          [ 0.5233,  0.6751,  0.6289,  0.8587,  0.9889],\n",
      "          [ 0.5832,  0.7587,  0.7504,  0.9993,  1.1365]],\n",
      "\n",
      "         [[-0.4153, -0.5796, -0.6295, -0.7870, -0.8699],\n",
      "          [-0.5396, -0.7349, -0.6861, -0.8536, -0.9436],\n",
      "          [-0.5234, -0.6751, -0.6289, -0.8587, -0.9889],\n",
      "          [-0.5832, -0.7587, -0.7504, -0.9993, -1.1364]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5897,  0.6783,  0.7084,  0.7971,  0.9273],\n",
      "          [ 0.6295,  0.6796,  0.6597,  0.8137,  1.0207],\n",
      "          [ 0.6160,  0.6516,  0.6394,  0.8580,  1.1464],\n",
      "          [ 0.6001,  0.6540,  0.6616,  0.8922,  1.2002]],\n",
      "\n",
      "         [[-0.5898, -0.6783, -0.7084, -0.7971, -0.9273],\n",
      "          [-0.6296, -0.6796, -0.6596, -0.8135, -1.0206],\n",
      "          [-0.6161, -0.6515, -0.6393, -0.8578, -1.1463],\n",
      "          [-0.6001, -0.6539, -0.6614, -0.8921, -1.2001]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.1040, -0.0598, -0.1906, -0.2125, -0.1554],\n",
      "          [ 0.1139, -0.0474, -0.1978, -0.1965, -0.1065],\n",
      "          [ 0.1502,  0.0220, -0.0409, -0.0218,  0.0372],\n",
      "          [ 0.2091,  0.1043,  0.1373,  0.1695,  0.1985]],\n",
      "\n",
      "         [[-0.1041,  0.0597,  0.1906,  0.2124,  0.1554],\n",
      "          [-0.1139,  0.0475,  0.1979,  0.1965,  0.1065],\n",
      "          [-0.1502, -0.0219,  0.0410,  0.0219, -0.0371],\n",
      "          [-0.2091, -0.1043, -0.1373, -0.1694, -0.1984]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 1 1 1 1]\n",
      " [0 1 1 1 1]\n",
      " [0 0 1 1 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7924,  1.0799,  1.2561,  1.3945,  1.5553],\n",
      "          [ 0.9746,  1.2590,  1.4351,  1.6027,  1.8117],\n",
      "          [ 1.1361,  1.4026,  1.5957,  1.7621,  1.9664],\n",
      "          [ 1.2919,  1.5922,  1.8762,  2.0398,  2.2137]],\n",
      "\n",
      "         [[-0.7925, -1.0799, -1.2560, -1.3945, -1.5553],\n",
      "          [-0.9746, -1.2589, -1.4350, -1.6026, -1.8116],\n",
      "          [-1.1361, -1.4025, -1.5956, -1.7620, -1.9663],\n",
      "          [-1.2919, -1.5921, -1.8761, -2.0396, -2.2136]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9049,  1.0455,  1.1118,  1.0948,  1.0867],\n",
      "          [ 1.1067,  1.1693,  1.1880,  1.1923,  1.2151],\n",
      "          [ 1.2020,  1.1914,  1.2170,  1.2749,  1.3552],\n",
      "          [ 1.3113,  1.3055,  1.3638,  1.4049,  1.4427]],\n",
      "\n",
      "         [[-0.9050, -1.0455, -1.1118, -1.0948, -1.0867],\n",
      "          [-1.1067, -1.1692, -1.1879, -1.1922, -1.2150],\n",
      "          [-1.2019, -1.1913, -1.2169, -1.2748, -1.3551],\n",
      "          [-1.3113, -1.3054, -1.3636, -1.4048, -1.4426]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0253,  1.2585,  1.4258,  1.4841,  1.4263],\n",
      "          [ 1.3131,  1.4822,  1.5950,  1.6723,  1.6340],\n",
      "          [ 1.4266,  1.5292,  1.6826,  1.7887,  1.7596],\n",
      "          [ 1.5732,  1.7341,  1.9840,  2.0438,  1.9628]],\n",
      "\n",
      "         [[-1.0254, -1.2585, -1.4258, -1.4841, -1.4263],\n",
      "          [-1.3131, -1.4822, -1.5950, -1.6722, -1.6339],\n",
      "          [-1.4267, -1.5292, -1.6825, -1.7887, -1.7595],\n",
      "          [-1.5732, -1.7341, -1.9839, -2.0437, -1.9627]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1827,  1.4676,  1.6978,  1.7970,  1.8697],\n",
      "          [ 1.4590,  1.6481,  1.7931,  1.8907,  1.9969],\n",
      "          [ 1.6151,  1.7379,  1.8313,  1.9183,  2.0433],\n",
      "          [ 1.7415,  1.9187,  2.0206,  2.0910,  2.2030]],\n",
      "\n",
      "         [[-1.1827, -1.4676, -1.6978, -1.7969, -1.8696],\n",
      "          [-1.4590, -1.6480, -1.7930, -1.8906, -1.9968],\n",
      "          [-1.6151, -1.7378, -1.8312, -1.9182, -2.0432],\n",
      "          [-1.7414, -1.9185, -2.0204, -2.0908, -2.2028]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7286,  0.8864,  1.0674,  1.2384,  1.3875],\n",
      "          [ 0.8485,  0.9493,  1.0350,  1.1480,  1.2537],\n",
      "          [ 0.8298,  0.8921,  0.9631,  1.0784,  1.2205],\n",
      "          [ 0.8333,  0.9677,  1.0752,  1.1787,  1.3643]],\n",
      "\n",
      "         [[-0.7287, -0.8865, -1.0675, -1.2384, -1.3875],\n",
      "          [-0.8485, -0.9493, -1.0349, -1.1479, -1.2536],\n",
      "          [-0.8299, -0.8920, -0.9631, -1.0783, -1.2204],\n",
      "          [-0.8334, -0.9677, -1.0751, -1.1786, -1.3641]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9953,  1.2385,  1.3971,  1.4265,  1.4177],\n",
      "          [ 1.2047,  1.3602,  1.4738,  1.5232,  1.5398],\n",
      "          [ 1.3288,  1.4078,  1.5376,  1.6307,  1.6619],\n",
      "          [ 1.5182,  1.6296,  1.8188,  1.9801,  2.0664]],\n",
      "\n",
      "         [[-0.9954, -1.2385, -1.3971, -1.4265, -1.4177],\n",
      "          [-1.2047, -1.3602, -1.4737, -1.5231, -1.5397],\n",
      "          [-1.3288, -1.4077, -1.5375, -1.6305, -1.6618],\n",
      "          [-1.5182, -1.6296, -1.8187, -1.9800, -2.0663]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.9217,  2.4710,  2.9521,  3.1698,  3.3438],\n",
      "          [ 2.4440,  2.7722,  3.3283,  3.6510,  3.9496],\n",
      "          [ 2.8880,  3.3324,  4.0325,  4.4486,  4.7936],\n",
      "          [ 3.0666,  3.6100,  4.3729,  4.7917,  5.0780]],\n",
      "\n",
      "         [[-1.9217, -2.4709, -2.9520, -3.1696, -3.3436],\n",
      "          [-2.4439, -2.7719, -3.3280, -3.6507, -3.9492],\n",
      "          [-2.8879, -3.3321, -4.0321, -4.4482, -4.7932],\n",
      "          [-3.0664, -3.6097, -4.3725, -4.7912, -5.0775]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.8174,  2.3239,  2.7521,  2.9383,  3.0893],\n",
      "          [ 2.3115,  2.6314,  3.1365,  3.4273,  3.7002],\n",
      "          [ 2.7099,  3.1086,  3.7335,  4.1206,  4.4369],\n",
      "          [ 2.8811,  3.3732,  4.0631,  4.4446,  4.7388]],\n",
      "\n",
      "         [[-1.8174, -2.3238, -2.7520, -2.9381, -3.0891],\n",
      "          [-2.3114, -2.6312, -3.1362, -3.4270, -3.6998],\n",
      "          [-2.7098, -3.1083, -3.7332, -4.1202, -4.4365],\n",
      "          [-2.8809, -3.3730, -4.0627, -4.4442, -4.7383]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6347,  0.7938,  0.9195,  1.0650,  1.2257],\n",
      "          [ 0.8007,  0.9674,  1.0687,  1.2663,  1.4664],\n",
      "          [ 0.9153,  1.0969,  1.2037,  1.4729,  1.6945],\n",
      "          [ 1.0842,  1.3113,  1.4420,  1.7328,  1.9691]],\n",
      "\n",
      "         [[-0.6347, -0.7939, -0.9195, -1.0651, -1.2257],\n",
      "          [-0.8007, -0.9674, -1.0686, -1.2662, -1.4664],\n",
      "          [-0.9153, -1.0968, -1.2036, -1.4729, -1.6944],\n",
      "          [-1.0842, -1.3112, -1.4419, -1.7327, -1.9690]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1374,  1.3999,  1.6268,  1.7729,  1.8517],\n",
      "          [ 1.4582,  1.6542,  1.8378,  2.0122,  2.1249],\n",
      "          [ 1.6465,  1.8450,  2.0372,  2.2046,  2.3040],\n",
      "          [ 1.7076,  1.9640,  2.1769,  2.3221,  2.3865]],\n",
      "\n",
      "         [[-1.1375, -1.4000, -1.6268, -1.7729, -1.8517],\n",
      "          [-1.4582, -1.6542, -1.8377, -2.0121, -2.1248],\n",
      "          [-1.6465, -1.8449, -2.0371, -2.2045, -2.3038],\n",
      "          [-1.7076, -1.9639, -2.1768, -2.3220, -2.3864]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7119,  0.9206,  1.0492,  0.9909,  0.9581],\n",
      "          [ 0.8827,  1.0841,  1.1926,  1.1075,  1.0721],\n",
      "          [ 1.0221,  1.2162,  1.3586,  1.2985,  1.2548],\n",
      "          [ 1.0500,  1.1677,  1.2596,  1.1755,  1.1202]],\n",
      "\n",
      "         [[-0.7119, -0.9206, -1.0492, -0.9909, -0.9581],\n",
      "          [-0.8827, -1.0840, -1.1924, -1.1074, -1.0720],\n",
      "          [-1.0221, -1.2160, -1.3584, -1.2983, -1.2547],\n",
      "          [-1.0500, -1.1675, -1.2595, -1.1753, -1.1201]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1070,  1.3701,  1.5665,  1.7042,  1.8362],\n",
      "          [ 1.3595,  1.5527,  1.7238,  1.9269,  2.1205],\n",
      "          [ 1.5269,  1.7045,  1.8963,  2.1401,  2.3719],\n",
      "          [ 1.6104,  1.8064,  2.0121,  2.2498,  2.4881]],\n",
      "\n",
      "         [[-1.1071, -1.3701, -1.5665, -1.7042, -1.8362],\n",
      "          [-1.3595, -1.5526, -1.7237, -1.9268, -2.1204],\n",
      "          [-1.5269, -1.7044, -1.8962, -2.1400, -2.3718],\n",
      "          [-1.6103, -1.8063, -2.0120, -2.2496, -2.4879]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.1220,  1.3610,  1.5838,  1.5990,  1.5774],\n",
      "          [ 1.3101,  1.4103,  1.6353,  1.7009,  1.7500],\n",
      "          [ 1.4554,  1.4781,  1.6714,  1.7835,  1.8775],\n",
      "          [ 1.6084,  1.7061,  1.8900,  1.9841,  2.0326]],\n",
      "\n",
      "         [[-1.1221, -1.3610, -1.5838, -1.5990, -1.5774],\n",
      "          [-1.3101, -1.4103, -1.6352, -1.7007, -1.7498],\n",
      "          [-1.4554, -1.4780, -1.6712, -1.7834, -1.8774],\n",
      "          [-1.6084, -1.7060, -1.8899, -1.9840, -2.0325]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.9898,  1.2242,  1.4172,  1.5227,  1.5821],\n",
      "          [ 1.2263,  1.3822,  1.5036,  1.6444,  1.7432],\n",
      "          [ 1.3626,  1.4683,  1.5563,  1.7149,  1.8206],\n",
      "          [ 1.4695,  1.6094,  1.6949,  1.8557,  1.9550]],\n",
      "\n",
      "         [[-0.9899, -1.2243, -1.4172, -1.5227, -1.5821],\n",
      "          [-1.2263, -1.3821, -1.5035, -1.6443, -1.7431],\n",
      "          [-1.3626, -1.4682, -1.5561, -1.7148, -1.8205],\n",
      "          [-1.4696, -1.6093, -1.6948, -1.8555, -1.9549]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.7994,  0.9523,  1.0129,  1.0401,  1.0669],\n",
      "          [ 0.9231,  1.0105,  1.0344,  1.1139,  1.1918],\n",
      "          [ 0.9817,  1.0251,  1.0541,  1.1794,  1.2841],\n",
      "          [ 1.1091,  1.1834,  1.2151,  1.3378,  1.4439]],\n",
      "\n",
      "         [[-0.7995, -0.9523, -1.0129, -1.0401, -1.0669],\n",
      "          [-0.9231, -1.0104, -1.0343, -1.1138, -1.1917],\n",
      "          [-0.9817, -1.0250, -1.0540, -1.1793, -1.2840],\n",
      "          [-1.1091, -1.1833, -1.2150, -1.3377, -1.4438]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.8299,  1.0473,  1.1253,  1.1876,  1.2313],\n",
      "          [ 0.9665,  1.1518,  1.1620,  1.2640,  1.3592],\n",
      "          [ 1.0676,  1.2455,  1.2615,  1.3946,  1.5113],\n",
      "          [ 1.2386,  1.4697,  1.5119,  1.6044,  1.6864]],\n",
      "\n",
      "         [[-0.8299, -1.0473, -1.1253, -1.1876, -1.2313],\n",
      "          [-0.9665, -1.1517, -1.1619, -1.2639, -1.3592],\n",
      "          [-1.0676, -1.2455, -1.2615, -1.3946, -1.5112],\n",
      "          [-1.2386, -1.4696, -1.5118, -1.6044, -1.6863]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.3004,  1.5779,  1.8767,  2.0131,  2.0569],\n",
      "          [ 1.6279,  1.7911,  2.0614,  2.2556,  2.3186],\n",
      "          [ 1.8444,  1.9727,  2.2728,  2.4619,  2.5431],\n",
      "          [ 1.9520,  2.1485,  2.4568,  2.5983,  2.6473]],\n",
      "\n",
      "         [[-1.3004, -1.5779, -1.8767, -2.0130, -2.0569],\n",
      "          [-1.6279, -1.7910, -2.0613, -2.2555, -2.3185],\n",
      "          [-1.8444, -1.9726, -2.2726, -2.4617, -2.5429],\n",
      "          [-1.9520, -2.1484, -2.4567, -2.5981, -2.6471]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.0165, -0.0274, -0.0528, -0.0865, -0.0508],\n",
      "          [-0.1254, -0.1160, -0.0768, -0.0693,  0.0276],\n",
      "          [-0.2935, -0.3024, -0.2540, -0.2016, -0.0319],\n",
      "          [-0.3217, -0.3384, -0.3048, -0.2690, -0.1354]],\n",
      "\n",
      "         [[-0.0166,  0.0274,  0.0528,  0.0865,  0.0508],\n",
      "          [ 0.1254,  0.1160,  0.0768,  0.0693, -0.0276],\n",
      "          [ 0.2935,  0.3025,  0.2541,  0.2017,  0.0320],\n",
      "          [ 0.3217,  0.3385,  0.3049,  0.2691,  0.1355]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 1 1 1 1]\n",
      " [1 1 1 1 0]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0651,  1.3326,  1.5859,  1.7886,  1.9062],\n",
      "          [ 1.4013,  1.6400,  1.8895,  2.1579,  2.3103],\n",
      "          [ 1.6090,  1.8869,  2.2122,  2.5428,  2.7268],\n",
      "          [ 1.7361,  2.1043,  2.4324,  2.7419,  2.9079]],\n",
      "\n",
      "         [[-1.0652, -1.3326, -1.5859, -1.7886, -1.9062],\n",
      "          [-1.4013, -1.6399, -1.8894, -2.1578, -2.3102],\n",
      "          [-1.6090, -1.8868, -2.2121, -2.5426, -2.7266],\n",
      "          [-1.7361, -2.1042, -2.4323, -2.7418, -2.9078]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5594,  0.5266,  0.4211,  0.3720,  0.3219],\n",
      "          [ 0.6832,  0.5958,  0.4422,  0.4654,  0.4828],\n",
      "          [ 0.7341,  0.6186,  0.4763,  0.5384,  0.5776],\n",
      "          [ 0.7369,  0.6189,  0.5032,  0.5953,  0.6695]],\n",
      "\n",
      "         [[-0.5595, -0.5266, -0.4211, -0.3721, -0.3219],\n",
      "          [-0.6832, -0.5957, -0.4422, -0.4653, -0.4828],\n",
      "          [-0.7341, -0.6185, -0.4762, -0.5383, -0.5775],\n",
      "          [-0.7369, -0.6188, -0.5031, -0.5953, -0.6694]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6406,  0.7411,  0.8589,  0.9698,  1.1056],\n",
      "          [ 0.7442,  0.8292,  0.9385,  1.0650,  1.2410],\n",
      "          [ 0.8396,  0.9869,  1.1270,  1.2479,  1.4243],\n",
      "          [ 0.7841,  0.9364,  1.1040,  1.2248,  1.3938]],\n",
      "\n",
      "         [[-0.6406, -0.7411, -0.8589, -0.9698, -1.1056],\n",
      "          [-0.7442, -0.8291, -0.9383, -1.0649, -1.2409],\n",
      "          [-0.8395, -0.9867, -1.1268, -1.2478, -1.4242],\n",
      "          [-0.7841, -0.9363, -1.1038, -1.2247, -1.3937]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5281,  0.6002,  0.6975,  0.7334,  0.7637],\n",
      "          [ 0.5984,  0.6721,  0.7621,  0.7820,  0.7712],\n",
      "          [ 0.6225,  0.7324,  0.8825,  0.9365,  0.9580],\n",
      "          [ 0.5888,  0.7550,  0.9660,  1.0373,  1.0568]],\n",
      "\n",
      "         [[-0.5281, -0.6002, -0.6975, -0.7334, -0.7637],\n",
      "          [-0.5984, -0.6720, -0.7620, -0.7820, -0.7712],\n",
      "          [-0.6225, -0.7322, -0.8824, -0.9364, -0.9580],\n",
      "          [-0.5888, -0.7549, -0.9659, -1.0373, -1.0568]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.6898,  0.8522,  0.9392,  1.0753,  1.2631],\n",
      "          [ 0.8295,  0.9844,  1.0116,  1.1745,  1.3996],\n",
      "          [ 0.9000,  1.0466,  1.0666,  1.2684,  1.5067],\n",
      "          [ 0.9207,  1.0906,  1.1470,  1.3877,  1.6210]],\n",
      "\n",
      "         [[-0.6899, -0.8522, -0.9392, -1.0753, -1.2631],\n",
      "          [-0.8295, -0.9843, -1.0116, -1.1744, -1.3995],\n",
      "          [-0.9001, -1.0466, -1.0665, -1.2683, -1.5066],\n",
      "          [-0.9207, -1.0905, -1.1470, -1.3876, -1.6209]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5497,  0.6714,  0.7547,  0.7246,  0.6515],\n",
      "          [ 0.6075,  0.7347,  0.8423,  0.8314,  0.7872],\n",
      "          [ 0.6479,  0.8087,  0.9943,  0.9927,  0.9605],\n",
      "          [ 0.6674,  0.8033,  0.9692,  0.9341,  0.8624]],\n",
      "\n",
      "         [[-0.5497, -0.6714, -0.7547, -0.7246, -0.6515],\n",
      "          [-0.6076, -0.7347, -0.8422, -0.8314, -0.7872],\n",
      "          [-0.6480, -0.8086, -0.9943, -0.9927, -0.9605],\n",
      "          [-0.6674, -0.8032, -0.9691, -0.9340, -0.8624]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.5375,  1.9375,  2.2905,  2.4271,  2.5224],\n",
      "          [ 1.9237,  2.2392,  2.5709,  2.7411,  2.9279],\n",
      "          [ 2.2188,  2.5713,  2.9680,  3.1867,  3.4071],\n",
      "          [ 2.3865,  2.7871,  3.2301,  3.4513,  3.6463]],\n",
      "\n",
      "         [[-1.5375, -1.9375, -2.2904, -2.4270, -2.5223],\n",
      "          [-1.9237, -2.2390, -2.5707, -2.7409, -2.9277],\n",
      "          [-2.2187, -2.5711, -2.9678, -3.1864, -3.4069],\n",
      "          [-2.3864, -2.7868, -3.2298, -3.4510, -3.6460]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.4382,  0.3794,  0.2107, -0.0806, -0.3747],\n",
      "          [ 0.4488,  0.2810,  0.0302, -0.2924, -0.5954],\n",
      "          [ 0.4421,  0.1474, -0.1596, -0.4771, -0.7716],\n",
      "          [ 0.5803,  0.2848, -0.0244, -0.3397, -0.6371]],\n",
      "\n",
      "         [[-0.4383, -0.3794, -0.2107,  0.0806,  0.3747],\n",
      "          [-0.4488, -0.2809, -0.0301,  0.2925,  0.5956],\n",
      "          [-0.4421, -0.1473,  0.1597,  0.4772,  0.7718],\n",
      "          [-0.5803, -0.2848,  0.0245,  0.3398,  0.6372]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 1 1]\n",
      " [0 0 0 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 0 1 1 1]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 0.5756,  0.6586,  0.7078,  0.7064,  0.7410],\n",
      "          [ 0.6069,  0.7120,  0.7918,  0.8645,  0.9745],\n",
      "          [ 0.6301,  0.7921,  0.9204,  1.0556,  1.2276],\n",
      "          [ 0.6926,  0.8992,  1.0126,  1.1271,  1.3008]],\n",
      "\n",
      "         [[-0.5757, -0.6586, -0.7078, -0.7064, -0.7410],\n",
      "          [-0.6070, -0.7119, -0.7917, -0.8644, -0.9744],\n",
      "          [-0.6301, -0.7920, -0.9202, -1.0554, -1.2275],\n",
      "          [-0.6926, -0.8991, -1.0125, -1.1269, -1.3006]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "shape of output: torch.Size([1, 2, 256, 256]) <class 'torch.Tensor'>\n",
      "output: tensor([[[[ 1.0591,  1.3159,  1.5162,  1.6493,  1.7756],\n",
      "          [ 1.2699,  1.4481,  1.6110,  1.7757,  1.9536],\n",
      "          [ 1.3585,  1.4554,  1.6190,  1.8242,  2.0340],\n",
      "          [ 1.4775,  1.6441,  1.9125,  2.2008,  2.4626]],\n",
      "\n",
      "         [[-1.0591, -1.3159, -1.5162, -1.6493, -1.7756],\n",
      "          [-1.2699, -1.4480, -1.6109, -1.7755, -1.9535],\n",
      "          [-1.3584, -1.4553, -1.6189, -1.8240, -2.0339],\n",
      "          [-1.4775, -1.6440, -1.9124, -2.2006, -2.4625]]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "pred: [[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-b0da874fabaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#del data_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#torch.cuda.empty_cache()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-62cc4ae70851>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, optimizer, epochs, scheduler, weights, save_epoch)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-693a45f8d1ed>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m# Data augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mdata_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_augmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# Return the torch.Tensor values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-693a45f8d1ed>\u001b[0m in \u001b[0;36mdata_augmentation\u001b[1;34m(cls, flip, mirror, *arrays)\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(a, order)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m     \"\"\"\n\u001b[1;32m--> 792\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;31m# Basic operations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses, mean_losses = train(net, optimizer, 15, scheduler)\n",
    "#del data_p\n",
    "#torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(losses)\n",
    "INFERENCE_BATCH_SIZE = 34\n",
    "model_path = r'K:\\Research\\Jupyter_notebooks\\Unet_4layer_final_20190911.pth'\n",
    "#trained_net = net \n",
    "saved_path = r'I:\\NewYorkCity_sidewalks\\Inferenced'\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "img_list = [r'K:\\Research\\NJTPA\\NJ_images\\TIF\\DOM20156244.TIF', r'K:\\Research\\NJTPA\\NJ_images\\TIF\\DOM20156245.TIF', r'K:\\Research\\NJTPA\\NJ_images\\TIF\\DOM20156243.TIF']\n",
    "def inference(net, img_list, stride=WINDOW_SIZE[0], batch_size=INFERENCE_BATCH_SIZE, window_size=WINDOW_SIZE, prefix='', saved_path=None):\n",
    "    #(net, test_ids, all=False, stride=WINDOW_SIZE[0], batch_size=TEST_BATCH_SIZE, window_size=WINDOW_SIZE, prefix=None, saved_path=None):\n",
    "    \n",
    "    # Use the network on the test set\n",
    "    cnt = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    print('Number of Network Parameters: {}', cnt)\n",
    "    test_images = (1 / 255 * np.asarray(io.imread(img), dtype='float32') for img in img_list)\n",
    "    #test_labels = (np.asarray(io.imread(LABEL_FOLDER.format(id)), dtype='uint8') for id in test_ids)\n",
    "    # huan \n",
    "    # eroded_labels = (convert_from_color(io.imread(ERODED_FOLDER.format(id))) for id in test_ids)\n",
    "    #eroded_labels = ((io.imread(ERODED_FOLDER.format(id))) for id in test_ids)\n",
    "    \n",
    "    all_preds = []\n",
    "    #all_gts = []\n",
    "    \n",
    "    # Switch the network to inference mode\n",
    "    #net = torch.nn.DataParallel(net)\n",
    "    net.eval()\n",
    "    \n",
    "    id_index = 0\n",
    "    \n",
    "    # huan tqdm is a progress bar for notebook.  zipped:      zipped((1,2),(3,4)) = ((1,3), (2,4))\n",
    "    for img in tqdm(test_images, total=len(img_list), leave=False):\n",
    "        pred = np.zeros(img.shape[:2] + (N_CLASSES,))        \n",
    "        print('Processing image: {}'.format(img_list[id_index]))\n",
    "\n",
    "        total = count_sliding_window(img, step=stride, window_size=window_size) // batch_size\n",
    "        for i, coords in enumerate(tqdm(grouper(batch_size, sliding_window(img, step=stride, window_size=window_size)), total=total, leave=False)):\n",
    "            # Display in progress results\n",
    "#             if i > 0 and total > 10 and i % int(10 * total / 100) == 0:\n",
    "#                     _pred = np.argmax(pred, axis=-1)\n",
    "#                     fig = plt.figure(figsize=(256, 256))\n",
    "#                     fig.add_subplot(1,3,1)\n",
    "#                     plt.imshow(np.asarray(255 * img, dtype='uint8'))\n",
    "#                     fig.add_subplot(1,3,2)\n",
    "#                     plt.imshow(convert_to_color(_pred))\n",
    "#                     fig.add_subplot(1,3,3)\n",
    "#                     plt.imshow(gt)\n",
    "#                     clear_output()\n",
    "#                     plt.show()\n",
    "                     \n",
    "\n",
    "            # Build the tensor\n",
    "            torch.no_grad()\n",
    "            image_patches = [np.copy(img[x:x+w, y:y+h]).transpose((2,0,1)) for x,y,w,h in coords]\n",
    "            image_patches = np.asarray(image_patches)\n",
    "            #image_patches = Variable(torch.from_numpy(image_patches).cuda(), volatile=torch.no_grad())\n",
    "            image_patches = Variable(torch.from_numpy(image_patches).cuda())\n",
    "            \n",
    "            # Do the inference\n",
    "            outs = net(image_patches)\n",
    "\n",
    "            outs = outs.data.cpu().numpy()\n",
    "            \n",
    "            # Fill in the results array\n",
    "            for out, (x, y, w, h) in zip(outs, coords):\n",
    "                out = out.transpose((1,2,0))\n",
    "                pred[x:x+w, y:y+h] += out\n",
    "            del(outs)\n",
    "\n",
    "        pred = np.argmax(pred, axis=-1)\n",
    "\n",
    "        # Display the result\n",
    "        #clear_output()\n",
    "#         fig = plt.figure(figsize=(256, 256))\n",
    "#         fig.add_subplot(1,3,1)\n",
    "#         plt.imshow(np.asarray(255 * img, dtype='uint8'))\n",
    "#         fig.add_subplot(1,3,2)\n",
    "#         plt.imshow(convert_to_color(pred))\n",
    "#         fig.add_subplot(1,3,3)\n",
    "#         plt.imshow(convert_to_color(gt))\n",
    "#         plt.show()\n",
    "\n",
    "        #all_preds.append(pred)\n",
    "        #all_gts.append(gt_e)\n",
    "\n",
    "        #clear_output()\n",
    "        accuracy = 0\n",
    "        # Compute some metrics\n",
    "        #metrics(pred.ravel(), gt_e.ravel(), Label_values)\n",
    "        #report_path = os.path.join(saved_path, prefix + '_test_report_{}.txt'.format(test_ids[id_index]))\n",
    "        #accuracy = metrics(np.concatenate([p.ravel() for p in all_preds]), np.concatenate([p.ravel() for p in all_gts]).ravel(), Label_values, report_path)\n",
    "        #accuracy =  metrics(pred.ravel(), gt_e.ravel(), Label_values, report_path)\n",
    "        #metrics(np.concatenate([p.ravel() for p in all_preds]), np.concatenate([p.ravel() for p in all_gts]).ravel(), Label_values)\n",
    "        #img = convert_to_color(pred)\n",
    "        #plt.imshow(img) and plt.show()\n",
    "        #io.imsave('./{}_100tiles.png'.format(test_ids[id_index]), img)\n",
    "        io.imsave(os.path.join(saved_path, '{}{}.png'.format(prefix,os.path.basename(img_list[id_index][:-4]))), pred)\n",
    "        #print('Result was saved: {}'.format(test_ids[id_index]))\n",
    "        \n",
    "        io.imsave(os.path.join(saved_path, '{}{}_color.png'.format(prefix,os.path.basename(img_list[id_index][:-4]))), convert_to_color(pred))\n",
    "        #print('Result was saved: {}'.format(img_list[id_index]))\n",
    "        \n",
    "        id_index = id_index + 1\n",
    "        \n",
    "    #report_path = os.path.join(saved_path, prefix + '_test_report_all.txt')    \n",
    "    #accuracy = metrics(np.concatenate([p.ravel() for p in all_preds]), np.concatenate([p.ravel() for p in all_gts]).ravel(), Label_values, report_path)\n",
    "            \n",
    "#     if all:\n",
    "#         return accuracy, all_preds, all_gts\n",
    "#     else:\n",
    "#         return accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Network Parameters: {} 7783554\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: I:\\NewYorkCity_sidewalks\\Images\\0.TIF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.8015,  1.0032,  1.1095,  ...,  0.9864,  0.8934,  0.7494],\n",
      "          [ 1.0253,  1.2347,  1.3156,  ...,  1.1854,  1.0962,  0.9626],\n",
      "          [ 1.1576,  1.3259,  1.3850,  ...,  1.2740,  1.1749,  1.0768],\n",
      "          ...,\n",
      "          [ 1.3406,  1.5708,  1.7222,  ...,  2.7832,  2.3929,  2.1072],\n",
      "          [ 1.1751,  1.3899,  1.5023,  ...,  2.3589,  2.0283,  1.7622],\n",
      "          [ 0.9866,  1.2346,  1.3699,  ...,  2.0725,  1.7605,  1.4070]],\n",
      "\n",
      "         [[-0.8016, -1.0033, -1.1096,  ..., -0.9864, -0.8934, -0.7495],\n",
      "          [-1.0254, -1.2347, -1.3155,  ..., -1.1853, -1.0961, -0.9626],\n",
      "          [-1.1576, -1.3258, -1.3848,  ..., -1.2738, -1.1748, -1.0768],\n",
      "          ...,\n",
      "          [-1.3406, -1.5707, -1.7221,  ..., -2.7829, -2.3926, -2.1071],\n",
      "          [-1.1751, -1.3899, -1.5022,  ..., -2.3586, -2.0281, -1.7621],\n",
      "          [-0.9867, -1.2346, -1.3699,  ..., -2.0724, -1.7604, -1.4071]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7980,  0.9901,  1.0877,  ...,  1.1407,  1.0631,  0.8691],\n",
      "          [ 1.0217,  1.2154,  1.2864,  ...,  1.2350,  1.1768,  1.0444],\n",
      "          [ 1.1232,  1.2637,  1.3214,  ...,  1.1327,  1.1070,  1.0710],\n",
      "          ...,\n",
      "          [ 2.1928,  2.4771,  2.9305,  ...,  1.6761,  1.5250,  1.3407],\n",
      "          [ 1.8161,  2.0669,  2.4509,  ...,  1.5947,  1.4416,  1.2276],\n",
      "          [ 1.4769,  1.8431,  2.1922,  ...,  1.4512,  1.2833,  1.0196]],\n",
      "\n",
      "         [[-0.7981, -0.9901, -1.0877,  ..., -1.1407, -1.0632, -0.8692],\n",
      "          [-1.0217, -1.2153, -1.2864,  ..., -1.2349, -1.1767, -1.0444],\n",
      "          [-1.1232, -1.2636, -1.3213,  ..., -1.1325, -1.1069, -1.0710],\n",
      "          ...,\n",
      "          [-2.1927, -2.4769, -2.9303,  ..., -1.6759, -1.5249, -1.3407],\n",
      "          [-1.8161, -2.0668, -2.4507,  ..., -1.5946, -1.4415, -1.2276],\n",
      "          [-1.4769, -1.8430, -2.1921,  ..., -1.4511, -1.2833, -1.0197]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9555,  1.2188,  1.3993,  ...,  1.6136,  1.4056,  1.1215],\n",
      "          [ 1.2374,  1.4916,  1.6213,  ...,  1.7259,  1.5794,  1.3983],\n",
      "          [ 1.3298,  1.5260,  1.6406,  ...,  1.7393,  1.6483,  1.5545],\n",
      "          ...,\n",
      "          [ 1.1649,  1.2840,  1.3355,  ...,  2.3732,  2.0333,  1.8022],\n",
      "          [ 1.1049,  1.2938,  1.3709,  ...,  2.0741,  1.7640,  1.5289],\n",
      "          [ 0.9404,  1.1750,  1.2592,  ...,  1.7710,  1.5078,  1.2202]],\n",
      "\n",
      "         [[-0.9555, -1.2188, -1.3993,  ..., -1.6136, -1.4056, -1.1215],\n",
      "          [-1.2374, -1.4915, -1.6212,  ..., -1.7257, -1.5793, -1.3982],\n",
      "          [-1.3298, -1.5258, -1.6405,  ..., -1.7391, -1.6482, -1.5545],\n",
      "          ...,\n",
      "          [-1.1649, -1.2839, -1.3354,  ..., -2.3730, -2.0332, -1.8021],\n",
      "          [-1.1050, -1.2937, -1.3708,  ..., -2.0740, -1.7639, -1.5289],\n",
      "          [-0.9405, -1.1750, -1.2592,  ..., -1.7710, -1.5078, -1.2202]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.5080, -0.8059, -1.0916,  ...,  0.6910,  0.6403,  0.5429],\n",
      "          [-0.6458, -0.8816, -1.1943,  ...,  0.7803,  0.7448,  0.6504],\n",
      "          [-0.7276, -1.0123, -1.3610,  ...,  0.8069,  0.7666,  0.6862],\n",
      "          ...,\n",
      "          [ 1.6557,  1.8632,  2.0782,  ...,  0.7775,  0.7722,  0.7416],\n",
      "          [ 1.4464,  1.6891,  1.9042,  ...,  1.0190,  0.9562,  0.8256],\n",
      "          [ 1.1745,  1.4762,  1.7006,  ...,  1.0996,  1.0028,  0.8079]],\n",
      "\n",
      "         [[ 0.5079,  0.8058,  1.0916,  ..., -0.6910, -0.6403, -0.5430],\n",
      "          [ 0.6457,  0.8816,  1.1944,  ..., -0.7801, -0.7447, -0.6504],\n",
      "          [ 0.7276,  1.0123,  1.3611,  ..., -0.8068, -0.7665, -0.6862],\n",
      "          ...,\n",
      "          [-1.6557, -1.8631, -2.0780,  ..., -0.7774, -0.7721, -0.7416],\n",
      "          [-1.4464, -1.6890, -1.9040,  ..., -1.0189, -0.9561, -0.8256],\n",
      "          [-1.1745, -1.4762, -1.7006,  ..., -1.0996, -1.0028, -0.8080]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7230,  0.8532,  1.0238,  ...,  0.2569,  0.2798,  0.2661],\n",
      "          [ 0.8481,  0.9194,  1.0810,  ...,  0.3138,  0.3261,  0.2723],\n",
      "          [ 0.8615,  0.8663,  1.0593,  ...,  0.3698,  0.3520,  0.2768],\n",
      "          ...,\n",
      "          [ 0.7327,  0.9548,  1.1330,  ..., -0.3737, -0.2507, -0.1726],\n",
      "          [ 0.7393,  0.9331,  1.0490,  ..., -0.3761, -0.2225, -0.1206],\n",
      "          [ 0.6540,  0.8273,  0.9380,  ..., -0.3419, -0.1681, -0.0259]],\n",
      "\n",
      "         [[-0.7231, -0.8533, -1.0238,  ..., -0.2569, -0.2798, -0.2662],\n",
      "          [-0.8482, -0.9194, -1.0809,  ..., -0.3137, -0.3260, -0.2724],\n",
      "          [-0.8615, -0.8662, -1.0592,  ..., -0.3697, -0.3520, -0.2768],\n",
      "          ...,\n",
      "          [-0.7327, -0.9547, -1.1329,  ...,  0.3738,  0.2507,  0.1725],\n",
      "          [-0.7393, -0.9330, -1.0489,  ...,  0.3762,  0.2225,  0.1205],\n",
      "          [-0.6541, -0.8273, -0.9380,  ...,  0.3419,  0.1680,  0.0258]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5260,  0.6138,  0.6350,  ...,  0.9981,  0.8743,  0.6758],\n",
      "          [ 0.5806,  0.6725,  0.7042,  ...,  1.1547,  1.0232,  0.8187],\n",
      "          [ 0.5881,  0.6774,  0.7606,  ...,  1.1719,  1.0544,  0.8931],\n",
      "          ...,\n",
      "          [ 0.5045,  0.6539,  0.7115,  ...,  1.1867,  1.0520,  0.8368],\n",
      "          [ 0.4558,  0.5143,  0.4971,  ...,  1.2240,  1.0768,  0.8538],\n",
      "          [ 0.3629,  0.3360,  0.2960,  ...,  1.0645,  0.9378,  0.7407]],\n",
      "\n",
      "         [[-0.5261, -0.6139, -0.6350,  ..., -0.9981, -0.8743, -0.6758],\n",
      "          [-0.5806, -0.6724, -0.7041,  ..., -1.1546, -1.0230, -0.8187],\n",
      "          [-0.5881, -0.6773, -0.7605,  ..., -1.1717, -1.0542, -0.8931],\n",
      "          ...,\n",
      "          [-0.5046, -0.6538, -0.7114,  ..., -1.1866, -1.0519, -0.8369],\n",
      "          [-0.4558, -0.5142, -0.4970,  ..., -1.2239, -1.0767, -0.8538],\n",
      "          [-0.3630, -0.3360, -0.2960,  ..., -1.0645, -0.9379, -0.7408]]]],\n",
      "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[[ 0.7172,  0.8800,  0.9384,  ...,  0.8664,  0.7860,  0.6784],\n",
      "          [ 0.7692,  0.9071,  0.9347,  ...,  0.9147,  0.8735,  0.8165],\n",
      "          [ 0.7376,  0.8505,  0.8960,  ...,  0.9763,  0.9862,  0.9571],\n",
      "          ...,\n",
      "          [-0.5514, -0.7124, -0.8635,  ..., -0.2747, -0.1782, -0.2037],\n",
      "          [-0.3937, -0.5611, -0.7763,  ..., -0.2811, -0.1043, -0.1141],\n",
      "          [-0.2544, -0.4618, -0.6707,  ..., -0.2324, -0.0758, -0.0199]],\n",
      "\n",
      "         [[-0.7173, -0.8800, -0.9384,  ..., -0.8664, -0.7860, -0.6784],\n",
      "          [-0.7692, -0.9070, -0.9346,  ..., -0.9146, -0.8734, -0.8165],\n",
      "          [-0.7376, -0.8504, -0.8959,  ..., -0.9762, -0.9861, -0.9571],\n",
      "          ...,\n",
      "          [ 0.5514,  0.7125,  0.8636,  ...,  0.2747,  0.1783,  0.2037],\n",
      "          [ 0.3937,  0.5612,  0.7764,  ...,  0.2811,  0.1043,  0.1140],\n",
      "          [ 0.2543,  0.4618,  0.6707,  ...,  0.2324,  0.0757,  0.0198]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9033,  1.1174,  1.2931,  ...,  1.4829,  1.2704,  0.9979],\n",
      "          [ 1.0789,  1.2378,  1.3641,  ...,  1.6260,  1.4308,  1.2005],\n",
      "          [ 1.1868,  1.3196,  1.4272,  ...,  1.7604,  1.5768,  1.3594],\n",
      "          ...,\n",
      "          [ 0.6521,  0.8761,  1.1111,  ...,  0.3762,  0.3832,  0.4042],\n",
      "          [ 0.6295,  0.8269,  1.0061,  ...,  0.4471,  0.4916,  0.4769],\n",
      "          [ 0.5737,  0.7194,  0.8333,  ...,  0.5066,  0.5420,  0.4958]],\n",
      "\n",
      "         [[-0.9033, -1.1174, -1.2930,  ..., -1.4828, -1.2704, -0.9980],\n",
      "          [-1.0789, -1.2377, -1.3639,  ..., -1.6258, -1.4307, -1.2005],\n",
      "          [-1.1868, -1.3195, -1.4271,  ..., -1.7602, -1.5767, -1.3594],\n",
      "          ...,\n",
      "          [-0.6521, -0.8760, -1.1110,  ..., -0.3762, -0.3832, -0.4042],\n",
      "          [-0.6295, -0.8269, -1.0061,  ..., -0.4471, -0.4916, -0.4770],\n",
      "          [-0.5738, -0.7194, -0.8333,  ..., -0.5067, -0.5421, -0.4959]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8099,  1.0263,  1.2453,  ...,  0.8003,  0.6671,  0.4785],\n",
      "          [ 1.0096,  1.1997,  1.3914,  ...,  0.9032,  0.7832,  0.5682],\n",
      "          [ 1.1312,  1.3167,  1.5415,  ...,  0.8750,  0.7633,  0.5969],\n",
      "          ...,\n",
      "          [ 0.8669,  0.9761,  1.0715,  ...,  3.0308,  2.7321,  2.3737],\n",
      "          [ 0.8776,  1.0465,  1.1766,  ...,  2.7775,  2.4023,  2.0440],\n",
      "          [ 0.7974,  1.0305,  1.2029,  ...,  2.4263,  2.0347,  1.5893]],\n",
      "\n",
      "         [[-0.8099, -1.0263, -1.2453,  ..., -0.8003, -0.6672, -0.4786],\n",
      "          [-1.0096, -1.1996, -1.3913,  ..., -0.9031, -0.7832, -0.5682],\n",
      "          [-1.1312, -1.3166, -1.5414,  ..., -0.8750, -0.7632, -0.5969],\n",
      "          ...,\n",
      "          [-0.8669, -0.9761, -1.0714,  ..., -3.0305, -2.7319, -2.3736],\n",
      "          [-0.8777, -1.0465, -1.1766,  ..., -2.7773, -2.4022, -2.0440],\n",
      "          [-0.7975, -1.0305, -1.2029,  ..., -2.4262, -2.0346, -1.5893]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.7092, -0.9457, -1.0477,  ...,  1.6054,  1.4362,  1.1354],\n",
      "          [-0.9157, -0.9974, -1.1077,  ...,  1.7079,  1.6079,  1.3911],\n",
      "          [-1.1327, -1.1986, -1.2327,  ...,  1.6868,  1.6443,  1.5096],\n",
      "          ...,\n",
      "          [-1.0188, -1.2432, -1.4039,  ...,  1.0501,  0.8941,  0.9286],\n",
      "          [-0.7819, -0.9686, -1.1570,  ...,  0.8333,  0.7911,  0.8859],\n",
      "          [-0.4926, -0.7446, -0.9303,  ...,  0.9250,  0.8660,  0.8362]],\n",
      "\n",
      "         [[ 0.7092,  0.9457,  1.0476,  ..., -1.6054, -1.4362, -1.1354],\n",
      "          [ 0.9157,  0.9975,  1.1078,  ..., -1.7078, -1.6078, -1.3911],\n",
      "          [ 1.1328,  1.1987,  1.2328,  ..., -1.6867, -1.6442, -1.5096],\n",
      "          ...,\n",
      "          [ 1.0188,  1.2432,  1.4040,  ..., -1.0500, -0.8940, -0.9286],\n",
      "          [ 0.7819,  0.9687,  1.1571,  ..., -0.8332, -0.7910, -0.8859],\n",
      "          [ 0.4925,  0.7446,  0.9303,  ..., -0.9250, -0.8660, -0.8363]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2285,  1.5384,  1.8119,  ...,  0.8223,  0.7464,  0.6466],\n",
      "          [ 1.5502,  1.7901,  2.0053,  ...,  0.7874,  0.7259,  0.6793],\n",
      "          [ 1.7525,  1.9569,  2.1608,  ...,  0.8191,  0.7422,  0.7060],\n",
      "          ...,\n",
      "          [ 1.3885,  1.4283,  1.5440,  ...,  0.0106,  0.1133,  0.1812],\n",
      "          [ 1.3043,  1.3887,  1.4651,  ..., -0.0496,  0.0837,  0.1804],\n",
      "          [ 1.0755,  1.2797,  1.4118,  ..., -0.0603,  0.0834,  0.1882]],\n",
      "\n",
      "         [[-1.2286, -1.5383, -1.8118,  ..., -0.8223, -0.7464, -0.6467],\n",
      "          [-1.5502, -1.7899, -2.0052,  ..., -0.7873, -0.7259, -0.6793],\n",
      "          [-1.7525, -1.9568, -2.1606,  ..., -0.8189, -0.7421, -0.7060],\n",
      "          ...,\n",
      "          [-1.3885, -1.4283, -1.5439,  ..., -0.0106, -0.1132, -0.1813],\n",
      "          [-1.3043, -1.3886, -1.4650,  ...,  0.0496, -0.0837, -0.1804],\n",
      "          [-1.0755, -1.2797, -1.4118,  ...,  0.0603, -0.0835, -0.1883]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9355,  1.1201,  1.1867,  ...,  1.4684,  1.2758,  1.0138],\n",
      "          [ 1.0062,  1.0732,  1.0873,  ...,  1.5015,  1.3499,  1.1813],\n",
      "          [ 1.0115,  1.0215,  1.0424,  ...,  1.5981,  1.4323,  1.3077],\n",
      "          ...,\n",
      "          [ 0.9220,  1.0308,  1.1813,  ...,  0.8901,  0.8563,  0.8969],\n",
      "          [ 0.8481,  0.9440,  1.0668,  ...,  1.0458,  0.9405,  0.8760],\n",
      "          [ 0.7229,  0.8495,  0.9595,  ...,  1.0462,  0.9086,  0.7638]],\n",
      "\n",
      "         [[-0.9356, -1.1202, -1.1867,  ..., -1.4684, -1.2758, -1.0139],\n",
      "          [-1.0063, -1.0731, -1.0872,  ..., -1.5014, -1.3498, -1.1813],\n",
      "          [-1.0115, -1.0215, -1.0423,  ..., -1.5979, -1.4322, -1.3077],\n",
      "          ...,\n",
      "          [-0.9220, -1.0307, -1.1812,  ..., -0.8898, -0.8561, -0.8969],\n",
      "          [-0.8481, -0.9439, -1.0667,  ..., -1.0456, -0.9403, -0.8760],\n",
      "          [-0.7230, -0.8495, -0.9595,  ..., -1.0462, -0.9085, -0.7638]]]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[[ 1.1170,  1.3544,  1.5443,  ...,  1.1159,  0.9369,  0.7263],\n",
      "          [ 1.3135,  1.4152,  1.5368,  ...,  1.2378,  1.0449,  0.8492],\n",
      "          [ 1.4208,  1.4722,  1.5824,  ...,  1.3167,  1.0850,  0.9016],\n",
      "          ...,\n",
      "          [ 0.0573,  0.2731,  0.6086,  ...,  1.3626,  1.2455,  1.0272],\n",
      "          [ 0.1116,  0.2500,  0.4665,  ...,  1.1011,  1.0314,  0.8805],\n",
      "          [ 0.1647,  0.2012,  0.3080,  ...,  0.8089,  0.7516,  0.6530]],\n",
      "\n",
      "         [[-1.1171, -1.3544, -1.5443,  ..., -1.1159, -0.9369, -0.7264],\n",
      "          [-1.3135, -1.4152, -1.5367,  ..., -1.2377, -1.0448, -0.8492],\n",
      "          [-1.4208, -1.4721, -1.5823,  ..., -1.3165, -1.0848, -0.9016],\n",
      "          ...,\n",
      "          [-0.0573, -0.2729, -0.6084,  ..., -1.3625, -1.2454, -1.0273],\n",
      "          [-0.1116, -0.2499, -0.4664,  ..., -1.1010, -1.0313, -0.8805],\n",
      "          [-0.1648, -0.2012, -0.3079,  ..., -0.8090, -0.7516, -0.6531]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9476,  1.0878,  1.1572,  ...,  1.7000,  1.4665,  1.1323],\n",
      "          [ 1.1768,  1.2198,  1.1934,  ...,  1.9271,  1.6930,  1.4072],\n",
      "          [ 1.3625,  1.3721,  1.3325,  ...,  2.0431,  1.8159,  1.5760],\n",
      "          ...,\n",
      "          [ 1.1466,  1.1878,  1.2285,  ...,  0.7637,  0.7980,  0.8356],\n",
      "          [ 0.9929,  1.0560,  1.0800,  ...,  0.7319,  0.7486,  0.7410],\n",
      "          [ 0.7407,  0.8248,  0.8615,  ...,  0.7282,  0.7134,  0.6449]],\n",
      "\n",
      "         [[-0.9477, -1.0878, -1.1571,  ..., -1.7000, -1.4666, -1.1323],\n",
      "          [-1.1767, -1.2197, -1.1932,  ..., -1.9270, -1.6929, -1.4072],\n",
      "          [-1.3625, -1.3719, -1.3323,  ..., -2.0430, -1.8158, -1.5759],\n",
      "          ...,\n",
      "          [-1.1466, -1.1877, -1.2284,  ..., -0.7636, -0.7979, -0.8356],\n",
      "          [-0.9929, -1.0560, -1.0799,  ..., -0.7319, -0.7485, -0.7410],\n",
      "          [-0.7408, -0.8248, -0.8615,  ..., -0.7282, -0.7135, -0.6450]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9254,  1.1529,  1.2870,  ..., -0.2239, -0.0305,  0.0132],\n",
      "          [ 1.1738,  1.3993,  1.5030,  ...,  0.0944,  0.1681,  0.0706],\n",
      "          [ 1.3032,  1.5431,  1.6730,  ...,  0.4260,  0.3672,  0.2044],\n",
      "          ...,\n",
      "          [ 0.9598,  1.0538,  1.1235,  ...,  1.6326,  1.3177,  1.1219],\n",
      "          [ 0.8889,  0.9771,  1.0347,  ...,  1.5259,  1.2123,  1.0025],\n",
      "          [ 0.7769,  0.9009,  0.9675,  ...,  1.3764,  1.0826,  0.8389]],\n",
      "\n",
      "         [[-0.9255, -1.1529, -1.2870,  ...,  0.2238,  0.0304, -0.0133],\n",
      "          [-1.1739, -1.3992, -1.5030,  ..., -0.0943, -0.1680, -0.0707],\n",
      "          [-1.3033, -1.5430, -1.6729,  ..., -0.4259, -0.3671, -0.2044],\n",
      "          ...,\n",
      "          [-0.9598, -1.0537, -1.1234,  ..., -1.6324, -1.3175, -1.1219],\n",
      "          [-0.8890, -0.9771, -1.0346,  ..., -1.5257, -1.2122, -1.0025],\n",
      "          [-0.7770, -0.9010, -0.9675,  ..., -1.3764, -1.0826, -0.8389]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.6199,  2.0140,  2.3631,  ...,  1.5255,  1.3183,  1.0521],\n",
      "          [ 2.0318,  2.2831,  2.5855,  ...,  1.7842,  1.5435,  1.3138],\n",
      "          [ 2.3339,  2.5616,  2.8831,  ...,  1.9895,  1.6986,  1.5004],\n",
      "          ...,\n",
      "          [ 0.0260,  0.0215, -0.0460,  ...,  0.8515,  0.7720,  0.7749],\n",
      "          [ 0.0481,  0.0713, -0.0366,  ...,  0.7976,  0.7591,  0.7602],\n",
      "          [ 0.0747,  0.0638, -0.0389,  ...,  0.7443,  0.7347,  0.6854]],\n",
      "\n",
      "         [[-1.6199, -2.0140, -2.3630,  ..., -1.5254, -1.3183, -1.0521],\n",
      "          [-2.0318, -2.2830, -2.5852,  ..., -1.7840, -1.5434, -1.3138],\n",
      "          [-2.3338, -2.5614, -2.8828,  ..., -1.9893, -1.6985, -1.5004],\n",
      "          ...,\n",
      "          [-0.0260, -0.0214,  0.0461,  ..., -0.8513, -0.7718, -0.7749],\n",
      "          [-0.0482, -0.0712,  0.0367,  ..., -0.7974, -0.7590, -0.7602],\n",
      "          [-0.0748, -0.0638,  0.0389,  ..., -0.7442, -0.7347, -0.6854]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0568,  1.3975,  1.6444,  ..., -0.2918, -0.2208, -0.1470],\n",
      "          [ 1.2470,  1.5114,  1.7108,  ..., -0.3527, -0.3270, -0.3261],\n",
      "          [ 1.3690,  1.5977,  1.7894,  ..., -0.4873, -0.5271, -0.5325],\n",
      "          ...,\n",
      "          [ 0.4724,  0.5924,  0.7772,  ...,  1.1451,  0.9859,  0.8851],\n",
      "          [ 0.4852,  0.5834,  0.6870,  ...,  1.1247,  0.9655,  0.8565],\n",
      "          [ 0.4465,  0.5047,  0.5595,  ...,  1.1108,  0.9406,  0.7821]],\n",
      "\n",
      "         [[-1.0569, -1.3975, -1.6444,  ...,  0.2919,  0.2208,  0.1469],\n",
      "          [-1.2470, -1.5113, -1.7107,  ...,  0.3529,  0.3271,  0.3260],\n",
      "          [-1.3690, -1.5976, -1.7893,  ...,  0.4875,  0.5272,  0.5325],\n",
      "          ...,\n",
      "          [-0.4724, -0.5923, -0.7770,  ..., -1.1449, -0.9858, -0.8851],\n",
      "          [-0.4852, -0.5833, -0.6868,  ..., -1.1246, -0.9654, -0.8565],\n",
      "          [-0.4466, -0.5047, -0.5594,  ..., -1.1107, -0.9406, -0.7822]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4763,  0.5722,  0.6489,  ...,  0.2283,  0.1691,  0.1257],\n",
      "          [ 0.3523,  0.3624,  0.3771,  ...,  0.3191,  0.2117,  0.1159],\n",
      "          [ 0.1366,  0.0531,  0.0423,  ...,  0.3404,  0.2159,  0.1464],\n",
      "          ...,\n",
      "          [ 1.3283,  1.5293,  1.6772,  ...,  1.0476,  0.8621,  0.7476],\n",
      "          [ 1.1972,  1.4458,  1.6288,  ...,  0.9044,  0.7772,  0.6947],\n",
      "          [ 0.9583,  1.2020,  1.3889,  ...,  0.8013,  0.7023,  0.6154]],\n",
      "\n",
      "         [[-0.4764, -0.5722, -0.6489,  ..., -0.2283, -0.1691, -0.1258],\n",
      "          [-0.3523, -0.3623, -0.3770,  ..., -0.3189, -0.2116, -0.1159],\n",
      "          [-0.1366, -0.0530, -0.0421,  ..., -0.3403, -0.2157, -0.1464],\n",
      "          ...,\n",
      "          [-1.3283, -1.5292, -1.6771,  ..., -1.0475, -0.8620, -0.7476],\n",
      "          [-1.1972, -1.4457, -1.6287,  ..., -0.9043, -0.7771, -0.6947],\n",
      "          [-0.9584, -1.2020, -1.3890,  ..., -0.8013, -0.7024, -0.6155]]]],\n",
      "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[[ 0.0800,  0.0541,  0.0370,  ..., -0.5719, -0.4588, -0.4173],\n",
      "          [ 0.0934,  0.1673,  0.2175,  ..., -0.4298, -0.4277, -0.5830],\n",
      "          [ 0.0982,  0.1955,  0.2894,  ..., -0.5481, -0.5964, -0.7021],\n",
      "          ...,\n",
      "          [ 0.0541,  0.1085,  0.4036,  ...,  2.3926,  2.2117,  1.9907],\n",
      "          [ 0.1196,  0.1635,  0.3564,  ...,  2.1012,  1.9013,  1.6833],\n",
      "          [ 0.2389,  0.2906,  0.4189,  ...,  1.9378,  1.6869,  1.3605]],\n",
      "\n",
      "         [[-0.0801, -0.0541, -0.0370,  ...,  0.5718,  0.4587,  0.4172],\n",
      "          [-0.0934, -0.1672, -0.2174,  ...,  0.4298,  0.4277,  0.5829],\n",
      "          [-0.0982, -0.1954, -0.2892,  ...,  0.5482,  0.5964,  0.7020],\n",
      "          ...,\n",
      "          [-0.0541, -0.1085, -0.4035,  ..., -2.3924, -2.2115, -1.9907],\n",
      "          [-0.1197, -0.1634, -0.3563,  ..., -2.1010, -1.9011, -1.6832],\n",
      "          [-0.2390, -0.2906, -0.4190,  ..., -1.9378, -1.6868, -1.3606]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4855,  0.4750,  0.4281,  ...,  1.6524,  1.4182,  1.0988],\n",
      "          [ 0.4925,  0.4185,  0.2602,  ...,  1.9394,  1.6997,  1.4133],\n",
      "          [ 0.4892,  0.4057,  0.1864,  ...,  2.1128,  1.8562,  1.6207],\n",
      "          ...,\n",
      "          [ 1.9355,  2.3194,  2.8451,  ...,  0.1464,  0.1392,  0.1804],\n",
      "          [ 1.6654,  2.0346,  2.4838,  ...,  0.1584,  0.1833,  0.2208],\n",
      "          [ 1.3309,  1.7398,  2.1258,  ...,  0.2305,  0.2461,  0.2590]],\n",
      "\n",
      "         [[-0.4856, -0.4751, -0.4281,  ..., -1.6524, -1.4182, -1.0989],\n",
      "          [-0.4925, -0.4184, -0.2601,  ..., -1.9393, -1.6996, -1.4133],\n",
      "          [-0.4892, -0.4057, -0.1863,  ..., -2.1126, -1.8561, -1.6207],\n",
      "          ...,\n",
      "          [-1.9354, -2.3192, -2.8448,  ..., -0.1463, -0.1391, -0.1804],\n",
      "          [-1.6654, -2.0344, -2.4836,  ..., -0.1583, -0.1832, -0.2209],\n",
      "          [-1.3310, -1.7398, -2.1258,  ..., -0.2305, -0.2461, -0.2591]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3982,  1.7571,  2.0755,  ...,  0.7776,  0.6596,  0.4707],\n",
      "          [ 1.7858,  2.0409,  2.3150,  ...,  0.9165,  0.8017,  0.5702],\n",
      "          [ 2.0326,  2.2158,  2.4866,  ...,  0.9028,  0.7902,  0.5935],\n",
      "          ...,\n",
      "          [ 0.4938,  0.5802,  0.6797,  ...,  1.3248,  1.2390,  1.0932],\n",
      "          [ 0.4728,  0.5392,  0.6204,  ...,  1.2143,  1.1292,  0.9556],\n",
      "          [ 0.4267,  0.5009,  0.6156,  ...,  1.0420,  0.9454,  0.7682]],\n",
      "\n",
      "         [[-1.3982, -1.7571, -2.0754,  ..., -0.7776, -0.6596, -0.4708],\n",
      "          [-1.7858, -2.0408, -2.3148,  ..., -0.9164, -0.8016, -0.5702],\n",
      "          [-2.0326, -2.2156, -2.4864,  ..., -0.9026, -0.7901, -0.5934],\n",
      "          ...,\n",
      "          [-0.4938, -0.5801, -0.6796,  ..., -1.3247, -1.2390, -1.0932],\n",
      "          [-0.4728, -0.5392, -0.6203,  ..., -1.2143, -1.1291, -0.9556],\n",
      "          [-0.4267, -0.5009, -0.6156,  ..., -1.0420, -0.9455, -0.7682]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.4333,  0.4679,  0.4930,  ...,  0.9674,  0.7892,  0.6127],\n",
      "          [ 0.3405,  0.3145,  0.2896,  ...,  1.0635,  0.9116,  0.7712],\n",
      "          [ 0.1474,  0.0606,  0.0054,  ...,  1.1763,  1.0598,  0.9753],\n",
      "          ...,\n",
      "          [ 1.2820,  1.2230,  1.1014,  ...,  0.3825,  0.2943,  0.2330],\n",
      "          [ 1.1236,  1.1368,  1.0574,  ...,  0.3166,  0.2758,  0.2368],\n",
      "          [ 0.9179,  1.0289,  1.0279,  ...,  0.2762,  0.2441,  0.2349]],\n",
      "\n",
      "         [[-0.4333, -0.4679, -0.4930,  ..., -0.9674, -0.7892, -0.6128],\n",
      "          [-0.3406, -0.3144, -0.2896,  ..., -1.0634, -0.9115, -0.7712],\n",
      "          [-0.1474, -0.0606, -0.0053,  ..., -1.1762, -1.0597, -0.9753],\n",
      "          ...,\n",
      "          [-1.2821, -1.2229, -1.1013,  ..., -0.3824, -0.2942, -0.2331],\n",
      "          [-1.1237, -1.1368, -1.0573,  ..., -0.3165, -0.2758, -0.2368],\n",
      "          [-0.9179, -1.0289, -1.0279,  ..., -0.2762, -0.2441, -0.2349]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0735,  1.3535,  1.6096,  ...,  1.5167,  1.3601,  1.1163],\n",
      "          [ 1.3613,  1.5776,  1.8216,  ...,  1.5793,  1.4782,  1.3516],\n",
      "          [ 1.5339,  1.7298,  1.9968,  ...,  1.6771,  1.6055,  1.5380],\n",
      "          ...,\n",
      "          [ 0.5328,  0.4441,  0.2060,  ...,  1.5495,  1.4893,  1.3729],\n",
      "          [ 0.5738,  0.5172,  0.3125,  ...,  1.4407,  1.3612,  1.2188],\n",
      "          [ 0.5619,  0.5773,  0.4815,  ...,  1.2763,  1.1723,  0.9842]],\n",
      "\n",
      "         [[-1.0735, -1.3536, -1.6096,  ..., -1.5167, -1.3601, -1.1164],\n",
      "          [-1.3613, -1.5776, -1.8215,  ..., -1.5791, -1.4781, -1.3516],\n",
      "          [-1.5339, -1.7297, -1.9966,  ..., -1.6770, -1.6054, -1.5380],\n",
      "          ...,\n",
      "          [-0.5328, -0.4440, -0.2059,  ..., -1.5493, -1.4892, -1.3729],\n",
      "          [-0.5739, -0.5171, -0.3124,  ..., -1.4405, -1.3611, -1.2188],\n",
      "          [-0.5620, -0.5774, -0.4815,  ..., -1.2763, -1.1723, -0.9843]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2086,  1.4893,  1.6803,  ...,  0.9322,  0.8769,  0.7231],\n",
      "          [ 1.4425,  1.5670,  1.6767,  ...,  1.0007,  0.9397,  0.8307],\n",
      "          [ 1.5768,  1.6236,  1.7311,  ...,  1.0055,  0.9521,  0.9064],\n",
      "          ...,\n",
      "          [ 0.5966,  0.5692,  0.6241,  ...,  2.2737,  2.0124,  1.7401],\n",
      "          [ 0.5786,  0.5621,  0.5964,  ...,  2.1399,  1.8534,  1.5323],\n",
      "          [ 0.5573,  0.5962,  0.6194,  ...,  1.8841,  1.6179,  1.2513]],\n",
      "\n",
      "         [[-1.2087, -1.4893, -1.6803,  ..., -0.9322, -0.8769, -0.7232],\n",
      "          [-1.4425, -1.5669, -1.6765,  ..., -1.0006, -0.9397, -0.8307],\n",
      "          [-1.5768, -1.6235, -1.7309,  ..., -1.0054, -0.9520, -0.9064],\n",
      "          ...,\n",
      "          [-0.5966, -0.5691, -0.6240,  ..., -2.2735, -2.0123, -1.7401],\n",
      "          [-0.5786, -0.5620, -0.5963,  ..., -2.1398, -1.8532, -1.5323],\n",
      "          [-0.5573, -0.5962, -0.6194,  ..., -1.8841, -1.6178, -1.2513]]]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[[ 0.8349,  1.0385,  1.2191,  ...,  1.5682,  1.3305,  1.0421],\n",
      "          [ 0.9955,  1.1455,  1.2457,  ...,  1.7306,  1.5348,  1.3017],\n",
      "          [ 1.0508,  1.1852,  1.2898,  ...,  1.8816,  1.6908,  1.4849],\n",
      "          ...,\n",
      "          [ 1.7524,  1.9748,  2.2012,  ...,  1.5823,  1.2914,  1.0876],\n",
      "          [ 1.5399,  1.8211,  2.0660,  ...,  1.3170,  1.0861,  0.9326],\n",
      "          [ 1.2242,  1.5563,  1.8043,  ...,  1.1588,  0.9758,  0.8004]],\n",
      "\n",
      "         [[-0.8349, -1.0385, -1.2191,  ..., -1.5682, -1.3305, -1.0421],\n",
      "          [-0.9956, -1.1455, -1.2456,  ..., -1.7304, -1.5347, -1.3017],\n",
      "          [-1.0508, -1.1852, -1.2897,  ..., -1.8815, -1.6906, -1.4848],\n",
      "          ...,\n",
      "          [-1.7523, -1.9747, -2.2010,  ..., -1.5821, -1.2913, -1.0875],\n",
      "          [-1.5399, -1.8210, -2.0659,  ..., -1.3168, -1.0860, -0.9326],\n",
      "          [-1.2242, -1.5563, -1.8042,  ..., -1.1587, -0.9758, -0.8005]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4680,  0.4463,  0.3557,  ...,  1.7217,  1.5186,  1.2778],\n",
      "          [ 0.4139,  0.3184,  0.1538,  ...,  1.7471,  1.6659,  1.5958],\n",
      "          [ 0.3055,  0.1935,  0.0427,  ...,  1.8770,  1.8418,  1.8403],\n",
      "          ...,\n",
      "          [ 1.3685,  1.5198,  1.7097,  ...,  1.8383,  1.5182,  1.2254],\n",
      "          [ 1.1588,  1.2905,  1.4431,  ...,  1.5210,  1.2561,  1.0106],\n",
      "          [ 0.9541,  1.1560,  1.3296,  ...,  1.1863,  0.9807,  0.7797]],\n",
      "\n",
      "         [[-0.4681, -0.4463, -0.3557,  ..., -1.7216, -1.5186, -1.2779],\n",
      "          [-0.4139, -0.3184, -0.1538,  ..., -1.7470, -1.6658, -1.5958],\n",
      "          [-0.3055, -0.1934, -0.0426,  ..., -1.8768, -1.8416, -1.8403],\n",
      "          ...,\n",
      "          [-1.3685, -1.5196, -1.7095,  ..., -1.8381, -1.5181, -1.2254],\n",
      "          [-1.1588, -1.2903, -1.4429,  ..., -1.5209, -1.2560, -1.0106],\n",
      "          [-0.9541, -1.1560, -1.3295,  ..., -1.1863, -0.9808, -0.7798]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2752,  1.5598,  1.8138,  ..., -0.1284, -0.1150, -0.0911],\n",
      "          [ 1.6225,  1.8103,  2.0092,  ..., -0.1990, -0.2239, -0.2483],\n",
      "          [ 1.8797,  2.0494,  2.2535,  ..., -0.3406, -0.4177, -0.4116],\n",
      "          ...,\n",
      "          [ 1.7143,  1.9979,  2.2346,  ...,  1.7883,  1.6265,  1.4585],\n",
      "          [ 1.5183,  1.7676,  1.9644,  ...,  1.5247,  1.3951,  1.2628],\n",
      "          [ 1.1632,  1.4172,  1.5997,  ...,  1.3000,  1.1745,  1.0104]],\n",
      "\n",
      "         [[-1.2752, -1.5598, -1.8137,  ...,  0.1284,  0.1150,  0.0910],\n",
      "          [-1.6225, -1.8102, -2.0091,  ...,  0.1992,  0.2240,  0.2483],\n",
      "          [-1.8796, -2.0492, -2.2533,  ...,  0.3408,  0.4178,  0.4116],\n",
      "          ...,\n",
      "          [-1.7143, -1.9978, -2.2344,  ..., -1.7882, -1.6264, -1.4585],\n",
      "          [-1.5184, -1.7676, -1.9643,  ..., -1.5246, -1.3950, -1.2628],\n",
      "          [-1.1633, -1.4172, -1.5997,  ..., -1.3000, -1.1745, -1.0104]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.5703,  0.7090,  0.7931,  ...,  1.2683,  1.1323,  0.9412],\n",
      "          [ 0.6760,  0.8021,  0.8320,  ...,  1.3890,  1.2659,  1.1171],\n",
      "          [ 0.7445,  0.8540,  0.8893,  ...,  1.5657,  1.4301,  1.2591],\n",
      "          ...,\n",
      "          [ 1.2536,  1.5166,  1.7063,  ...,  1.4426,  1.3928,  1.3004],\n",
      "          [ 1.0927,  1.3321,  1.5183,  ...,  1.3481,  1.2767,  1.1531],\n",
      "          [ 0.8154,  1.0026,  1.1632,  ...,  1.2368,  1.1264,  0.9441]],\n",
      "\n",
      "         [[-0.5704, -0.7091, -0.7931,  ..., -1.2683, -1.1323, -0.9413],\n",
      "          [-0.6760, -0.8020, -0.8319,  ..., -1.3889, -1.2658, -1.1171],\n",
      "          [-0.7445, -0.8539, -0.8892,  ..., -1.5656, -1.4300, -1.2591],\n",
      "          ...,\n",
      "          [-1.2536, -1.5165, -1.7062,  ..., -1.4425, -1.3927, -1.3004],\n",
      "          [-1.0927, -1.3320, -1.5182,  ..., -1.3480, -1.2766, -1.1531],\n",
      "          [-0.8155, -1.0026, -1.1631,  ..., -1.2367, -1.1264, -0.9441]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9374,  1.1308,  1.3148,  ...,  1.3604,  1.2791,  1.1103],\n",
      "          [ 1.1535,  1.2660,  1.3794,  ...,  1.3322,  1.2964,  1.2910],\n",
      "          [ 1.2629,  1.3749,  1.5044,  ...,  1.3910,  1.3738,  1.4481],\n",
      "          ...,\n",
      "          [ 1.3892,  1.5214,  1.6301,  ...,  0.1057,  0.1602,  0.2761],\n",
      "          [ 1.2854,  1.4891,  1.6295,  ...,  0.1662,  0.3005,  0.4387],\n",
      "          [ 1.0456,  1.3100,  1.4980,  ...,  0.4782,  0.5402,  0.5550]],\n",
      "\n",
      "         [[-0.9375, -1.1308, -1.3148,  ..., -1.3604, -1.2791, -1.1104],\n",
      "          [-1.1535, -1.2659, -1.3793,  ..., -1.3321, -1.2963, -1.2910],\n",
      "          [-1.2630, -1.3748, -1.5042,  ..., -1.3908, -1.3737, -1.4481],\n",
      "          ...,\n",
      "          [-1.3892, -1.5213, -1.6299,  ..., -0.1056, -0.1601, -0.2761],\n",
      "          [-1.2854, -1.4890, -1.6294,  ..., -0.1662, -0.3005, -0.4387],\n",
      "          [-1.0456, -1.3100, -1.4980,  ..., -0.4783, -0.5403, -0.5551]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1252,  1.3845,  1.5939,  ...,  1.7450,  1.5180,  1.2104],\n",
      "          [ 1.3874,  1.5385,  1.6837,  ...,  1.7675,  1.6453,  1.4659],\n",
      "          [ 1.5329,  1.6481,  1.7870,  ...,  1.8340,  1.7707,  1.6563],\n",
      "          ...,\n",
      "          [-0.3327, -0.2732, -0.1797,  ..., -0.3849, -0.3549, -0.1902],\n",
      "          [-0.1158, -0.0492, -0.0173,  ..., -0.3798, -0.3055, -0.1906],\n",
      "          [ 0.0509,  0.0742,  0.1073,  ..., -0.3506, -0.2070, -0.0773]],\n",
      "\n",
      "         [[-1.1252, -1.3845, -1.5939,  ..., -1.7449, -1.5180, -1.2104],\n",
      "          [-1.3874, -1.5384, -1.6836,  ..., -1.7674, -1.6452, -1.4659],\n",
      "          [-1.5329, -1.6480, -1.7869,  ..., -1.8338, -1.7706, -1.6563],\n",
      "          ...,\n",
      "          [ 0.3327,  0.2732,  0.1798,  ...,  0.3850,  0.3549,  0.1902],\n",
      "          [ 0.1158,  0.0493,  0.0173,  ...,  0.3799,  0.3056,  0.1905],\n",
      "          [-0.0510, -0.0742, -0.1074,  ...,  0.3506,  0.2069,  0.0772]]]],\n",
      "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[[ 9.6885e-01,  1.2011e+00,  1.3768e+00,  ...,  8.2837e-01,\n",
      "            6.5333e-01,  5.1390e-01],\n",
      "          [ 1.1772e+00,  1.3521e+00,  1.4783e+00,  ...,  7.7336e-01,\n",
      "            6.4120e-01,  5.3536e-01],\n",
      "          [ 1.3035e+00,  1.4547e+00,  1.5819e+00,  ...,  7.0354e-01,\n",
      "            5.5754e-01,  4.5105e-01],\n",
      "          ...,\n",
      "          [ 1.5591e-01,  1.0451e-01,  2.2003e-01,  ..., -1.7564e+00,\n",
      "           -1.8571e+00, -1.5805e+00],\n",
      "          [ 6.2653e-02, -2.1229e-02,  1.5331e-02,  ..., -1.5442e+00,\n",
      "           -1.5449e+00, -1.3244e+00],\n",
      "          [ 1.1672e-01, -4.9797e-04, -9.1535e-02,  ..., -1.3164e+00,\n",
      "           -1.2390e+00, -9.5225e-01]],\n",
      "\n",
      "         [[-9.6892e-01, -1.2011e+00, -1.3768e+00,  ..., -8.2836e-01,\n",
      "           -6.5334e-01, -5.1396e-01],\n",
      "          [-1.1772e+00, -1.3520e+00, -1.4781e+00,  ..., -7.7326e-01,\n",
      "           -6.4111e-01, -5.3537e-01],\n",
      "          [-1.3034e+00, -1.4545e+00, -1.5818e+00,  ..., -7.0342e-01,\n",
      "           -5.5743e-01, -4.5104e-01],\n",
      "          ...,\n",
      "          [-1.5596e-01, -1.0445e-01, -2.1992e-01,  ...,  1.7566e+00,\n",
      "            1.8572e+00,  1.5805e+00],\n",
      "          [-6.2699e-02,  2.1277e-02, -1.5235e-02,  ...,  1.5443e+00,\n",
      "            1.5450e+00,  1.3244e+00],\n",
      "          [-1.1681e-01,  4.6587e-04,  9.1528e-02,  ...,  1.3164e+00,\n",
      "            1.2390e+00,  9.5219e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2442e-01,  1.9124e-01,  1.6139e-01,  ...,  7.1098e-01,\n",
      "            6.2106e-01,  5.1547e-01],\n",
      "          [ 2.2318e-01,  1.7883e-01,  9.3567e-02,  ...,  9.9828e-01,\n",
      "            8.7004e-01,  7.0396e-01],\n",
      "          [ 1.9654e-01,  1.3836e-01,  6.3380e-02,  ...,  1.3026e+00,\n",
      "            1.1504e+00,  9.4254e-01],\n",
      "          ...,\n",
      "          [ 7.7899e-02,  1.4671e-01,  3.1232e-01,  ..., -1.1520e+00,\n",
      "           -1.2309e+00, -1.1762e+00],\n",
      "          [ 1.4039e-01,  1.4324e-01,  2.2173e-01,  ..., -8.2138e-01,\n",
      "           -8.4186e-01, -8.5825e-01],\n",
      "          [ 1.3942e-01,  6.3010e-02,  7.6146e-02,  ..., -5.3924e-01,\n",
      "           -5.6889e-01, -5.0718e-01]],\n",
      "\n",
      "         [[-2.2448e-01, -1.9123e-01, -1.6136e-01,  ..., -7.1096e-01,\n",
      "           -6.2106e-01, -5.1553e-01],\n",
      "          [-2.2317e-01, -1.7871e-01, -9.3406e-02,  ..., -9.9815e-01,\n",
      "           -8.6994e-01, -7.0397e-01],\n",
      "          [-1.9651e-01, -1.3820e-01, -6.3180e-02,  ..., -1.3025e+00,\n",
      "           -1.1503e+00, -9.4253e-01],\n",
      "          ...,\n",
      "          [-7.7893e-02, -1.4660e-01, -3.1220e-01,  ...,  1.1522e+00,\n",
      "            1.2310e+00,  1.1762e+00],\n",
      "          [-1.4040e-01, -1.4316e-01, -2.2165e-01,  ...,  8.2150e-01,\n",
      "            8.4195e-01,  8.5821e-01],\n",
      "          [-1.3950e-01, -6.3031e-02, -7.6170e-02,  ...,  5.3924e-01,\n",
      "            5.6888e-01,  5.0708e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7416e-01,  1.1124e+00,  1.2629e+00,  ...,  1.2809e+00,\n",
      "            1.1056e+00,  8.5487e-01],\n",
      "          [ 1.0804e+00,  1.2602e+00,  1.3159e+00,  ...,  1.2811e+00,\n",
      "            1.1756e+00,  1.0069e+00],\n",
      "          [ 1.2535e+00,  1.3780e+00,  1.3587e+00,  ...,  1.3036e+00,\n",
      "            1.2171e+00,  1.1077e+00],\n",
      "          ...,\n",
      "          [-1.0629e+00, -1.1623e+00, -1.2330e+00,  ...,  2.5697e-01,\n",
      "            2.6692e-01,  4.3192e-01],\n",
      "          [-8.5697e-01, -9.5834e-01, -1.0748e+00,  ...,  3.5989e-01,\n",
      "            3.9906e-01,  5.0518e-01],\n",
      "          [-6.0351e-01, -8.1443e-01, -9.3992e-01,  ...,  5.6662e-01,\n",
      "            5.6684e-01,  5.5273e-01]],\n",
      "\n",
      "         [[-8.7422e-01, -1.1124e+00, -1.2629e+00,  ..., -1.2809e+00,\n",
      "           -1.1056e+00, -8.5494e-01],\n",
      "          [-1.0804e+00, -1.2601e+00, -1.3158e+00,  ..., -1.2810e+00,\n",
      "           -1.1755e+00, -1.0069e+00],\n",
      "          [-1.2535e+00, -1.3779e+00, -1.3585e+00,  ..., -1.3035e+00,\n",
      "           -1.2170e+00, -1.1077e+00],\n",
      "          ...,\n",
      "          [ 1.0629e+00,  1.1624e+00,  1.2331e+00,  ..., -2.5685e-01,\n",
      "           -2.6685e-01, -4.3195e-01],\n",
      "          [ 8.5694e-01,  9.5842e-01,  1.0749e+00,  ..., -3.5980e-01,\n",
      "           -3.9900e-01, -5.0521e-01],\n",
      "          [ 6.0343e-01,  8.1441e-01,  9.3991e-01,  ..., -5.6663e-01,\n",
      "           -5.6686e-01, -5.5281e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.1418e+00,  1.4172e+00,  1.6271e+00,  ...,  1.3829e+00,\n",
      "            1.2087e+00,  9.8931e-01],\n",
      "          [ 1.3958e+00,  1.6050e+00,  1.7670e+00,  ...,  1.5191e+00,\n",
      "            1.3612e+00,  1.1990e+00],\n",
      "          [ 1.5804e+00,  1.7722e+00,  1.9212e+00,  ...,  1.6755e+00,\n",
      "            1.5204e+00,  1.3758e+00],\n",
      "          ...,\n",
      "          [-2.5868e-01, -2.7610e-01, -1.7323e-01,  ...,  2.2432e+00,\n",
      "            2.0968e+00,  1.9219e+00],\n",
      "          [-1.7037e-01, -2.3701e-01, -2.3639e-01,  ...,  2.0138e+00,\n",
      "            1.8333e+00,  1.6349e+00],\n",
      "          [-8.0455e-02, -2.2214e-01, -3.1004e-01,  ...,  1.8707e+00,\n",
      "            1.6420e+00,  1.3342e+00]],\n",
      "\n",
      "         [[-1.1419e+00, -1.4172e+00, -1.6271e+00,  ..., -1.3829e+00,\n",
      "           -1.2087e+00, -9.8936e-01],\n",
      "          [-1.3958e+00, -1.6049e+00, -1.7669e+00,  ..., -1.5190e+00,\n",
      "           -1.3611e+00, -1.1990e+00],\n",
      "          [-1.5804e+00, -1.7721e+00, -1.9211e+00,  ..., -1.6753e+00,\n",
      "           -1.5203e+00, -1.3758e+00],\n",
      "          ...,\n",
      "          [ 2.5870e-01,  2.7625e-01,  1.7342e-01,  ..., -2.2430e+00,\n",
      "           -2.0967e+00, -1.9218e+00],\n",
      "          [ 1.7038e-01,  2.3713e-01,  2.3654e-01,  ..., -2.0136e+00,\n",
      "           -1.8332e+00, -1.6348e+00],\n",
      "          [ 8.0389e-02,  2.2215e-01,  3.1006e-01,  ..., -1.8706e+00,\n",
      "           -1.6420e+00, -1.3342e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5936e-01,  1.2123e+00,  1.3951e+00,  ...,  1.2410e+00,\n",
      "            1.1238e+00,  9.4310e-01],\n",
      "          [ 1.1366e+00,  1.3518e+00,  1.4925e+00,  ...,  1.2546e+00,\n",
      "            1.1681e+00,  1.0668e+00],\n",
      "          [ 1.2351e+00,  1.4486e+00,  1.5926e+00,  ...,  1.2904e+00,\n",
      "            1.2151e+00,  1.1286e+00],\n",
      "          ...,\n",
      "          [ 1.1866e+00,  1.3816e+00,  1.4663e+00,  ...,  1.1998e+00,\n",
      "            1.2250e+00,  1.1983e+00],\n",
      "          [ 1.0414e+00,  1.2285e+00,  1.3082e+00,  ...,  1.1481e+00,\n",
      "            1.1183e+00,  1.0705e+00],\n",
      "          [ 8.5598e-01,  1.0399e+00,  1.1272e+00,  ...,  1.1332e+00,\n",
      "            1.0495e+00,  9.1559e-01]],\n",
      "\n",
      "         [[-9.5942e-01, -1.2123e+00, -1.3951e+00,  ..., -1.2410e+00,\n",
      "           -1.1238e+00, -9.4317e-01],\n",
      "          [-1.1366e+00, -1.3517e+00, -1.4924e+00,  ..., -1.2545e+00,\n",
      "           -1.1680e+00, -1.0668e+00],\n",
      "          [-1.2351e+00, -1.4485e+00, -1.5925e+00,  ..., -1.2902e+00,\n",
      "           -1.2150e+00, -1.1285e+00],\n",
      "          ...,\n",
      "          [-1.1866e+00, -1.3815e+00, -1.4661e+00,  ..., -1.1997e+00,\n",
      "           -1.2249e+00, -1.1983e+00],\n",
      "          [-1.0414e+00, -1.2284e+00, -1.3080e+00,  ..., -1.1480e+00,\n",
      "           -1.1182e+00, -1.0705e+00],\n",
      "          [-8.5605e-01, -1.0399e+00, -1.1272e+00,  ..., -1.1332e+00,\n",
      "           -1.0495e+00, -9.1564e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9600e-01,  9.9364e-01,  1.1746e+00,  ...,  1.7784e+00,\n",
      "            1.5448e+00,  1.2037e+00],\n",
      "          [ 9.6246e-01,  1.1331e+00,  1.2583e+00,  ...,  1.9966e+00,\n",
      "            1.8257e+00,  1.5435e+00],\n",
      "          [ 1.0603e+00,  1.2308e+00,  1.3492e+00,  ...,  2.1407e+00,\n",
      "            2.0101e+00,  1.7621e+00],\n",
      "          ...,\n",
      "          [ 1.4487e+00,  1.7028e+00,  1.8875e+00,  ..., -1.1740e+00,\n",
      "           -1.0213e+00, -8.9279e-01],\n",
      "          [ 1.2972e+00,  1.5628e+00,  1.7594e+00,  ..., -9.5473e-01,\n",
      "           -7.6945e-01, -6.6728e-01],\n",
      "          [ 1.0837e+00,  1.3910e+00,  1.6096e+00,  ..., -7.4388e-01,\n",
      "           -5.6573e-01, -4.0916e-01]],\n",
      "\n",
      "         [[-7.9606e-01, -9.9364e-01, -1.1746e+00,  ..., -1.7783e+00,\n",
      "           -1.5448e+00, -1.2037e+00],\n",
      "          [-9.6247e-01, -1.1330e+00, -1.2582e+00,  ..., -1.9964e+00,\n",
      "           -1.8256e+00, -1.5434e+00],\n",
      "          [-1.0603e+00, -1.2307e+00, -1.3490e+00,  ..., -2.1405e+00,\n",
      "           -2.0100e+00, -1.7621e+00],\n",
      "          ...,\n",
      "          [-1.4486e+00, -1.7026e+00, -1.8874e+00,  ...,  1.1741e+00,\n",
      "            1.0214e+00,  8.9274e-01],\n",
      "          [-1.2972e+00, -1.5627e+00, -1.7593e+00,  ...,  9.5481e-01,\n",
      "            7.6950e-01,  6.6722e-01],\n",
      "          [-1.0837e+00, -1.3909e+00, -1.6096e+00,  ...,  7.4385e-01,\n",
      "            5.6568e-01,  4.0905e-01]]]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[[ 1.3042e+00,  1.6341e+00,  1.9047e+00,  ...,  1.1617e+00,\n",
      "            9.8989e-01,  7.6513e-01],\n",
      "          [ 1.6401e+00,  1.8805e+00,  2.0885e+00,  ...,  1.2810e+00,\n",
      "            1.1162e+00,  9.0622e-01],\n",
      "          [ 1.8524e+00,  2.0447e+00,  2.2156e+00,  ...,  1.3827e+00,\n",
      "            1.2156e+00,  1.0296e+00],\n",
      "          ...,\n",
      "          [ 6.2597e-01,  7.0035e-01,  6.8828e-01,  ...,  1.7572e+00,\n",
      "            1.5786e+00,  1.3621e+00],\n",
      "          [ 5.6528e-01,  6.2560e-01,  5.5915e-01,  ...,  1.6020e+00,\n",
      "            1.4381e+00,  1.2183e+00],\n",
      "          [ 4.4794e-01,  4.9735e-01,  4.6736e-01,  ...,  1.4755e+00,\n",
      "            1.2856e+00,  1.0206e+00]],\n",
      "\n",
      "         [[-1.3042e+00, -1.6341e+00, -1.9047e+00,  ..., -1.1617e+00,\n",
      "           -9.8990e-01, -7.6520e-01],\n",
      "          [-1.6401e+00, -1.8804e+00, -2.0884e+00,  ..., -1.2809e+00,\n",
      "           -1.1161e+00, -9.0623e-01],\n",
      "          [-1.8524e+00, -2.0445e+00, -2.2154e+00,  ..., -1.3826e+00,\n",
      "           -1.2156e+00, -1.0296e+00],\n",
      "          ...,\n",
      "          [-6.2597e-01, -7.0024e-01, -6.8816e-01,  ..., -1.7571e+00,\n",
      "           -1.5785e+00, -1.3621e+00],\n",
      "          [-5.6529e-01, -6.2551e-01, -5.5905e-01,  ..., -1.6019e+00,\n",
      "           -1.4380e+00, -1.2183e+00],\n",
      "          [-4.4801e-01, -4.9736e-01, -4.6737e-01,  ..., -1.4755e+00,\n",
      "           -1.2856e+00, -1.0207e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2137e-01,  9.1858e-01,  1.0175e+00,  ...,  1.5851e+00,\n",
      "            1.3577e+00,  1.0486e+00],\n",
      "          [ 8.5784e-01,  1.0960e+00,  1.2542e+00,  ...,  1.7404e+00,\n",
      "            1.5877e+00,  1.3378e+00],\n",
      "          [ 9.5612e-01,  1.2034e+00,  1.4113e+00,  ...,  1.7932e+00,\n",
      "            1.6877e+00,  1.4998e+00],\n",
      "          ...,\n",
      "          [ 1.3634e+00,  1.5172e+00,  1.7428e+00,  ...,  1.9878e+00,\n",
      "            1.8838e+00,  1.7980e+00],\n",
      "          [ 1.2028e+00,  1.3719e+00,  1.5795e+00,  ...,  1.7445e+00,\n",
      "            1.6474e+00,  1.5342e+00],\n",
      "          [ 1.0321e+00,  1.2758e+00,  1.4878e+00,  ...,  1.5830e+00,\n",
      "            1.4623e+00,  1.2474e+00]],\n",
      "\n",
      "         [[-7.2145e-01, -9.1861e-01, -1.0175e+00,  ..., -1.5850e+00,\n",
      "           -1.3577e+00, -1.0487e+00],\n",
      "          [-8.5788e-01, -1.0960e+00, -1.2541e+00,  ..., -1.7402e+00,\n",
      "           -1.5876e+00, -1.3378e+00],\n",
      "          [-9.5615e-01, -1.2034e+00, -1.4112e+00,  ..., -1.7930e+00,\n",
      "           -1.6875e+00, -1.4998e+00],\n",
      "          ...,\n",
      "          [-1.3634e+00, -1.5170e+00, -1.7426e+00,  ..., -1.9877e+00,\n",
      "           -1.8837e+00, -1.7980e+00],\n",
      "          [-1.2028e+00, -1.3718e+00, -1.5793e+00,  ..., -1.7443e+00,\n",
      "           -1.6473e+00, -1.5342e+00],\n",
      "          [-1.0321e+00, -1.2758e+00, -1.4878e+00,  ..., -1.5830e+00,\n",
      "           -1.4623e+00, -1.2475e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.5764e-02, -2.5012e-01, -6.1379e-01,  ...,  1.1539e+00,\n",
      "            1.0230e+00,  8.2851e-01],\n",
      "          [-6.1481e-03, -1.7597e-01, -5.5810e-01,  ...,  1.2430e+00,\n",
      "            1.1531e+00,  1.0045e+00],\n",
      "          [ 6.7460e-04, -2.0963e-01, -6.1096e-01,  ...,  1.3194e+00,\n",
      "            1.2249e+00,  1.0908e+00],\n",
      "          ...,\n",
      "          [ 1.7148e+00,  1.8955e+00,  2.1774e+00,  ...,  2.8308e-01,\n",
      "            3.6655e-01,  4.8896e-01],\n",
      "          [ 1.5577e+00,  1.7735e+00,  2.0391e+00,  ...,  2.2682e-01,\n",
      "            3.3289e-01,  4.5747e-01],\n",
      "          [ 1.2499e+00,  1.5456e+00,  1.8346e+00,  ...,  3.4446e-01,\n",
      "            4.2311e-01,  4.7117e-01]],\n",
      "\n",
      "         [[ 2.5657e-02,  2.5005e-01,  6.1374e-01,  ..., -1.1538e+00,\n",
      "           -1.0230e+00, -8.2857e-01],\n",
      "          [ 6.0828e-03,  1.7597e-01,  5.5814e-01,  ..., -1.2428e+00,\n",
      "           -1.1530e+00, -1.0045e+00],\n",
      "          [-7.4098e-04,  2.0963e-01,  6.1099e-01,  ..., -1.3192e+00,\n",
      "           -1.2248e+00, -1.0908e+00],\n",
      "          ...,\n",
      "          [-1.7148e+00, -1.8954e+00, -2.1772e+00,  ..., -2.8304e-01,\n",
      "           -3.6651e-01, -4.8899e-01],\n",
      "          [-1.5577e+00, -1.7734e+00, -2.0390e+00,  ..., -2.2679e-01,\n",
      "           -3.3287e-01, -4.5751e-01],\n",
      "          [-1.2500e+00, -1.5456e+00, -1.8346e+00,  ..., -3.4450e-01,\n",
      "           -4.2316e-01, -4.7126e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.3149e-01,  2.4712e-01,  2.0363e-01,  ...,  1.7341e+00,\n",
      "            1.4730e+00,  1.1564e+00],\n",
      "          [ 1.6711e-01,  1.6502e-01,  8.6999e-02,  ...,  1.8930e+00,\n",
      "            1.6678e+00,  1.4232e+00],\n",
      "          [ 3.5256e-02, -5.0613e-02, -1.4494e-01,  ...,  2.0520e+00,\n",
      "            1.8373e+00,  1.6394e+00],\n",
      "          ...,\n",
      "          [-4.4506e-01, -1.8363e-01,  1.5827e-01,  ...,  4.9608e-01,\n",
      "            5.3984e-01,  5.4746e-01],\n",
      "          [-3.9134e-01, -2.1431e-01, -4.8172e-03,  ...,  2.7470e-01,\n",
      "            3.9529e-01,  4.4102e-01],\n",
      "          [-3.0191e-01, -3.2614e-01, -2.8016e-01,  ...,  2.0164e-01,\n",
      "            2.9980e-01,  3.4351e-01]],\n",
      "\n",
      "         [[-2.3157e-01, -2.4715e-01, -2.0364e-01,  ..., -1.7341e+00,\n",
      "           -1.4730e+00, -1.1565e+00],\n",
      "          [-1.6714e-01, -1.6496e-01, -8.6911e-02,  ..., -1.8929e+00,\n",
      "           -1.6677e+00, -1.4232e+00],\n",
      "          [-3.5281e-02,  5.0684e-02,  1.4505e-01,  ..., -2.0518e+00,\n",
      "           -1.8372e+00, -1.6393e+00],\n",
      "          ...,\n",
      "          [ 4.4507e-01,  1.8379e-01, -1.5808e-01,  ..., -4.9596e-01,\n",
      "           -5.3973e-01, -5.4745e-01],\n",
      "          [ 3.9134e-01,  2.1443e-01,  4.9712e-03,  ..., -2.7461e-01,\n",
      "           -3.9522e-01, -4.4104e-01],\n",
      "          [ 3.0184e-01,  3.2614e-01,  2.8018e-01,  ..., -2.0166e-01,\n",
      "           -2.9983e-01, -3.4359e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0797e+00,  1.3305e+00,  1.5512e+00,  ...,  1.1531e+00,\n",
      "            1.1178e+00,  1.0003e+00],\n",
      "          [ 1.3102e+00,  1.4569e+00,  1.6043e+00,  ...,  1.0717e+00,\n",
      "            1.1442e+00,  1.1697e+00],\n",
      "          [ 1.4244e+00,  1.5289e+00,  1.6523e+00,  ...,  1.0452e+00,\n",
      "            1.1516e+00,  1.2441e+00],\n",
      "          ...,\n",
      "          [ 8.8067e-01,  9.2374e-01,  9.9886e-01,  ...,  1.2656e+00,\n",
      "            1.1212e+00,  1.2253e+00],\n",
      "          [ 8.8000e-01,  9.4646e-01,  9.9223e-01,  ...,  1.1012e+00,\n",
      "            1.0334e+00,  1.1134e+00],\n",
      "          [ 7.7598e-01,  9.0619e-01,  9.9281e-01,  ...,  1.0961e+00,\n",
      "            1.0565e+00,  1.0032e+00]],\n",
      "\n",
      "         [[-1.0798e+00, -1.3306e+00, -1.5512e+00,  ..., -1.1531e+00,\n",
      "           -1.1177e+00, -1.0003e+00],\n",
      "          [-1.3102e+00, -1.4568e+00, -1.6042e+00,  ..., -1.0715e+00,\n",
      "           -1.1441e+00, -1.1697e+00],\n",
      "          [-1.4244e+00, -1.5289e+00, -1.6522e+00,  ..., -1.0450e+00,\n",
      "           -1.1514e+00, -1.2441e+00],\n",
      "          ...,\n",
      "          [-8.8068e-01, -9.2365e-01, -9.9874e-01,  ..., -1.2655e+00,\n",
      "           -1.1211e+00, -1.2253e+00],\n",
      "          [-8.8001e-01, -9.4638e-01, -9.9213e-01,  ..., -1.1011e+00,\n",
      "           -1.0333e+00, -1.1134e+00],\n",
      "          [-7.7605e-01, -9.0620e-01, -9.9280e-01,  ..., -1.0961e+00,\n",
      "           -1.0565e+00, -1.0033e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1082e-01,  9.9492e-01,  1.0759e+00,  ...,  1.7585e+00,\n",
      "            1.5265e+00,  1.2036e+00],\n",
      "          [ 8.8213e-01,  9.9674e-01,  9.9012e-01,  ...,  1.9202e+00,\n",
      "            1.7341e+00,  1.4905e+00],\n",
      "          [ 9.1013e-01,  9.6374e-01,  8.9958e-01,  ...,  2.0210e+00,\n",
      "            1.8532e+00,  1.6531e+00],\n",
      "          ...,\n",
      "          [ 1.4614e+00,  1.5305e+00,  1.7599e+00,  ...,  7.3654e-01,\n",
      "            7.3811e-01,  7.9999e-01],\n",
      "          [ 1.2335e+00,  1.3308e+00,  1.5468e+00,  ...,  7.4274e-01,\n",
      "            7.1473e-01,  7.3317e-01],\n",
      "          [ 9.8057e-01,  1.1676e+00,  1.4039e+00,  ...,  8.3482e-01,\n",
      "            7.4893e-01,  6.6828e-01]],\n",
      "\n",
      "         [[-8.1088e-01, -9.9490e-01, -1.0758e+00,  ..., -1.7584e+00,\n",
      "           -1.5264e+00, -1.2036e+00],\n",
      "          [-8.8212e-01, -9.9663e-01, -9.8997e-01,  ..., -1.9200e+00,\n",
      "           -1.7340e+00, -1.4905e+00],\n",
      "          [-9.1013e-01, -9.6363e-01, -8.9945e-01,  ..., -2.0208e+00,\n",
      "           -1.8531e+00, -1.6530e+00],\n",
      "          ...,\n",
      "          [-1.4614e+00, -1.5304e+00, -1.7598e+00,  ..., -7.3638e-01,\n",
      "           -7.3799e-01, -7.9998e-01],\n",
      "          [-1.2336e+00, -1.3308e+00, -1.5467e+00,  ..., -7.4260e-01,\n",
      "           -7.1462e-01, -7.3317e-01],\n",
      "          [-9.8064e-01, -1.1676e+00, -1.4039e+00,  ..., -8.3480e-01,\n",
      "           -7.4893e-01, -6.6834e-01]]]], device='cuda:0',\n",
      "       grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[[ 0.6314,  0.7965,  0.9188,  ...,  0.5855,  0.7069,  0.7044],\n",
      "          [ 0.7395,  0.8980,  1.0047,  ...,  0.6169,  0.7726,  0.8291],\n",
      "          [ 0.7912,  0.9383,  1.0640,  ...,  0.5882,  0.7698,  0.8603],\n",
      "          ...,\n",
      "          [ 0.7226,  0.8941,  1.0059,  ...,  2.0970,  1.9226,  1.6891],\n",
      "          [ 0.6300,  0.7707,  0.8223,  ...,  1.9447,  1.7346,  1.4660],\n",
      "          [ 0.5305,  0.6214,  0.6516,  ...,  1.7410,  1.5039,  1.1790]],\n",
      "\n",
      "         [[-0.6315, -0.7965, -0.9188,  ..., -0.5855, -0.7069, -0.7044],\n",
      "          [-0.7395, -0.8980, -1.0046,  ..., -0.6168, -0.7725, -0.8291],\n",
      "          [-0.7912, -0.9382, -1.0639,  ..., -0.5881, -0.7697, -0.8603],\n",
      "          ...,\n",
      "          [-0.7226, -0.8940, -1.0058,  ..., -2.0968, -1.9224, -1.6891],\n",
      "          [-0.6300, -0.7706, -0.8222,  ..., -1.9445, -1.7345, -1.4660],\n",
      "          [-0.5306, -0.6214, -0.6516,  ..., -1.7410, -1.5039, -1.1790]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6536,  2.0366,  2.3589,  ...,  1.7125,  1.4695,  1.1480],\n",
      "          [ 2.0442,  2.2521,  2.4943,  ...,  1.8757,  1.7009,  1.4585],\n",
      "          [ 2.3105,  2.4783,  2.7289,  ...,  1.9761,  1.8313,  1.6470],\n",
      "          ...,\n",
      "          [ 0.5390,  0.7290,  0.9433,  ...,  0.3566,  0.2213,  0.1120],\n",
      "          [ 0.5199,  0.6612,  0.8212,  ...,  0.3851,  0.3021,  0.1997],\n",
      "          [ 0.4757,  0.5713,  0.6660,  ...,  0.3730,  0.3111,  0.2388]],\n",
      "\n",
      "         [[-1.6536, -2.0366, -2.3588,  ..., -1.7125, -1.4695, -1.1480],\n",
      "          [-2.0442, -2.2519, -2.4941,  ..., -1.8756, -1.7008, -1.4585],\n",
      "          [-2.3104, -2.4780, -2.7286,  ..., -1.9759, -1.8312, -1.6469],\n",
      "          ...,\n",
      "          [-0.5390, -0.7290, -0.9432,  ..., -0.3565, -0.2212, -0.1121],\n",
      "          [-0.5199, -0.6611, -0.8211,  ..., -0.3851, -0.3021, -0.1997],\n",
      "          [-0.4758, -0.5713, -0.6660,  ..., -0.3730, -0.3111, -0.2389]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6234,  0.7648,  0.8206,  ...,  1.5907,  1.3690,  1.1212],\n",
      "          [ 0.7419,  0.8822,  0.9198,  ...,  1.7566,  1.5401,  1.3892],\n",
      "          [ 0.7754,  0.8621,  0.8930,  ...,  1.9487,  1.6881,  1.5789],\n",
      "          ...,\n",
      "          [ 0.9908,  1.1443,  1.2133,  ...,  1.9511,  1.7157,  1.5801],\n",
      "          [ 0.9037,  1.0586,  1.1007,  ...,  1.6958,  1.5074,  1.3666],\n",
      "          [ 0.7941,  0.9763,  1.0486,  ...,  1.5676,  1.3716,  1.1334]],\n",
      "\n",
      "         [[-0.6235, -0.7648, -0.8205,  ..., -1.5907, -1.3689, -1.1213],\n",
      "          [-0.7420, -0.8821, -0.9197,  ..., -1.7565, -1.5400, -1.3892],\n",
      "          [-0.7754, -0.8620, -0.8929,  ..., -1.9485, -1.6879, -1.5788],\n",
      "          ...,\n",
      "          [-0.9908, -1.1442, -1.2132,  ..., -1.9509, -1.7155, -1.5801],\n",
      "          [-0.9037, -1.0585, -1.1006,  ..., -1.6957, -1.5073, -1.3666],\n",
      "          [-0.7942, -0.9763, -1.0486,  ..., -1.5675, -1.3716, -1.1334]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0098,  1.2531,  1.4675,  ...,  1.5288,  1.3506,  1.0881],\n",
      "          [ 1.2584,  1.4550,  1.6350,  ...,  1.6895,  1.5367,  1.3395],\n",
      "          [ 1.4385,  1.6203,  1.7888,  ...,  1.8386,  1.7176,  1.5533],\n",
      "          ...,\n",
      "          [ 0.9449,  1.0581,  1.0811,  ...,  1.4908,  1.3808,  1.2575],\n",
      "          [ 0.8714,  1.0268,  1.0871,  ...,  1.3530,  1.2465,  1.1052],\n",
      "          [ 0.7566,  0.9335,  1.0246,  ...,  1.2284,  1.1183,  0.9325]],\n",
      "\n",
      "         [[-1.0098, -1.2531, -1.4675,  ..., -1.5288, -1.3506, -1.0881],\n",
      "          [-1.2584, -1.4549, -1.6349,  ..., -1.6893, -1.5366, -1.3395],\n",
      "          [-1.4385, -1.6202, -1.7887,  ..., -1.8384, -1.7175, -1.5532],\n",
      "          ...,\n",
      "          [-0.9449, -1.0580, -1.0810,  ..., -1.4906, -1.3807, -1.2575],\n",
      "          [-0.8714, -1.0267, -1.0870,  ..., -1.3529, -1.2464, -1.1052],\n",
      "          [-0.7566, -0.9335, -1.0245,  ..., -1.2284, -1.1183, -0.9325]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9453,  1.1790,  1.3411,  ...,  0.3479,  0.3170,  0.2968],\n",
      "          [ 1.1499,  1.3435,  1.4727,  ...,  0.2828,  0.1986,  0.1772],\n",
      "          [ 1.3017,  1.4808,  1.6143,  ...,  0.2719,  0.1216,  0.1003],\n",
      "          ...,\n",
      "          [ 1.2808,  1.4238,  1.4482,  ...,  1.3728,  1.2306,  1.0587],\n",
      "          [ 1.1490,  1.3291,  1.3774,  ...,  1.1708,  1.0516,  0.9057],\n",
      "          [ 0.9374,  1.1513,  1.2553,  ...,  0.9964,  0.8790,  0.7371]],\n",
      "\n",
      "         [[-0.9454, -1.1790, -1.3411,  ..., -0.3479, -0.3170, -0.2969],\n",
      "          [-1.1499, -1.3434, -1.4726,  ..., -0.2827, -0.1985, -0.1772],\n",
      "          [-1.3017, -1.4807, -1.6141,  ..., -0.2718, -0.1215, -0.1003],\n",
      "          ...,\n",
      "          [-1.2809, -1.4237, -1.4480,  ..., -1.3726, -1.2304, -1.0587],\n",
      "          [-1.1490, -1.3290, -1.3773,  ..., -1.1707, -1.0515, -0.9057],\n",
      "          [-0.9375, -1.1513, -1.2553,  ..., -0.9964, -0.8790, -0.7371]]],\n",
      "\n",
      "\n",
      "        [[[-0.3014, -0.4922, -0.6803,  ...,  1.4695,  1.2940,  1.0239],\n",
      "          [-0.3477, -0.4462, -0.6002,  ...,  1.6534,  1.5324,  1.3039],\n",
      "          [-0.4222, -0.5755, -0.7073,  ...,  1.7701,  1.6834,  1.4834],\n",
      "          ...,\n",
      "          [ 1.1941,  1.3380,  1.4117,  ...,  1.1303,  0.9807,  0.8420],\n",
      "          [ 1.0902,  1.2498,  1.3413,  ...,  1.1048,  0.9520,  0.7977],\n",
      "          [ 0.9176,  1.1201,  1.2483,  ...,  0.9799,  0.8546,  0.6967]],\n",
      "\n",
      "         [[ 0.3014,  0.4922,  0.6803,  ..., -1.4695, -1.2940, -1.0240],\n",
      "          [ 0.3476,  0.4462,  0.6003,  ..., -1.6533, -1.5323, -1.3039],\n",
      "          [ 0.4222,  0.5756,  0.7074,  ..., -1.7699, -1.6833, -1.4834],\n",
      "          ...,\n",
      "          [-1.1941, -1.3379, -1.4116,  ..., -1.1302, -0.9806, -0.8420],\n",
      "          [-1.0902, -1.2498, -1.3412,  ..., -1.1047, -0.9520, -0.7977],\n",
      "          [-0.9176, -1.1201, -1.2483,  ..., -0.9799, -0.8546, -0.6968]]]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[[ 0.1552,  0.0150, -0.1965,  ...,  0.8621,  0.6501,  0.4783],\n",
      "          [ 0.1823,  0.0632, -0.1166,  ...,  1.0459,  0.8543,  0.6376],\n",
      "          [ 0.2331,  0.0735, -0.1032,  ...,  1.1969,  0.9925,  0.7430],\n",
      "          ...,\n",
      "          [-0.2438, -0.2317, -0.1572,  ...,  1.0801,  0.7588,  0.5866],\n",
      "          [-0.0351, -0.0430, -0.0346,  ...,  0.9865,  0.7233,  0.5429],\n",
      "          [ 0.1516,  0.1506,  0.1633,  ...,  0.8005,  0.6438,  0.5058]],\n",
      "\n",
      "         [[-0.1553, -0.0150,  0.1965,  ..., -0.8621, -0.6501, -0.4784],\n",
      "          [-0.1823, -0.0632,  0.1167,  ..., -1.0458, -0.8542, -0.6376],\n",
      "          [-0.2331, -0.0735,  0.1033,  ..., -1.1968, -0.9924, -0.7430],\n",
      "          ...,\n",
      "          [ 0.2437,  0.2317,  0.1573,  ..., -1.0800, -0.7588, -0.5866],\n",
      "          [ 0.0351,  0.0430,  0.0346,  ..., -0.9864, -0.7233, -0.5430],\n",
      "          [-0.1517, -0.1506, -0.1634,  ..., -0.8005, -0.6439, -0.5059]]],\n",
      "\n",
      "\n",
      "        [[[-0.0644, -0.1990, -0.3772,  ...,  1.4545,  1.2549,  0.9830],\n",
      "          [-0.1249, -0.1996, -0.3409,  ...,  1.6061,  1.4392,  1.2122],\n",
      "          [-0.1463, -0.2314, -0.3234,  ...,  1.6933,  1.5321,  1.3395],\n",
      "          ...,\n",
      "          [ 1.6982,  1.9862,  2.3643,  ..., -0.0873,  0.1204,  0.3086],\n",
      "          [ 1.5185,  1.8244,  2.1783,  ...,  0.0773,  0.2961,  0.4330],\n",
      "          [ 1.2186,  1.5626,  1.8738,  ...,  0.2938,  0.4462,  0.4937]],\n",
      "\n",
      "         [[ 0.0643,  0.1990,  0.3772,  ..., -1.4545, -1.2549, -0.9831],\n",
      "          [ 0.1249,  0.1997,  0.3410,  ..., -1.6059, -1.4391, -1.2122],\n",
      "          [ 0.1463,  0.2315,  0.3235,  ..., -1.6932, -1.5319, -1.3394],\n",
      "          ...,\n",
      "          [-1.6982, -1.9861, -2.3642,  ...,  0.0874, -0.1203, -0.3086],\n",
      "          [-1.5185, -1.8243, -2.1782,  ..., -0.0773, -0.2961, -0.4330],\n",
      "          [-1.2187, -1.5626, -1.8737,  ..., -0.2939, -0.4462, -0.4938]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3302,  0.2981,  0.2584,  ...,  0.7760,  0.7543,  0.6629],\n",
      "          [ 0.2916,  0.2381,  0.1791,  ...,  0.7621,  0.8008,  0.7727],\n",
      "          [ 0.2379,  0.1947,  0.1498,  ...,  0.7192,  0.8065,  0.8280],\n",
      "          ...,\n",
      "          [ 1.3571,  1.4088,  1.5682,  ...,  0.8452,  0.7769,  0.6654],\n",
      "          [ 1.2450,  1.3094,  1.4324,  ...,  0.6562,  0.6338,  0.5430],\n",
      "          [ 1.0724,  1.2634,  1.4204,  ...,  0.4891,  0.4679,  0.4119]],\n",
      "\n",
      "         [[-0.3303, -0.2981, -0.2584,  ..., -0.7760, -0.7544, -0.6630],\n",
      "          [-0.2916, -0.2380, -0.1789,  ..., -0.7620, -0.8007, -0.7728],\n",
      "          [-0.2379, -0.1946, -0.1497,  ..., -0.7191, -0.8064, -0.8280],\n",
      "          ...,\n",
      "          [-1.3571, -1.4087, -1.5680,  ..., -0.8450, -0.7768, -0.6654],\n",
      "          [-1.2450, -1.3094, -1.4323,  ..., -0.6561, -0.6337, -0.5431],\n",
      "          [-1.0725, -1.2634, -1.4204,  ..., -0.4891, -0.4679, -0.4119]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.9178,  1.1614,  1.3418,  ...,  1.4358,  1.2778,  1.0526],\n",
      "          [ 1.1137,  1.3398,  1.4944,  ...,  1.5800,  1.4305,  1.2653],\n",
      "          [ 1.2762,  1.4857,  1.6129,  ...,  1.7483,  1.6040,  1.4597],\n",
      "          ...,\n",
      "          [ 1.3557,  1.5549,  1.8079,  ...,  2.7793,  2.4974,  2.2312],\n",
      "          [ 1.1607,  1.3443,  1.5230,  ...,  2.5425,  2.2252,  1.9173],\n",
      "          [ 0.9654,  1.1979,  1.3631,  ...,  2.3298,  1.9652,  1.5446]],\n",
      "\n",
      "         [[-0.9178, -1.1614, -1.3418,  ..., -1.4357, -1.2778, -1.0527],\n",
      "          [-1.1137, -1.3396, -1.4943,  ..., -1.5798, -1.4303, -1.2652],\n",
      "          [-1.2762, -1.4855, -1.6127,  ..., -1.7481, -1.6039, -1.4597],\n",
      "          ...,\n",
      "          [-1.3557, -1.5547, -1.8077,  ..., -2.7791, -2.4971, -2.2311],\n",
      "          [-1.1607, -1.3442, -1.5229,  ..., -2.5423, -2.2250, -1.9173],\n",
      "          [-0.9655, -1.1979, -1.3631,  ..., -2.3297, -1.9651, -1.5446]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1797,  1.4888,  1.7005,  ...,  1.9016,  1.6327,  1.2863],\n",
      "          [ 1.4460,  1.7089,  1.8638,  ...,  1.9449,  1.7444,  1.5457],\n",
      "          [ 1.6705,  1.9422,  2.0884,  ...,  2.0464,  1.8824,  1.7507],\n",
      "          ...,\n",
      "          [ 1.5331,  1.6931,  1.7512,  ...,  1.8516,  1.6671,  1.5150],\n",
      "          [ 1.3860,  1.5882,  1.7003,  ...,  1.7553,  1.5636,  1.3838],\n",
      "          [ 1.1385,  1.4016,  1.5654,  ...,  1.6646,  1.4469,  1.1802]],\n",
      "\n",
      "         [[-1.1798, -1.4888, -1.7005,  ..., -1.9015, -1.6326, -1.2864],\n",
      "          [-1.4460, -1.7087, -1.8636,  ..., -1.9447, -1.7443, -1.5456],\n",
      "          [-1.6705, -1.9420, -2.0882,  ..., -2.0462, -1.8822, -1.7507],\n",
      "          ...,\n",
      "          [-1.5331, -1.6930, -1.7510,  ..., -1.8514, -1.6669, -1.5149],\n",
      "          [-1.3860, -1.5880, -1.7001,  ..., -1.7551, -1.5635, -1.3837],\n",
      "          [-1.1385, -1.4015, -1.5654,  ..., -1.6645, -1.4468, -1.1803]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9318,  1.1377,  1.2656,  ...,  1.5383,  1.3818,  1.1489],\n",
      "          [ 1.1276,  1.2775,  1.3589,  ...,  1.6345,  1.5092,  1.3824],\n",
      "          [ 1.2850,  1.4143,  1.4967,  ...,  1.8038,  1.6984,  1.6034],\n",
      "          ...,\n",
      "          [ 1.2528,  1.2538,  1.3140,  ...,  0.6897,  0.6954,  0.7488],\n",
      "          [ 1.2218,  1.2661,  1.3081,  ...,  0.6687,  0.6562,  0.6851],\n",
      "          [ 1.0589,  1.2159,  1.3029,  ...,  0.7095,  0.6502,  0.6144]],\n",
      "\n",
      "         [[-0.9319, -1.1377, -1.2656,  ..., -1.5382, -1.3818, -1.1490],\n",
      "          [-1.1276, -1.2774, -1.3587,  ..., -1.6344, -1.5091, -1.3824],\n",
      "          [-1.2851, -1.4142, -1.4965,  ..., -1.8036, -1.6982, -1.6034],\n",
      "          ...,\n",
      "          [-1.2528, -1.2537, -1.3138,  ..., -0.6895, -0.6953, -0.7488],\n",
      "          [-1.2218, -1.2660, -1.3080,  ..., -0.6685, -0.6561, -0.6851],\n",
      "          [-1.0589, -1.2159, -1.3029,  ..., -0.7095, -0.6502, -0.6145]]]],\n",
      "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[[ 1.0742,  1.3169,  1.5160,  ...,  1.5953,  1.4235,  1.1407],\n",
      "          [ 1.3377,  1.4976,  1.5991,  ...,  1.6871,  1.5791,  1.3950],\n",
      "          [ 1.5370,  1.6574,  1.7018,  ...,  1.7877,  1.7211,  1.5810],\n",
      "          ...,\n",
      "          [ 0.8137,  0.8444,  0.8923,  ...,  1.1990,  1.1944,  1.1586],\n",
      "          [ 0.8057,  0.8811,  0.9445,  ...,  1.1165,  1.0951,  1.0237],\n",
      "          [ 0.7635,  0.9110,  1.0152,  ...,  1.0780,  1.0136,  0.8704]],\n",
      "\n",
      "         [[-1.0743, -1.3170, -1.5160,  ..., -1.5953, -1.4235, -1.1408],\n",
      "          [-1.3377, -1.4975, -1.5989,  ..., -1.6870, -1.5790, -1.3950],\n",
      "          [-1.5369, -1.6573, -1.7017,  ..., -1.7875, -1.7209, -1.5809],\n",
      "          ...,\n",
      "          [-0.8137, -0.8443, -0.8922,  ..., -1.1988, -1.1944, -1.1586],\n",
      "          [-0.8057, -0.8810, -0.9444,  ..., -1.1164, -1.0950, -1.0237],\n",
      "          [-0.7636, -0.9110, -1.0152,  ..., -1.0780, -1.0136, -0.8705]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8686,  1.0479,  1.1662,  ...,  1.3744,  1.2134,  0.9687],\n",
      "          [ 1.0357,  1.1468,  1.2200,  ...,  1.5234,  1.3897,  1.1956],\n",
      "          [ 1.1603,  1.2309,  1.2929,  ...,  1.6546,  1.5393,  1.3832],\n",
      "          ...,\n",
      "          [ 1.2341,  1.2744,  1.3205,  ...,  2.2666,  2.0407,  1.7508],\n",
      "          [ 1.1103,  1.2179,  1.2926,  ...,  2.0307,  1.7880,  1.5076],\n",
      "          [ 0.9385,  1.1302,  1.2581,  ...,  1.7923,  1.5376,  1.2196]],\n",
      "\n",
      "         [[-0.8687, -1.0480, -1.1662,  ..., -1.3744, -1.2134, -0.9687],\n",
      "          [-1.0357, -1.1468, -1.2199,  ..., -1.5233, -1.3896, -1.1956],\n",
      "          [-1.1603, -1.2308, -1.2927,  ..., -1.6544, -1.5392, -1.3832],\n",
      "          ...,\n",
      "          [-1.2341, -1.2743, -1.3204,  ..., -2.2665, -2.0406, -1.7508],\n",
      "          [-1.1103, -1.2178, -1.2925,  ..., -2.0305, -1.7879, -1.5076],\n",
      "          [-0.9386, -1.1302, -1.2581,  ..., -1.7923, -1.5376, -1.2196]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1843,  1.4839,  1.7096,  ...,  1.7406,  1.4888,  1.1578],\n",
      "          [ 1.4530,  1.6561,  1.8272,  ...,  1.9095,  1.7007,  1.4309],\n",
      "          [ 1.6199,  1.7855,  1.9505,  ...,  2.0675,  1.8836,  1.6392],\n",
      "          ...,\n",
      "          [ 1.2329,  1.3283,  1.4655,  ...,  1.9442,  1.7735,  1.6137],\n",
      "          [ 1.0800,  1.2179,  1.3418,  ...,  1.7717,  1.5971,  1.4071],\n",
      "          [ 0.8911,  1.0853,  1.2228,  ...,  1.6704,  1.4583,  1.1752]],\n",
      "\n",
      "         [[-1.1844, -1.4839, -1.7096,  ..., -1.7405, -1.4888, -1.1578],\n",
      "          [-1.4530, -1.6560, -1.8271,  ..., -1.9093, -1.7006, -1.4309],\n",
      "          [-1.6199, -1.7854, -1.9503,  ..., -2.0674, -1.8835, -1.6391],\n",
      "          ...,\n",
      "          [-1.2329, -1.3282, -1.4654,  ..., -1.9440, -1.7734, -1.6137],\n",
      "          [-1.0801, -1.2178, -1.3417,  ..., -1.7716, -1.5970, -1.4071],\n",
      "          [-0.8911, -1.0853, -1.2228,  ..., -1.6704, -1.4583, -1.1753]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0284,  1.3174,  1.5289,  ...,  0.9174,  0.8227,  0.6682],\n",
      "          [ 1.2815,  1.5561,  1.7241,  ...,  1.1319,  1.0350,  0.8700],\n",
      "          [ 1.4847,  1.7534,  1.9058,  ...,  1.2631,  1.1611,  1.0061],\n",
      "          ...,\n",
      "          [ 1.4603,  1.6714,  1.7671,  ...,  2.2023,  1.9196,  1.7144],\n",
      "          [ 1.3247,  1.5792,  1.7398,  ...,  1.8949,  1.6665,  1.4677],\n",
      "          [ 1.0229,  1.2642,  1.4407,  ...,  1.7020,  1.4734,  1.1961]],\n",
      "\n",
      "         [[-1.0285, -1.3174, -1.5289,  ..., -0.9173, -0.8227, -0.6682],\n",
      "          [-1.2815, -1.5560, -1.7240,  ..., -1.1318, -1.0349, -0.8700],\n",
      "          [-1.4846, -1.7533, -1.9057,  ..., -1.2629, -1.1610, -1.0061],\n",
      "          ...,\n",
      "          [-1.4602, -1.6712, -1.7669,  ..., -2.2021, -1.9195, -1.7144],\n",
      "          [-1.3246, -1.5790, -1.7396,  ..., -1.8947, -1.6664, -1.4677],\n",
      "          [-1.0230, -1.2642, -1.4406,  ..., -1.7019, -1.4734, -1.1962]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3290,  1.6803,  1.9671,  ...,  2.6093,  2.1610,  1.7126],\n",
      "          [ 1.6720,  1.9541,  2.2278,  ...,  2.8494,  2.4153,  2.1412],\n",
      "          [ 1.8934,  2.1394,  2.4434,  ...,  3.3215,  2.8339,  2.5545],\n",
      "          ...,\n",
      "          [ 1.9325,  2.2734,  2.6946,  ...,  2.9412,  2.5063,  2.2536],\n",
      "          [ 1.6192,  1.9203,  2.2584,  ...,  2.4783,  2.1003,  1.8678],\n",
      "          [ 1.2995,  1.6575,  1.9605,  ...,  2.2223,  1.8617,  1.5016]],\n",
      "\n",
      "         [[-1.3290, -1.6803, -1.9671,  ..., -2.6092, -2.1609, -1.7126],\n",
      "          [-1.6720, -1.9540, -2.2276,  ..., -2.8491, -2.4151, -2.1411],\n",
      "          [-1.8933, -2.1393, -2.4432,  ..., -3.3212, -2.8336, -2.5544],\n",
      "          ...,\n",
      "          [-1.9325, -2.2732, -2.6944,  ..., -2.9409, -2.5061, -2.2535],\n",
      "          [-1.6191, -1.9202, -2.2583,  ..., -2.4780, -2.1001, -1.8678],\n",
      "          [-1.2996, -1.6574, -1.9604,  ..., -2.2222, -1.8616, -1.5016]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7751,  2.2322,  2.6780,  ...,  2.0669,  1.7244,  1.3719],\n",
      "          [ 2.2257,  2.5243,  2.9928,  ...,  2.2645,  1.9319,  1.7077],\n",
      "          [ 2.6323,  2.9785,  3.5564,  ...,  2.5463,  2.1766,  1.9857],\n",
      "          ...,\n",
      "          [ 2.3217,  2.6743,  3.2354,  ...,  2.7629,  2.3550,  2.0774],\n",
      "          [ 1.9077,  2.1969,  2.6474,  ...,  2.3350,  1.9974,  1.7431],\n",
      "          [ 1.5382,  1.9400,  2.3347,  ...,  2.0779,  1.7560,  1.4027]],\n",
      "\n",
      "         [[-1.7751, -2.2321, -2.6779,  ..., -2.0668, -1.7243, -1.3719],\n",
      "          [-2.2256, -2.5241, -2.9925,  ..., -2.2643, -1.9317, -1.7077],\n",
      "          [-2.6321, -2.9782, -3.5561,  ..., -2.5461, -2.1764, -1.9856],\n",
      "          ...,\n",
      "          [-2.3216, -2.6741, -3.2351,  ..., -2.7626, -2.3547, -2.0773],\n",
      "          [-1.9076, -2.1967, -2.6472,  ..., -2.3348, -1.9972, -1.7430],\n",
      "          [-1.5382, -1.9399, -2.3346,  ..., -2.0778, -1.7560, -1.4027]]]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[[ 0.3133,  0.3618,  0.3362,  ...,  1.1549,  1.0224,  0.8548],\n",
      "          [ 0.3645,  0.4685,  0.4422,  ...,  1.3069,  1.1753,  1.0633],\n",
      "          [ 0.3189,  0.3717,  0.3329,  ...,  1.4270,  1.2613,  1.1919],\n",
      "          ...,\n",
      "          [ 0.9992,  1.1908,  1.3009,  ...,  1.3914,  1.2487,  1.1434],\n",
      "          [ 0.8809,  1.0555,  1.1264,  ...,  1.1837,  1.0908,  0.9940],\n",
      "          [ 0.7562,  0.9277,  0.9995,  ...,  1.0630,  0.9679,  0.8230]],\n",
      "\n",
      "         [[-0.3134, -0.3618, -0.3363,  ..., -1.1548, -1.0224, -0.8548],\n",
      "          [-0.3646, -0.4685, -0.4421,  ..., -1.3067, -1.1752, -1.0633],\n",
      "          [-0.3189, -0.3716, -0.3328,  ..., -1.4269, -1.2612, -1.1919],\n",
      "          ...,\n",
      "          [-0.9992, -1.1907, -1.3008,  ..., -1.3913, -1.2486, -1.1434],\n",
      "          [-0.8810, -1.0554, -1.1263,  ..., -1.1836, -1.0907, -0.9940],\n",
      "          [-0.7563, -0.9277, -0.9995,  ..., -1.0630, -0.9679, -0.8231]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7436,  0.9328,  1.0424,  ...,  1.3735,  1.1950,  0.9886],\n",
      "          [ 0.9174,  1.1033,  1.2047,  ...,  1.5105,  1.3374,  1.2177],\n",
      "          [ 1.0068,  1.1494,  1.2661,  ...,  1.6310,  1.4297,  1.3679],\n",
      "          ...,\n",
      "          [ 0.9049,  1.0674,  1.1998,  ...,  1.6480,  1.4689,  1.3772],\n",
      "          [ 0.7822,  0.9168,  0.9894,  ...,  1.4222,  1.2935,  1.1993],\n",
      "          [ 0.6691,  0.8104,  0.8728,  ...,  1.3293,  1.1873,  1.0043]],\n",
      "\n",
      "         [[-0.7436, -0.9328, -1.0424,  ..., -1.3735, -1.1950, -0.9886],\n",
      "          [-0.9174, -1.1032, -1.2046,  ..., -1.5104, -1.3373, -1.2177],\n",
      "          [-1.0067, -1.1493, -1.2659,  ..., -1.6308, -1.4296, -1.3679],\n",
      "          ...,\n",
      "          [-0.9049, -1.0673, -1.1997,  ..., -1.6478, -1.4688, -1.3771],\n",
      "          [-0.7822, -0.9167, -0.9893,  ..., -1.4221, -1.2934, -1.1993],\n",
      "          [-0.6691, -0.8104, -0.8728,  ..., -1.3293, -1.1873, -1.0043]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8202,  1.0144,  1.1443,  ...,  0.9801,  0.8707,  0.7245],\n",
      "          [ 1.0040,  1.1631,  1.2693,  ...,  1.1561,  1.0343,  0.9043],\n",
      "          [ 1.1114,  1.2328,  1.3521,  ...,  1.2119,  1.0701,  0.9862],\n",
      "          ...,\n",
      "          [ 1.1124,  1.2675,  1.3994,  ...,  1.5024,  1.3594,  1.2804],\n",
      "          [ 0.9639,  1.0993,  1.1712,  ...,  1.2939,  1.2038,  1.1233],\n",
      "          [ 0.8052,  0.9774,  1.0615,  ...,  1.1955,  1.0927,  0.9346]],\n",
      "\n",
      "         [[-0.8203, -1.0144, -1.1443,  ..., -0.9801, -0.8707, -0.7246],\n",
      "          [-1.0040, -1.1630, -1.2692,  ..., -1.1560, -1.0342, -0.9043],\n",
      "          [-1.1113, -1.2327, -1.3519,  ..., -1.2117, -1.0700, -0.9862],\n",
      "          ...,\n",
      "          [-1.1124, -1.2674, -1.3993,  ..., -1.5022, -1.3592, -1.2803],\n",
      "          [-0.9639, -1.0992, -1.1711,  ..., -1.2938, -1.2037, -1.1233],\n",
      "          [-0.8053, -0.9774, -1.0615,  ..., -1.1955, -1.0927, -0.9347]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.8416,  0.9389,  0.9477,  ...,  1.6478,  1.4108,  1.1098],\n",
      "          [ 0.9020,  0.8885,  0.7925,  ...,  1.7479,  1.5775,  1.3529],\n",
      "          [ 0.9089,  0.8487,  0.6943,  ...,  1.8811,  1.7308,  1.5358],\n",
      "          ...,\n",
      "          [ 1.1419,  1.2969,  1.3967,  ...,  1.6695,  1.4492,  1.2600],\n",
      "          [ 1.0312,  1.2222,  1.3310,  ...,  1.4849,  1.3025,  1.1180],\n",
      "          [ 0.8647,  1.0880,  1.2233,  ...,  1.3315,  1.1670,  0.9485]],\n",
      "\n",
      "         [[-0.8416, -0.9388, -0.9477,  ..., -1.6477, -1.4108, -1.1099],\n",
      "          [-0.9020, -0.8884, -0.7923,  ..., -1.7477, -1.5774, -1.3529],\n",
      "          [-0.9088, -0.8486, -0.6941,  ..., -1.8809, -1.7306, -1.5357],\n",
      "          ...,\n",
      "          [-1.1419, -1.2968, -1.3965,  ..., -1.6693, -1.4491, -1.2600],\n",
      "          [-1.0312, -1.2221, -1.3309,  ..., -1.4848, -1.3024, -1.1180],\n",
      "          [-0.8647, -1.0880, -1.2233,  ..., -1.3315, -1.1670, -0.9485]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7292,  0.9275,  1.0443,  ...,  1.6975,  1.4796,  1.1863],\n",
      "          [ 0.8848,  1.0835,  1.1637,  ...,  1.8268,  1.6825,  1.4838],\n",
      "          [ 0.9954,  1.1821,  1.2735,  ...,  1.9323,  1.8248,  1.6797],\n",
      "          ...,\n",
      "          [ 1.2815,  1.4461,  1.6135,  ...,  0.9066,  0.7952,  0.6891],\n",
      "          [ 1.1155,  1.2922,  1.4372,  ...,  0.8272,  0.7429,  0.6339],\n",
      "          [ 0.9269,  1.1454,  1.2983,  ...,  0.7505,  0.6757,  0.5653]],\n",
      "\n",
      "         [[-0.7293, -0.9275, -1.0443,  ..., -1.6974, -1.4796, -1.1864],\n",
      "          [-0.8848, -1.0834, -1.1636,  ..., -1.8267, -1.6824, -1.4838],\n",
      "          [-0.9954, -1.1820, -1.2734,  ..., -1.9321, -1.8246, -1.6797],\n",
      "          ...,\n",
      "          [-1.2815, -1.4460, -1.6134,  ..., -0.9064, -0.7951, -0.6891],\n",
      "          [-1.1155, -1.2921, -1.4370,  ..., -0.8270, -0.7428, -0.6339],\n",
      "          [-0.9269, -1.1454, -1.2982,  ..., -0.7505, -0.6758, -0.5654]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0776,  1.3509,  1.5603,  ...,  1.9580,  1.6739,  1.2983],\n",
      "          [ 1.3152,  1.5244,  1.6833,  ...,  2.1428,  1.9104,  1.6124],\n",
      "          [ 1.4558,  1.6321,  1.7679,  ...,  2.3447,  2.1237,  1.8498],\n",
      "          ...,\n",
      "          [ 1.1040,  1.2566,  1.3747,  ...,  1.0906,  0.9479,  0.8394],\n",
      "          [ 0.9870,  1.1423,  1.2361,  ...,  1.0106,  0.9020,  0.7861],\n",
      "          [ 0.8356,  1.0187,  1.1205,  ...,  0.9454,  0.8480,  0.7051]],\n",
      "\n",
      "         [[-1.0777, -1.3509, -1.5603,  ..., -1.9580, -1.6739, -1.2983],\n",
      "          [-1.3152, -1.5243, -1.6831,  ..., -2.1427, -1.9102, -1.6124],\n",
      "          [-1.4558, -1.6320, -1.7678,  ..., -2.3445, -2.1235, -1.8497],\n",
      "          ...,\n",
      "          [-1.1040, -1.2565, -1.3745,  ..., -1.0904, -0.9478, -0.8394],\n",
      "          [-0.9870, -1.1422, -1.2360,  ..., -1.0105, -0.9019, -0.7861],\n",
      "          [-0.8356, -1.0187, -1.1205,  ..., -0.9454, -0.8480, -0.7052]]]],\n",
      "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[[[ 0.9613,  1.1435,  1.1998,  ...,  1.3650,  1.2284,  0.9981],\n",
      "          [ 1.1165,  1.2473,  1.2658,  ...,  1.4739,  1.3995,  1.2388],\n",
      "          [ 1.1898,  1.3063,  1.3293,  ...,  1.4878,  1.4529,  1.3549],\n",
      "          ...,\n",
      "          [ 1.0376,  1.2063,  1.3622,  ...,  0.8566,  0.7779,  0.6987],\n",
      "          [ 0.9329,  1.1025,  1.2280,  ...,  0.7635,  0.7180,  0.6418],\n",
      "          [ 0.8036,  0.9902,  1.1030,  ...,  0.6953,  0.6514,  0.5666]],\n",
      "\n",
      "         [[-0.9614, -1.1435, -1.1997,  ..., -1.3650, -1.2284, -0.9981],\n",
      "          [-1.1165, -1.2472, -1.2656,  ..., -1.4737, -1.3994, -1.2388],\n",
      "          [-1.1898, -1.3062, -1.3292,  ..., -1.4876, -1.4528, -1.3549],\n",
      "          ...,\n",
      "          [-1.0376, -1.2062, -1.3620,  ..., -0.8564, -0.7778, -0.6987],\n",
      "          [-0.9330, -1.1025, -1.2279,  ..., -0.7634, -0.7179, -0.6418],\n",
      "          [-0.8037, -0.9902, -1.1030,  ..., -0.6953, -0.6514, -0.5667]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9744,  1.2167,  1.3807,  ...,  1.5848,  1.3949,  1.1208],\n",
      "          [ 1.1986,  1.3852,  1.4884,  ...,  1.7068,  1.5912,  1.3982],\n",
      "          [ 1.3166,  1.4531,  1.5235,  ...,  1.7779,  1.6976,  1.5596],\n",
      "          ...,\n",
      "          [ 0.9811,  1.0891,  1.1752,  ...,  1.0877,  0.9344,  0.8236],\n",
      "          [ 0.8841,  1.0014,  1.0611,  ...,  0.9908,  0.8738,  0.7656],\n",
      "          [ 0.7636,  0.9106,  0.9762,  ...,  0.9138,  0.8186,  0.6898]],\n",
      "\n",
      "         [[-0.9744, -1.2167, -1.3807,  ..., -1.5848, -1.3949, -1.1208],\n",
      "          [-1.1986, -1.3851, -1.4883,  ..., -1.7066, -1.5911, -1.3982],\n",
      "          [-1.3166, -1.4530, -1.5234,  ..., -1.7777, -1.6975, -1.5596],\n",
      "          ...,\n",
      "          [-0.9811, -1.0890, -1.1751,  ..., -1.0876, -0.9343, -0.8236],\n",
      "          [-0.8841, -1.0013, -1.0610,  ..., -0.9907, -0.8737, -0.7656],\n",
      "          [-0.7637, -0.9106, -0.9762,  ..., -0.9138, -0.8187, -0.6899]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0390,  1.3078,  1.5049,  ...,  1.0998,  0.9425,  0.7598],\n",
      "          [ 1.2765,  1.4807,  1.6128,  ...,  1.2921,  1.1038,  0.9403],\n",
      "          [ 1.4106,  1.5649,  1.6683,  ...,  1.3886,  1.1561,  1.0345],\n",
      "          ...,\n",
      "          [ 0.8317,  0.9533,  1.0901,  ...,  1.6824,  1.4727,  1.3222],\n",
      "          [ 0.7698,  0.8919,  0.9864,  ...,  1.4115,  1.2704,  1.1396],\n",
      "          [ 0.6963,  0.8389,  0.9191,  ...,  1.2473,  1.1122,  0.9315]],\n",
      "\n",
      "         [[-1.0390, -1.3078, -1.5049,  ..., -1.0998, -0.9425, -0.7598],\n",
      "          [-1.2765, -1.4806, -1.6126,  ..., -1.2920, -1.1037, -0.9403],\n",
      "          [-1.4106, -1.5647, -1.6681,  ..., -1.3884, -1.1560, -1.0345],\n",
      "          ...,\n",
      "          [-0.8317, -0.9532, -1.0899,  ..., -1.6823, -1.4725, -1.3222],\n",
      "          [-0.7698, -0.8919, -0.9863,  ..., -1.4113, -1.2703, -1.1396],\n",
      "          [-0.6964, -0.8390, -0.9191,  ..., -1.2473, -1.1122, -0.9315]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.1357,  1.4378,  1.7013,  ...,  1.7015,  1.4262,  1.1327],\n",
      "          [ 1.4108,  1.6638,  1.9399,  ...,  1.9203,  1.6300,  1.4124],\n",
      "          [ 1.6181,  1.8583,  2.1836,  ...,  2.1383,  1.7900,  1.6059],\n",
      "          ...,\n",
      "          [ 1.3047,  1.5198,  1.7654,  ...,  1.4846,  1.3400,  1.2333],\n",
      "          [ 1.1217,  1.3083,  1.4781,  ...,  1.2655,  1.1698,  1.0680],\n",
      "          [ 0.9353,  1.1620,  1.3164,  ...,  1.1326,  1.0320,  0.8767]],\n",
      "\n",
      "         [[-1.1358, -1.4377, -1.7012,  ..., -1.7014, -1.4262, -1.1328],\n",
      "          [-1.4108, -1.6637, -1.9398,  ..., -1.9202, -1.6299, -1.4123],\n",
      "          [-1.6180, -1.8582, -2.1834,  ..., -2.1381, -1.7899, -1.6059],\n",
      "          ...,\n",
      "          [-1.3047, -1.5196, -1.7652,  ..., -1.4844, -1.3399, -1.2333],\n",
      "          [-1.1217, -1.3082, -1.4780,  ..., -1.2654, -1.1697, -1.0680],\n",
      "          [-0.9354, -1.1619, -1.3164,  ..., -1.1326, -1.0320, -0.8768]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0920,  1.3940,  1.6433,  ...,  1.1853,  1.0312,  0.8411],\n",
      "          [ 1.3579,  1.6215,  1.8784,  ...,  1.3572,  1.1911,  1.0435],\n",
      "          [ 1.5474,  1.7896,  2.0860,  ...,  1.4330,  1.2388,  1.1503],\n",
      "          ...,\n",
      "          [ 1.0046,  1.1946,  1.3816,  ...,  1.5019,  1.3295,  1.1964],\n",
      "          [ 0.8653,  1.0251,  1.1354,  ...,  1.2884,  1.1690,  1.0424],\n",
      "          [ 0.7272,  0.8933,  0.9817,  ...,  1.1418,  1.0225,  0.8552]],\n",
      "\n",
      "         [[-1.0921, -1.3940, -1.6433,  ..., -1.1853, -1.0312, -0.8412],\n",
      "          [-1.3579, -1.6213, -1.8782,  ..., -1.3570, -1.1910, -1.0435],\n",
      "          [-1.5474, -1.7895, -2.0858,  ..., -1.4328, -1.2387, -1.1503],\n",
      "          ...,\n",
      "          [-1.0046, -1.1945, -1.3814,  ..., -1.5017, -1.3293, -1.1964],\n",
      "          [-0.8653, -1.0250, -1.1352,  ..., -1.2882, -1.1689, -1.0424],\n",
      "          [-0.7272, -0.8933, -0.9817,  ..., -1.1418, -1.0225, -0.8553]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7642,  0.9570,  1.0704,  ...,  1.1101,  0.9606,  0.7765],\n",
      "          [ 0.9495,  1.1455,  1.2572,  ...,  1.2940,  1.1276,  0.9614],\n",
      "          [ 1.0474,  1.2155,  1.3581,  ...,  1.3708,  1.1804,  1.0593],\n",
      "          ...,\n",
      "          [ 1.1768,  1.3824,  1.5935,  ...,  1.7612,  1.5612,  1.4101],\n",
      "          [ 1.0127,  1.1860,  1.3206,  ...,  1.5019,  1.3637,  1.2249],\n",
      "          [ 0.8427,  1.0399,  1.1607,  ...,  1.3587,  1.2096,  1.0061]],\n",
      "\n",
      "         [[-0.7642, -0.9570, -1.0704,  ..., -1.1100, -0.9606, -0.7765],\n",
      "          [-0.9495, -1.1454, -1.2570,  ..., -1.2939, -1.1275, -0.9614],\n",
      "          [-1.0474, -1.2154, -1.3580,  ..., -1.3707, -1.1802, -1.0593],\n",
      "          ...,\n",
      "          [-1.1768, -1.3822, -1.5934,  ..., -1.7610, -1.5610, -1.4101],\n",
      "          [-1.0127, -1.1859, -1.3205,  ..., -1.5017, -1.3636, -1.2248],\n",
      "          [-0.8427, -1.0399, -1.1606,  ..., -1.3587, -1.2096, -1.0062]]]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\skimage\\io\\_io.py:141: UserWarning: I:\\NewYorkCity_sidewalks\\Inferenced\\0.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "Lossy conversion from int64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#img_list = [r'I:\\NewYorkCity_sidewalks\\Images\\68.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\69.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\77.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\78.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\198.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\199.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\217.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\218.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\318.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\394.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\395.TIF']\n",
    "#saved_path = r'I:\\NewYorkCity_sidewalks\\Inferenced'\n",
    "#img_list = [r'I:\\NewYorkCity_sidewalks\\Images\\17.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\30.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\44.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\60.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\72.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\85.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\96.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\111.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\126.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\137.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\155.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\165.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\176.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\186.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\198.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\211.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\221.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\231.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\241.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\251.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\262.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\272.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\282.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\292.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\303.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\313.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\327.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\339.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\353.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\366.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\378.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\390.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\401.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\412.TIF', r'I:\\NewYorkCity_sidewalks\\Images\\426.TIF']\n",
    "img_list = glob(r'I:\\NewYorkCity_sidewalks\\Images\\*.TIF')[:1]\n",
    "inference(net, img_list, saved_path=saved_path)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the network\n",
    "\n",
    "Now that the training has ended, we can load the final weights and test the network using a reasonable stride, e.g. half or a quarter of the window size. Inference time depends on the chosen stride, e.g. a step size of 32 (75% overlap) will take ~15 minutes, but no overlap will take only one minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = r'Unet_4layer_final_20190911.pth'\n",
    "saved_path = r'I:\\NewYorkCity_sidewalks\\test_results'\n",
    "prefix = os.path.basename(model_path)\n",
    "net.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "In RendererAgg: Out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m   2054\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m                         \u001b[0mdryrun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   2057\u001b[0m                     \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bbox_extra_artists\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m             \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mDraw\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \"\"\"\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mget_renderer\u001b[1;34m(self, cleared)\u001b[0m\n\u001b[0;32m    397\u001b[0m                           and getattr(self, \"_lastKey\", None) == key)\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreuse_renderer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lastKey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcleared\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, width, height, dpi)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_renderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_RendererAgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filter_renderers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: In RendererAgg: Out of memory"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 18432x18432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from int64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result was saved: 292\n",
      "Processing image: 303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eefebfe79fc4ae48990ba6873391b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12324), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, all_preds, all_gts = test(net, test_ids, all=True, stride=32, prefix=prefix, saved_path=saved_path)\n",
    "\n",
    "# for p, id_ in zip(all_preds, test_ids):\n",
    "#     img = convert_to_color(p)\n",
    "#     #img = p\n",
    "#     plt.imshow(img) and plt.show()\n",
    "#     io.imsave(os.path.join(saved_path, prefix + '_{}_color.png'.format(id_)), img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results\n",
    "\n",
    "We can visualize and save the resulting tiles for qualitative assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imsave('./{}.png'.format(id_), img)\n",
    "# for p, id_ in zip(all_preds, test_ids):\n",
    "#     img = convert_to_color(p)\n",
    "#     plt.imshow(img) and plt.show()\n",
    "#     io.imsave('./{}.png'.format(id_), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'D:\\Dataset\\DX\\segnet_final_40tiles_76.png', 0) \n",
    "kernel = np.ones((5,5), np.uint8) \n",
    "  \n",
    "# The first parameter is the original image, \n",
    "# kernel is the matrix with which image is  \n",
    "# convolved and third parameter is the number  \n",
    "# of iterations, which will determine how much  \n",
    "# you want to erode/dilate a given image.  \n",
    "img_erosion = cv2.erode(img, kernel, iterations=1) \n",
    "img_dilation = cv2.dilate(img, kernel, iterations=1) \n",
    "  \n",
    "cv2.imshow('Input', img) \n",
    "cv2.imshow('Erosion', img_erosion) \n",
    "cv2.imshow('Dilation', img_dilation) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob(r'D:\\Dataset\\DX\\t\\*.tif')\n",
    "for file in all_files:\n",
    "    new_name = file.replace('.png', '_color')\n",
    "    new_name = new_name.replace('.tif', '.png')\n",
    "    p = io.imread(file)\n",
    "    img = convert_to_color(p)\n",
    "    io.imsave(new_name, img)\n",
    "    # for p, id_ in zip(all_preds, test_ids):\n",
    "    #     img = convert_to_color(p)\n",
    "    #     plt.imshow(img) and plt.show()\n",
    "    #     io.imsave('./{}.png'.format(id_), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = Variable(torch.randn(10))\n",
    "log_prob = F.softmax(logits, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9142, -1.2398, -0.9730, -0.3966, -0.3067, -0.9201,  0.6701, -0.7556,\n",
       "         1.3324, -0.4429])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0412, 0.0297, 0.0388, 0.0691, 0.0756, 0.0409, 0.2008, 0.0483, 0.3895,\n",
       "        0.0660])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
